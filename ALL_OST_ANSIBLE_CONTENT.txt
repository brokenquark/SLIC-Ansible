Total files to analyze: 1101
----------------------------------------------------------------------------------------------------
=========================:::1:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-container-registry/vars/main.yml
**********
_full_docker_options: "{% if container_registry_selinux|bool %}--selinux-enabled {% endif %}{% if container_registry_additional_sockets | length > 0 %}-H unix:///run/docker.sock {% for soc in container_registry_additional_sockets %}-H unix://{{ soc }}{% if not loop.last %} {% endif %}{% endfor %}{% endif %} {{ container_registry_docker_options }}"

**********
DECISION===>: PASS
**********
=========================:::1:::END!!!=========================
=========================:::2:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-container-registry/tasks/docker-distribution.yml
**********
# tasks file for ansible-role-container-registry

- name: ensure docker-distribution is installed
  package:
    name: docker-distribution
    state: present

- name: manage /etc/docker-distribution/registry/config.yml
  template:
    src: docker-distribution-config.yml.j2
    dest: /etc/docker-distribution/registry/config.yml
  notify: restart docker-distribution service

- name: force systemd to reread configs
  meta: flush_handlers

- name: enable and start docker-distribution
  systemd:
    enabled: true
    state: started
    name: docker-distribution

**********
DECISION===>: PASS
**********
=========================:::2:::END!!!=========================
=========================:::3:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-container-registry/tasks/docker.yml
**********
# tasks file for ansible-role-container-registry

# NOTE(aschultz): LP#1750194 - need to set ip_forward before docker starts
# so lets set it before we install the package if we're managing it.
- name: enable net.ipv4.ip_forward
  sysctl:
    name: net.ipv4.ip_forward
    value: 1
    sysctl_set: yes
    state: present
    reload: yes

# NOTE(aschultz): LP#1765121 - need to check that we don't have any ftype=0
# volumes because other wise docker is very unhappy
- name: Check if there are XFS volumes with ftype=0
  become: true
  shell: |
    for dev in $(df -h | grep '/dev/' | grep -v 'tmp' | cut -d' ' -f1)
    do
      parseftype=$(xfs_info $dev | grep ftype=0);
      if [[ ! -z "$parseftype" ]]; then
        ftype="ftype=0";
        break;
      fi
    done
    echo $ftype;
  register: ftype
  changed_when: false

- name: Check ftype
  fail:
    msg: >
      XFS volumes formatted using ftype=0 are incompatible
      with the docker overlayfs driver.
  when:
    - ftype.stdout == 'ftype=0'

- name: ensure docker is installed
  package:
    name: docker
    state: present

- name: manage /etc/systemd/system/docker.service.d
  file:
    path: /etc/systemd/system/docker.service.d
    state: directory
  when: ansible_service_mgr == 'systemd'

- name: unset mountflags
  ini_file:
    path: /etc/systemd/system/docker.service.d/99-unset-mountflags.conf
    section: Service
    option: MountFlags
    value: ""
    create: yes
  notify: restart docker service
  when: ansible_service_mgr == 'systemd'

- name: configure OPTIONS in /etc/sysconfig/docker
  lineinfile:
    path: /etc/sysconfig/docker
    regexp: '^OPTIONS='
    line: "OPTIONS='{{ _full_docker_options }}'"
    create: yes
  notify: restart docker service

- name: configure INSECURE_REGISTRY in /etc/sysconfig/docker
  lineinfile:
    path: /etc/sysconfig/docker
    regexp: '^INSECURE_REGISTRY='
    line: "INSECURE_REGISTRY='{{ registry_flags }}'"
  when: container_registry_insecure_registries | length > 0
  notify: restart docker service
  vars:
    registry_flags: "{% for reg in container_registry_insecure_registries %}--insecure-registry {{ reg }}{% if not loop.last %} {% endif %}{% endfor %}"

- name: Create additional socket directories
  file:
    path: "{{ item | dirname }}"
    state: directory
  notify: restart docker service
  with_items: "{{ container_registry_additional_sockets }}"
  when: container_registry_additional_sockets | length > 0

- name: manage /etc/docker/daemon.json
  template:
    src: docker-daemon.json.j2
    dest: /etc/docker/daemon.json
  notify: restart docker service

- name: configure DOCKER_STORAGE_OPTIONS in /etc/sysconfig/docker-storage
  lineinfile:
    path: /etc/sysconfig/docker-storage
    regexp: '^DOCKER_STORAGE_OPTIONS='
    line: "DOCKER_STORAGE_OPTIONS=' {{ container_registry_storage_options }}'"
    create: yes
  when: container_registry_storage_options != ""
  notify: restart docker service

- name: configure DOCKER_NETWORK_OPTIONS in /etc/sysconfig/docker-network
  lineinfile:
    path: /etc/sysconfig/docker-network
    regexp: '^DOCKER_NETWORK_OPTIONS='
    line: "DOCKER_NETWORK_OPTIONS=' {{ container_registry_network_options }}'"
    create: yes
  when: container_registry_storage_options != ""
  notify: restart docker service

- name: ensure docker group exists
  group:
    name: docker
    state: present

- name: add deployment user to docker group
  user:
    name: "{{ container_registry_deployment_user }}"
    groups: docker
    append: yes
  when: container_registry_deployment_user != ""

- name: force systemd to reread configs
  meta: flush_handlers

- name: enable and start docker
  systemd:
    enabled: true
    state: started
    name: docker
  when: ansible_service_mgr == 'systemd'

**********
DECISION===>: PASS
**********
=========================:::3:::END!!!=========================
=========================:::4:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-container-registry/tasks/main.yml
**********
# tasks file for ansible-role-container-registry

- include_tasks: docker.yml
  when: container_registry_deploy_docker|bool

- include_tasks: docker-distribution.yml
  when: container_registry_deploy_docker_distribution|bool

**********
DECISION===>: PASS
**********
=========================:::4:::END!!!=========================
=========================:::5:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-container-registry/tasks/docker-update.yml
**********
# tasks file for ansible-role-container-registry
# the tasks will ensure docker is up to date.

- name: set package manager to yum
  set_fact:
    registry_pkg_manager: yum
  when:
    - ansible_os_family == 'RedHat'
    - ansible_distribution_major_version|int == 7

- name: set package manager to dnf
  set_fact:
    registry_pkg_manager: dnf
  when: (ansible_os_family == 'RedHat' and ansible_distribution_major_version|int > 7) or (ansible_distribution == 'Fedora')


- name: can docker be updated
  shell: "{{ registry_pkg_manager }} check-update docker"
  register: docker_check_update
  failed_when: docker_check_update.rc not in [0, 100]
  changed_when: docker_check_update.rc == 100

- name: set docker_rpm_needs_update fact
  set_fact: docker_rpm_needs_update={{ docker_check_update.rc == 100 }}

- name: stop all containers before update
  # xargs is preferable to docker stop $(docker ps -q) as that might generate a
  # a too long command line
  shell: docker ps -q | xargs --no-run-if-empty -n1 docker stop
  when: docker_rpm_needs_update

- name: ensure docker is installed
  package:
    name: docker
    state: present
  when: docker_rpm_needs_update

- name: update the docker package (yum)
  yum: name=docker state=latest update_cache=yes # cache for https://bugs.launchpad.net/tripleo/+bug/1703830
  notify: restart docker service
  when:
    - docker_rpm_needs_update
    - registry_pkg_manager == 'yum'

- name: update the docker package (dnf)
  dnf: name=docker state=latest
  notify: restart docker service
  when:
    - docker_rpm_needs_update
    - registry_pkg_manager == 'dnf'


**********
DECISION===>: suspicious comment
**********
=========================:::5:::END!!!=========================
=========================:::6:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-container-registry/tests/test.yml
**********
- hosts: localhost
  become: true
  roles:
    - container-registry

**********
DECISION===>: PASS
**********
=========================:::6:::END!!!=========================
=========================:::7:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-container-registry/meta/main.yml
**********
galaxy_info:
  author: Emilien Macchi
  description: A role to deploy a container registry.

  license: Apache 2.0

  min_ansible_version: 2.4

  platforms:
    - name: EL
      versions:
        - 7

  galaxy_tags:
    - docker
    - registry

dependencies: []

**********
DECISION===>: PASS
**********
=========================:::7:::END!!!=========================
=========================:::8:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-container-registry/defaults/main.yml
**********
# defaults file for ansible-role-container-registry

container_registry_debug: false
container_registry_deploy_docker: true
container_registry_deploy_docker_distribution: true
container_registry_deployment_user: centos
container_registry_docker_options: '--log-driver=journald --signature-verification=false --iptables=false --live-restore'
container_registry_insecure_registries: []
container_registry_network_options: ''
container_registry_host: localhost
container_registry_port: 8787
container_registry_mirror: ''
container_registry_storage_options: '-s overlay2'
container_registry_selinux: false
container_registry_additional_sockets: []

**********
DECISION===>: PASS, (Although there is a hardcoded secret)
**********
=========================:::8:::END!!!=========================
=========================:::9:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-container-registry/zuul.d/layout.yaml
**********
- project:
    templates:
      - tripleo-multinode-container-minimal
    check:
      jobs:
        - openstack-tox-linters
    gate:
      jobs:
        - openstack-tox-linters
    post:
      jobs:
        - publish-openstack-python-branch-tarball

**********
DECISION===>: PASS
**********
=========================:::9:::END!!!=========================
=========================:::10:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-container-registry/handlers/main.yml
**********
---
- name: restart docker
  command: /bin/true
  notify:
    - Docker | reload systemd
    - Docker | reload docker
    - Docker | pause while Docker restarts
    - Docker | wait for docker
  listen: "restart docker service"

- name: restart docker-distribution
  command: /bin/true
  notify:
    - Docker | reload systemd
    - Docker | reload docker-distribution
    - Docker | wait for registry
  listen: "restart docker-distribution service"

- name: Docker | reload systemd
  systemd:
    daemon_reload: yes
  when: ansible_service_mgr == 'systemd'

- name: Docker | reload docker
  service:
    name: docker
    state: restarted

- name: Docker | pause while Docker restarts
  pause:
    seconds: 10
    prompt: "Waiting for docker restart"

- name: Docker | wait for docker
  command: /usr/bin/docker images
  register: docker_ready
  retries: 10
  delay: 5
  until: docker_ready.rc == 0

- name: Docker | reload docker-distribution
  service:
    name: docker-distribution
    state: restarted

# NOTE(bogdando): import caveates https://github.com/ansible/ansible/issues/42621
- name: Docker | wait for registry
  uri:
    # Just checking API version should be fine
    # https://docs.docker.com/registry/spec/api/#api-version-check
    url: "http://{{ container_registry_host }}:{{ container_registry_port }}/v2/"
    return_content: yes
  register: registry_status
  retries: 10
  delay: 5
  until: "registry_status.status|int == 200 and 'OK' in registry_status.msg"

**********
DECISION===>: Using HTTP without TLS, Suspicious Comments
**********
=========================:::10:::END!!!=========================
=========================:::11:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-python_venv_build/vars/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

_venv_build_base_distro_package_list:
  debian:
    - cmake
    - gcc
    - "{{ (venv_python_executable == 'python2') | ternary('pkg-config', 'python3-pkgconfig') }}"
    - "{{ (venv_python_executable == 'python2') | ternary('python-dev', 'python3-dev') }}"
  redhat:
    - autoconf
    - cmake
    - gcc
    - gcc-c++
    - "{{ (venv_python_executable == 'python2') | ternary('python2-devel', 'python3-devel') }}"
  suse:
    - autoconf
    - cmake
    - gcc
    - gcc-c++
    - "{{ (venv_python_executable == 'python2') | ternary('python-devel', 'python3-devel') }}"

**********
DECISION===>: PASS
**********
=========================:::11:::END!!!=========================
=========================:::12:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-python_venv_build/tasks/python_venv_preflight.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Verify that venv_install_destination_path has been provided
  fail:
    msg: |
      The variable venv_install_destination_path is required and
      has not been set.
  when:
    - venv_install_destination_path is not defined

- name: Collect the version of virtualenv
  shell: |
    virtualenv --version 2>/dev/null || echo 'none'
  args:
    executable: /bin/bash
  changed_when: false
  failed_when: false
  register: _virtualenv_version

- name: Fail when required virtualenv version is not present
  fail:
    msg: >-
      The required virtualenv version is not present.
      The minimum version of 1.10 is required, but
      {{ _virtualenv_version.stdout }} is installed.
  when:
    - ((_virtualenv_version.stdout | trim) == 'none') or
      ((_virtualenv_version.stdout | trim) is version_compare('1.10', '<'))

- name: Set extra virtualenv parameters
  set_fact:
    _venv_create_extra_options: >-
      {{ ((_virtualenv_version.stdout | trim) is version_compare('14.0.0', '<')) | ternary('--never-download', '--no-download') }}
      {{ ((_virtualenv_version.stdout | trim) is version_compare('1.7.0', '<')) | ternary('--no-site-packages', '') }}

**********
DECISION===>: PASS
**********
=========================:::12:::END!!!=========================
=========================:::13:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-python_venv_build/tasks/python_venv_wheel_build.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Build the wheels on the build host
  delegate_to: "{{ venv_build_host }}"
  become: "{{ venv_build_host == 'localhost' }}"
  when:
    - venv_build_host != inventory_hostname
  block:
    - name: Install distro packages for wheel build
      package:
        name: "{{ (venv_build_base_distro_package_list + venv_build_distro_package_list) | unique }}"
        state: "{{ venv_distro_package_state }}"
        update_cache: "{{ (ansible_pkg_mgr in ['apt', 'zypper']) | ternary('yes', omit) }}"
        cache_valid_time: "{{ (ansible_pkg_mgr == 'apt') | ternary(venv_distro_cache_valid_time, omit) }}"
      when:
        - (venv_build_distro_package_list | length > 0) or
          (venv_install_distro_package_list | length > 0)
      register: _install_build_distro_packages
      until: _install_build_distro_packages is success
      retries: 5
      delay: 2

    - name: Ensure a fresh venv_build_host_venv_path if venv_rebuild is enabled
      file:
        path: "{{ venv_build_host_venv_path }}"
        state: absent
      when:
        - venv_rebuild | bool

    - name: Create wheel directory on the build host
      file:
        path: "{{ venv_build_host_wheel_path }}"
        state: directory

    # NOTE(odyssey4me):
    # Not using --always-copy for CentOS/SuSE due to
    # https://github.com/pypa/virtualenv/issues/565
    - name: Create the wheel build virtualenv (if it does not exist)
      command: >-
        virtualenv
        {{ _venv_create_extra_options }}
        --python={{ venv_python_executable }}
        {{ (ansible_pkg_mgr == 'apt') | ternary('--always-copy', '') }}
        {{ venv_build_host_venv_path }}
      args:
        creates: "{{ venv_build_host_venv_path }}/bin/activate"

    - name: Upgrade the wheel build virtualenv pip/setuptools/wheel to the versions we want
      pip:
        name:
          - pip
          - setuptools
          - wheel
        state: "{{ venv_pip_package_state }}"
        virtualenv: "{{ venv_build_host_venv_path }}"
        extra_args: >-
          --find-links {{ venv_build_host_wheel_path }}/
          --log /var/log/python_venv_build.log
          {{ venv_pip_install_args }}
      register: _update_virtualenv_packages
      until: _update_virtualenv_packages is success
      retries: 5
      delay: 2

    - name: Build wheels for the packages to be installed into the venv
      command: >-
        {{  venv_build_host_venv_path }}/bin/pip wheel
        --wheel-dir {{ venv_build_host_wheel_path }}/
        --find-links {{ venv_build_host_wheel_path }}/
        --log /var/log/python_wheel_build.log
        {{ venv_pip_install_args }}
        {{ (venv_default_pip_packages + venv_pip_packages) | join(' ') }}
      register: _build_python_wheels
      until: _build_python_wheels is success
      changed_when: (_build_python_wheels.stdout.find('Successfully built') != -1) or
                    (_build_python_wheels.stdout | regex_search('Saved \S*\.whl'))
      retries: 5
      delay: 2

**********
DECISION===>: PASS
**********
=========================:::13:::END!!!=========================
=========================:::14:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-python_venv_build/tasks/python_venv_set_facts.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Ensure local facts folder exists
  file:
    path: /etc/ansible/facts.d
    state: directory

- name: Record the necessary facts
  ini_file:
    dest: "/etc/ansible/facts.d/{{ venv_facts_dest }}.fact"
    section: "{{ item.section }}"
    option: "{{ item.option }}"
    value: "{{ item.value }}"
  with_items: "{{ venv_facts_when_changed }}"
  when:
    - venv_facts_when_changed != []
    - (_install_venv_pip_packages is defined and
       _install_venv_pip_packages is mapping and
       _install_venv_pip_packages is changed)

**********
DECISION===>: PASS
**********
=========================:::14:::END!!!=========================
=========================:::15:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-python_venv_build/tasks/python_venv_install.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# TODO(odyssey4me):
# Set a fact for the selective inclusion of the build package list.
# Perhaps do this if the distro/architecture of the target host differs
# from the build host.

- name: Install distro packages for venv build
  package:
    name: "{{ (venv_build_host != inventory_hostname) | ternary(venv_install_distro_package_list, (venv_build_base_distro_package_list + venv_build_distro_package_list + venv_install_distro_package_list) | unique) }}"
    state: "{{ venv_distro_package_state }}"
    update_cache: "{{ (ansible_pkg_mgr in ['apt', 'zypper']) | ternary('yes', omit) }}"
    cache_valid_time: "{{ (ansible_pkg_mgr == 'apt') | ternary(venv_distro_cache_valid_time, omit) }}"
  when:
    - (venv_build_distro_package_list | length > 0) or
      (venv_install_distro_package_list | length > 0)
  register: _install_distro_packages
  until: _install_distro_packages is success
  retries: 5
  delay: 2

- name: Ensure a fresh venv_install_destination_path if venv_rebuild is enabled
  file:
    path: "{{ venv_install_destination_path }}"
    state: absent
  when:
    - venv_rebuild | bool

# NOTE(odyssey4me):
# Not using --always-copy for CentOS/SuSE due to
# https://github.com/pypa/virtualenv/issues/565
- name: Create the virtualenv (if it does not exist)
  command: >-
    virtualenv
    {{ _venv_create_extra_options }}
    --python={{ venv_python_executable }}
    {{ (ansible_pkg_mgr == 'apt') | ternary('--always-copy', '') }}
    {{ venv_install_destination_path }}
  args:
    creates: "{{ venv_install_destination_path }}/bin/activate"

- name: Upgrade pip/setuptools/wheel to the versions we want
  pip:
    name:
      - pip
      - setuptools
      - wheel
    state: "{{ venv_pip_package_state }}"
    virtualenv: "{{ venv_install_destination_path }}"
    extra_args: >-
      --log /var/log/python_venv_build.log
      {{ venv_pip_install_args }}
  register: _update_virtualenv_packages
  until: _update_virtualenv_packages is success
  retries: 5
  delay: 2

- name: Install python packages into the venv
  pip:
    name: "{{ venv_default_pip_packages + venv_pip_packages }}"
    state: "{{ venv_pip_package_state }}"
    virtualenv: "{{ venv_install_destination_path }}"
    extra_args: >-
      --pre
      --log /var/log/python_venv_build.log
      {{ venv_pip_install_args }}
  register: _install_venv_pip_packages
  until: _install_venv_pip_packages is success
  retries: 5
  delay: 2
  notify:
    - venv changed

**********
DECISION===>: PASS
**********
=========================:::15:::END!!!=========================
=========================:::16:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-python_venv_build/tasks/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- import_tasks: "python_venv_preflight.yml"
  tags:
    - always

- import_tasks: "python_venv_wheel_build.yml"
  run_once: yes
  tags:
    - build

- import_tasks: "python_venv_install.yml"
  tags:
    - install

- import_tasks: "python_venv_set_facts.yml"
  tags:
    - install

**********
DECISION===>: PASS
**********
=========================:::16:::END!!!=========================
=========================:::17:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-python_venv_build/tests/test.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Prepare the host/containers
  import_playbook: common/test-setup-host.yml

- name: Prepare web server on localhost to serve python packages
  hosts: localhost
  connection: local
  become: yes
  any_errors_fatal: yes
  tasks:
    - name: Set venv_build_archive_path and venv_install_source_path
      set_fact:
        venv_build_host_wheel_path: >-
          {%- if ansible_distribution == "Ubuntu" %}
          {%-   set _path = "/var/www/html" %}
          {%- elif ansible_distribution == "CentOS" %}
          {%-   set _path = "/usr/share/nginx/html" %}
          {%- else %}
          {%-   set _path = "/srv/www/htdocs" %}
          {%- endif %}
          {{- _path }}

    - name: Install EPEL gpg keys
      rpm_key:
        key: "http://dl.fedoraproject.org/pub/epel/RPM-GPG-KEY-EPEL-7"
        state: present
      when:
        - ansible_pkg_mgr in ['yum', 'dnf']
      register: _add_yum_keys
      until: _add_yum_keys  is success
      retries: 5
      delay: 2

    - name: Install the EPEL repository
      yum_repository:
        name: epel-nginx
        baseurl: "{{ (centos_epel_mirror | default ('http://download.fedoraproject.org/pub/epel')) ~ '/' ~ ansible_distribution_major_version ~ '/' ~ ansible_architecture }}"
        description: 'Extra Packages for Enterprise Linux 7 - $basearch'
        gpgcheck: yes
        enabled: yes
        state: present
        includepkgs: 'nginx*'
      when:
        - ansible_pkg_mgr in ['yum', 'dnf']
      register: install_epel_repo
      until: install_epel_repo  is success
      retries: 5
      delay: 2

    - name: Install distro packages
      package:
        name: "nginx"
        update_cache: "{{ (ansible_pkg_mgr in ['apt', 'zypper']) | ternary('yes', omit) }}"
      register: install
      until: install  is success
      retries: 5
      delay: 2

    - name: Enable and start nginx
      service:
        name: nginx
        enabled: yes
        daemon_reload: yes
        state: restarted

- name: Verify not using a build host
  hosts: "container1"
  remote_user: root
  any_errors_fatal: yes
  vars:
    venv_pip_packages:
      - "Jinja2==2.10"
    venv_install_destination_path: "/openstack/venvs/test-venv"
  tasks:

    - name: Execute venv install
      include_role:
        name: "python_venv_build"
        private: yes
      vars:
        venv_facts_when_changed:
          - section: "{{ inventory_hostname }}"
            option: "test"
            value: True

    - name: refresh local facts
      setup:
        filter: ansible_local
        gather_subset: "!all"

    - name: Show the ansible_local facts
      debug:
        var: ansible_local

    - name: Verify that the facts were set
      assert:
        that:
          - ansible_local['openstack_ansible'][inventory_hostname]['test'] | bool

    - name: Find files/folders on targets
      find:
        file_type: directory
        get_checksum: no
        recurse: no
        paths:
          - "{{ venv_install_destination_path | dirname }}"
      register: _target_folders

    - name: Compile the folder list from the targets
      set_fact:
        _target_folder_list: "{{ _target_folders['files'] | map(attribute='path') | list }}"

    - name: Show the files/folder from the targets
      debug:
        var: _target_folder_list

    - name: Verify the folder list from the targets
      assert:
        that:
          - "{{ venv_install_destination_path in _target_folder_list }}"

- name: Verify using a build host
  hosts: "container2:container3"
  remote_user: root
  any_errors_fatal: yes
  vars:
    venv_default_pip_packages:
      - "elasticsearch>=6.0.0,<7.0.0"
    venv_pip_packages:
      - "Jinja2==2.10"
    venv_install_destination_path: "/openstack/venvs/test-venv"
    venv_pip_install_args: >-
      --find-links http://{{ hostvars['localhost'].ansible_default_ipv4.address }}
      --trusted-host {{ hostvars['localhost'].ansible_default_ipv4.address }}
    venv_build_host: localhost
    venv_build_host_wheel_path: "{{ hostvars['localhost']['venv_build_host_wheel_path'] }}"
  tasks:

    - name: Execute venv install
      include_role:
        name: "python_venv_build"
        private: yes
      vars:
        venv_facts_when_changed:
          - section: "{{ inventory_hostname }}"
            option: "test"
            value: True

    - name: refresh local facts
      setup:
        filter: ansible_local
        gather_subset: "!all"

    - name: Show the ansible_local facts
      debug:
        var: ansible_local

    - name: Verify that the facts were set
      assert:
        that:
          - ansible_local['openstack_ansible'][inventory_hostname]['test'] | bool

    - name: Find files/folders on targets
      find:
        file_type: directory
        get_checksum: no
        recurse: no
        paths:
          - "{{ venv_install_destination_path | dirname }}"
      register: _target_folders

    - name: Compile the folder list from the targets
      set_fact:
        _target_folder_list: "{{ _target_folders['files'] | map(attribute='path') | list }}"

    - name: Show the files/folder from the targets
      debug:
        var: _target_folder_list

    - name: Verify the folder list from the targets
      assert:
        that:
          - "{{ venv_install_destination_path in _target_folder_list }}"

**********
DECISION===>: Use of HTTP without TLS, Hardcoded secret, Not Using Integrity Check
**********
=========================:::17:::END!!!=========================
=========================:::18:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-python_venv_build/tests/ansible-role-requirements.yml
**********
- name: apt_package_pinning
  src: https://git.openstack.org/openstack/openstack-ansible-apt_package_pinning
  scm: git
  version: master
- name: pip_install
  src: https://git.openstack.org/openstack/openstack-ansible-pip_install
  scm: git
  version: master
- name: openstack_hosts
  src: https://git.openstack.org/openstack/openstack-ansible-openstack_hosts
  scm: git
  version: master
- name: lxc_hosts
  src: https://git.openstack.org/openstack/openstack-ansible-lxc_hosts
  scm: git
  version: master
- name: lxc_container_create
  src: https://git.openstack.org/openstack/openstack-ansible-lxc_container_create
  scm: git
  version: master

**********
DECISION===>: PASS
**********
=========================:::18:::END!!!=========================
=========================:::19:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-python_venv_build/tests/group_vars/all_containers.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

container_networks:
  management_address:
    address: "{{ ansible_host }}"
    bridge: "br-mgmt"
    interface: "eth1"
    netmask: "255.255.252.0"
    type: "veth"
physical_host: localhost
properties:
  service_name: "{{ inventory_hostname }}"

# NOTE(cloudnull): The lxc-openstack AA profile for is used to ensure general
#                  container functionality typical to the integrated build.
lxc2_container_config_list:
  - 'lxc.aa_profile=lxc-openstack'

lxc3_container_config_list:
  - 'lxc.apparmor.profile=lxc-openstack'

lxc_container_config_list: "{{ lookup('pipe', 'lxc-info --version || echo 2.0.0') is version_compare('3.0.0', 'lt') | ternary(lxc2_container_config_list, lxc3_container_config_list) }}"

**********
DECISION===>: PASS
**********
=========================:::19:::END!!!=========================
=========================:::20:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-python_venv_build/tests/host_vars/container1.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

ansible_host: 10.1.0.2
ansible_become: True
ansible_user: root
container_name: container1

**********
DECISION===>: Hardcoded Secret
**********
=========================:::20:::END!!!=========================
=========================:::21:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-python_venv_build/tests/host_vars/container2.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

ansible_host: 10.1.0.3
ansible_become: True
ansible_user: root
container_name: container2

**********
DECISION===>: Hardcoded Secret
**********
=========================:::21:::END!!!=========================
=========================:::22:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-python_venv_build/tests/host_vars/container3.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

ansible_host: 10.1.0.4
ansible_become: True
ansible_user: root
container_name: container3

**********
DECISION===>: Hardcoded Secret
**********
=========================:::22:::END!!!=========================
=========================:::23:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-python_venv_build/tests/host_vars/localhost.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

bridges:
  - name: "br-mgmt"
    ip_addr: "10.1.0.1"

ansible_python_interpreter: "/usr/bin/python2"

**********
DECISION===>: PASS
**********
=========================:::23:::END!!!=========================
=========================:::24:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-python_venv_build/meta/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

galaxy_info:
  author: openstack-ansible
  description: Python venv preparation
  company: OpenStack
  license: Apache2
  min_ansible_version: 2.4
  platforms:
    - name: Ubuntu
      versions:
        - xenial
        - bionic
    - name: EL
      versions:
        - 7
    - name: opensuse
      versions:
        - 42.1
        - 42.2
        - 42.3
  categories:
    - cloud
    - python
    - development
dependencies: []

**********
DECISION===>: PASS
**********
=========================:::24:::END!!!=========================
=========================:::25:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-python_venv_build/defaults/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

#
# Required variables
#

# The path where venvs are extracted to
# on the target host during an install, for example:
# venv_install_destination_path: "/openstack/venvs/myvenv"

#
# Optional variables
#

# Distribution packages which must be installed
# on all hosts when building python wheels.
venv_build_base_distro_package_list: "{{ _venv_build_base_distro_package_list[ansible_os_family | lower] }}"

# Distribution packages which must be installed
# on the host for the purpose of building the
# python wheels.
venv_build_distro_package_list: []

# Distribution packages which must be installed
# on the host when installing the venv.
venv_install_distro_package_list: []

# Set the package install state for packages
# Options are 'present' and 'latest'
venv_distro_package_state: "latest"
venv_pip_package_state: "latest"

# The time in seconds that the distribution package
# cache is valid for. This is only used by the apt
# package manager.
venv_distro_cache_valid_time: 600

# Default python packages which will be installed
# into every venv.
venv_default_pip_packages: []

# Python packages which must be installed
# into the venv.
venv_pip_packages: []

# Arguments to pass to pip when installing into the venv
venv_pip_install_args: ""

# The python executable to use for creating the venv
venv_python_executable: "python2"

# Enable the recreation of the venv from scratch.
# This is useful if you think the venv may be corrupted
# or if you have changed options which means that packages
# should be removed from the venv.
# Under normal circumstances, the installs will be done
# into the existing venv over the top of any previously
# installed packages.
venv_rebuild: no

# Set the host where the wheels will be built.
# If this host is not the same as the target host, then
# python wheels will be built in order to speed up the
# subsequent venv builds on this host and others. When
# this is the same as the target host, then we will not
# bother building wheels.
venv_build_host: "{{ ((groups['repo_all'] is defined) and (groups['repo_all'] | length > 0)) | ternary(groups.get('repo_all')[0], inventory_hostname) }}"

# The path for the wheel build venv.
# This is the path where a venv will be created on the
# build host for the purpose of building the wheels.
venv_build_host_venv_path: "/openstack/venvs/wheel-builder"

# The path where the wheels are cached on the build host
# for speeding up the build process.
# TODO(odyssey4me):
# Once we remove the repo build process, this needs to point
# to the location where wheels are served by pypiserver.
# For now we use this to ensure that we don't rebuild the wheels
# that were already built by the repo build process. It has also
# been found that pypiserver hangs when it encounters duplicated
# wheels.
venv_build_host_wheel_path: >-
  /var/www/repo/os-releases/{{ openstack_release | default('master') }}/{{ (ansible_distribution | lower) | replace(' ', '_') }}-{{ ansible_distribution_version.split('.')[:2] | join('.') }}-{{ ansible_architecture | lower }}

# The facts to set when the venv changes during a
# build, or the installation of a venv.
# Eg:
# set_facts_when_changed:
#   - section: glance
#     option: venv_tag
#     value: "{{ glance_venv_tag }}"
venv_facts_when_changed: []

# The INI file name to use for the fact setting.
venv_facts_dest: "openstack_ansible"

**********
DECISION===>: PASS
**********
=========================:::25:::END!!!=========================
=========================:::26:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-python_venv_build/zuul.d/project.yaml
**********
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- project:
    templates:
      - openstack-ansible-role-jobs
      - check-requirements
      - publish-openstack-docs-pti
      - release-notes-jobs-python3

**********
DECISION===>: PASS
**********
=========================:::26:::END!!!=========================
=========================:::27:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-python_venv_build/handlers/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: venv changed
  meta: noop
  when: false

**********
DECISION===>: PASS
**********
=========================:::27:::END!!!=========================
=========================:::28:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-systemd_mount/ansible-role-requirements.yaml
**********
- name: "plugins"
  src: "https://git.openstack.org/openstack/openstack-ansible-plugins"
  scm: git
  version: "master"

**********
DECISION===>: PASS
**********
=========================:::28:::END!!!=========================
=========================:::29:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-systemd_mount/vars/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

systemd_mount_states:
  reloaded: reload
  restarted: reload-or-restart
  started: reload-or-restart
  stopped: stopped
  absent: stopped

**********
DECISION===>: PASS
**********
=========================:::29:::END!!!=========================
=========================:::30:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-systemd_mount/tasks/systemd_mounts.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Set mount facts
  set_fact:
    systemd_mount_suffix: "{{ (item.type == 'swap') | ternary('swap', 'mount') }}"
    systemd_mount_item: "{{ item.where | default(item.what) }}"

- name: Escape mount service file name
  command: systemd-escape -p --suffix="{{ systemd_mount_suffix }}" "{{ systemd_mount_item }}"
  changed_when: false
  register: mount_service_name

- name: Create mount target(s)
  file:
    path: "{{ item.where }}"
    state: directory
    owner: "{{ item.owner | default(omit) }}"
    group: "{{ item.group | default(omit) }}"
    mode: "0755"
  when:
    - item.where is defined
    - item.state | default('unknown') != 'absent'
    - item.type != 'swap'
  tags:
    - systemd-mount

- name: Create systemd mount services(s)
  config_template:
    src: "systemd-mount.j2"
    dest: "/etc/systemd/system/{{ mount_service_name.stdout }}"
    owner: "root"
    group: "root"
    mode: "0640"
    config_overrides: "{{ item.config_overrides | default({}) }}"
    config_type: "ini"
  when:
    - item.state | default('unknown') != 'absent'
  tags:
    - systemd-mount

- name: Load or Unload mount(s)
  systemd:
    daemon_reload: yes
    name: "{{ mount_service_name.stdout }}"
    enabled: "{{ item.enabled | default(true) }}"
  when:
    - item.state | default('unknown') != 'absent'

# NOTE(cloudnull): The systemd module is not used to start the
#                  mount because we don't want to inavertently
#                  "restart" a mount unnecessarily. To ensure
#                  we're able to load new options without
#                  requiring a mount restart the systemctl
#                  command is used with the "reload-or-restart"
#                  argument. Additionally this command escapes
#                  the name of the mount. If this command fails
#                  the task will be rescued and the regular
#                  systemd module will be attempted before
#                  failing the task run.
- name: Mount state block
  block:
    - name: Set the state of the mount
      shell: >-
        systemctl
        {{ systemd_mount_states[item.state] }}
        $(systemd-escape -p --suffix="{{ systemd_mount_suffix }}" "{{ systemd_mount_item }}")
      args:
        warn: no
      when:
        - item.state is defined
      tags:
        - skip_ansible_lint
  rescue:
    - name: Set the state of the mount (fallback)
      systemd:
        name: "{{ mount_service_name.stdout }}"
        state: "{{ item.state }}"

- name: Unload mount(s)
  systemd:
    daemon_reload: yes
    name: "{{ mount_service_name.stdout }}"
    enabled: false
    no_block: yes
  when:
    - item.state | default('unknown') == 'absent'
  notify: Remove mount

**********
DECISION===>: Hardcoded Secret
**********
=========================:::30:::END!!!=========================
=========================:::31:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-systemd_mount/tasks/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Fail if mount is missing what parameters
  fail:
    msg: "Mount parameters [ type ] is missing for mount {{ item }}"
  with_items: "{{ systemd_mounts }}"
  when:
    - item.type is undefined
  tags:
    - always

- name: Fail if mount is missing what parameters
  fail:
    msg: "Mount parameters [ what ] is missing for mount {{ item }}"
  with_items: "{{ systemd_mounts }}"
  when:
    - item.what is undefined
  tags:
    - always

- name: Fail if mount is missing where parameters
  fail:
    msg: "Mount parameters [ where ] is missing for mount {{ item }}"
  with_items: "{{ systemd_mounts }}"
  when:
    - item.where is undefined and item.type != 'swap'
  tags:
    - always

- include_tasks: systemd_mounts.yml
  with_items: "{{ systemd_mounts }}"

**********
DECISION===>: PASS
**********
=========================:::31:::END!!!=========================
=========================:::32:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-systemd_mount/tests/systemd_init-overrides.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

tempest_run: yes
tempest_venv_tag: "{{ tempest_git_install_branch }}"
tempest_venv_bin: "/opt/tempest_{{ tempest_venv_tag }}/bin"
tempest_log_dir: "/var/log/"
tempest_test_whitelist:
  - tempest.scenario.test_server_basic_ops.TestServerBasicOps.test_server_basic_ops

neutron_provider_networks:
  network_types: "vxlan,flat"
  network_mappings: "flat:eth12"
  network_vxlan_ranges: "1:1000"

**********
DECISION===>: PASS
**********
=========================:::32:::END!!!=========================
=========================:::33:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-systemd_mount/tests/test.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
# Copyright 2018, Logan Vig <logan2211@gmail.com>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- import_playbook: test-create-swap-dev.yml

- import_playbook: test-create-nfs-dev.yml

- import_playbook: test-create-btrfs-dev.yml

- name: Playbook for role testing
  hosts: localhost
  connection: local
  user: root
  become: true
  roles:
    - role: "systemd_mount"

  post_tasks:
    - name: Ensure mount are mounted
      command: grep -w '{{ item }}' /proc/mounts
      with_items:
        - /var/lib/sparse-file
        - /var/lib/test
      tags:
        - skip_ansible_lint

    - name: Ensure swap is enabled
      shell: swapon | grep -w '/var/lib/test-swap.img'
      tags:
        - skip_ansible_lint

  vars:
    systemd_mounts:
      - what: '/var/lib/sparse-file.img'
        where: '/var/lib/sparse-file'
        type: 'btrfs'
        options: 'loop'
        state: 'started'
        enabled: true
        config_overrides:
          Unit:
            ConditionPathExists: '/var/lib/sparse-file.img'

      - what: "/var/lib/test-swap.img"
        priority: "0"
        options: "%%"
        type: "swap"
        state: 'started'
        enabled: true

      - what: "127.0.0.1:/srv/nfs/test"
        where: "/var/lib/test"
        type: "nfs"
        options: "_netdev,auto"
        state: 'started'
        enabled: true
        config_overrides:
          Unit:
            After:
              ? network.target
              ? network-online.target
            Wants: network-online.target

**********
DECISION===>: Hardcoded Secret
**********
=========================:::33:::END!!!=========================
=========================:::34:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-systemd_mount/tests/ansible-role-requirements.yaml
**********
- name: "plugins"
  src: "https://git.openstack.org/openstack/openstack-ansible-plugins"
  scm: git
  version: "master"

**********
DECISION===>: PASS
**********
=========================:::34:::END!!!=========================
=========================:::35:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-systemd_mount/tests/test-create-btrfs-dev.yml
**********
---
# Copyright 2017, BBC R&D
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Configure BTRFS sparse file
  hosts: localhost
  user: root
  become: true
  connection: local
  tasks:
    - name: Install BTRFS packages
      package:
        name: "{{ btrfs_package[ansible_pkg_mgr | lower] }}"
        state: present

    - name: Create base directories
      file:
        path: "/var/lib"
        state: "directory"

    - name: Create sparse file
      command: "truncate -s 1024G /var/lib/sparse-file.img"
      args:
        creates: /var/lib/sparse-file.img
      register: sparse_file

    - name: Format the sparse file
      filesystem:
        fstype: btrfs
        dev: /var/lib/sparse-file.img
      when:
        - sparse_file  is changed
  vars:
    btrfs_package:
      apt: "btrfs-tools"
      yum: "btrfs-progs"
      zypper: "btrfsprogs"

**********
DECISION===>: Hardcoded Secret
**********
=========================:::35:::END!!!=========================
=========================:::36:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-systemd_mount/tests/test-create-swap-dev.yml
**********
---
# Copyright 2017, BBC R&D
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Configure swap sparse file
  hosts: localhost
  user: root
  become: true
  connection: local
  tasks:
    - name: Create swap file
      command: "dd if=/dev/zero of=/var/lib/test-swap.img bs=1M count=128"
      args:
        creates: /var/lib/test-swap.img
      register: create_swap

    - name: Format the swap file
      command: mkswap /var/lib/test-swap.img
      failed_when: false
      when:
        - create_swap  is changed

**********
DECISION===>: PASS
**********
=========================:::36:::END!!!=========================
=========================:::37:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-systemd_mount/tests/test-create-nfs-dev.yml
**********
---
# Copyright 2017, BBC R&D
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Create an NFS backing store
  hosts: localhost
  user: root
  become: true
  connection: local
  tasks:
    - name: Install NFS packages
      package:
        name: "{{ nfs_package[ansible_distribution.split()[0] | lower] }}"
        state: present

    - name: create the system group for nfs
      group:
        name: "nfs-user"
        gid: "10000"
        state: "present"
        system: "yes"

    - name: Create the system user for nfs
      user:
        name: "nfs-user"
        uid: "10000"
        group: "nfs-user"
        comment: "nfs-user"
        shell: "/bin/false"
        system: "yes"
        createhome: "yes"
        home: "/srv/nfs"

    - name: Create base directories
      file:
        path: "{{ item }}"
        state: "directory"
        owner: "nfs-user"
        group: "nfs-user"
      with_items:
        - "/srv/nfs/test"

    - name: Create exports file
      lineinfile:
        path: /etc/exports
        line: '{{ item }} 127.0.0.1/255.0.0.0(rw,sync,no_subtree_check,insecure,all_squash,anonuid=10000,anongid=10000)'
        owner: root
        group: root
        mode: 0644
        create: yes
      with_items:
        - "/srv/nfs/test"
      register: nfs_exportfs

    - name: Restart nfs-server
      systemd:
        daemon_reload: yes
        name: "nfs-server"
        enabled: "yes"
        state: "restarted"
      when:
        - nfs_exportfs  is changed

    - name: Export NFS
      command: exportfs -rav
      tags:
        - skip_ansible_lint
  vars:
    nfs_package:
      ubuntu: "nfs-kernel-server"
      centos: "nfs-utils"
      opensuse: "nfs-kernel-server"

**********
DECISION===>: Hardcoded Secret
**********
=========================:::37:::END!!!=========================
=========================:::38:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-systemd_mount/tests/group_vars/all_containers.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

container_networks:
  management_address:
    address: "{{ ansible_host }}"
    bridge: "br-mgmt"
    interface: "eth1"
    netmask: "255.255.255.0"
    type: "veth"

physical_host: localhost
properties:
  service_name: "{{ inventory_hostname }}"

**********
DECISION===>: PASS
**********
=========================:::38:::END!!!=========================
=========================:::39:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-systemd_mount/tests/host_vars/localhost.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

neutron_provider_networks:
  network_types: "vxlan,flat"
  network_mappings: "flat:eth12"
  network_vxlan_ranges: "1:1000"

neutron_local_ip:  10.1.2.1

ansible_python_interpreter: "/usr/bin/python2"

bridges:
  - name: "br-mgmt"
    ip_addr: "10.1.1.1"

**********
DECISION===>: PASS
**********
=========================:::39:::END!!!=========================
=========================:::40:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-systemd_mount/meta/main.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

galaxy_info:
  author: rcbops
  description: Installation and setup of systemd_mount
  company: Rackspace
  license: Apache2
  min_ansible_version: 2.0
  platforms:
    - name: Ubuntu
      versions:
        - xenial
        - bionic
    - name: EL
      versions:
        - 7
    - name: opensuse
      versions:
        - 42.1
        - 42.2
        - 42.3
  categories:
    - systemd
    - development
  dependencies:
    - plugins

**********
DECISION===>: PASS
**********
=========================:::40:::END!!!=========================
=========================:::41:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-systemd_mount/defaults/main.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Any optioned required to make the mount point work. If no options are
#  provided the default will be used. This list is comma separted.
#  https://www.freedesktop.org/software/systemd/man/systemd.mount.html#Options=
systemd_default_mount_options: 'defaults'

# The systemd mounts dictionary is a set of mounts that will be created. The
#  dictionary can contain the following options:
#  `config_overrides` -- (optional) used to inject extra configuration options into the mount file.
#  `what` -- (required) Define what will be mounted. This can be a network target.
#  `where` -- (required) Where will the "what" be mounted. Required when type is not swap.
#  `type` -- (required) The type of file system that will be mounted.
#  `options` -- (optional) Any optioned required to make the mount point work.
#                          If no options are provided the default will be used.
#                          This list is comma separted. See
#                          `systemd_default_mount_options` for more details.
#  `state` -- (optional) system state of the mount point. The default will omit
#                        the state so that it is not started or stopped
#                        unessisarily. If it is desirable for this role to
#                        start/stop the mount immediately this can be done by
#                        setting the state to ["started", "stopped", "absent"].
#                        If the state is absent the mount will be stopped and
#                        unit file deleted.
#  `enabled` -- (optional) Set a Boolean to enable or disable the mount, the
#                          default is set to "true".

# systemd_mounts:
#   - what: '/var/lib/machines.raw'
#     where: '/var/lib/machines'
#     type: 'btrfs'
#     options: 'loop'

#     state: 'started'
#     enabled: true
#   - config_overrides: {}
#     What: "10.1.10.1:/srv/nfs"
#     Where: "/var/lib/glance/images"
#     type: "nfs"
#     options: "_netdev,auto"

#   - what: "/openstack/swap.img"
#     priority: "0"
#     options: "%%"
#     type: "swap"
#     state: 'started'
#     enabled: true

systemd_mounts: []

**********
DECISION===>: PASS
**********
=========================:::41:::END!!!=========================
=========================:::42:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-systemd_mount/examples/playbook.yml
**********
.. code-block:: yaml

    - name: Create a systemd mount file for Mount1 and 2
      hosts: localhost
      become: true
      roles:
        - role: "systemd_mount"
          systemd_mounts:
            machines:
              what: '/var/lib/machines.raw'
              where: '/var/lib/machines'
              type: 'btrfs'
              options: 'loop'
              unit:
                ConditionPathExists:
                  - '/var/lib/machines.raw'
              state: 'started'
              enabled: true
            glance_images:
              config_overrides: {}
              What: "10.1.10.1:/srv/nfs"
              Where: "/var/lib/glance/images"
              type: "nfs"
              options: "_netdev,auto"
              unit:
                After:
                  - network.target

**********
DECISION===>: PASS
**********
=========================:::42:::END!!!=========================
=========================:::43:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-systemd_mount/zuul.d/project.yaml
**********
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- project:
    templates:
      - openstack-ansible-role-jobs
      - check-requirements
      - publish-openstack-docs-pti
      - release-notes-jobs-python3

**********
DECISION===>: PASS
**********
=========================:::43:::END!!!=========================
=========================:::44:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-systemd_mount/handlers/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Delete mount file(s)
  file:
    path: "/etc/systemd/system/{{ item.where.strip('/') | replace('/', '-') }}.{{ item.type == 'swap' | ternary('swap', 'mount') }}"
    state: "absent"
  when:
    - item.state | default('unknown') == 'absent'
  with_items: "{{ systemd_mounts }}"
  listen: Remove mount

- name: Delete mount target(s)
  file:
    path: "{{ item.where }}"
    state: "absent"
  when:
    - item.state | default('unknown') == 'absent'
  with_items: "{{ systemd_mounts }}"
  listen: Remove mount

- name: Reload systemd daemon
  systemd:
    daemon_reload: yes
    no_block: yes
  listen: Remove mount

**********
DECISION===>: PASS
**********
=========================:::44:::END!!!=========================
=========================:::45:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-systemd_networkd/ansible-role-requirements.yaml
**********
- name: "plugins"
  src: "https://git.openstack.org/openstack/openstack-ansible-plugins"
  scm: git
  version: "master"

**********
DECISION===>: PASS
**********
=========================:::45:::END!!!=========================
=========================:::46:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-systemd_networkd/vars/ubuntu.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

_systemd_resolved_available: true

_systemd_networkd_update_initramfs: "/usr/sbin/update-initramfs -u"

**********
DECISION===>: PASS
**********
=========================:::46:::END!!!=========================
=========================:::47:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-systemd_networkd/vars/redhat-7.yml
**********
---
# Copyright 2018, Logan Vig <logan2211@gmail.com>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

_systemd_networkd_distro_packages:
  - systemd-networkd
  - systemd-resolved

_systemd_resolved_available: true

_systemd_networkd_update_initramfs: "dracut -f"

**********
DECISION===>: PASS
**********
=========================:::47:::END!!!=========================
=========================:::48:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-systemd_networkd/vars/suse-42.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

_systemd_resolved_available: false

_systemd_networkd_update_initramfs: "dracut -f"

**********
DECISION===>: PASS
**********
=========================:::48:::END!!!=========================
=========================:::49:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-systemd_networkd/vars/main.yml
**********
---
# Copyright 2018, Logan Vig <logan2211@gmail.com>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

## APT Cache options
cache_timeout: 600

**********
DECISION===>: PASS
**********
=========================:::49:::END!!!=========================
=========================:::50:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-systemd_networkd/tasks/main.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Gather variables for each operating system
  include_vars: "{{ item }}"
  with_first_found:
    - files:
        - "{{ ansible_distribution | lower }}-{{ ansible_distribution_version | lower }}.yml"
        - "{{ ansible_distribution | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
        - "{{ ansible_os_family | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
        - "{{ ansible_distribution | lower }}.yml"
        - "{{ ansible_os_family | lower }}.yml"
      skip: true
  tags:
    - always

- name: Install networkd distro packages
  package:
    name: "{{ systemd_networkd_distro_packages }}"
    state: "present"
    update_cache: "{{ (ansible_pkg_mgr == 'apt') | ternary('yes', omit) }}"
    cache_valid_time: "{{ (ansible_pkg_mgr == 'apt') | ternary(600, omit) }}"
  when:
    - systemd_networkd_distro_packages | length > 0
  register: install_packages
  until: install_packages is success
  retries: 3
  delay: 2

- name: Create systemd-networkd directory
  file:
    path: "/etc/systemd/network"
    state: directory
  tags:
    - systemd-networkd

- name: Create systemd-networkd link
  config_template:
    src: "systemd-network-link.j2"
    dest: "/etc/systemd/network/99-default.link"
    owner: "root"
    group: "root"
    mode: "0644"
    config_overrides: "{{ systemd_link_config_overrides }}"
    config_type: "ini"
  notify:
    - Restart systemd-networkd
    - Update initramfs
  tags:
    - systemd-networkd

- name: Create systemd-resolved config
  template:
    src: "systemd-resolved.conf.j2"
    dest: "/etc/systemd/resolved.conf"
    owner: "root"
    group: "root"
    mode: "0644"
  when:
    - systemd_resolved
  notify:
    - Restart systemd-resolved
  tags:
    - systemd-resolved

- name: Find prefixed netdev and network files
  find:
    paths: "/etc/systemd/network"
    patterns: "*{{ systemd_networkd_prefix }}*.netdev,*{{ systemd_networkd_prefix }}*.network"
  register: networkd_files
  when:
    - systemd_interface_cleanup | bool
  tags:
    - systemd-networkd

- name: Remove prefixed network files
  file:
    path: "{{ item.path }}"
    state: absent
  with_items: "{{ networkd_files.files }}"
  when:
    - systemd_interface_cleanup | bool
  notify:
    - Restart systemd-networkd
  tags:
    - systemd-networkd

- name: Create systemd-networkd network device(s)
  template:
    src: "systemd-netdev.j2"
    dest: "/etc/systemd/network/{{ item.1.filename | default(systemd_networkd_netdev_filename) }}"
    owner: "root"
    group: "root"
    mode: "0644"
  with_indexed_items: "{{ systemd_netdevs }}"
  notify:
    - Restart systemd-networkd
  tags:
    - systemd-networkd

- name: Create systemd-networkd network(s)
  config_template:
    src: "systemd-network.j2"
    dest: "/etc/systemd/network/{{ item.1.filename | default(systemd_networkd_network_filename) }}"
    owner: "root"
    group: "root"
    mode: "0644"
    config_overrides: "{{ item.1.config_overrides | default({}) }}"
    config_type: "ini"
  with_indexed_items: "{{ systemd_networks }}"
  notify:
    - Restart systemd-networkd
  tags:
    - systemd-networkd

- name: Enable and start systemd-networkd
  systemd:
    name: "systemd-networkd"
    enabled: "yes"
    state: started
  async: 45
  poll: 0
  when:
    - systemd_run_networkd | bool
  tags:
    - systemd-networkd

**********
DECISION===>: Hardcoded Secret
**********
=========================:::50:::END!!!=========================
=========================:::51:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-systemd_networkd/tests/systemd_init-overrides.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

tempest_run: yes
tempest_venv_tag: "{{ tempest_git_install_branch }}"
tempest_venv_bin: "/opt/tempest_{{ tempest_venv_tag }}/bin"
tempest_log_dir: "/var/log/"
tempest_test_whitelist:
  - tempest.scenario.test_server_basic_ops.TestServerBasicOps.test_server_basic_ops

neutron_provider_networks:
  network_types: "vxlan,flat"
  network_mappings: "flat:eth12"
  network_vxlan_ranges: "1:1000"

**********
DECISION===>: PASS
**********
=========================:::51:::END!!!=========================
=========================:::52:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-systemd_networkd/tests/test.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
# Copyright 2018, Logan Vig <logan2211@gmail.com>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Playbook for role testing
  hosts: localhost
  connection: local
  become: true
  gather_facts: true
  roles:
    - role: "systemd_networkd"
  vars:
    systemd_run_networkd: yes
    systemd_resolved:
      DNS: "208.67.222.222"
      FallbackDNS: "8.8.8.8"
      Cache: yes
    systemd_netdevs:
      - NetDev:
          Name: dummy0
          Kind: dummy
      - NetDev:
          Name: dummy1
          Kind: dummy
      - NetDev:
          Name: bond0
          Kind: bond
        Bond:
          Mode: 802.3ad
          TransmitHashPolicy: layer3+4
          MIIMonitorSec: 1s
          LACPTransmitRate: fast
      - NetDev:
          Name: br-dummy
          Kind: bridge
      - NetDev:
          Name: dummy2
          Kind: dummy
      - NetDev:
          Name: br-test
          Kind: bridge
    systemd_networks:
      - interface: "dummy0"
        bond: "bond0"
        mtu: 9000
      - interface: "dummy1"
        bond: "bond0"
        mtu: 9000
      - interface: "bond0"
        bridge: "br-dummy"
        mtu: 9000
      - interface: "br-dummy"
        address: "10.0.0.100"
        netmask: "255.255.255.0"
        gateway: "10.0.0.1"
        mtu: 9000
        usedns: true
        static_routes:
          - gateway: "10.1.0.1"
            cidr: "10.1.0.0/24"
        config_overrides:
          Network:
            ConfigureWithoutCarrier: true
      - interface: "dummy2"
        bridge: "br-test"
      - interface: "br-test"
        address: "10.1.0.1"
        netmask: "255.255.255.0"


- name: Test networkd
  hosts: localhost
  connection: local
  become: true
  gather_facts: true
  tasks:
    - name: Interface check
      assert:
        that:
          - ansible_dummy0['active'] == true
          - ansible_dummy0['type'] == 'ether'
          - ansible_dummy0['mtu'] == 9000
          - ansible_dummy1['active'] == true
          - ansible_dummy1['type'] == 'ether'
          - ansible_dummy1['mtu'] == 9000
          - ansible_dummy2['active'] == true
          - ansible_dummy2['type'] == 'ether'
    - name: Bond check
      assert:
        that:
          - ansible_bond0['active'] == true
          - ansible_bond0['type'] == 'bonding'
          - ansible_bond0['mtu'] == 9000
    - name: Bridge check
      assert:
        that:
          - ansible_br_dummy['active'] == true
          - ansible_br_dummy['type'] == 'bridge'
          - ansible_br_dummy['ipv4']['address'] == '10.0.0.100'
          - ansible_br_dummy['ipv4']['netmask'] == '255.255.255.0'
    - name: Bridge check
      assert:
        that:
          - ansible_br_test['active'] == true
          - ansible_br_test['type'] == 'bridge'
          - ansible_br_test['ipv4']['address'] == '10.1.0.1'
          - ansible_br_test['ipv4']['netmask'] == '255.255.255.0'


- name: Playbook for role testing with cleanup
  hosts: localhost
  connection: local
  become: true
  gather_facts: true
  roles:
    - role: "systemd_networkd"
  post_tasks:
    - name: Interface check
      assert:
        that:
          - ansible_br_test is defined
          - ansible_dummy2['active'] == true
          - ansible_dummy2['type'] == 'ether'
    - name: Bridge check
      assert:
        that:
          - ansible_br_test['active'] == true
          - ansible_br_test['type'] == 'bridge'
          - ansible_br_test['ipv4']['address'] == '10.1.0.1'
          - ansible_br_test['ipv4']['netmask'] == '255.255.255.0'
  vars:
    systemd_interface_cleanup: true
    systemd_run_networkd: yes
    systemd_netdevs:
      - NetDev:
          Name: dummy2
          Kind: dummy
      - NetDev:
          Name: br-test
          Kind: bridge
    systemd_networks:
      - interface: "dummyX"
        bridge: "br-test"
      - interface: "br-test"
        address: "10.1.0.1"
        netmask: "255.255.255.0"

**********
DECISION===>: PASS
**********
=========================:::52:::END!!!=========================
=========================:::53:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-systemd_networkd/tests/ansible-role-requirements.yaml
**********
- name: "plugins"
  src: "https://git.openstack.org/openstack/openstack-ansible-plugins"
  scm: git
  version: "master"

**********
DECISION===>: PASS
**********
=========================:::53:::END!!!=========================
=========================:::54:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-systemd_networkd/tests/group_vars/all_containers.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

container_networks:
  management_address:
    address: "{{ ansible_host }}"
    bridge: "br-mgmt"
    interface: "eth1"
    netmask: "255.255.255.0"
    type: "veth"

physical_host: localhost
properties:
  service_name: "{{ inventory_hostname }}"

**********
DECISION===>: PASS
**********
=========================:::54:::END!!!=========================
=========================:::55:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-systemd_networkd/tests/host_vars/localhost.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

neutron_provider_networks:
  network_types: "vxlan,flat"
  network_mappings: "flat:eth12"
  network_vxlan_ranges: "1:1000"

neutron_local_ip:  10.1.2.1

ansible_python_interpreter: "/usr/bin/python2"

bridges:
  - name: "br-mgmt"
    ip_addr: "10.1.1.1"

**********
DECISION===>: PASS
**********
=========================:::55:::END!!!=========================
=========================:::56:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-systemd_networkd/meta/main.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

galaxy_info:
  author: rcbops
  description: Installation and setup of systemd_networkd
  company: Rackspace
  license: Apache2
  min_ansible_version: 2.0
  platforms:
    - name: Ubuntu
      versions:
        - xenial
        - bionic
    - name: EL
      versions:
        - 7
    - name: opensuse
      versions:
        - 42.1
        - 42.2
        - 42.3
  categories:
    - systemd
    - development
  dependencies:
    - plugins

**********
DECISION===>: PASS
**********
=========================:::56:::END!!!=========================
=========================:::57:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-systemd_networkd/defaults/main.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Cleanup all known network interfaces. When this option is enabled the role
# will search for and remove all network interface files that match the prefix.
systemd_interface_cleanup: false

# Prefix for all networkd files created by this role. This prefix allows
# deployers to set specific file names reducing the chance of a collision
# and simplifies the network interface file cleanup operation should it ever
# be needed. By default, the prefix is "general" however this can be changed
# to meet the needs of the deployer.
systemd_networkd_prefix: "general"

# Enable systemd-networkd and (re)start the service
systemd_run_networkd: false

# Default filename formatting
systemd_networkd_netdev_filename: "{{ item.0 }}-{{ systemd_networkd_prefix }}-{{ item.1.NetDev.Name }}.netdev"
systemd_networkd_network_filename: "{{ item.0 }}-{{ systemd_networkd_prefix }}-{{ item.1.interface }}.network"

# The `systemd_link_config_overrides` option can be used on the default link.
#  See the following link for all available options:
#   https://www.freedesktop.org/software/systemd/man/systemd.link.html
# systemd_default_unit:
#   Match:
#     Driver=things other thing
systemd_link_config_overrides: {}

# All items listed in the `systemd_netdevs` array are craeted using the exact
# networkd syntax found here:
#   https://www.freedesktop.org/software/systemd/man/systemd.netdev.html
# At an absolute minimum, the items must have "NetDev" and "Name" defined.
# Items generated will have an integer assigned to them so that they're loaded
# in the order specified.

# systemd_netdevs:
#   - NetDev:
#       Name: dummy0
#       Kind: dummy
#   - NetDev:
#       Name: dummy1
#       Kind: dummy
#     filename: "{{ item.1.NetDev.Name }}.netdev"
#   - NetDev:
#       Name: bond0
#       Kind: bond
#     Bond:
#       Mode: 802.3ad
#       TransmitHashPolicy: layer3+4
#       MIIMonitorSec: 1s
#       LACPTransmitRate: fast
#   - NetDev:
#       Name: br-dummy
#       Kind: bridge

systemd_netdevs: []

# The systemd networkd dictionary is a set of networks that will be created.
# items generated will have an integer assigned to them so that they're loaded
# in the order specified. The dictionary can contain the following options:
#  `config_overrides` -- (optional) used to inject extra configuration options
#                                   into the network file. A full list of all
#                                   options can be found here:
#                                   https://www.freedesktop.org/software/systemd/man/systemd.network.html
#  `interface` -- (required) Name of interface to match
#  `address` -- (option) IP address the interface should be given. To make this
#                        interface use DHCP set this string to "dhcp"
#  `netmask` -- (optional) Netmask to use for the interface
#  `gateway` -- (optional) Gateway to use for the interface
#  `bridge` -- (optional) Bridge name for a mapped interface
#  `bond` -- (optional) Bond name for a mapped interface
#  `vlan` -- (optional) VLAN name for a mapped interface
#  `macvlan` -- (optional) MACVLAN name for a mapped interface
#  `vxlan` -- (optional) VXLAN name for a mapped interface
#  `mtu` -- (optional) MTU to use for the interface
#  `usedns` -- (optional) When set to true the interface will accept DNS when
#                         running in dhcp mode
#  `static_routes` -- (optional) list of routes to use for the network. This
#                                option requires a gateway and cidr to be set
#                                within the list item.

# systemd_networks:
#   - interface: "dummy0"
#     bridge: "bond0"
#     mtu: 9000
#   - interface: "dummy1"
#     filename: "{{ item.1.interface }}.network"
#     bridge: "bond0"
#     mtu: 9000
#   - interface: "bond0"
#     bridge: "br-dummy"
#     mtu: 9000
#   - interface: "br-dummy"
#     bridge: "br-dummy"
#     address: "10.0.0.100"
#     netmask: "255.255.255.0"
#     gateway: "10.0.0.1"
#     mtu: 9000
#     usedns: true
#     config_overrides:
#       Network:
#         ConfigureWithoutCarrier: true

systemd_networks: []

# The systemd resolved service can be setup using th following configuration.
# The generator is a Key=Value pair hash and will set whatever directives it's
# instructed to. For more information on all of the possible configuration see
# https://www.freedesktop.org/software/systemd/man/resolved.conf.html

# systemd_resolved:
#   DNS: "10.127.83.1"
#   FallbackDNS: "208.67.222.222 8.8.8.8"
#   Cache: yes

systemd_resolved: {}

# Enable or Disable the availability of systemd-resolved. This option is a
# Boolean variable.

systemd_resolved_available: "{{ _systemd_resolved_available | default(true) }}"

# Specify the command used to update the initramfs. By default this will run
# "/bin/true" which is done because the command required to run should never
# be assumed. Distro specific config is available in vars otherwise deployers
# can set this as needed.

systemd_networkd_update_initramfs: "{{ _systemd_networkd_update_initramfs | default('true') }}"

# Provide a list of packages that are to be installed before this role is
# executed.

# _systemd_networkd_distro_packages:
#  - systemd-networkd
#  - systemd-resolved

systemd_networkd_distro_packages: "{{ _systemd_networkd_distro_packages | default([]) }}"

**********
DECISION===>: PASS
**********
=========================:::57:::END!!!=========================
=========================:::58:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-systemd_networkd/examples/playbook.yml
**********
.. code-block:: yaml

    ---
    - name: Create a systemd-networkd interfaces
      hosts: localhost
      become: true
      roles:
        - role: "systemd_networkd"
          systemd_interface_cleanup: true
          systemd_run_networkd: true
          systemd_netdevs:
            - NetDev:
                Name: dummy0
                Kind: dummy
            - NetDev:
                Name: dummy2
                Kind: dummy
            - NetDev:
                Name: dummy1
                Kind: dummy
            - NetDev:
                Name: dummy3
                Kind: dummy

            - NetDev:
                Name: bond0
                Kind: bond
              Bond:
                Mode: 802.3ad
                TransmitHashPolicy: layer3+4
                MIIMonitorSec: 1s
                LACPTransmitRate: fast
            - NetDev:
                Name: bond1
                Kind: bond
              Bond:
                Mode: 802.3ad
                TransmitHashPolicy: layer3+4
                MIIMonitorSec: 1s
                LACPTransmitRate: fast

            - NetDev:
                Name: bond0.110
                Kind: vlan
              VLAN:
                Id: 110
            - NetDev:
                Name: bond0.120
                Kind: vlan
              VLAN:
                Id: 120
            - NetDev:
                Name: bond0.130
                Kind: vlan
              VLAN:
                Id: 130
            - NetDev:
                Name: bond0.140
                Kind: vlan
              VLAN:
                Id: 140
            - NetDev:
                Name: bond1.210
                Kind: vlan
              VLAN:
                Id: 210

            - NetDev:
                Name: br-mgmt
                Kind: bridge
            - NetDev:
                Name: br-vxlan
                Kind: bridge
            - NetDev:
                Name: br-storage
                Kind: bridge
            - NetDev:
                Name: br-vlan
                Kind: bridge
            - NetDev:
                Name: br-dbaas
                Kind: bridge
            - NetDev:
                Name: br-lbaas
                Kind: bridge

            - NetDev:
                Name: br-vlan-veth
                Kind: veth
              Peer:
                Name: eth12
            - NetDev:
                Name: br-dbaas-veth
                Kind: veth
              Peer:
                Name: eth13
            - NetDev:
                Name: br-lbaas-veth
                Kind: veth
              Peer:
                Name: eth14

          systemd_networks:
            - interface: "dummy0"
              bond: "bond0"
              mtu: 9000
            - interface: "dummy2"
              bond: "bond0"
              mtu: 9000
            - interface: "dummy1"
              bond: "bond1"
              mtu: 9000
            - interface: "dummy3"
              bond: "bond1"
              mtu: 9000

            - interface: "bond0"
              config_overrides:
                Network:
                  VLAN:
                    ? "bond0.110"
                    ? "bond0.120"
                    ? "bond0.130"
                    ? "bond0.140"
              mtu: 9000
            - interface: "bond1"
              bridge: "br-vlan"
              config_overrides:
                Network:
                  VLAN:
                    ? "bond1.210"
              mtu: 9000

            - interface: "bond0.110"
              bridge: "br-mgmt"
              mtu: 9000
            - interface: "br-mgmt"
              address: "172.29.236.100"
              netmask: "255.255.252.0"

            - interface: "bond0.120"
              bridge: "br-storage"
              mtu: 9000
            - interface: "br-storage"
              address: "172.29.244.100"
              netmask: "255.255.252.0"

            - interface: "bond0.130"
              bridge: "br-dbaas"
              mtu: 9000
            - interface: "br-dbaas"
              address: "172.29.232.100"
              netmask: "255.255.252.0"
            - interface: "br-dbaas-veth"
              bridge: "br-dbaas"
              mtu: 9000

            - interface: "bond0.140"
              bridge: "br-lbaas"
              mtu: 9000
            - interface: "br-lbaas"
              address: "172.29.252.100"
              netmask: "255.255.252.0"
            - interface: "br-lbaas-veth"
              bridge: "br-lbaas"
              mtu: 9000

            - interface: "bond1.210"
              bridge: "br-vxlan"
              mtu: 9000
            - interface: "br-vxlan"
              address: "172.29.240.100"
              netmask: "255.255.252.0"

            - interface: "br-vlan"
              config_overrides:
                Network:
                  Address:
                    ? "172.29.248.100/22"
                    ? "172.29.248.1/22"
            - interface: "br-vlan-veth"
              bridge: "br-vlan"
              mtu: 9000

**********
DECISION===>: PASS
**********
=========================:::58:::END!!!=========================
=========================:::59:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-systemd_networkd/zuul.d/project.yaml
**********
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- project:
    templates:
      - openstack-ansible-role-jobs
      - check-requirements
      - publish-openstack-docs-pti
      - release-notes-jobs-python3

**********
DECISION===>: PASS
**********
=========================:::59:::END!!!=========================
=========================:::60:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-systemd_networkd/handlers/main.yml
**********
---
# Copyright 2018, Logan Vig <logan2211@gmail.com>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Restart networkd
  systemd:
    name: "systemd-networkd"
    state: restarted
    enabled: "yes"
  async: 45
  poll: 0
  when:
    - systemd_run_networkd | bool
  listen: Restart systemd-networkd
  tags:
    - systemd-networkd

- name: (RE)Gather facts post setup
  setup:
    gather_subset: "network"
  listen: Restart systemd-networkd

- name: Restart systemd-resolved
  systemd:
    name: "systemd-resolved"
    state: restarted
    enabled: "yes"
  when:
    - systemd_resolved_available | bool
  tags:
    - systemd-networkd
    - systemd-resolved

- name: Update initramfs
  command: "{{ systemd_networkd_update_initramfs }}"

**********
DECISION===>: PASS
**********
=========================:::60:::END!!!=========================
=========================:::61:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-tripleo-modify-image/vars/main.yml
**********
# we support 'docker' or 'buildah'
build_commands:
  docker: docker build
  buildah: buildah bud

**********
DECISION===>: PASS
**********
=========================:::61:::END!!!=========================
=========================:::62:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-tripleo-modify-image/tasks/rpm_install.yml
**********
- import_tasks: precheck.yml
  tags:
    - always

- import_tasks: get_original_user.yml

- name: Create image build context directory
  tempfile:
    state: directory
    prefix: tripleo-modify-image
  register: context_dir

- name: Set modify_dir_path
  set_fact:
    modify_dir_path: "{{ context_dir.path }}"

- name: List RPMs
  find:
    paths: "{{ rpms_path }}"
    patterns: "^.*?\\.rpm$"
    use_regex: yes
  when: rpms_path is defined
  register: context_rpms

- name: Set rpms_list
  set_fact:
    rpms_list: "{{  context_rpms.files|json_query('[*].path') }}"

- name: Copy RPMs to context dir
  copy:
    src: "{{ item }}"
    dest: "{{ modify_dir_path }}"
  with_list: "{{ rpms_list }}"

- name: Write Dockerfile to {{ modify_dir_path }}
  template:
    src: Dockerfile-rpm.j2
    dest: "{{ modify_dir_path }}/Dockerfile"

- name: Write rpm_install.sh
  copy:
    src: rpm_install.sh
    dest: "{{ modify_dir_path }}/rpm_install.sh"
    mode: '0555'

- include_tasks: modify_image.yml

- name: Clean modify directory
  file:
    state: absent
    path: "{{ modify_dir_path }}"

**********
DECISION===>: PASS
**********
=========================:::62:::END!!!=========================
=========================:::63:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-tripleo-modify-image/tasks/yum_update.yml
**********
- import_tasks: precheck.yml
  tags:
    - always

- import_tasks: get_original_user.yml

- name: Create image build context directory
  tempfile:
    state: directory
    prefix: tripleo-modify-image
  register: context_dir

- name: Set modify_dir_path
  set_fact:
    modify_dir_path: "{{ context_dir.path }}"

- name: Copy local file repos to context directory
  shell: |
    #!/bin/sh
    set -ex

    cp -a {{ yum_repos_dir_path }} {{ modify_dir_path }}/yum.repos.d

    # discover repos with local packages
    repos=$(sed -n 's/baseurl=file:\/\///p' {{ yum_repos_dir_path }}/*.repo)

    mkdir repos
    for repo in $repos ; do
        if [ -d $repo ]; then
            target_dir=repos$repo
            echo "copying $repo to $target_dir"
            mkdir -p $target_dir
            cp -a $repo/* $target_dir
        fi
    done
  args:
    chdir: "{{ modify_dir_path }}"
  when: yum_repos_dir_path is defined

- name: Write Dockerfile to {{ modify_dir_path }}
  template:
    src: Dockerfile-yum.j2
    dest: "{{ modify_dir_path }}/Dockerfile"

- name: Write yum_update.sh
  copy:
    src: yum_update.sh
    dest: "{{ modify_dir_path }}/yum_update.sh"
    mode: '0555'

- include_tasks: modify_image.yml

- name: Clean modify directory
  file:
    state: absent
    path: "{{ modify_dir_path }}"

**********
DECISION===>: PASS
**********
=========================:::63:::END!!!=========================
=========================:::64:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-tripleo-modify-image/tasks/precheck.yml
**********
- name: Ensure that source_image is defined
  assert:
    that:
      - source_image is defined
      - source_image | length > 0

- name: Ensure that container_build_tool is correctly set
  fail: msg="{{ container_build_tool }} is not a valid value for container_build_tool. Pick docker or buildah."
  when: container_build_tool not in ['docker', 'buildah']

**********
DECISION===>: PASS
**********
=========================:::64:::END!!!=========================
=========================:::65:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-tripleo-modify-image/tasks/dev_install.yml
**********
- import_tasks: precheck.yml
  tags:
    - always

- import_tasks: get_original_user.yml

- name: Create image build context directory
  tempfile:
    state: directory
    prefix: tripleo-modify-image
  register: context_dir

- name: Set modify_dir_path
  set_fact:
    modify_dir_path: "{{ context_dir.path }}"

- name: Write Dockerfile to {{ modify_dir_path }}
  template:
    src: Dockerfile-dev.j2
    dest: "{{ modify_dir_path }}/Dockerfile"

- name: Write dev_install.sh
  copy:
    src: dev_install.sh
    dest: "{{ modify_dir_path }}/dev_install.sh"
    mode: '0555'

- name: Git checkout the refspecs into local temp dir
  command: "/bin/bash dev_install.sh {{ item.project }} {{ item.refspec }}"
  args:
    chdir: "{{ modify_dir_path }}"
  loop: "{{ refspecs }}"

- include_tasks: modify_image.yml

**********
DECISION===>: PASS
**********
=========================:::65:::END!!!=========================
=========================:::66:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-tripleo-modify-image/tasks/get_original_user.yml
**********
- when: container_build_tool == 'docker'
  block:
    - name: Inspect image with Docker
      docker_image_facts:
        name: "{{ source_image }}"
      retries: 5
      delay: 5
      until: source_image_facts.images is defined
      register: source_image_facts
    - name: Set original_user with Docker
      set_fact:
        original_user: "{{ source_image_facts.images[0].Config.User }}"

- when: container_build_tool == 'buildah'
  block:
    - name: Inspect image with Buildah
      command: buildah inspect {{ source_image }}
      register: source_image_facts
      become: true
    - name: Set config with Buildah
      set_fact:
       buildah_config: "{{ source_image_facts.stdout_lines | join('') | from_json }}"
    - name: Set original_user with Buildah
      set_fact:
       original_user: "{{ buildah_config['Docker']['config']['User'] }}"


**********
DECISION===>: PASS
**********
=========================:::66:::END!!!=========================
=========================:::67:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-tripleo-modify-image/tasks/modify_image.yml
**********
- import_tasks: precheck.yml
  tags:
    - always

- name: Ensure that modify_dir_path is defined
  assert:
    that:
      - modify_dir_path is defined
      - modify_dir_path | length > 0

- name: Set default modified_append_tag
  set_fact:
    modified_append_tag: "{{ lookup('pipe','date +-modified-%Y%m%d%H%M%S') }}"
  when: modified_append_tag is undefined

- name: Copy Dockerfile to Dockerfile.modified
  copy:
    src: "{{ modify_dir_path }}/Dockerfile"
    dest: "{{ modify_dir_path }}/Dockerfile.modified"

- name: Replace FROM directive
  lineinfile:
    path: "{{ modify_dir_path }}/Dockerfile.modified"
    regexp: "^FROM "
    line: "FROM {{ source_image }}"

- name: Add LABEL modified_append_tag={{ modified_append_tag }}
  lineinfile:
    path: "{{ modify_dir_path }}/Dockerfile.modified"
    insertafter: "^FROM "
    line: "LABEL modified_append_tag={{ modified_append_tag }}"

- name: Modify image from {{ modify_dir_path }}
  command: "{{ build_commands[container_build_tool] }} --tag {{ target_image | default(source_image) }}{{ modified_append_tag }} --file Dockerfile.modified --network host ./"
  #FIXME: buildah should not required root commands to build an image
  become: "{{ true if build_commands[container_build_tool] == 'buildah' else false }}"
  args:
    chdir: "{{ modify_dir_path }}"

**********
DECISION===>: Suspicious Comment
**********
=========================:::67:::END!!!=========================
=========================:::68:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-tripleo-modify-image/tasks/main.yml
**********
- import_tasks: precheck.yml
  tags:
    - always

- import_tasks: "{{ tasks_from | default('modify_image.yml') }}"

**********
DECISION===>: PASS
**********
=========================:::68:::END!!!=========================
=========================:::69:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-tripleo-modify-image/meta/main.yml
**********
galaxy_info:
  author: Steve Baker
  description: Modify container images built for TripleO
  company: Red Hat
  license: Apache 2.0
  min_ansible_version: 2.4

  platforms:
  - name: EL
    versions:
      - 7

  galaxy_tags:
    - docker
    - buildah
    - container
    - openstack
    - tripleo
    - packaging
    - system

dependencies: []

**********
DECISION===>: PASS
**********
=========================:::69:::END!!!=========================
=========================:::70:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-tripleo-modify-image/defaults/main.yml
**********
update_repo: ''
container_build_tool: 'docker'

**********
DECISION===>: PASS
**********
=========================:::70:::END!!!=========================
=========================:::71:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ansible-role-tripleo-modify-image/zuul.d/layout.yaml
**********
- project:
    templates:
      - tripleo-multinode-container-minimal
    check:
      jobs:
        - openstack-tox-linters
        - tripleo-ci-centos-7-scenario001-multinode-oooq-container
    gate:
      jobs:
        - openstack-tox-linters
        - tripleo-ci-centos-7-scenario001-multinode-oooq-container
      queue: tripleo
    post:
      jobs:
        - publish-openstack-python-branch-tarball

**********
DECISION===>: PASS
**********
=========================:::71:::END!!!=========================
=========================:::72:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/example-deploy-all-available-nodes.yaml
**********
# This is an example playbook utilizing role conditionals to permit
# deployment on available nodes.
#
# To utilize:
# export BIFROST_INVENTORY_SOURCE=ironic
# ansible-playbook -vvvv -i inventory/bifrost_inventory.py example-deploy-all-available-nodes.yaml
#
# NOTE(TheJulia): The format of this example will cause hosts to be deployed
# utilizing DHCP on eth0 of Ubuntu/Debian hosts. It is advisable you build
# your deployment image with the dhcp-all-interfaces element when deploying
# other operating systems or if your target node has multiple ethernet
# interfaces.
#
# NOTE(TheJulia): A user could utilize the os_ironic_facts module with another
# data source such as a CSV, YAML, or JSON file formats to query ironic, and
# the example role conditionals below to query current status and deploy to
# nodes.
---
- hosts: localhost
  connection: local
  name: "Collect facts"
  become: no
  gather_facts: yes
- hosts: baremetal
  name: "Create configuration drive files and deploy machines from inventory"
  become: no
  connection: local
  roles:
    - { role: bifrost-configdrives-dynamic, when: provision_state == "available" and maintenance | bool != true }
    - { role: bifrost-deploy-nodes-dynamic, when: provision_state == "available" and maintenance | bool != true }

**********
DECISION===>: PASS
**********
=========================:::72:::END!!!=========================
=========================:::73:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/enroll-dynamic.yaml
**********
---
- hosts: baremetal
  name: "Enroll hardware from inventory into Ironic"
  become: no
  gather_facts: no
  roles:
    - role: ironic-enroll-dynamic
      delegate_to: "{{ groups['target'][0] if groups['target'] is defined else 'localhost' }}"
    - role: ironic-inspect-node
      when: inspect_nodes | default('false') | bool == true
      delegate_to: "{{ groups['target'][0] if groups['target'] is defined else 'localhost' }}"

**********
DECISION===>: PASS
**********
=========================:::73:::END!!!=========================
=========================:::74:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/test-bifrost.yaml
**********
# Example command line to use:
# Create a VM:
# ansible-playbook -vvvv -i inventory/localhost test-bifrost-create-vm.yaml
# Set BIFROST_INVENTORY_SOURCE
# export BIFROST_INVENTORY_SOURCE=/tmp/baremetal.json
# Execute the installation and VM startup test.
# ansible-playbook -vvvv -i inventory/bifrost_inventory.py test-bifrost.yaml -e use_cirros=true -e testing_user=cirros
---
- hosts: localhost
  connection: local
  name: "Setting pre-test conditions"
  become: yes
  ignore_errors: yes
  tasks:
    # NOTE(TheJulia): While the test was created to run with five VMs,
    # in the interest of keeping the active memory footprint small,
    # should stop all of the VMs in advance, so we can proceed with
    # install and initial deploy.
  - name: Remove pre-existing leases file
    file: path=/var/lib/misc/dnsmasq.leases state=absent

- hosts: localhost
  connection: local
  name: "Executes install, enrollment, and testing in one playbook"
  become: no
  gather_facts: yes
  pre_tasks:
    - name: "Set ci_testing_zuul if it appears we are running in upstream OpenStack CI"
      set_fact:
         ci_testing: true
         ci_testing_zuul: true
         ironic_git_url: "{{ lookup('env', 'WORKSPACE') }}/openstack/ironic"
         ironicclient_git_url: "{{ lookup('env', 'WORKSPACE') }}/openstack/python-ironicclient"
         openstacksdk_git_url: "{{ lookup('env', 'WORKSPACE') }}/openstack/openstacksdk"
         shade_git_url: "{{ lookup('env', 'WORKSPACE') }}/openstack-infra/shade"
         dib_git_url: "/opt/git/openstack/diskimage-builder"
         ironicinspector_git_url: "{{ lookup('env', 'WORKSPACE') }}/openstack/ironic-inspector"
         ironicinspectorclient_git_url: "{{ lookup('env', 'WORKSPACE') }}/openstack/python-ironic-inspector-client"
         keystone_git_url: "/opt/git/openstack/keystone"
         reqs_git_url: "{{ lookup('env', 'WORKSPACE') }}/openstack/requirements"
         staging_drivers_git_url: "/opt/git/openstack/ironic-staging-drivers"
      # TODO(TheJulia) Fix the above paths to be consistent, because the NV job gets the dib
      # folder cloned, while the gate job does not.  Likely need to work out a semi-hybrid
      # solution.
      when: lookup('env', 'ZUUL_BRANCH') | length > 0
    - name: "Set ci_testing_zuul_changes if ZUUL_CHANGES is set"
      set_fact:
         ci_testing_zuul_changes: true
      when: lookup('env', 'ZUUL_CHANGES') | length > 0
    - name: "Override the ipv4_gateway setting"
      set_fact:
         ipv4_gateway: "192.168.122.1"
  roles:
    - { role: bifrost-prep-for-install, when: skip_install is not defined }
    - { role: bifrost-openstack-ci-prep, when: ci_testing_zuul is defined }
  environment:
    http_proxy: "{{ lookup('env','http_proxy') }}"
    https_proxy: "{{ lookup('env','https_proxy') }}"

- hosts: localhost
  connection: local
  name: "Executes install, enrollment, and testing in one playbook"
  become: yes
  gather_facts: yes
  pre_tasks:
    - name: "Collect process list if running in a CI System"
      command: ps aux
      when: ci_testing is defined
    - name: "Collect list of listening network sockets if running in a CI system"
      shell: netstat -apn|grep LISTEN
      when: ci_testing is defined
  roles:
    - role: bifrost-keystone-install
    - role: bifrost-ironic-install
      cleaning: false
      testing: true
    # NOTE(TheJulia): While the next step creates a ramdisk, some elements
    # do not support ramdisk-image-create as they invoke steps to cleanup
    # the ramdisk which causes ramdisk-image-create to believe it failed.
    - { role: bifrost-create-dib-image, dib_imagename: "{{ http_boot_folder }}/ipa", build_ramdisk: false, dib_os_element: "{{ ipa_dib_os_element|default('debian') }}", dib_os_release: "jessie", dib_elements: "ironic-agent {{ ipa_extra_dib_elements | default('') }}", dib_packages: "bsdmainutils", when: create_ipa_image | bool == true }
    # NOTE(TheJulia): This creates the guest image.
    - { role: bifrost-create-dib-image, dib_imagetype: "qcow2", dib_imagename: "{{deploy_image}}", dib_os_element: "debian", dib_os_release: "jessie", dib_elements: "vm enable-serial-console simple-init {{ extra_dib_elements|default('') }}", when: create_image_via_dib | bool == true and transform_boot_image | bool == false }
    - role: bifrost-keystone-client-config
      user: "{{ ansible_env.SUDO_USER | default(ansible_user_id) }}"
      clouds:
        bifrost:
          config_username: "{{ ironic.keystone.default_username }}"
          config_password: "{{ ironic.keystone.default_password }}"
          config_project_name: "baremetal"
          config_region_name: "{{ keystone.bootstrap.region_name }}"
          config_auth_url: "{{ keystone.bootstrap.public_url }}"
  environment:
    http_proxy: "{{ lookup('env','http_proxy') }}"
    https_proxy: "{{ lookup('env','https_proxy') }}"

- hosts: baremetal
  name: "Enroll node with Ironic"
  become: no
  connection: local
  roles:
    - role: ironic-enroll-dynamic
    - { role: ironic-inspect-node, when: inspect_nodes | default('false') | bool == true }
    - role: bifrost-test-inspection
      when: inspect_nodes | default('false') | bool == true

- hosts: localhost
  name: "Tests the use of openstack clients"
  connection: local
  tasks:
    - name: "List bare metal nodes using openstack client"
      command: openstack baremetal node list
      environment:
        OS_CLOUD: bifrost
    - name: "List introspection rules using openstack client"
      command: openstack baremetal introspection rule list
      environment:
        OS_CLOUD: "{% if enable_keystone | default(false) | bool %}bifrost{% else %}bifrost-inspector{% endif %}"
      when: enable_inspector | bool

- hosts: baremetal
  name: "Create configuration drive files and deploy machines"
  vars:
    multinode_testing: "{{ inventory_dhcp | bool == true }}"
  become: no
  connection: local
  roles:
    - role: bifrost-configdrives-dynamic
    - role: bifrost-deploy-nodes-dynamic

- hosts: baremetal
  name: "Prepare for deployment verification"
  become: no
  connection: local
  serial: 1
  roles:
    - role: bifrost-prepare-for-test-dynamic

# The testvm Host group is added by bifrost-prepare-for-test based
# on the contents of the CSV file.
- hosts: test
  name: "Tests connectivity to the VM"
  become: no
  gather_facts: no
  remote_user: "{{ testing_user }}"
  serial: 1
  any_errors_fatal: yes
  max_fail_percentage: 0
  roles:
    - role: bifrost-test-vm

- hosts: baremetal
  connection: local
  name: "Unprovisions the test node"
  become: no
  gather_facts: no
  roles:
    - role: bifrost-unprovision-node-dynamic
    - role: ironic-delete-dynamic

# The following tasks are intended to test DHCP functionality
- hosts: localhost
  connection: local
  name: "Start VMs that were not enrolled to ironic"
  become: yes
  vars:
    not_enrolled_data_file: /tmp/baremetal.json.rest
  tasks:
    # NOTE(TheJulia): Moved the power ON of the excess VMs until after
    # the other test VMs have been shutdown, in order to explicitly
    # validate that the dhcp config is working as expected and not
    # serving these requests.
  - name: Power on remaining test VMs
    virt:
      name: "{{item.key}}"
      state: running
    with_dict: "{{ lookup('file', not_enrolled_data_file) | from_json }}"
    ignore_errors: yes
    when: inventory_dhcp | bool == true
  - name: Wait 30 seconds
    pause:
      seconds: 30
    when: inventory_dhcp | bool == true

- hosts: localhost
  connection: local
  name: "Executes DHCP test script"
  become: yes
  gather_facts: yes
  vars:
    inventory_dhcp: "{{ inventory_dhcp | bool == true }}"
    inventory_dhcp_static_ip: "{{ inventory_dhcp_static_ip | bool == true }}"
  roles:
    - { role: bifrost-test-dhcp, when: inventory_dhcp | bool == true }
  environment:
    http_proxy: "{{ lookup('env','http_proxy') }}"
    https_proxy: "{{ lookup('env','https_proxy') }}"


**********
DECISION===>: PASS
**********
=========================:::74:::END!!!=========================
=========================:::75:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/test-bifrost-create-vm.yaml
**********
# Create a default VM
---
- hosts: localhost
  connection: local
  name: "Executes install, enrollment, and testing in one playbook"
  become: yes
  gather_facts: yes
  pre_tasks:
    - name: "Warn if baremetal_csv_file is defined"
      debug:
        msg: >
          "WARNING - 'baremetal_csv_file' variable is defined.
          Its use is deprecated. The file created will be in JSON format.
          Use 'baremetal_json_file' variable instead."
      when: baremetal_csv_file is defined
    - name: "Re-set baremetal json to csv file if defined"
      set_fact:
        baremetal_json_file: "{{ baremetal_csv_file }}"
      when: baremetal_csv_file is defined
    - name: "Set default baremetal.json file if not already defined"
      set_fact:
         baremetal_json_file: "/tmp/baremetal.json"
      when: baremetal_json_file is not defined
    - name: "Set ci_testing flag if a list of changes are found in the environment variables"
      set_fact:
         ci_testing: true
      when: lookup('env', 'ZUUL_CHANGES') | length > 0
    - name: "Set ci_testing_zuul if it appears we are running in upstream OpenStack CI"
      set_fact:
         ci_testing_zuul: true
      when: "'bare-trusty' in ansible_hostname"
    - name: "Collect process list if running in OpenStack CI"
      command: ps aux
      when: ci_testing_zuul is defined
    - name: "Collect list of listening network sockets if running in OpenStack CI"
      shell: netstat -apn|grep LISTEN
      when: ci_testing_zuul is defined
  roles:
    - role: bifrost-create-vm-nodes

**********
DECISION===>: PASS
**********
=========================:::75:::END!!!=========================
=========================:::76:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/cleanup-deployment-images.yaml
**********
---
- hosts: localhost
  connection: local
  name: "Remove the master_images folder and deployment kernel/ramdisk for clean redeployments when testing."
  become: yes
  gather_facts: yes
  tasks:
    - file: path="{{ironic_tftp_master_path}}" state=absent
    - file: path="{{ipa_kernel}}" state=absent
    - file: path="{{ipa_ramdisk}}" state=absent

**********
DECISION===>: PASS
**********
=========================:::76:::END!!!=========================
=========================:::77:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/deploy-dynamic.yaml
**********
---
- hosts: baremetal
  name: "Create configuration drive files and deploy machines from inventory"
  become: no
  gather_facts: no
  roles:
    - role: bifrost-configdrives-dynamic
      delegate_to: "{{ groups['target'][0] if groups['target'] is defined else 'localhost' }}"
    - role: bifrost-deploy-nodes-dynamic
      delegate_to: "{{ groups['target'][0] if groups['target'] is defined else 'localhost' }}"

**********
DECISION===>: PASS
**********
=========================:::77:::END!!!=========================
=========================:::78:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/install.yaml
**********
---
- hosts: target
  name: "Install Ironic on the target host."
  become: yes
  gather_facts: yes
  roles:
    - { role: bifrost-prep-for-install, when: skip_install is not defined }
    - bifrost-keystone-install
    - bifrost-ironic-install
    - role: bifrost-keystone-client-config
      user: "{{ ansible_env.SUDO_USER | default(ansible_user_id) }}"
      clouds:
        bifrost:
          config_username: "{{ ironic.keystone.default_username }}"
          config_password: "{{ ironic.keystone.default_password }}"
          config_project_name: "baremetal"
          config_region_name: "{{ keystone.bootstrap.region_name }}"
          config_auth_url: "{{ keystone.bootstrap.public_url }}"
        bifrost-admin:
          config_username: "{{ keystone.bootstrap.username }}"
          config_password: "{{ keystone.bootstrap.password }}"
          config_project_name: "{{ keystone.bootstrap.project_name }}"
          config_region_name: "{{ keystone.bootstrap.region_name }}"
          config_auth_url: "{{ keystone.bootstrap.public_url }}"
    - { role: bifrost-create-dib-image, dib_imagename: "{{ http_boot_folder }}/ipa", build_ramdisk: false, dib_os_element: "{{ ipa_dib_os_element|default('debian') }}", dib_elements: "ironic-agent {{ ipa_extra_dib_elements | default('') }}", when: create_ipa_image | bool == true }
    - { role: bifrost-create-dib-image, dib_imagename: "{{ deploy_image }}", dib_imagetype: "qcow2", dib_elements: "{{ dib_image_type|default('vm') }} enable-serial-console {{ dib_init_element|default('simple-init') }} {{ extra_dib_elements|default('') }}", when: create_image_via_dib | bool == true and transform_boot_image | bool == false }
  environment:
    http_proxy: "{{ lookup('env','http_proxy') }}"
    https_proxy: "{{ lookup('env','https_proxy') }}"
    no_proxy: "{{ lookup('env', 'no_proxy') }}"

**********
DECISION===>: Hardcoded Secret, Default Password
**********
=========================:::78:::END!!!=========================
=========================:::79:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/redeploy-dynamic.yaml
**********
# This playbook redeploys nodes by doing the following:
# 1) For each node in provision active state, unprovision the node
#    (ie. set the provision state to 'available'
# 2) Each node is given a configurable amount of time to transition
#    to 'available' state.
# 3) For each node now in 'available' state, deploy the node.
# 4) Each node is given a configurable amount of time to transition
#    to 'active' state.
#
# To utilize:
# export BIFROST_INVENTORY_SOURCE=<path to json, csv, or yaml data source>
# ansible-playbook -vvvv -i inventory/bifrost_inventory.py redeploy-dynamic.yaml
# NOTE: 'ironic' may be used as the data source, in which case ironic will
# will be queried for all the nodes.
#
# NOTE(TheJulia): The format of this example will cause hosts to be deployed
# utilizing DHCP on eth0 of Ubuntu/Debian hosts. It is advisable you build
# your deployment image with the dhcp-all-interfaces element when deploying
# other operating systems or if your target node has multiple ethernet
# interfaces.
---
- hosts: localhost
  connection: local
  name: "Collect facts"
  become: no
  gather_facts: yes
- hosts: baremetal
  name: "Unprovision the nodes"
  become: no
  connection: local
  pre_tasks:
    - name: "Pull initial ironic facts"
      os_ironic_facts:
        auth_type: "{{ auth_type | default(omit) }}"
        auth: "{{ auth | default(omit) }}"
        name: "{{ inventory_hostname }}"
        ironic_url: "{{ ironic_url }}"
        skip_items: []
  roles:
    - { role: bifrost-unprovision-node-dynamic, when: (provision_state == "active"
              or provision_state == "deploy failed"
              or provision_state == "error") and maintenance | bool != true }
  post_tasks:
    - name: "Pull ironic facts until provision state available"
      os_ironic_facts:
        auth_type: "{{ auth_type | default(omit) }}"
        auth: "{{ auth | default(omit) }}"
        name: "{{ inventory_hostname }}"
        ironic_url: "{{ ironic_url }}"
        skip_items: []
      register: result
      until: provision_state == "available"
      retries: "{{ available_state_wait_retries | default(15) }}"
      delay: "{{ provision_state_retry_interval | default(20) }}"
- hosts: baremetal
  name: "Activate the nodes"
  become: no
  connection: local
  roles:
    - { role: bifrost-configdrives-dynamic, when: provision_state == "available" and maintenance | bool != true }
    - { role: bifrost-deploy-nodes-dynamic, when: provision_state == "available" and maintenance | bool != true }
  post_tasks:
    - name: "Pull ironic facts until provision state active"
      os_ironic_facts:
        auth_type: "{{ auth_type | default(omit) }}"
        auth: "{{ auth | default(omit) }}"
        name: "{{ inventory_hostname }}"
        ironic_url: "{{ ironic_url }}"
        skip_items: []
      register: result
      until: provision_state == "active"
      retries: "{{ active_state_wait_retries | default(30) }}"
      delay: "{{ provision_state_retry_interval | default(20) }}"


**********
DECISION===>: PASS, (Although there is an information exposure in auth.default )
**********
=========================:::79:::END!!!=========================
=========================:::80:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/legacy/bifrost-integration-dibipa-debian/run.yaml
**********
- hosts: all
  name: Autoconverted job legacy-bifrost-integration-dibipa-debian from old job gate-bifrost-integration-dibipa-debian-ubuntu-xenial-nv
  roles:
    - role: bindep
      bindep_dir: "{{ ansible_user_dir }}/{{ zuul.projects['git.openstack.org/openstack/bifrost'].src_dir }}"

  tasks:

    - name: Ensure legacy workspace directory
      file:
        path: '{{ ansible_user_dir }}/workspace'
        state: directory

    - shell:
        cmd: |
          set -e
          set -x
          CLONEMAP=`mktemp`
          REQS_DIR=`mktemp -d`
          function cleanup {
              mkdir -p $WORKSPACE
              rm -rf $CLONEMAP $REQS_DIR
          }
          trap cleanup EXIT
          cat > $CLONEMAP << EOF
          clonemap:
            - name: $ZUUL_PROJECT
              dest: .
          EOF
          # zuul cloner works poorly if there are 2 names that are the
          # same in here.
          if [[ "$ZUUL_PROJECT" != "openstack/requirements" ]]; then
          cat >> $CLONEMAP << EOF
            - name: openstack/requirements
              dest: $REQS_DIR
          EOF
          fi
          /usr/zuul-env/bin/zuul-cloner -m $CLONEMAP --cache-dir /opt/git \
              git://git.openstack.org $ZUUL_PROJECT openstack/requirements
          # REQS_DIR is not set for openstack/requirements and there is also
          # no need to copy in this case.
          if [[ "$ZUUL_PROJECT" != "openstack/requirements" ]]; then
              cp $REQS_DIR/upper-constraints.txt ./
          fi
        executable: /bin/bash
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

    - shell:
        cmd: |
          set -u
          set -e
          set -x
          cd $WORKSPACE

          /usr/zuul-env/bin/zuul-cloner --cache-dir /opt/git \
            git://git.openstack.org \
            openstack/bifrost \
            openstack/diskimage-builder \
            openstack/ironic \
            openstack/python-ironicclient \
            openstack-infra/shade \
            openstack/openstacksdk \
            openstack/ironic-inspector \
            openstack/python-ironic-inspector-client \
            openstack/requirements
          export GIT_BASE=$(pwd)
          export UPPER_CONSTRAINTS_FILE=$WORKSPACE/upper-constraints.txt
          cd openstack/bifrost
          scripts/test-bifrost-build-images.sh
        executable: /bin/bash
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

**********
DECISION===>: PASS
**********
=========================:::80:::END!!!=========================
=========================:::81:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/legacy/bifrost-integration-dibipa-debian/post.yaml
**********
- hosts: all
  tasks:

    - name: Copy files from {{ ansible_user_dir }}/workspace/ on node
      synchronize:
        src: '{{ ansible_user_dir }}/workspace/'
        dest: '{{ zuul.executor.log_root }}'
        mode: pull
        copy_links: true
        verify_host: true
        rsync_opts:
          - --include=/logs/**
          - --include=*/
          - --exclude=*
          - --prune-empty-dirs

**********
DECISION===>: PASS
**********
=========================:::81:::END!!!=========================
=========================:::82:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/legacy/bifrost-integration-dhcp/run.yaml
**********
- hosts: all
  name: Autoconverted job legacy-bifrost-integration-dhcp from old job gate-bifrost-integration-dhcp-ubuntu-xenial-nv
  roles:
    - role: bindep
      bindep_dir: "{{ ansible_user_dir }}/{{ zuul.projects['git.openstack.org/openstack/bifrost'].src_dir }}"

  tasks:

    - name: Ensure legacy workspace directory
      file:
        path: '{{ ansible_user_dir }}/workspace'
        state: directory

    - shell:
        cmd: |
          set -e
          set -x
          CLONEMAP=`mktemp`
          REQS_DIR=`mktemp -d`
          function cleanup {
              mkdir -p $WORKSPACE
              rm -rf $CLONEMAP $REQS_DIR
          }
          trap cleanup EXIT
          cat > $CLONEMAP << EOF
          clonemap:
            - name: $ZUUL_PROJECT
              dest: .
          EOF
          # zuul cloner works poorly if there are 2 names that are the
          # same in here.
          if [[ "$ZUUL_PROJECT" != "openstack/requirements" ]]; then
          cat >> $CLONEMAP << EOF
            - name: openstack/requirements
              dest: $REQS_DIR
          EOF
          fi
          /usr/zuul-env/bin/zuul-cloner -m $CLONEMAP --cache-dir /opt/git \
              git://git.openstack.org $ZUUL_PROJECT openstack/requirements
          # REQS_DIR is not set for openstack/requirements and there is also
          # no need to copy in this case.
          if [[ "$ZUUL_PROJECT" != "openstack/requirements" ]]; then
              cp $REQS_DIR/upper-constraints.txt ./
          fi
        executable: /bin/bash
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

    - shell:
        cmd: |
          set -u
          set -e
          set -x
          cd $WORKSPACE

          /usr/zuul-env/bin/zuul-cloner --cache-dir /opt/git \
            git://git.openstack.org \
            openstack/bifrost \
            openstack/diskimage-builder \
            openstack/ironic \
            openstack/python-ironicclient \
            openstack-infra/shade \
            openstack/openstacksdk \
            openstack/ironic-inspector \
            openstack/python-ironic-inspector-client \
            openstack/requirements
          export GIT_BASE=$(pwd)
          export UPPER_CONSTRAINTS_FILE=$WORKSPACE/upper-constraints.txt
          cd openstack/bifrost
          scripts/test-bifrost-inventory-dhcp.sh
        executable: /bin/bash
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

**********
DECISION===>: PASS
**********
=========================:::82:::END!!!=========================
=========================:::83:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/legacy/bifrost-integration-dhcp/post.yaml
**********
- hosts: all
  tasks:

    - name: Copy files from {{ ansible_user_dir }}/workspace/ on node
      synchronize:
        src: '{{ ansible_user_dir }}/workspace/'
        dest: '{{ zuul.executor.log_root }}'
        mode: pull
        copy_links: true
        verify_host: true
        rsync_opts:
          - --include=/logs/**
          - --include=*/
          - --exclude=*
          - --prune-empty-dirs

**********
DECISION===>: PASS
**********
=========================:::83:::END!!!=========================
=========================:::84:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/legacy/bifrost-integration-tinyipa/run.yaml
**********
- hosts: all
  name: Autoconverted job legacy-bifrost-integration-tinyipa from old job gate-bifrost-integration-tinyipa-ubuntu-xenial
  roles:
    - role: bindep
      bindep_dir: "{{ ansible_user_dir }}/{{ zuul.projects['git.openstack.org/openstack/bifrost'].src_dir }}"

  tasks:

    - name: Set script name for testing without Keystone
      set_fact:
        script_name: scripts/test-bifrost.sh
      when: not (use_keystone | default(false) | bool)

    - name: Set script name for testing with Keystone
      set_fact:
        script_name: scripts/test-bifrost-keystone-auth.sh
      when: use_keystone | default(false) | bool

    - name: Ensure legacy workspace directory
      file:
        path: '{{ ansible_user_dir }}/workspace'
        state: directory

    - shell:
        cmd: |
          set -e
          set -x
          CLONEMAP=`mktemp`
          REQS_DIR=`mktemp -d`
          function cleanup {
              mkdir -p $WORKSPACE
              rm -rf $CLONEMAP $REQS_DIR
          }
          trap cleanup EXIT
          cat > $CLONEMAP << EOF
          clonemap:
            - name: openstack/bifrost
              dest: .
          EOF
          # zuul cloner works poorly if there are 2 names that are the
          # same in here.
          if [[ "$ZUUL_PROJECT" != "openstack/requirements" ]]; then
          cat >> $CLONEMAP << EOF
            - name: openstack/requirements
              dest: $REQS_DIR
          EOF
          fi
          /usr/zuul-env/bin/zuul-cloner -m $CLONEMAP --cache-dir /opt/git \
              git://git.openstack.org openstack/bifrost openstack/requirements
          # REQS_DIR is not set for openstack/requirements and there is also
          # no need to copy in this case.
          if [[ "$ZUUL_PROJECT" != "openstack/requirements" ]]; then
              cp $REQS_DIR/upper-constraints.txt ./
          fi
        executable: /bin/bash
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

    - shell:
        cmd: |
          set -u
          set -e
          set -x
          cd $WORKSPACE

          /usr/zuul-env/bin/zuul-cloner --cache-dir /opt/git \
            git://git.openstack.org \
            openstack/bifrost \
            openstack/ironic \
            openstack/python-ironicclient \
            openstack-infra/shade \
            openstack/openstacksdk \
            openstack/ironic-inspector \
            openstack/python-ironic-inspector-client \
            openstack/requirements
          export GIT_BASE=$(pwd)
          export UPPER_CONSTRAINTS_FILE=$WORKSPACE/upper-constraints.txt
          cd openstack/bifrost
          "{{ script_name }}"
        executable: /bin/bash
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

**********
DECISION===>: PASS
**********
=========================:::84:::END!!!=========================
=========================:::85:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/legacy/bifrost-integration-tinyipa/post.yaml
**********
- hosts: all
  tasks:

    - name: Copy files from {{ ansible_user_dir }}/workspace/ on node
      synchronize:
        src: '{{ ansible_user_dir }}/workspace/'
        dest: '{{ zuul.executor.log_root }}'
        mode: pull
        copy_links: true
        verify_host: true
        rsync_opts:
          - --include=/logs/**
          - --include=*/
          - --exclude=*
          - --prune-empty-dirs

**********
DECISION===>: PASS
**********
=========================:::85:::END!!!=========================
=========================:::86:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/ironic-enroll-dynamic/vars/main.yml
**********
---
# vars file for ironic-enroll-dynamic

**********
DECISION===>: PASS
**********
=========================:::86:::END!!!=========================
=========================:::87:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/ironic-enroll-dynamic/tasks/main.yml
**********
# Copyright (c) 2015 Hewlett-Packard Development Company, L.P.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
---
- name: "Collect facts"
  setup:

- name: "If in noauth mode, unset authentication parameters."
  set_fact:
    auth_type: None
    auth: {}
  when: noauth_mode is defined and noauth_mode | bool == true

- name: "Execute os_client_config to collect facts"
  os_client_config:
  no_log: yes
  when: noauth_mode is defined and noauth_mode | bool == false

# NOTE(TheJulia): The first record returned by os_client_config
# is utilized as the default. A user can still define the parameters
# if so desired.
- name: "Set os_client_config's auth parameters if not already set."
  set_fact:
    auth: "{{ openstack.clouds[0].auth }}"
    auth_type: "{{ openstack.clouds[0].auth_type }}"
  when: auth is undefined
  no_log: yes

- name: "Dynamic enrollment"
  os_ironic:
    cloud: "{{ cloud_name | default(omit) }}"
    auth_type: "{{ auth_type | default(omit) }}"
    auth: "{{ auth | default(omit) }}"
    ironic_url: "{{ ironic_url | default(omit) }}"
    driver: "{{ driver }}"
    uuid: "{{ uuid | default() }}"
    name: "{{ name | default() }}"
    state: present
    nics: "{{nics}}"
    properties: "{{ properties | default({}) }}"
    driver_info:
      power: "{{ driver_info.power }}"
      deploy:
        deploy_kernel: "{{ ipa_kernel_url }}"
        deploy_ramdisk: "{{ ipa_ramdisk_url }}"

**********
DECISION===>: PASS
**********
=========================:::87:::END!!!=========================
=========================:::88:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/ironic-enroll-dynamic/meta/main.yml
**********
---
galaxy_info:
  author: Ironic Developers
  description: Enrolls nodes into Ironic
  company: OpenStack
  license: Apache
  min_ansible_version: 2.0
  platforms:
  - name: EL
    versions:
    - 7
  - name: Debian
    versions:
    - wheezy
  - name: Ubuntu
    versions:
    - trusty
    - utopic
  categories:
  - cloud
  - cloud:openstack
dependencies: []

**********
DECISION===>: PASS
**********
=========================:::88:::END!!!=========================
=========================:::89:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/ironic-enroll-dynamic/defaults/main.yml
**********
---
ironic_url: "http://localhost:6385/"
file_url_port: "8080"
# Default network interface that bifrost will be attached to.
network_interface: "virbr0"

# Normally this would setting would be http in a bifrost installation
# without TLS. This setting allows a user to override the setting in case
# the local webserver has been updated to support HTTPS.
# Note: Users wishing to leverage HTTPS should reference the iPXE
# documentation at http://ipxe.org/crypto
ipa_file_protocol: "http"

ipa_kernel_url: "{{ ipa_file_protocol }}://{{ hostvars[inventory_hostname]['ansible_' + network_interface | replace('-', '_')]['ipv4']['address'] }}:{{file_url_port}}/ipa.vmlinuz"
ipa_ramdisk_url: "{{ ipa_file_protocol }}://{{ hostvars[inventory_hostname]['ansible_' + network_interface | replace('-', '_')]['ipv4']['address'] }}:{{file_url_port}}/ipa.initramfs"

noauth_mode: true

**********
DECISION===>: PASS
**********
=========================:::89:::END!!!=========================
=========================:::90:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/ironic-enroll-dynamic/handlers/main.yml
**********
---
# handlers file for ironic-enroll-dynamic

**********
DECISION===>: PASS
**********
=========================:::90:::END!!!=========================
=========================:::91:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-keystone-client-config/tasks/main.yml
**********
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.
---
- name: redefine cloud settings vars for backward compat
  set_fact:
    clouds:
      bifrost:
        config_username: "{{ config_username }}"
        config_password: "{{ config_password }}"
        config_project_name: "{{ config_project_name }}"
        config_region_name: "{{ config_region_name }}"
        config_auth_url: "{{ config_auth_url}}"
        config_project_domain_id: "{{ config_project_domain_id|default('default') }}"
        config_user_domain_id: "{{ config_user_domain_id|default('default') }}"
  when:
    - "{{ enable_keystone | default(false) | bool }}"
    - "{{ clouds is undefined }}"
    - "{{ config_username is defined }}"
    - "{{ config_password is defined }}"
    - "{{ config_project_name is defined }}"
    - "{{ config_region_name is defined }}"
    - "{{ config_auth_url is defined }}"

- name: "Ensure the ~/.config exists"
  file:
    name: "~{{ user | default('root') }}/.config"
    state: directory
    owner: "{{ user | default('root') }}"
    mode: 0700

- name: "Ensure ~/.config/openstack/ exists"
  file:
    name: "~{{ user | default('root') }}/.config/openstack"
    state: directory
    owner: "{{ user | default('root') }}"
    mode: 0700

- name: "Write clouds.yaml configuration from template"
  template:
    src: clouds.yaml.j2
    dest: "~{{ user | default('root') }}/.config/openstack/clouds.yaml"
    owner: "{{ user | default('root') }}"
    mode: 0600

- name: "Write openrc configuration from template"
  template:
    src: openrc.j2
    dest: "~{{ user | default('root') }}/openrc"
    owner: "{{ user | default('root') }}"
    mode: 0600

**********
DECISION===>: PASS
**********
=========================:::91:::END!!!=========================
=========================:::92:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-keystone-client-config/meta/main.yml
**********
---
galaxy_info:
  author: Ironic Developers
  description: Creates simple clouds.yaml file for Bifrost usage
  company: OpenStack
  license: Apache
  min_ansible_version: 2.0
  platforms:
  - name: EL
    versions:
    - 7
  - name: Debian
    versions:
    - wheezy
  - name: Ubuntu
    versions:
    - trusty
    - utopic
  categories:
  - cloud
  - cloud:openstack
dependencies: []

**********
DECISION===>: PASS
**********
=========================:::92:::END!!!=========================
=========================:::93:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-keystone-client-config/defaults/main.yml
**********
---
ironic_api_url: "http://localhost:6385"
ironic_inspector_api_url: "http://localhost:5050"

**********
DECISION===>: PASS
**********
=========================:::93:::END!!!=========================
=========================:::94:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-test-inspection/vars/main.yml
**********
---
# vars file for bifrost-test-inspection

**********
DECISION===>: PASS
**********
=========================:::94:::END!!!=========================
=========================:::95:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-test-inspection/tasks/main.yml
**********
# Copyright (c) 2018 StackHPC Ltd.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
---
- block:
    - name: Check node hardware inspection data
      command: "openstack baremetal introspection data save {{ uuid }}"
      register: inspection_data
      environment:
        OS_CLOUD: "{% if enable_keystone | default(false) | bool %}bifrost{% else %}bifrost-inspector{% endif %}"

    # TODO(mgoddard): More validation of data format and contents.
    - name: Validate the inspection data format
      assert:
        that:
          - "'inventory' in data"
          - "'memory' in inventory"
          - "'cpu' in inventory"
          - "'bmc_address' in inventory"
          - "'interfaces' in inventory"
          - "'disks' in inventory"
      vars:
        data: "{{ inspection_data.stdout | from_json }}"
        inventory: "{{ data.inventory }}"
  when: inspector_store_data_in_nginx | bool

**********
DECISION===>: PASS
**********
=========================:::95:::END!!!=========================
=========================:::96:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-test-inspection/meta/main.yml
**********
---
galaxy_info:
  author: Ironic Developers
  description: Tests inspection of nodes created by Bifrost.
  company: OpenStack
  license: Apache
  min_ansible_version: 1.9
  #
  # Below are all platforms currently available. Just uncomment
  # the ones that apply to your role. If you don't see your
  # platform on this list, let us know and we'll get it added!
  #
  platforms:
  #- name: EL
  #  versions:
  #  - all
  #  - 5
  #  - 6
  #  - 7
  #- name: GenericUNIX
  #  versions:
  #  - all
  #  - any
  #- name: Fedora
  #  versions:
  #  - all
  #  - 16
  #  - 17
  #  - 18
  #  - 19
  #  - 20
  #- name: SmartOS
  #  versions:
  #  - all
  #  - any
  #- name: opensuse
  #  versions:
  #  - all
  #  - 12.1
  #  - 12.2
  #  - 12.3
  #  - 13.1
  #  - 13.2
  #- name: Amazon
  #  versions:
  #  - all
  #  - 2013.03
  #  - 2013.09
  #- name: GenericBSD
  #  versions:
  #  - all
  #  - any
  #- name: FreeBSD
  #  versions:
  #  - all
  #  - 8.0
  #  - 8.1
  #  - 8.2
  #  - 8.3
  #  - 8.4
  #  - 9.0
  #  - 9.1
  #  - 9.1
  #  - 9.2
  #- name: Ubuntu
  #  versions:
  #  - all
  #  - lucid
  #  - maverick
  #  - natty
  #  - oneiric
  #  - precise
  #  - quantal
  #  - raring
  #  - saucy
    - trusty
  #- name: SLES
  #  versions:
  #  - all
  #  - 10SP3
  #  - 10SP4
  #  - 11
  #  - 11SP1
  #  - 11SP2
  #  - 11SP3
  #- name: GenericLinux
  #  versions:
  #  - all
  #  - any
  #- name: Debian
  #  versions:
  #  - all
  #  - etch
  #  - lenny
  #  - squeeze
  #  - wheezy
  #
  # Below are all categories currently available. Just as with
  # the platforms above, uncomment those that apply to your role.
  #
  categories:
  - cloud
  - cloud:openstack
  #- cloud:gce
  #- cloud:rax
  #- clustering
  #- database
  #- database:nosql
  #- database:sql
  #- development
  #- monitoring
  #- networking
  #- packaging
  #- system
  #- web
dependencies: []

**********
DECISION===>: PASS
**********
=========================:::96:::END!!!=========================
=========================:::97:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-test-inspection/defaults/main.yml
**********
---
# defaults file for bifrost-test-inspection

file_url_port: "8080"

# Whether to store introspection data using the local Nginx web server as an
# object storage service.
inspector_store_data_in_nginx: true

# When inspector_store_data_in_nginx is true, this is the URL of the Nginx
# 'Swift' API endpoint.
inspector_store_data_url: "http://localhost:{{ file_url_port }}"

**********
DECISION===>: PASS
**********
=========================:::97:::END!!!=========================
=========================:::98:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-test-inspection/handlers/main.yml
**********
---
# handlers file for bifrost-test-inspection

**********
DECISION===>: PASS
**********
=========================:::98:::END!!!=========================
=========================:::99:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-test-dhcp/vars/main.yml
**********
---
# vars file for bifrost-test-dhcp

**********
DECISION===>: PASS
**********
=========================:::99:::END!!!=========================
=========================:::100:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-test-dhcp/tasks/main.yml
**********
# Copyright (c) 2016 Hewlett-Packard Development Company, L.P.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
---
- name: Execute python dhcp check file
  become: true
  script: test-dhcp.py "{{inventory_dhcp}}" "{{inventory_dhcp_static_ip}}"

**********
DECISION===>: PASS
**********
=========================:::100:::END!!!=========================
=========================:::101:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-test-dhcp/meta/main.yml
**********
---
galaxy_info:
  author: Infra-cloud Developers
  description: Basic dnsmasq checks created by Bifrost.
  company: OpenStack
  license: Apache
  min_ansible_version: 1.9
  platforms:
  - name: Ubuntu
    versions:
    - trusty
  categories:
  - cloud
  - cloud:openstack
dependencies: []

**********
DECISION===>: PASS
**********
=========================:::101:::END!!!=========================
=========================:::102:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-test-dhcp/defaults/main.yml
**********
---
# defaults file for bifrost-test-dhcp

**********
DECISION===>: PASS
**********
=========================:::102:::END!!!=========================
=========================:::103:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-test-dhcp/handlers/main.yml
**********
---
# handlers file for bifrost-test-dhcp


**********
DECISION===>: PASS
**********
=========================:::103:::END!!!=========================
=========================:::104:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-keystone-install/tasks/start.yml
**********
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.
---
- name: "Reload systemd configuration"
  command: systemctl daemon-reload
  when: init_template == 'systemd_template.j2'

- name: "Ensure services are running with current config"
  service: name={{ item }} state=restarted enabled=yes
  with_items:
    - nginx
    - uwsgi

**********
DECISION===>: PASS
**********
=========================:::104:::END!!!=========================
=========================:::105:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-keystone-install/tasks/pip_install.yml
**********
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.
---

- name: set virtualenv_command
  set_fact:
    venv_command: "{{ hostvars[inventory_hostname].ansible_python.executable }} -m virtualenv"
  when: enable_venv|bool

- name: "Install {{ package }} package from pip using virtualenv"
  pip:
    name: "{{ package }}"
    state: "{{ state | default(omit) }}"
    version: "{{ version | default(omit) }}"
    virtualenv: "{{ bifrost_venv_dir }}"
    virtualenv_command: "{{ venv_command | default(omit) }}"
    extra_args: "{{ extra_args | default(omit) }}"
  register: pip_package_install_done
  until: pip_package_install_done|succeeded
  retries: 5
  delay: 10
  when: (source_install is not defined or source_install == false) and enable_venv|bool

- name: "Install {{ package }} package from pip without virtualenv"
  pip:
    name: "{{ package }}"
    state: "{{ state | default(omit) }}"
    version: "{{ version | default(omit) }}"
    extra_args: "{{ extra_args | default(omit) }}"
    requirements: "{{ requirements_file | default(omit) }}"
  register: pip_package_install_done
  until: pip_package_install_done|succeeded
  retries: 5
  delay: 10
  when: (source_install is not defined or source_install == false) and not enable_venv|bool

# NOTE (cinerama): We should be able to use the pip module here and
# possibly merge these two tasks when
# https://github.com/ansible/ansible-modules-core/pull/2600 lands.
- name: "Install from {{ sourcedir }} using pip"
  command: pip install --upgrade {{ sourcedir }} {{ extra_args | default('') }}
  register: pip_package_install_done
  until: pip_package_install_done|succeeded
  retries: 5
  delay: 10
  when: source_install is defined and (source_install | bool == true)
  environment: "{{ bifrost_venv_env if enable_venv else {} }}"

**********
DECISION===>: PASS
**********
=========================:::105:::END!!!=========================
=========================:::106:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-keystone-install/tasks/bootstrap.yml
**********
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.
---
# NOTE(TheJulia): There is significant commonality between this playbook
# and the bifrost bootstrap process.
- name: "If VENV is set in the environment, enable installation into venv"
  set_fact:
    enable_venv: true
    uwsgi_venv: "{{ bifrost_venv_env.get('VIRTUAL_ENV', '') }}"
  when: lookup('env', 'VENV') | length > 0

- name: "Get uwsgi install location"
  shell: echo $(dirname $(which uwsgi))
  register: uwsgi_install_prefix
  environment: "{{ bifrost_venv_env if enable_venv else {} }}"

- name: "Get keystone-wsgi-admin location"
  shell: echo $(dirname $(which keystone-wsgi-admin))
  register: keystone_install_prefix
  environment: "{{ bifrost_venv_env if enable_venv else {} }}"

# NOTE(sean-k-mooney) only the RabbitMQ server and MySQL db are started
# during bootstrapping. all other services are started in the Start phase.
- name: "Start database service"
  service: name={{ mysql_service_name }} state=started enabled=yes

- name: "Start rabbitmq-server"
  service: name=rabbitmq-server state=started enabled=yes

# NOTE(cinerama): on some systems, rabbit may not be ready when we want to
# make changes to users if we don't wait first
- name: "Wait for rabbitmq"
  wait_for: port="{{ keystone.message_queue.port | default('5672') }}" delay=5

- name: "Ensure guest user is removed from rabbitmq"
  rabbitmq_user:
    user: "guest"
    state: absent
    force: yes

- name: "Create keystone user in RabbitMQ"
  rabbitmq_user:
    user: "{{ keystone.message_queue.username }}"
    password: "{{ keystone.message_queue.password }}"
    force: yes
    state: present
    configure_priv: ".*"
    write_priv: ".*"
    read_priv: ".*"
  no_log: true

- name: "Set mysql_username if environment variable mysql_user is set"
  set_fact:
    mysql_username: "{{ lookup('env', 'mysql_user') }}"
  when: lookup('env', 'mysql_user') | length > 0
  no_log: true

- name: "Set mysql_password if environment variable mysql_pass is set"
  set_fact:
    mysql_password: "{{ lookup('env', 'mysql_pass') }}"
  when: lookup('env', 'mysql_pass') | length > 0
  no_log: true

- name: Setting MySQL socket fact
  set_fact:
    mysql_socket_path: "/var/{% if ansible_os_family | lower == 'redhat' %}lib{% else %}run{% endif %}/{% if ansible_os_family | lower == 'debian' %}mysqld/mysqld.sock{% else %}mysql/mysql.sock{% endif %}"
  when: ansible_version.full is version_compare('2.6.5', '>=')

- name: "MySQL - Creating DB"
  mysql_db:
    login_unix_socket: "{{ mysql_socket_path | default(omit) }}"
    name: "{{ keystone.database.name }}"
    state: present
    encoding: utf8
    login_user: "{{ mysql_username | default(None) }}"
    login_password: "{{ mysql_password | default(None) }}"
  register: test_created_keystone_db
  when: keystone.database.host == 'localhost'

- name: "MySQL - Creating user for keystone"
  mysql_user:
    login_unix_socket: "{{ mysql_socket_path | default(omit) }}"
    name: "{{ keystone.database.username }}"
    password: "{{ keystone.database.password }}"
    priv: "{{ keystone.database.name }}.*:ALL"
    state: present
    login_user: "{{ mysql_username | default(None) }}"
    login_password: "{{ mysql_password | default(None) }}"
  when: keystone.database.host == 'localhost'

- name: "Create an keystone service group"
  group:
    name: "keystone"

- name: "Create an keystone service user"
  user:
    name: "keystone"
    group: "keystone"

- name: "Ensure /etc/keystone exists"
  file:
    name: "/etc/keystone"
    state: directory
    owner: "keystone"
    group: "keystone"
    mode: 0755

- name: "Retrieve Keystone major version"
  command: keystone-manage --version
  register: keystone_version_str
  environment: "{{ bifrost_venv_env if enable_venv else {} }}"

- name: "Set Keystone major version"
  set_fact:
    keystone_version: "{{ keystone_version_str.stderr.split('.')[0] }}"

- name: "Set Keystone provider to uuid"
  set_fact:
    keystone_provider: "uuid"
  when: keystone_version | int < 13

- name: "Set Keystone provider to fernet"
  set_fact:
    keystone_provider: "fernet"
  when: keystone_version | int >= 13

- name: "Write keystone configuration from template"
  template:
    src: keystone.conf.j2
    dest: "/etc/keystone/keystone.conf"
    owner: "keystone"
    group: "keystone"
    mode: 0755

- name: "Apply/Update keystone DB Schema"
  command: keystone-manage db_sync
  environment: "{{ bifrost_venv_env if enable_venv else {} }}"

- name: "Setup Fernet key repositories"
  command: >
    keystone-manage fernet_setup
    --keystone-user="{{ nginx_user }}" --keystone-group="{{ nginx_user }}"
  environment: "{{ bifrost_venv_env if enable_venv else {} }}"
  when: keystone_version | int >= 13

- name: "Setup Keystone Credentials"
  command: >
    keystone-manage credential_setup
    --keystone-user="{{ nginx_user }}" --keystone-group="{{ nginx_user }}"
  environment: "{{ bifrost_venv_env if enable_venv else {} }}"

- name: "Setting external Keystone public URL"
  set_fact:
    keystone_public_url: "{{ keystone.bootstrap.public_url | replace('127.0.0.1', public_ip | default(hostvars[inventory_hostname]['ansible_' + ans_network_interface]['ipv4']['address'])) }}"
  when: use_public_urls | default(false) | bool

- name: "Setting internal Keystone URL"
  set_fact:
    keystone_private_url: "{{ keystone.bootstrap.internal_url | replace('127.0.0.1', private_ip) }}"
  when: private_ip is defined and private_ip | length > 0

- name: "Bootstrap Keystone Database"
  command: >
    keystone-manage bootstrap
    --bootstrap-username="{{ keystone.bootstrap.username }}"
    --bootstrap-password="{{ keystone.bootstrap.password }}"
    --bootstrap-project-name="{{ keystone.bootstrap.project_name }}"
    --bootstrap-service-name="keystone"
    --bootstrap-admin-url="{{ keystone.bootstrap.admin_url }}"
    --bootstrap-public-url="{{ keystone_public_url | default(keystone.bootstrap.public_url) }}"
    --bootstrap-internal-url="{{ keystone_private_url | default(keystone.bootstrap.internal_url) }}"
    --bootstrap-region-id="{{ keystone.bootstrap.region_name }}"
  environment: "{{ bifrost_venv_env if enable_venv else {} }}"
  when: >
    test_created_keystone_db.changed | bool == true and
    keystone.bootstrap.enabled | bool == true and
    keystone.database.host == 'localhost'

- name: "Reserve keystone admin port"
  sysctl:
    name: "net.ipv4.ip_local_reserved_ports"
    value: 35357
    sysctl_set: yes
    state: present
    reload: yes

- name: "Ensure /var/www/keystone exists"
  file:
    name: "/var/www/keystone"
    state: directory
    owner: "keystone"
    group: "{{ nginx_user }}" # TODO(TheJulia): Split webserver user/group.
    mode: 0755

- name: "Add keystone to web server group"
  user:
    name: "keystone"
    append: yes
    groups: "{{nginx_user}}" # TODO(TheJulia): Split webserver user/group.

- name: "Make folder for keystone logs"
  file:
    name: "/var/log/nginx/keystone"
    state: directory
    owner: "{{ nginx_user }}"
    group: "{{ nginx_user }}" # TODO(TheJulia): Split webserver user/group.
    mode: 0755

# Note(ashestakov): "copy" module in ansible doesn't support recursive
# copying on remote host. "cp" command used instead.
- name: "Copy keystone-wsgi-public  to /var/www/keystone/public"
  command: cp -r "{{ keystone_install_prefix.stdout }}/keystone-wsgi-public" /var/www/keystone/public

- name: "Ensure owner and mode of keystone-wsgi-public"
  file:
    path: /var/www/keystone/public
    owner: "keystone"
    group: "{{nginx_user}}"
    mode: 0754

# Note(ashestakov): "copy" module in ansible doesn't support recursive
# copying on remote host. "cp" command used instead.
- name: "Copy keystone-wsgi-admin to /var/www/keystone/admin"
  command: cp -r "{{ keystone_install_prefix.stdout }}/keystone-wsgi-admin" /var/www/keystone/admin

- name: "Ensure owner and mode of keystone-wsgi-admin"
  file:
    path: /var/www/keystone/admin
    owner: "keystone"
    group: "{{nginx_user}}"
    mode: 0754

- name: "Ensure /etc/uwsgi exists"
  file:
    name: "/etc/uwsgi"
    state: directory
    owner: "{{ nginx_user }}"
    group: "{{ nginx_user }}" # TODO(TheJulia): Split webserver user/group.
    mode: 0755

- name: "Ensure /etc/uwsgi/apps-available exists"
  file:
    name: "/etc/uwsgi/apps-available"
    state: directory
    owner: "{{ nginx_user }}"
    group: "{{ nginx_user }}" # TODO(TheJulia): Split webserver user/group.
    mode: 0755

- name: "Ensure /etc/uwsgi/apps-enabled exists"
  file:
    name: "/etc/uwsgi/apps-enabled"
    state: directory
    owner: "{{ nginx_user }}"
    group: "{{ nginx_user }}" # TODO(TheJulia): Split webserver user/group.
    mode: 0755

- name: "Place keystone public uwsgi config"
  template:
    src: keystone-public.ini.j2
    dest: /etc/uwsgi/apps-available/keystone-public.ini
    owner: "{{ nginx_user }}"
    group: "{{ nginx_user }}" # TODO(TheJulia): Split webserver user/group.
    mode: 0755

- name: "Place keystone admin uwsgi config"
  template:
    src: keystone-admin.ini.j2
    dest: /etc/uwsgi/apps-available/keystone-admin.ini
    owner: "{{ nginx_user }}"
    group: "{{ nginx_user }}" # TODO(TheJulia): Split webserver user/group.
    mode: 0755

- name: "Enable keystone-public in uwsgi"
  file:
    src: "/etc/uwsgi/apps-available/keystone-public.ini"
    dest: "/etc/uwsgi/apps-enabled/keystone-public.ini"
    state: link

- name: "Enable keystone-admin in uwsgi"
  file:
    src: "/etc/uwsgi/apps-available/keystone-admin.ini"
    dest: "/etc/uwsgi/apps-enabled/keystone-admin.ini"
    state: link

- name: "Place nginx core configuration"
  # TODO(TheJulia): Refactor this out so we don't have anything related to
  # bifrost it's self in the main config file.
  template:
    src: nginx.conf.j2
    dest: /etc/nginx/nginx.conf
    owner: "{{ nginx_user }}"
    group: "{{ nginx_user }}" # TODO(TheJulia): Split webserver user/group.
    mode: 0755

- name: "Place nginx configuration for keystone"
  # TODO(TheJulia): Refactor this so we use sites-enabled, but bifrost's
  # handling of co-existence needs to be cleaned up first.
  template:
    src: nginx_conf.d_bifrost-keystone.conf.j2
    dest: /etc/nginx/conf.d/bifrost-keystone.conf
    owner: "{{ nginx_user }}"
    group: "{{ nginx_user }}" # TODO(TheJulia): Split webserver user/group.
    mode: 0755

- name: "Place uwsgi services"
  template:
    src: "{{ init_template }}"
    dest: "{{ init_dest_dir }}{{ item.service_name }}{{ init_ext }}"
    owner: "root"
    group: "root"
  with_items:
    - { service_path: "{{ uwsgi_install_prefix.stdout | default('') }}",
        service_name: 'uwsgi',
        username: "{{ nginx_user }}",
        exec_start_pre: "/usr/bin/install -m 755 -o {{ nginx_user }} -g {{ nginx_user }} -d /run/uwsgi",
        args: '--master --emperor /etc/uwsgi/apps-enabled'} # TODO(TheJulia): Split webserver user/group.

# NOTE(ashestakov) https://github.com/ansible/ansible-modules-core/issues/3764
- name: "Remove uwsgi sysvinit init script"
  command: update-rc.d -f uwsgi remove
  ignore_errors: yes

**********
DECISION===>: Hardcoded Secret
**********
=========================:::106:::END!!!=========================
=========================:::107:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-keystone-install/tasks/install.yml
**********
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.
---
- import_role:
    name: venv_python_path

- name: "Install packages"
  action: "{{ ansible_pkg_mgr }} name={{ item }} state=present"
  with_items: "{{ required_packages }}"
  environment: "{{ venv }}"

# NOTE(TheJulia) While we don't necessarilly require /opt/stack any longer
# and it should already be created by the Ansible setup, we will leave this
# here for the time being.
- name: "Ensure /opt/stack is present"
  file: name=/opt/stack state=directory owner=root group=root
  when: skip_install is not defined

# NOTE(TheJulia): Part of Bifrost's install does this as well, but
# duplicating here as we are installing a separate service with this.
# We may wish to refactor this at a later point in time.
- name: "Install configparser in venv if using"
  include: pip_install.yml
    package=configparser
    virtualenv=bifrost_venv_dir
    extra_args="-c {{ upper_constraints_file }}"
  when:
    - skip_install is not defined
    - enable_venv | bool == true

- name: "Install pymysql in venv if using"
  include: pip_install.yml
    package=pymysql
    virtualenv=bifrost_venv_dir
    extra_args="-c {{ upper_constraints_file }}"
  when:
    - skip_install is not defined
    - enable_venv | bool == true

- name: "Install python-openstackclient in venv if using"
  include: pip_install.yml
    package=python-openstackclient
    virtualenv=bifrost_venv_dir
    extra_args="-c {{ upper_constraints_file }}"
  when:
    - skip_install is not defined
    - enable_venv | bool == true

- name: "Install keystone in venv if using"
  include: pip_install.yml
    package=keystone
    virtualenv=bifrost_venv_dir
    state=latest
    sourcedir={{ keystone_git_folder }}
    source_install={{ keystone_source_install | bool }}
    extra_args="--no-cache-dir --upgrade {{ pip_opts }} -c {{ upper_constraints_file }}"
  when:
    - skip_install is not defined
    - enable_venv | bool == true

- name: "Install configparser if not using a venv"
  include: pip_install.yml
    package=configparser
    extra_args="-c {{ upper_constraints_file }}"
  when:
    - skip_install is not defined
    - enable_venv | bool == false

- name: "Install pymysql if not using a venv"
  include: pip_install.yml
    package=pymysql
    extra_args="-c {{ upper_constraints_file }}"
  when:
    - skip_install is not defined
    - enable_venv | bool == false

- name: "Install python-openstackclient if not using a venv"
  include: pip_install.yml
    package=python-openstackclient
    extra_args="-c {{ upper_constraints_file }}"
  when:
    - skip_install is not defined
    - enable_venv | bool == false

- name: "Install keystone if not using a venv"
  include: pip_install.yml
    package=keystone
    state=latest
    sourcedir={{ keystone_git_folder }}
    source_install={{ keystone_source_install | bool }}
    extra_args="--no-cache-dir --upgrade {{ pip_opts }} -c {{ upper_constraints_file }}"
  when:
    - skip_install is not defined
    - enable_venv | bool == false

**********
DECISION===>: Hardcoded Secret
**********
=========================:::107:::END!!!=========================
=========================:::108:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-keystone-install/tasks/main.yml
**********
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.
---
# NOTE(cinerama) dummy-defaults.yml is an empty defaults file. We use it
# here to ensure that with_first_found won't fail should we not have
# defaults for a particular distribution, version, etc.
- name: Include OS family-specific defaults
  include_vars: "{{ item }}"
  with_first_found:
    - "../defaults/required_defaults_{{ ansible_os_family }}_family.yml"
    - "../defaults/dummy-defaults.yml"

- name: Include OS distribution-specific defaults
  include_vars: "{{ item }}"
  with_first_found:
    - "../defaults/required_defaults_{{ ansible_distribution }}.yml"
    - "../defaults/dummy-defaults.yml"

- name: Include OS version-specific defaults
  include_vars: "{{ item }}"
  with_first_found:
    - "../defaults/required_defaults_{{ ansible_distribution }}_{{ ansible_distribution_release }}.yml"
    - "../defaults/required_defaults_{{ ansible_distribution }}_{{ ansible_distribution_version }}.yml"
    - "../defaults/dummy-defaults.yml"

- name: "Install Keystone"
  include: install.yml
  when: enable_keystone is defined and enable_keystone |bool == True and skip_package_install | bool != True

- name: "Bootstrap Keystone"
  include: bootstrap.yml
  when: enable_keystone is defined and enable_keystone |bool == True and skip_bootstrap | bool != True

- name: "Start Keystone services"
  include: start.yml
  when: enable_keystone is defined and enable_keystone |bool == True and skip_start | bool != True

**********
DECISION===>: PASS
**********
=========================:::108:::END!!!=========================
=========================:::109:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-keystone-install/meta/main.yml
**********
---
galaxy_info:
  author: Ironic Developers
  description: Install keystone for Bifrost
  company: OpenStack
  license: Apache
  min_ansible_version: 2.1
  platforms:
  - name: Ubuntu
    versions:
    - xenial
  categories:
  - cloud
  - cloud:openstack
dependencies: []

**********
DECISION===>: PASS
**********
=========================:::109:::END!!!=========================
=========================:::110:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-keystone-install/defaults/required_defaults_Debian_jessie.yml
**********
---
init_template: systemd_template.j2
init_dest_dir: /usr/lib/systemd/system/
init_ext: .service
nginx_user: www-data
mysql_service_name: mysql
required_packages:
  - mysql-server
  - rabbitmq-server
  - python-dev
  - python-mysqldb
  - python-configparser
  - libffi-dev
  - libxslt1-dev
  - libssl-dev
  - libxml2-dev
  - nginx
  - uwsgi
  - uwsgi-core
  - uwsgi-plugin-python

**********
DECISION===>: PASS
**********
=========================:::110:::END!!!=========================
=========================:::111:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-keystone-install/defaults/required_defaults_RedHat_family.yml
**********
---
init_template: systemd_template.j2
init_dest_dir: /usr/lib/systemd/system/
init_ext: .service
ipxe_dir: /usr/share/ipxe/
ipxe_full_binary: ipxe.lkrn
sgabios_dir: /usr/share/sgabios/
nginx_user: nginx
virt_group: libvirt
mysql_service_name: mariadb
tftp_service_name: tftp
required_packages:
  - mariadb-server
  - rabbitmq-server
  - python-devel
  - MySQL-python
  - python-iniparse
  - libffi-devel
  - libxslt-devel
  - openssl-devel
  - libxml2-devel
  - nginx
  - uwsgi
  - uwsgi-plugin-python

**********
DECISION===>: PASS
**********
=========================:::111:::END!!!=========================
=========================:::112:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-keystone-install/defaults/required_defaults_Fedora_22.yml
**********
---
# NOTE(cinerama): On Fedora 22, ansible 1.9, ansible_pkg_mgr
# defaults to yum, which may not be installed. This can be safely
# removed when we start using an ansible release which prefers dnf.
ansible_pkg_mgr: "dnf"

**********
DECISION===>: PASS
**********
=========================:::112:::END!!!=========================
=========================:::113:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-keystone-install/defaults/dummy-defaults.yml
**********
---
# NOTE(cinerama) This file is intentionally left blank - do not
# add variables here.

**********
DECISION===>: PASS
**********
=========================:::113:::END!!!=========================
=========================:::114:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-keystone-install/defaults/required_defaults_Suse_family.yml
**********
---
init_template: systemd_template.j2
init_dest_dir: /usr/lib/systemd/system/
init_ext: .service
mysql_service_name: mysql
required_packages:
  - python-selinux
  - mariadb
  - rabbitmq-server
  - python-devel
  - python-MySQL-python
  - python-iniparse
  - libffi-devel
  - libxslt-devel
  - libopenssl-devel
  - libxml2-devel
  - nginx
  - uwsgi
  - uwsgi-python

**********
DECISION===>: PASS
**********
=========================:::114:::END!!!=========================
=========================:::115:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-keystone-install/defaults/required_defaults_Ubuntu_16.04.yml
**********
---
init_template: systemd_template.j2
init_dest_dir: /lib/systemd/system/
init_ext: .service
required_packages:
  - mysql-server
  - rabbitmq-server
  - python-dev
  - python-mysqldb
  - python-configparser
  - libffi-dev
  - libxslt1-dev
  - libssl-dev
  - libxml2-dev
  - nginx
  - uwsgi
  - uwsgi-core
  # - python-django-uwsgi - This may not be needed
  - uwsgi-plugin-python
  - python-pip
  - python-pymysql

**********
DECISION===>: PASS
**********
=========================:::115:::END!!!=========================
=========================:::116:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-keystone-install/defaults/required_defaults_Debian_family.yml
**********
---
init_template: upstart_template.j2
init_dest_dir: /etc/init/
init_ext: .conf
nginx_user: www-data
mysql_service_name: mysql
required_packages:
  - mysql-server
  - rabbitmq-server
  - python-dev
  - python-mysqldb
  - python-configparser
  - libffi-dev
  - libxslt1-dev
  - libssl-dev
  - libxml2-dev
  - nginx
  - uwsgi
  - uwsgi-core
  # - python-django-uwsgi - This may not be needed
  - uwsgi-plugin-python

**********
DECISION===>: PASS
**********
=========================:::116:::END!!!=========================
=========================:::117:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-keystone-install/defaults/main.yml
**********
---
keystone_source_install: true
# *_git_url can be overridden by local clones for offline installs
keystone_git_url: https://git.openstack.org/openstack/keystone
keystone_git_folder: /opt/stack/keystone

# set to true to skip installing ironic dependencies
skip_package_install: False
# set to true to skip generation of configs, ironic db and rabbitmq configuration
skip_bootstrap: False
# set to true to skip starting ironic services and dependencies
skip_start: False

# Parameters for connecting to mysql for database manipulation.
mysql_username: "root"
mysql_password: ""

# Support for CORS configuration
# By default CORS support is disabled.
enable_cors: false
# Origin to accept for CORS requests
cors_allowed_origin: "http://localhost:8000"
# bifrost utilizes noauth mode by default and as such
# the setting should be set to false. This setting should
# not need to be modified by the user.
enable_cors_credential_support: false

# Defaults required by this role that are normally inherited via
# other roles.
file_url_port: 8080
http_boot_folder: /httpboot

# Settings related to installing bifrost in a virtual environment
enable_venv: false
bifrost_venv_dir: "{{ lookup('env', 'VENV') | default('/opt/stack/bifrost') }}"
bifrost_venv_env:
  VIRTUAL_ENV: "{{ bifrost_venv_dir }}"
  PATH: "{{ bifrost_venv_dir }}/bin:{{ ansible_env.PATH }}" # include regular path via lookup env
  pydoc: "python -m pydoc"


keystone:
  debug: true
  bootstrap:
    enabled: true
    username: admin
    password: ChangeThisPa55w0rd
    project_name: admin
    admin_url: "http://127.0.0.1:35357/v3/"
    public_url: "http://127.0.0.1:5000/v3/"
    internal_url: "http://127.0.0.1:5000/v3/"
    region_name: "RegionOne"
  message_queue:
    username: keystone
    password: ChangeThisPa55w0rd
    host: localhost
    port: 5672
  database:
    name: keystone
    username: keystone
    password: ChangeThisPa55w0rd
    host: localhost

# NOTE(hwoarang): openSUSE distros may come with recent pip versions so
# upgrade only what's necessary
pip_opts: "{{ ((ansible_os_family | lower == 'suse') or (enable_venv | bool)) | ternary('--upgrade-strategy only-if-needed', '--force-reinstall') }}"

**********
DECISION===>: Hardcoded Secret, Empty Password
**********
=========================:::117:::END!!!=========================
=========================:::118:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-keystone-install/defaults/required_defaults_Ubuntu_15.04.yml
**********
---
init_template: systemd_template.j2
init_dest_dir: /lib/systemd/system/
init_ext: .service

**********
DECISION===>: PASS
**********
=========================:::118:::END!!!=========================
=========================:::119:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-keystone-install/defaults/required_defaults_Ubuntu_15.10.yml
**********
---
init_template: systemd_template.j2
init_dest_dir: /lib/systemd/system/
init_ext: .service

**********
DECISION===>: PASS
**********
=========================:::119:::END!!!=========================
=========================:::120:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/venv_python_path/tasks/main.yml
**********
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.
---
- name: "If VENV is set in the environment, enable installation into venv"
  set_fact:
    enable_venv: true
  when: lookup('env', 'VENV') | length > 0

- name: "Retrieve venv python path"
  shell: "/bin/echo -e \"import sys\\nprint(':'.join(sys.path))\" | {{ ansible_python.get('executable', '/usr/bin/python').split('/')[-1] }}"
  environment: "{{ bifrost_venv_env | default({}) }}"
  register: venv_pythonpath_result
  when: enable_venv

- name: "Compute venv python path"
  set_fact:
    venv_pythonpath:
      PYTHONPATH: "{{ venv_pythonpath_result.get('stdout', '') }}"
  when: enable_venv

- name: "Compute proper complete venv including proper Python path"
  set_fact:
    venv: "{{ venv | default({}) | combine(bifrost_venv_env | default({})) | combine(venv_pythonpath | default({})) }}"

**********
DECISION===>: PASS
**********
=========================:::120:::END!!!=========================
=========================:::121:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-create-vm-nodes/vars/main.yml
**********
---
# vars file for bifrost-create-vm-nodes

**********
DECISION===>: PASS
**********
=========================:::121:::END!!!=========================
=========================:::122:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-create-vm-nodes/tasks/create_vm.yml
**********
# Copyright (c) 2017 Mirantis Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Create a VM and volume for it, save its MAC address
---
# NOTE(pas-ha) item here refers to name of the test vm
- set_fact:
    vm_name: "{{ item }}"
    vm_log_file: "{{ test_vm_logdir }}/{{ item }}_console.log"
    vm_host_group: "{{ test_vm_default_groups }}"

- set_fact:
    vm_host_group: "{{ test_vm_default_groups | union(test_vm_groups[vm_name]) }}"
  when: test_vm_groups[vm_name] is defined

- name: set prealloc arg for Debian
  set_fact:
    prealloc: "--prealloc-metadata"
  when:
    - ansible_os_family == 'Debian'
    - test_vm_libvirt_uri == 'qemu:///system'

- name: list info on pools
  virt_pool:
    command: facts
    uri: "{{ test_vm_libvirt_uri }}"

- name: list existing vms
  virt:
    command: list_vms
  register: existing_vms

# NOTE(pas-ha) wrapping in block/rescue to have diagnostic output, requires Ansible>=2
- block:
  # NOTE(pas-ha) Ansible still lacks modules to operate on libvirt volumes
  # NOTE(pas-ha) adding extra 1G for disk size to accomodate for partition table / configdrive
  - name: create volume for vm
    command: >
      virsh --connect {{ test_vm_libvirt_uri }}
      vol-create-as {{ test_vm_storage_pool }} {{ vm_name }}.qcow2
      {{ test_vm_disk_gib | int + 1 }}G
      --format qcow2 {{ prealloc|default("") }}
    when: (vm_name + '.qcow2') not in ansible_libvirt_pools[test_vm_storage_pool].volumes

  - name: set path to the volume created
    set_fact:
      vm_volume_path: "{{ ansible_libvirt_pools[test_vm_storage_pool].path }}/{{ vm_name }}.qcow2"

  - name: pre-touch the vm volume
    file:
      state: touch
      path: "{{ vm_volume_path }}"
    when: test_vm_libvirt_uri == 'qemu:///system'

  # NOTE(TheJulia): CentOS default installs with an XFS root, and chattr
  # fails to set +C on XFS.  This could be more elegant, however the use
  # case is for CI testing.
  - name: set copy-on-write for volume on non-CentOS systems
    command: chattr +C {{ vm_volume_path }}
    ignore_errors: yes
    when:
      - ansible_distribution != 'CentOS'
      - test_vm_libvirt_uri == 'qemu:///system'

  - name: create_vm
    virt:
      command: define
      name: "{{ vm_name }}"
      uri: "{{ test_vm_libvirt_uri }}"
      xml: "{{ lookup('template', 'testvm.xml.j2') }}"

  rescue:
    - name: "Execute `dmesg` to collect debugging output should VM creation fail."
      command: dmesg
    - name: >
        "Execute `virsh capabilities` to collect debugging output
        should VM creation fail."
      command: virsh capabilities
    - name: "Abort due to failed VM creation"
      fail: >
        msg="VM creation step failed, please review dmesg
        output for additional details"
  when: vm_name not in existing_vms.list_vms

# TODO(pas-ha) replace 'command: vbmc ...' tasks
# with a custom Ansible module using vbmc Python API
- name: get list of nodes from virtualbmc
  command: vbmc list
  register: vbmc_list
  environment: "{{ bifrost_venv_env if enable_venv else {} }}"

# NOTE(NobodyCam): Space at the end of the find clause is required for proper matching.
- name: delete vm from virtualbmc if it is there
  command: vbmc delete {{ vm_name }}
  environment: "{{ bifrost_venv_env if enable_venv else {} }}"
  when: vbmc_list.stdout.find(vm_name) != -1

- set_fact:
    virtual_ipmi_port: "{{ (test_vm_ipmi_port_start|default(623) | int ) + (testvm_json_data | length) }}"

- name: plug vm into vbmc
  command: vbmc add {{ vm_name }} --libvirt-uri {{ test_vm_libvirt_uri }} --port {{ virtual_ipmi_port }}
  environment: "{{ bifrost_venv_env if enable_venv else {} }}"

- name: start virtualbmc
  command: vbmc start {{ vm_name }}
  environment: "{{ bifrost_venv_env if enable_venv else {} }}"

- name: get XML of the vm
  virt:
    name: "{{ vm_name }}"
    command: get_xml
  register: testvm_xml

# NOTE(pas-ha) relies on our XML template for VM that defines a single NIC
- name: get MAC from vm XML
  set_fact:
    vm_mac: "{{ (testvm_xml.get_xml | regex_findall(\"<mac address='.*'/>\") | first).split('=') | last | regex_replace(\"['/>]\", '') }}"

# NOTE(pas-ha) using default username and password set by virtualbmc - "admin" and "password" respectively
# see vbmc add --help
- name: set the json entry for vm
  set_fact:
    testvm_data:
      name: "{{ vm_name }}"
      uuid: "{{ vm_name | to_uuid }}"
      host_groups: "{{ vm_host_group }}"
      driver: "{{ test_vm_node_driver|default('ipmi') }}"
      driver_info:
        power:
          ipmi_address: "192.168.122.1"
          ipmi_port: "{{ virtual_ipmi_port }}"
          ipmi_username: "admin"
          ipmi_password: "password"
      nics:
        - mac: "{{ vm_mac }}"
      ansible_ssh_host: "192.168.122.{{ testvm_json_data | length + 2 }}"
      ipv4_address: "192.168.122.{{ testvm_json_data | length + 2 }}"
      properties:
        cpu_arch: "{{ test_vm_arch }}"
        ram: "{{ test_vm_memory_size }}"
        cpus: "{{ test_vm_cpu_count }}"
        disk_size: "{{ test_vm_disk_gib }}"

- name: add created vm info
  set_fact:
    testvm_json_data: "{{ testvm_json_data | combine({vm_name: testvm_data}) }}"

**********
DECISION===>: Suspicious Comment, Hardcoded Secret
**********
=========================:::122:::END!!!=========================
=========================:::123:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-create-vm-nodes/tasks/prepare_libvirt.yml
**********
# Copyright (c) 2017 Mirantis Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Setup libvirt - ensure network and storage pool are defined and active,
# prepare dir for vm logs
---
- name: install libvirt-python and lxml
  pip:
    name: "{{ item }}"
    extra_args: "-c {{ upper_constraints_file }}"
    virtualenv: "{{ enable_venv | bool | ternary(bifrost_venv_dir, omit) }}"
  with_items:
    - libvirt-python
    - lxml

- name: "Restart libvirt service"
  service: name="{{libvirt_service_name}}" state=restarted

# NOTE(Shrews) We need to enable ip forwarding for the libvirt bridge to
# operate properly with dnsmasq. This should be done before starting dnsmasq.
- name: "Enable IP forwarding in sysctl"
  sysctl:
    name: "net.ipv4.ip_forward"
    value: 1
    sysctl_set: yes
    state: present
    reload: yes

# NOTE(Shrews) Ubuntu packaging+apparmor issue prevents libvirt from loading
# the ROM from /usr/share/misc.
- name: "Look for sgabios in {{ sgabios_dir }}"
  stat: path={{ sgabios_dir }}/sgabios.bin
  register: test_sgabios_qemu

- name: "Look for sgabios in /usr/share/misc"
  stat: path=/usr/share/misc/sgabios.bin
  register: test_sgabios_misc

- name: "Place sgabios.bin"
  command: cp /usr/share/misc/sgabios.bin /usr/share/qemu/sgabios.bin
  when: >
    test_sgabios_qemu == false and
    test_sgabios_misc == true

# NOTE(TheJulia): In order to prevent conflicts, stop
# dnsmasq to prevent conflicts with libvirt restarting.
# TODO(TheJulia): We shouldn't need to do this, but the
# libvirt dhcp instance conflicts withour specific config
# and taking this path allows us to not refactor dhcp at
# this moment. Our DHCP serving should be refactored
# so we don't need to do this.
- name: "Stop default dnsmasq service"
  service:
    name: dnsmasq
    state: stopped
  ignore_errors: true

# NOTE(TheJulia): Seems if you test in a VM, this might
# be helpful if your installed your host originally
# with the default 192.168.122/0/24 network
- name: destroy libvirt network
  virt_net:
    name: "{{ test_vm_network }}"
    state: absent
    uri: "{{ test_vm_libvirt_uri }}"

- name: ensure libvirt network is present
  virt_net:
    name: "{{ test_vm_network }}"
    state: present
    xml: "{{ lookup('template', 'net.xml.j2') }}"
    uri: "{{ test_vm_libvirt_uri }}"

- name: find facts on libvirt networks
  virt_net:
    command: facts
    uri: "{{ test_vm_libvirt_uri }}"

# NOTE(pas-ha) yet another place where non-local libvirt will not work
- name: "Delete network interface if virtual network is not active"
  command: ip link del {{ ansible_libvirt_networks[test_vm_network].bridge }}
  when:
    - ansible_libvirt_networks[test_vm_network].state != 'active'
    - test_vm_libvirt_uri == 'qemu:///system'
  ignore_errors: yes

- name: set libvirt network to autostart
  virt_net:
    name: "{{ test_vm_network }}"
    autostart: yes
    uri: "{{ test_vm_libvirt_uri }}"

- name: ensure libvirt network is running
  virt_net:
    name: "{{ test_vm_network }}"
    state: active
    uri: "{{ test_vm_libvirt_uri }}"

- name: get libvirt network status
  virt_net:
    name: "{{ test_vm_network }}"
    command: status
    uri: "{{ test_vm_libvirt_uri }}"
  register: test_vm_net_status

- name: fail if libvirt network is not active
  assert:
    that: test_vm_net_status.status == 'active'

- name: define a libvirt pool if not set
  virt_pool:
    name: "{{ test_vm_storage_pool }}"
    state: present
    uri: "{{ test_vm_libvirt_uri }}"
    xml: "{{ lookup('template', 'pool_dir.xml.j2') }}"

- name: ensure libvirt pool is running
  virt_pool:
    name: "{{ test_vm_storage_pool }}"
    state: active
    autostart: yes
    uri: "{{ test_vm_libvirt_uri }}"

- name: create dir for bm logs
  file:
    state: directory
    path: "{{ test_vm_logdir }}"
    recurse: yes
    mode: "0755"

- name: ensure parent dir for bm logs has proper rights
  file:
    state: directory
    path: "{{ test_vm_logdir | dirname }}"
    mode: "0755"

- name: install virtualbmc
  pip:
    name: virtualbmc
    extra_args: "-c {{ upper_constraints_file }}"
    virtualenv: "{{ enable_venv | bool | ternary(bifrost_venv_dir, omit) }}"

**********
DECISION===>: PASS
**********
=========================:::123:::END!!!=========================
=========================:::124:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-create-vm-nodes/tasks/main.yml
**********
# Copyright (c) 2015 Hewlett-Packard Development Company, L.P.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
---
- name: produce warning when csv file is defined
  debug:
    msg: >
      "WARNING - Variable 'baremetal_csv_file' is deprecated.
      For backward compatibility, its value will be used as path for
      file to write data for created 'virtual' baremetal nodes,
      but the file will be JSON formatted."
  when: baremetal_csv_file is defined

- name: override baremetal_json_file with csv file path
  set_fact:
    baremetal_json_file: "{{ baremetal_csv_file }}"
  when: baremetal_csv_file is defined

# NOTE(cinerama) openSUSE Tumbleweed & Leap have different distribution
# IDs which are not currently accounted for in Ansible, so adjust facts
# so we can have shared defaults for the whole SuSE family.
# This change can be removed when the pull request at
# https://github.com/ansible/ansible/pull/17575 lands in a new version.
- name: Ensure openSUSE Tumbleweed has the correct family
  set_fact:
    ansible_os_family: "Suse"
  when: ansible_os_family | search("openSUSE Tumbleweed")

- name: Ensure openSUSE Leap has the correct family
  set_fact:
    ansible_os_family: "Suse"
  when: (ansible_os_family | search("SUSE LINUX")) or
        (ansible_os_family | search("openSUSE Leap"))

# NOTE(hwoarang) The 'apt' module needs python-apt installed in the virtualenv
# but it's not possible to do that. See https://github.com/ansible/ansible/issues/14468
# python-apt only works if it's installed on the local system so we need to switch the
# Ansible python interpreter.
- name: "Update apt cache if Ubuntu/Debian"
  apt:
    update_cache: yes
  vars:
    ansible_python_interpreter: '/usr/bin/python'
  when: ansible_os_family == "Debian"

- name: "Load distribution defaults"
  include_vars: "{{ item }}"
  with_first_found:
    - "../defaults/required_defaults_{{ ansible_distribution }}.yml"
    - "../defaults/required_defaults_{{ ansible_os_family }}.yml"

- name: "Include OS version-specific defaults"
  include_vars: "{{ item }}"
  with_first_found:
    - "../defaults/required_defaults_{{ ansible_distribution }}_{{ ansible_distribution_release }}.yml"
    - "../defaults/dummy-defaults.yml"
# NOTE(cinerama): On Fedora 22, ansible 1.9, ansible_pkg_mgr
# defaults to yum, which may not be installed. This can be safely
# removed when we start using an ansible release which prefers dnf.

- name: "Check for dnf"
  stat:
    path: "/usr/bin/dnf"
  register: test_dnf

- name: "Adjust ansible_pkg_mgr if dnf exists"
  set_fact:
    ansible_pkg_mgr: "dnf"
  when: ansible_distribution == 'Fedora' and test_dnf.stat.exists|bool

# NOTE(hwoarang) The 'apt' module needs python-apt installed in the virtualenv
# but it's not possible to do that. See https://github.com/ansible/ansible/issues/14468
# python-apt only works if it's installed on the local system so we need to switch the
# Ansible python interpreter.
- name: "Install required packages"
  action: "{{ ansible_pkg_mgr }} name={{ item }} state=present"
  with_items: "{{ required_packages }}"
  vars:
    ansible_python_interpreter: '/usr/bin/python'

- include: prepare_libvirt.yml

- name: truncate explicit list of vm names
  set_fact:
    test_vm_node_names: "{{ test_vm_node_names[:(test_vm_num_nodes|int)] }}"

- name: generate test vm names
  set_fact:
    generated_test_vm_node_names: "{{ generated_test_vm_node_names|default([]) + [item] }}"
  with_sequence: count={{ test_vm_num_nodes | int }} format={{ test_vm_node_name_base }}%i
  when: test_vm_node_names | length == 0

- name: set test vm names
  set_fact:
    test_vm_node_names: "{{ generated_test_vm_node_names }}"
  when: test_vm_node_names | length == 0

- name: create placeholder var for vm entries in JSON format
  set_fact:
    testvm_json_data: {}

- include: create_vm.yml
  with_items: "{{ test_vm_node_names }}"

- name: remove previous baremetal data file
  file:
    state: absent
    path: "{{ baremetal_json_file }}"

- name: write to baremetal json file
  copy:
    dest: "{{ baremetal_json_file }}"
    content: "{{ testvm_json_data | to_nice_json }}"

- name: >
    "Set file permissions such that the baremetal data file
    can be read by the user executing Ansible"
  file:
    path: "{{ baremetal_json_file }}"
    owner: "{{ ansible_env.SUDO_USER }}"
  when: >
    ansible_env.SUDO_USER is defined and
    baremetal_json_file != ""

**********
DECISION===>: PASS
**********
=========================:::124:::END!!!=========================
=========================:::125:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-create-vm-nodes/meta/main.yml
**********
---
galaxy_info:
  author: Ironic Developers
  description: Create VM nodes for local Bifrost testing.
  company: OpenStack
  license: Apache
  min_ansible_version: 1.9
  platforms:
  - name: EL
    versions:
    - 7
  - name: Debian
    versions:
    - wheezy
    - jessie
  - name: Ubuntu
    versions:
    - trusty
    - utopic
  categories:
  - cloud
  - cloud:openstack
dependencies: []

**********
DECISION===>: PASS
**********
=========================:::125:::END!!!=========================
=========================:::126:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-create-vm-nodes/defaults/required_defaults_Debian_jessie.yml
**********
---
libvirt_service_name: libvirtd

**********
DECISION===>: PASS
**********
=========================:::126:::END!!!=========================
=========================:::127:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-create-vm-nodes/defaults/dummy-defaults.yml
**********
---
# Note(TheJulia): This file is intentionally left empty. Do not edit.

**********
DECISION===>: PASS
**********
=========================:::127:::END!!!=========================
=========================:::128:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-create-vm-nodes/defaults/required_defaults_RedHat.yml
**********
---
sgabios_dir: /usr/share/sgabios/
libvirt_service_name: libvirtd
required_packages:
 - gcc-c++
 - qemu-img
 - qemu-kvm-tools
 - qemu-kvm
 - qemu-kvm-common
 - qemu-system-x86
 - sgabios-bin
 - libvirt
 - libvirt-client
 - libvirt-daemon
 - pkgconfig
 - libvirt-devel
 - libxslt-devel
 - libxml2-devel

**********
DECISION===>: PASS
**********
=========================:::128:::END!!!=========================
=========================:::129:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-create-vm-nodes/defaults/required_defaults_Fedora.yml
**********
---
sgabios_dir: /usr/share/sgabios/
libvirt_service_name: libvirtd
required_packages:
 - qemu-img
 - qemu-kvm
 - qemu-system-x86
 - sgabios-bin
 - libvirt
 - libvirt-client
 - libvirt-daemon
 - pkgconfig
 - libvirt-devel
 - libselinux-python

**********
DECISION===>: PASS
**********
=========================:::129:::END!!!=========================
=========================:::130:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-create-vm-nodes/defaults/required_defaults_CentOS.yml
**********
---
sgabios_dir: /usr/share/sgabios/
libvirt_service_name: libvirtd
required_packages:
 - qemu-img
 - qemu-kvm-tools
 - qemu-kvm
 - qemu-kvm-common
 - qemu-system-x86
 - sgabios
 - sgabios-bin
 - libvirt
 - libvirt-client
 - libvirt-daemon
 - libvirt-daemon-config-network
 - libvirt-daemon-config-nwfilter
 - libvirt-daemon-driver-network
 - libvirt-daemon-driver-nodedev
 - libvirt-daemon-driver-nwfilter
 - libvirt-daemon-driver-qemu
 - libvirt-daemon-driver-secret
 - libvirt-daemon-driver-storage
 - libvirt-daemon-kvm
 - pkgconfig
 - libvirt-devel
test_vm_emulator: "/bin/qemu-system-x86_64"

**********
DECISION===>: PASS
**********
=========================:::130:::END!!!=========================
=========================:::131:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-create-vm-nodes/defaults/required_defaults_Suse.yml
**********
---
sgabios_dir: /usr/share/sgabios/
libvirt_service_name: libvirtd
required_packages:
 - gcc-c++
 - qemu-tools
 - qemu-kvm
 - qemu-x86
 - qemu-sgabios
 - libvirt
 - libvirt-client
 - libvirt-daemon
 - libxslt-devel
 - libxml2-devel
 - pkg-config
 - libvirt-devel

**********
DECISION===>: PASS
**********
=========================:::131:::END!!!=========================
=========================:::132:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-create-vm-nodes/defaults/required_defaults_Debian.yml
**********
---
sgabios_dir: /usr/share/qemu/
libvirt_service_name: libvirt-bin
required_packages:
 - g++
 - libvirt-bin
 - libxslt1-dev
 - libxml2-dev
 - qemu-utils
 - qemu-kvm
 - qemu-system-x86
 - sgabios
 - pkg-config
 - libvirt-dev

**********
DECISION===>: PASS
**********
=========================:::132:::END!!!=========================
=========================:::133:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-create-vm-nodes/defaults/main.yml
**********
---
# defaults file for bifrost-create-vm-nodes
baremetal_json_file: '/tmp/baremetal.json'
test_vm_memory_size: "3072"
test_vm_num_nodes: 1
test_vm_domain_type: "qemu"
test_vm_arch: "x86_64"
test_vm_cpu: "host-model"
test_vm_nic: "virtio"
test_vm_groups: {}
test_vm_default_groups: "{{ lookup('env', 'DEFAULT_HOST_GROUPS').split() | default(['baremetal'], true) }}"
test_vm_disk_gib: "{{ lookup('env', 'VM_DISK') | default(10, true) }}"
test_vm_cpu_count: "{{ lookup('env', 'VM_CPU') | default(1, true) }}"
test_vm_disk_cache: "{{ lookup('env', 'VM_DISK_CACHE') | default('writeback', true) }}"
test_vm_node_name_base: "{{ lookup('env', 'NODEBASE') | default('testvm', true) }}"
test_vm_node_names: "{{ lookup('env', 'TEST_VM_NODE_NAMES').split() }}"

# NOTE(pas-ha) name and default are chosen to be the same
# as in 'bifrost-ironic-install' role
network_interface: "virbr0"
# NOTE(pas-ha) these correspond to settings for the libvirt network created by default
test_vm_network: "{{ lookup('env', 'VM_NET_BRIDGE') | default('default', true) }}"
test_vm_network_ip: "192.168.122.1"
test_vm_network_netmask: "255.255.255.0"
test_vm_network_enable_dhcp: true
test_vm_network_dhcp_start: "192.168.122.2"
test_vm_network_dhcp_end: "192.168.122.254"

test_vm_storage_pool: "{{ lookup('env', 'LIBVIRT_STORAGE_POOL') | default('default', true) }}"
test_vm_storage_pool_path: "/var/lib/libvirt/images"
test_vm_logdir: "/var/log/libvirt/baremetal_logs"
# NOTE(pas-ha) next two are generic values for most OSes, overridden by distro-specifc vars
test_vm_emulator: "/usr/bin/qemu-system-x86_64"
test_vm_machine: "pc-1.0"
# NOTE(pas-ha) not really tested with non-local qemu connections
test_vm_libvirt_uri: "{{ lookup('env', 'LIBVIRT_CONNECT_URI') | default('qemu:///system', true) }}"
# Settings related to installing bifrost in a virtual environment
enable_venv: false
bifrost_venv_dir: "{{ lookup('env', 'VENV') | default('/opt/stack/bifrost') }}"
bifrost_venv_env:
  VIRTUAL_ENV: "{{ bifrost_venv_dir }}"
  PATH: "{{ bifrost_venv_dir }}/bin:{{ ansible_env.PATH }}" # include regular path via lookup env
reqs_git_folder: /opt/stack/requirements
upper_constraints_file: "{{ lookup('env', 'UPPER_CONSTRAINTS_FILE') | default(reqs_git_folder + '/upper-constraints.txt', True) }}"

**********
DECISION===>: PASS
**********
=========================:::133:::END!!!=========================
=========================:::134:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-create-vm-nodes/handlers/main.yml
**********
---
# handlers file for bifrost-create-vm-nodes

**********
DECISION===>: PASS
**********
=========================:::134:::END!!!=========================
=========================:::135:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-create-bootable-image/tasks/create_bootable_image.yml
**********
# Copyright (c) 2015 Hewlett-Packard Development Company, L.P.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.
---
- name: "Extract the raw disk image"
  command: qemu-img convert -O raw "{{deploy_image}}" "{{deploy_image}}.raw"
- name: "Copy image however with 32k of empty space at the beginning of the file."
  command: dd if="{{deploy_image}}.raw" of="{{deploy_image}}.bootimg" seek=64
- name: "Create partition table lining up with the copied file's contents."
  shell: echo '32;' | sfdisk "{{deploy_image}}.bootimg" -uB -f
- name: "Allocate one of two loopbacks"
  command: losetup -f
  register: stored_value_loopback_alpha
- name: "Create loopback connetion to new image file"
  command: losetup "{{stored_value_loopback_alpha.stdout}}" "{{deploy_image}}.bootimg"
- name: "Force partition table to be re-read"
  command: kpartx -v -a "{{stored_value_loopback_alpha.stdout}}"
  # Using second loopback as for some reason /dev/mapper does not translate into a chroot cleanly when devfs is mounted
- name: "Allocate second loopback pointing to the initial partition"
  command: losetup -f
  register: stored_value_loopback_beta
- name: "Bind second loopback to the first partition"
  shell: losetup "{{stored_value_loopback_beta.stdout}}" /dev/mapper/$(echo "{{stored_value_loopback_alpha.stdout}}"|cut -f3 -d '/')p1
  # TODO parameterize folder name/location
- name: "Ensure we have a location to mount the disk to"
  file: path=/mnt/bootimg state=directory
- name: "Mount volume on /mnt/bootimg"
  command: mount "{{stored_value_loopback_beta.stdout}}" /mnt/bootimg
- name: "Bind /sys into /mnt/bootimg/sys"
  command: mount -t sysfs sysfs /mnt/bootimg/sys
- name: "Bind /proc into /mnt/bootimg/proc"
  command: mount -t proc proc /mnt/bootimg/proc
- name: "Bind /dev into /mnt/bootimg/dev"
  command: mount --bind /dev /mnt/bootimg/dev
- name: "Disable Grub Prober"
  shell: echo "GRUB_DISABLE_OS_PROBER=true" >>/etc/default/grub
- name: "Disable Grub Prober"
  shell: echo 'GRUB_TERMINAL="serial console"' >>/etc/default/grub
- name: "Run the grub-install tool"
  command: chroot /mnt/bootimg grub-install --boot-directory=/boot --modules="biosdisk part_msdos" "{{stored_value_loopback_alpha.stdout}}"
- name: "Unlink /dev/bootimg/dev"
  command: umount /mnt/bootimg/dev
- name: "Unlink /dev/bootimg/proc"
  command: umount /mnt/bootimg/proc
- name: "Unlink /dev/bootimg/sys"
  command: umount /mnt/bootimg/sys
- name: "Unmount image"
  command: umount /mnt/bootimg
- name: "Detach second loop device"
  command: losetup -d "{{stored_value_loopback_beta.stdout}}"
- name: "Remove partition map"
  command: kpartx -v -d "{{stored_value_loopback_alpha.stdout}}"
- name: "Detach first loop device"
  command: losetup -d "{{stored_value_loopback_alpha.stdout}}"
- name: "Move image to .oldimg"
  command: mv "{{deploy_image}}" "{{deploy_image}}.oldimg"
- name: "Move new image into place"
  command: mv "{{deploy_image}}.bootimg" "{{deploy_image}}"

**********
DECISION===>: PASS
**********
=========================:::135:::END!!!=========================
=========================:::136:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-create-bootable-image/tasks/main.yml
**********
# Copyright (c) 2015 Hewlett-Packard Development Company, L.P.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.
---
- name: "Test if deploy image is present"
  stat: path={{ deploy_image }}
  register: test_image_present
- name: "Create bootable image"
  include: create_bootable_image.yml
  when: test_image_present.stat.exists == true

**********
DECISION===>: PASS
**********
=========================:::136:::END!!!=========================
=========================:::137:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-create-bootable-image/meta/main.yml
**********
---
galaxy_info:
  author: Ironic Developers
  description: Create bootable disk image for Bifrost
  company: OpenStack
  license: Apache
  min_ansible_version: 1.9
  platforms:
  - name: Ubuntu
    versions:
    - trusty
    - utopic
  categories:
  - cloud
  - cloud:openstack
dependencies: []

**********
DECISION===>: PASS
**********
=========================:::137:::END!!!=========================
=========================:::138:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-create-bootable-image/defaults/main.yml
**********
---
http_boot_folder: /httpboot
deploy_image_filename: "partition_image.raw"
deploy_image: "{{http_boot_folder}}/{{deploy_image_filename}}"


**********
DECISION===>: PASS
**********
=========================:::138:::END!!!=========================
=========================:::139:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-prep-for-install/tasks/main.yml
**********
# Copyright (c) 2015 Hewlett-Packard Development Company, L.P.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.
---
- name: ensure installation root folder exists
  become: yes
  file:
    state: directory
    dest: "{{ git_root }}"
    owner: "{{ ansible_user_id }}"
    group: "{{ ansible_user_gid }}"

- name: "Download via GIT"
  git:
    dest: "{{ item.git_folder }}"
    force: yes
    repo: "{{ item.git_url }}"
    version: "{{ item.git_branch }}"
    update: yes
    clone: yes
  with_items: "{{ bifrost_install_sources }}"
  when: ci_testing_zuul | bool == false and copy_from_local_path | bool == false

- name: "Copy from local path"
  command: cp -a {{ item.git_url }} {{ item.git_folder }} creates={{ item.git_folder }}
  with_items: "{{ bifrost_install_sources }}"
  when: ci_testing_zuul | bool == true or copy_from_local_path | bool == true

**********
DECISION===>: PASS
**********
=========================:::139:::END!!!=========================
=========================:::140:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-prep-for-install/meta/main.yml
**********
---
galaxy_info:
  author: Ironic Developers
  description: Install Ironic for Bifrost
  company: OpenStack
  license: Apache
  min_ansible_version: 1.9
  platforms:
  - name: EL
    versions:
    - 7
  - name: Debian
    versions:
    - wheezy
  - name: Ubuntu
    versions:
    - trusty
    - utopic
  categories:
  - cloud
  - cloud:openstack
dependencies: []

**********
DECISION===>: PASS
**********
=========================:::140:::END!!!=========================
=========================:::141:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-prep-for-install/defaults/main.yml
**********
---
# git_root is the folder where to place downloaded git repos
git_root: "/opt/stack"
# *_git_url can be overridden by local clones for offline installs
dib_git_url: https://git.openstack.org/openstack/diskimage-builder
ironicclient_git_url: https://git.openstack.org/openstack/python-ironicclient
openstacksdk_git_url: https://git.openstack.org/openstack/openstacksdk
shade_git_url: https://git.openstack.org/openstack-infra/shade
ironic_git_url: https://git.openstack.org/openstack/ironic
ironicinspector_git_url: https://github.com/openstack/ironic-inspector
ironicinspectorclient_git_url: https://github.com/openstack/python-ironic-inspector-client
reqs_git_url: https://git.openstack.org/openstack/requirements
staging_drivers_git_url: https://git.openstack.org/openstack/ironic-staging-drivers
keystone_git_url: https://git.openstack.org/openstack/keystone
# *_git_folder can be overridden by local clones for offline installs
ironicclient_git_folder: "{{ git_root}}/python-ironicclient"
ironic_git_folder: "{{ git_root}}/ironic"
ironicinspector_git_folder: "{{ git_root}}/ironic-inspector"
ironicinspectorclient_git_folder: "{{ git_root}}/python-ironic-inspector-client"
openstacksdk_git_folder: "{{ git_root}}/openstacksdk"
shade_git_folder: "{{ git_root}}/shade"
dib_git_folder: "{{ git_root }}/diskimage-builder"
reqs_git_folder: "{{ git_root }}/requirements"
upper_constraints_file: "{{ lookup('env', 'UPPER_CONSTRAINTS_FILE') | default(reqs_git_folder + '/upper-constraints.txt', True) }}"
staging_drivers_git_folder: "{{ git_root }}/ironic-staging-drivers"
keystone_git_folder: "{{ git_root}}/keystone"
# *_git_branch can be overridden for stable branch testing
ironicclient_git_branch: master
ironic_git_branch: master
openstacksdk_git_branch: master
shade_git_branch: master
dib_git_branch: master
ironicinspector_git_branch: master
ironicinspectorclient_git_branch: master
reqs_git_branch: master
staging_drivers_git_branch: master
keystone_git_branch: master

# Conditional variables utilized based on CI or manual testing options.
copy_from_local_path: false
ci_testing_zuul: false

bifrost_install_sources:
  - git_folder: "{{ ironic_git_folder }}"
    git_url: "{{ ironic_git_url }}"
    git_branch: "{{ ironic_git_branch }}"
    name: ironic
  - git_folder: "{{ ironicclient_git_folder }}"
    git_url: "{{ ironicclient_git_url }}"
    git_branch: "{{ ironicclient_git_branch }}"
    name: ironicclient
  - git_folder: "{{ openstacksdk_git_folder }}"
    git_url: "{{ openstacksdk_git_url }}"
    git_branch: "{{ openstacksdk_git_branch }}"
    name: openstacksdk
  - git_folder: "{{ shade_git_folder }}"
    git_url: "{{ shade_git_url }}"
    git_branch: "{{ shade_git_branch }}"
    name: shade
  - git_folder: "{{ dib_git_folder }}"
    git_url: "{{ dib_git_url }}"
    git_branch: "{{ dib_git_branch }}"
    name: dib
  - git_folder: "{{ ironicinspector_git_folder }}"
    git_url: "{{ ironicinspector_git_url }}"
    git_branch: "{{ ironicinspector_git_branch }}"
    name: ironicinspector
  - git_folder: "{{ ironicinspectorclient_git_folder }}"
    git_url: "{{ ironicinspectorclient_git_url }}"
    git_branch: "{{ ironicinspectorclient_git_branch }}"
    name: ironicinspectorclient
  - git_folder: "{{ reqs_git_folder }}"
    git_url: "{{ reqs_git_url }}"
    git_branch: "{{ reqs_git_branch }}"
    name: requirements
  - git_folder: "{{ staging_drivers_git_folder }}"
    git_url: "{{ staging_drivers_git_url }}"
    git_branch: "{{ staging_drivers_git_branch }}"
    name: ironic-staging-drivers
  - git_folder: "{{ keystone_git_folder }}"
    git_url: "{{ keystone_git_url }}"
    git_branch: "{{ keystone_git_branch }}"
    name: keystone

**********
DECISION===>: PASS
**********
=========================:::141:::END!!!=========================
=========================:::142:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-prepare-for-test-dynamic/vars/main.yml
**********
---
# vars file for bifrost-prepare-for-test-dynamic

**********
DECISION===>: PASs
**********
=========================:::142:::END!!!=========================
=========================:::143:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-prepare-for-test-dynamic/tasks/main.yml
**********
# Copyright (c) 2015 Hewlett-Packard Development Company, L.P.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
---
- name: "Wait for the base testvm machine to become available."
  wait_for: state=started port=22 host={{ ipv4_address }} timeout={{ wait_timeout }}
  when: ipv4_address is defined
- name: "Pause for 4 seconds to allow testvm to become fully operational and to avoid any potential sshd startup race."
  # NOTE(TheJulia): AFAIK sshd opens it's socket and then loads/generates
  # keys, which can become visible as a race, hence the four second pause.
  pause: seconds={{ node_ssh_pause }}
- name: "Add testvm(s) to Ansible Inventory"
  # NOTE(TheJulia): add_host only triggers once per play. Since we need to
  # add all hosts, we need to use a loop.
  add_host: name="{{ hostvars[item]['ipv4_address'] }}:22" groups=test
  with_items: "{{ groups['baremetal'] }}"
  when: ipv4_address is defined
- name: "Ensure ~/.ssh/known_hosts is present"
  file:
    path: "~/.ssh/known_hosts"
    state: touch
    mode: 0600
  when: ipv4_address is defined
- name: "Remove testvm hosts from SSH known_hosts file."
  command: ssh-keygen -R "{{ ipv4_address }}"
  when: ipv4_address is defined
- name: "Pause before asking for keyscan, to avoid races"
  pause: minutes=3
  when: multinode_testing | bool == true
- name: >
    Re-check SSH connectivity prior to proceeding with multi-node testing
  wait_for:
    state: started
    port: 22
    host: "{{ ipv4_address }}"
  when: ipv4_address is defined and multinode_testing | bool == true
- name: >
    Additional SSH startup pause when performing multi-node testing
  pause:
    seconds: "{{ node_ssh_pause }}"
  when: multinode_testing | bool == true
- name: "Add testvm hosts from SSH known_hosts file."
  shell: ssh-keyscan "{{ ipv4_address }}" >> "{{ ansible_env.HOME }}/.ssh/known_hosts"
  when: ipv4_address is defined

**********
DECISION===>: PASS
**********
=========================:::143:::END!!!=========================
=========================:::144:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-prepare-for-test-dynamic/meta/main.yml
**********
---
galaxy_info:
  author: Ironic Developers
  description: Prepare for basic bifrost testing.
  company: OpenStack
  license: Apache
  min_ansible_version: 1.9
  platforms:
  - name: EL
    versions:
    - 7
  - name: Debian
    versions:
    - wheezy
  - name: Ubuntu
    versions:
    - trusty
    - utopic
  categories:
  - cloud
  - cloud:openstack
dependencies: []

**********
DECISION===>: PASS
**********
=========================:::144:::END!!!=========================
=========================:::145:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-prepare-for-test-dynamic/defaults/main.yml
**********
---
node_ssh_pause: 10
wait_timeout: 900
multinode_testing: false

**********
DECISION===>: PASS
**********
=========================:::145:::END!!!=========================
=========================:::146:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-prepare-for-test-dynamic/handlers/main.yml
**********
---
# handlers file for bifrost-prepare-for-test-dynamic

**********
DECISION===>: PASS
**********
=========================:::146:::END!!!=========================
=========================:::147:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-configdrives-dynamic/vars/main.yml
**********
---
metadata_versions:
  - "2012-08-10"
  - "2015-10-15"
  - "latest"

metadata_versions_supporting_network_data:
  - "2015-10-15"
  - "latest"

**********
DECISION===>: PASS
**********
=========================:::147:::END!!!=========================
=========================:::148:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-configdrives-dynamic/tasks/ssh_public_key_path.yaml
**********
# Copyright (c) 2015 Hewlett-Packard Development Company, L.P.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
---
- name: "Defined ssh_public_key_path - Check to see if there is a file where the ssh_public_key_path is defined"
  local_action: stat path={{ ssh_public_key_path }}
  register: test_ssh_public_key_path
  when: ssh_public_key_path is defined

- name: "Defined ssh_public_key_path - Error if ssh_public_key_path is not valid"
  local_action: fail msg="ssh_public_key_path is not valid."
  when: test_ssh_public_key_path.stat.exists == false

- name: "Defined ssh_public_key_path - Read SSH public key in"
  set_fact: ssh_public_key="{{ lookup('file', ssh_public_key_path ) }}"

**********
DECISION===>: PASS
**********
=========================:::148:::END!!!=========================
=========================:::149:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-configdrives-dynamic/tasks/update_facts_from_ironic.yaml
**********
# Copyright (c) 2015 Hewlett-Packard Development Company, L.P.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
---
- name: "If in noauth mode, set auth parameters accordingly."
  set_fact:
    auth_type: None
    auth: {}
  when: noauth_mode is defined and noauth_mode | bool == true

- name: "Execute os_client_config to collect facts"
  os_client_config:
  no_log: yes
  when: noauth_mode is defined and noauth_mode | bool == false

# NOTE(TheJulia): The first record returned by os_client_config
# is utilized as the default. A user can still define the parameters
# if so desired.
- name: "Set os_client_config's auth parameters if not already set."
  set_fact:
    auth: "{{ openstack.clouds[0].auth }}"
    auth_type: "{{ openstack.clouds[0].auth_type }}"
  when: auth is undefined
  no_log: yes

# Note(TheJulia): This step allows us to collect things that
# ironic knows, that we do not know potentially, such as an UUID
# should a node have been created without one.
- name: "Collecting node facts"
  os_ironic_facts:
    cloud: "{{ cloud_name | default(omit) }}"
    auth_type: "{{ auth_type }}"
    auth: "{{ auth }}"
    ironic_url: "{{ ironic_url | default(omit) }}"
    uuid: "{{ uuid | default() }}"
    name: "{{ name | default() }}"
    skip_items:
      - instance_info

**********
DECISION===>: PASS
**********
=========================:::149:::END!!!=========================
=========================:::150:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-configdrives-dynamic/tasks/main.yml
**********
# Copyright (c) 2015 Hewlett-Packard Development Company, L.P.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
---
# Note(TheJulia): Fact collection from ironic is necessary to obtain
# the host's assigned UUID value.
- name: "Update facts from ironic to fill in any missing values"
  include: update_facts_from_ironic.yaml

- name: "Identify ssh_public_key from ssh_public_key_path"
  include: ssh_public_key_path.yaml
  when: ssh_public_key is undefined

- name: "Make temporary folder to build configdrive"
  command: mktemp -d
  register: variable_configdrive_location

- name: "Make metadata folders - /openstack/<version>"
  file:
    state: directory
    name: "{{ variable_configdrive_location.stdout }}/{{ uuid }}/openstack/{{ item }}/"
  with_items: "{{ metadata_versions }}"

- name: "Place template in each openstack/<version> folder"
  template:
    src: openstack_meta_data.json.j2
    dest: "{{ variable_configdrive_location.stdout }}/{{ uuid }}/openstack/{{ item }}/meta_data.json"
  with_items: "{{ metadata_versions }}"

- name: "Generate network_data"
  network_metadata:
    ipv4_address: "{{ ipv4_address | default('') }}"
    ipv4_gateway: "{{ ipv4_gateway | default('') }}"
    ipv4_interface_mac: "{{ ipv4_interface_mac | default('') }}"
    ipv4_nameserver: "{% if ipv4_nameserver is string %}['{{ ipv4_nameserver | default('') }}']{% else %}{{ ipv4_nameserver }}{% endif %}"
    ipv4_subnet_mask: "{{ ipv4_subnet_mask | default('') }}"
    vlan_id: "{{ vlan_id | default('') }}"
    network_mtu: "{{ network_mtu | default('1500') }}"
    nics: "{{ nics | default(omit) }}"
    node_network_data: "{{ node_network_data | default(node_network_info) }}"
  when: addressing_mode is undefined or "dhcp" not in addressing_mode

- name: "Place network data template in each openstack/<version> folder"
  template:
    src: network_data.json.j2
    dest: "{{ variable_configdrive_location.stdout }}/{{ uuid }}/openstack/{{ item }}/network_data.json"
  with_items: "{{ metadata_versions }}"
  when:
    - item in metadata_versions_supporting_network_data
    - addressing_mode is undefined or "dhcp" not in addressing_mode

# TODO(TheJulia): Deprecation removal of the old network_info file name
# should likely take place after an elongated deprecation cycle.
# Begin deprecated in the Ocata release suggests Queens as the point
# in which we should remove it.
- name: "Place deprecated network info file location in each openstack/<version> folder"
  template:
    src: network_data.json.j2
    dest: "{{ variable_configdrive_location.stdout }}/{{ uuid }}/openstack/{{ item }}/network_info.json"
  with_items: "{{ metadata_versions }}"
  when:
    - item in metadata_versions_supporting_network_data
    - addressing_mode is undefined or "dhcp" not in addressing_mode

- name: "Make metadata folder - /openstack/content"
  file:
    state: directory
    name: "{{ variable_configdrive_location.stdout }}/{{ uuid }}/openstack/content/"

- name: "Write network Debian style interface template"
  template: src=interfaces.j2 dest={{ variable_configdrive_location.stdout }}/{{ uuid }}/openstack/content/0000
  when: write_interfaces_file | bool == true

- name: "Check if mkisofs is available"
  shell: mkisofs --help &> /dev/null
  ignore_errors: yes
  register: test_mkisofs

- name: "If mkisofs is not available, fallback to genisoimage"
  set_fact:
    iso_gen_utility: "genisoimage"
  when: ('genisoimage' in test_mkisofs.stderr) or test_mkisofs.rc != 0

- name: "Check if genisoimage is available"
  shell: genisoimage --help &> /dev/null
  ignore_errors: yes
  register: test_genisoimage

- name: "fail if genisoimage is not available."
  fail: msg="Neither mkisofs or genisoimage is available. Cannot make config drive files."
  when: test_genisoimage.rc != 0 and test_mkisofs.rc != 0

- name: "Make config drive files"
  become: yes
  command: "{{iso_gen_utility}} -R -V config-2 -o {{http_boot_folder}}/configdrive-{{ uuid }}.iso {{ variable_configdrive_location.stdout }}/{{ uuid }}"

- name: "Make config drive files base64 encoded and gzip compressed"
  become:  yes
  shell: gzip -c {{http_boot_folder}}/configdrive-{{ uuid }}.iso | base64 > {{http_boot_folder}}/configdrive-{{ uuid }}.iso.gz

- name: "Cleanup configdrive .iso files"
  become: yes
  file:
    state: absent
    name: "{{http_boot_folder}}/configdrive-{{ uuid }}.iso"

- name: "Cleanup configdrive temp folder"
  become: yes
  file:
    state: absent
    force: yes
    name: "{{ variable_configdrive_location.stdout }}"

**********
DECISION===>: PASS
**********
=========================:::150:::END!!!=========================
=========================:::151:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-configdrives-dynamic/meta/main.yml
**********
---
galaxy_info:
  author: Ironic Developers
  description: Creates a basic configdrive for Bifrost
  company: OpenStack
  license: Apache
  min_ansible_version: 2.0
  platforms:
  - name: EL
    versions:
    - 7
  - name: Ubuntu
    versions:
    - trusty
    - utopic
  - name: Debian
    versions:
    - wheezy
    - jessie
  categories:
  - cloud
  - cloud:openstack
dependencies: []

**********
DECISION===>: PASS
**********
=========================:::151:::END!!!=========================
=========================:::152:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-configdrives-dynamic/defaults/main.yml
**********
---
# write_interfaces_file is intended for utilizing base logic to write
# a debian style interfaces file into the configuration drive file
# such that cirros will receive basic network configuration when
# performing basic testing.
write_interfaces_file: false
http_boot_folder: /httpboot
# Default location to the ssh public key for the user operating Bifrost.
ssh_public_key_path: "{{ lookup('env', 'HOME') }}/.ssh/id_rsa.pub"

# Default interface name
# TODO(TheJulia): Remove this default.
node_default_network_interface: eth0

# Basic networking defaults
# TODO(TheJulia): Require these to be supplied some other way.
ipv4_subnet_mask: 255.255.255.0
ipv4_gateway: 192.168.1.1
ipv4_nameserver: 8.8.8.8
network_mtu: 1500

# Default URL to Ironic
ironic_url: "http://localhost:6385/"

# Default ISO generation utility
iso_gen_utility: "mkisofs"

# Deprecated, remove in Queens release
node_network_info: {}

**********
DECISION===>: Use of HTTP without TLS
**********
=========================:::152:::END!!!=========================
=========================:::153:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-configdrives-dynamic/handlers/main.yml
**********
---
# handlers file for bifrost-configdrives-dynamic

**********
DECISION===>: PASS
**********
=========================:::153:::END!!!=========================
=========================:::154:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-ironic-install/tasks/get_ipxe.yml
**********
# Copyright (c) 2016 Hewlett Packard Enterprise Development LP.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.
---
- import_role:
    name: venv_python_path

- name: Create {{ ipxe_dir }}
  file:
    name={{ ipxe_dir }}
    state=directory
    owner=root
    group=root
    mode=0755

- name: Get iPXE files
  get_url:
    url: "https://boot.ipxe.org/{{ item }}"
    dest: "{{ ipxe_dir }}/{{ item }}"
    force: yes
  register: ipxe_files_download_done
  until: ipxe_files_download_done|succeeded
  retries: 5
  delay: 10
  with_items:
    - undionly.kpxe
    - ipxe.pxe
  environment: "{{ venv }}"

- name: Get iPXE EFI binary
  get_url:
    url: "https://boot.ipxe.org/{{ item }}"
    dest: "{{ ipxe_dir }}/{{ item }}"
    force: yes
  register: ipxe_efi_binary_download_done
  until: ipxe_efi_binary_download_done|succeeded
  retries: 5
  delay: 10
  with_items:
    - "{{ ipxe_efi_binary }}"
  environment: "{{ venv }}"
  when: enable_uefi_ipxe | bool == true

**********
DECISION===>: Hardcoded Secret
**********
=========================:::154:::END!!!=========================
=========================:::155:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-ironic-install/tasks/keystone_setup.yml
**********
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.
---

# TODO(TheJulia): The user and project domains are hardcoded in this.
# We should likely address that at some point, however I think a user
# should be the driver of that work.

- name: "Initialize default venv"
  set_fact:
    venv:
      OS_IDENTITY_API_VERSION: "3"

- name: "Error if credentials are undefined."
  fail:
    msg: |
        Credentials are missing or undefined, unable to proceed.
        Please consult roled defaults/main.yml.
  when: >
      keystone is undefined or keystone.bootstrap is undefined or
      keystone.bootstrap.username is undefined or
      keystone.bootstrap.password is undefined or
      keystone.bootstrap.project_name is undefined or
      ironic.service_catalog.auth_url is undefined or
      ironic.service_catalog.username is undefined or
      ironic.service_catalog.password is undefined or
      ironic.service_catalog.project_name is undefined or
      ironic.keystone is undefined or
      ironic.keystone.default_username is undefined or
      ironic.keystone.default_password is undefined

- import_role:
    name: venv_python_path

- name: "Ensure service project is present"
  os_project:
    name: "{{ ironic.service_catalog.project_name }}"
    state: present
    description: "Service Project"
    domain_id: "default"
    enabled: yes
    auth:
      auth_url: "{{ ironic.service_catalog.auth_url | default('http://127.0.0.1:5000/') }}/"
      username: "{{ keystone.bootstrap.username }}"
      password: "{{ keystone.bootstrap.password }}"
      project_name: "{{ keystone.bootstrap.project_name | default('admin') }}"
      project_domain_id: "default"
      user_domain_id: "default"
  environment: "{{ venv }}"
  no_log: true

- name: "Create service user for ironic"
  os_user:
    name: "{{ ironic.service_catalog.username }}"
    password: "{{ ironic.service_catalog.password }}"
    state: present
    domain: "default"
    default_project: "{{ ironic.service_catalog.project_name }}"
    auth:
      auth_url: "{{ ironic.service_catalog.auth_url | default('http://127.0.0.1:5000/') }}"
      username: "{{ keystone.bootstrap.username }}"
      password: "{{ keystone.bootstrap.password }}"
      project_name: "{{ keystone.bootstrap.project_name | default('admin') }}"
      project_domain_id: "default"
      user_domain_id: "default"
    wait: yes
  environment: "{{ venv }}"
  no_log: true

- name: "Associate ironic user to admin role"
  os_user_role:
    user: "{{ ironic.service_catalog.username }}"
    role: "admin"
    project: "{{ ironic.service_catalog.project_name }}"
    auth:
      auth_url: "{{ ironic.service_catalog.auth_url | default('http://127.0.0.1:5000/') }}"
      username: "{{ keystone.bootstrap.username }}"
      password: "{{ keystone.bootstrap.password }}"
      project_name: "{{ keystone.bootstrap.project_name | default('admin') }}"
      project_domain_id: "default"
      user_domain_id: "default"
    wait: yes
  environment: "{{ venv }}"
  no_log: true

- name: "Create keystone service record for ironic"
  os_keystone_service:
    state: present
    name: "ironic"
    service_type: "baremetal"
    description: OpenStack Baremetal Service
    auth:
      auth_url: "{{ ironic.service_catalog.auth_url | default('http://127.0.0.1:5000/') }}"
      username: "{{ keystone.bootstrap.username }}"
      password: "{{ keystone.bootstrap.password }}"
      project_name: "{{ keystone.bootstrap.project_name | default('admin') }}"
      project_domain_id: "default"
      user_domain_id: "default"
    wait: yes
  environment: "{{ venv }}"
  no_log: true

- name: "Check ironic admin endpoint exists"
  command: |
    openstack
    --os-identity-api-version 3
    --os-username "{{ keystone.bootstrap.username }}"
    --os-password "{{ keystone.bootstrap.password }}"
    --os-auth-url "{{ ironic.service_catalog.auth_url | default('http://127.0.0.1:5000/') }}"
    --os-project-name "{{ keystone.bootstrap.project_name | default('admin') }}"
    endpoint list -f json --noindent --service baremetal --interface admin
    --region "{{ keystone.bootstrap.region_name | default('RegionOne') }}"
  no_log: true
  register: test_ironic_admin_endpoint
  ignore_errors: true
  environment: "{{ bifrost_venv_env if enable_venv else {} }}"

- name: "Check ironic public endpoint exists"
  command: |
    openstack
    --os-identity-api-version 3
    --os-username "{{ keystone.bootstrap.username }}"
    --os-password "{{ keystone.bootstrap.password }}"
    --os-auth-url "{{ ironic.service_catalog.auth_url | default('http://127.0.0.1:5000/') }}"
    --os-project-name "{{ keystone.bootstrap.project_name | default('admin') }}"
    endpoint list -f json --noindent --service baremetal --interface public
    --region "{{ keystone.bootstrap.region_name | default('RegionOne') }}"
  no_log: true
  register: test_ironic_public_endpoint
  ignore_errors: true
  environment: "{{ bifrost_venv_env if enable_venv else {} }}"

- name: "Check ironic internal endpoint exists"
  command: |
    openstack
    --os-identity-api-version 3
    --os-username "{{ keystone.bootstrap.username }}"
    --os-password "{{ keystone.bootstrap.password }}"
    --os-auth-url "{{ ironic.service_catalog.auth_url | default('http://127.0.0.1:5000/') }}"
    --os-project-name "{{ keystone.bootstrap.project_name | default('admin') }}"
    endpoint list -f json --noindent --service baremetal --interface internal
    --region "{{ keystone.bootstrap.region_name | default('RegionOne') }}"
  no_log: true
  register: test_ironic_internal_endpoint
  ignore_errors: true
  environment: "{{ bifrost_venv_env if enable_venv else {} }}"

- name: "Create ironic admin endpoint"
  command: |
    openstack
    --os-identity-api-version 3
    --os-username "{{ keystone.bootstrap.username }}"
    --os-password "{{ keystone.bootstrap.password }}"
    --os-auth-url "{{ ironic.service_catalog.auth_url | default('http://127.0.0.1:5000/') }}"
    --os-project-name "{{ keystone.bootstrap.project_name | default('admin') }}"
    endpoint create --region "{{ keystone.bootstrap.region_name | default('RegionOne') }}"
    baremetal admin "{{ ironic.keystone.admin_url | default('http://127.0.0.1:6385/') }}"
  no_log: true
  environment: "{{ bifrost_venv_env if enable_venv else {} }}"
  when: test_ironic_admin_endpoint.rc != 0 or test_ironic_admin_endpoint.stdout == '[]'

- name: "Setting external Ironic public URL"
  set_fact:
    ironic_public_url: "{{ ironic.keystone.public_url | default('http://127.0.0.1:6385/') | replace('127.0.0.1', public_ip | default(hostvars[inventory_hostname]['ansible_' + ans_network_interface]['ipv4']['address'])) }}"
  when: use_public_urls | default(false) | bool

- name: "Create ironic public endpoint"
  command: |
    openstack
    --os-identity-api-version 3
    --os-username "{{ keystone.bootstrap.username }}"
    --os-password "{{ keystone.bootstrap.password }}"
    --os-auth-url "{{ ironic.service_catalog.auth_url | default('http://127.0.0.1:5000/') }}"
    --os-project-name "{{ keystone.bootstrap.project_name | default('admin') }}"
    endpoint create --region "{{ keystone.bootstrap.region_name | default('RegionOne') }}"
    baremetal public "{{ ironic_public_url | default(ironic.keystone.public_url) | default('http://127.0.0.1:6385/') }}"
  no_log: true
  environment: "{{ bifrost_venv_env if enable_venv else {} }}"
  when: test_ironic_public_endpoint.rc != 0 or test_ironic_public_endpoint.stdout == '[]'

- name: "Setting internal Ironic URL"
  set_fact:
    ironic_private_url: "{{ ironic.keystone.internal_url | default('http://127.0.0.1:6385/') | replace('127.0.0.1', private_ip) }}"
  when: private_ip is defined and private_ip | length > 0

- name: "Create ironic internal endpoint"
  command: |
    openstack
    --os-identity-api-version 3
    --os-username "{{ keystone.bootstrap.username }}"
    --os-password "{{ keystone.bootstrap.password }}"
    --os-auth-url "{{ ironic.service_catalog.auth_url | default('http://127.0.0.1:5000/') }}"
    --os-project-name "{{ keystone.bootstrap.project_name | default('admin') }}"
    endpoint create --region "{{ keystone.bootstrap.region_name | default('RegionOne') }}"
    baremetal internal "{{ ironic_private_url | default(ironic.keystone.internal_url) | default('http://127.0.0.1:6385/') }}"
  no_log: true
  environment: "{{ bifrost_venv_env if enable_venv else {} }}"
  when: test_ironic_internal_endpoint.rc != 0 or test_ironic_internal_endpoint.stdout == '[]'

- name: "Create baremetal_admin role"
  os_keystone_role:
    name: "baremetal_admin"
    state: present
    auth:
      auth_url: "{{ ironic.service_catalog.auth_url | default('http://127.0.0.1:5000/') }}"
      username: "{{ keystone.bootstrap.username }}"
      password: "{{ keystone.bootstrap.password }}"
      project_name: "{{ keystone.bootstrap.project_name | default('admin') }}"
      project_domain_id: "default"
      user_domain_id: "default"
  environment: "{{ venv }}"
  no_log: true

- name: "Create baremetal_observer role"
  os_keystone_role:
    name: "baremetal_observer"
    state: present
    auth:
      auth_url: "{{ ironic.service_catalog.auth_url | default('http://127.0.0.1:5000/') }}"
      username: "{{ keystone.bootstrap.username }}"
      password: "{{ keystone.bootstrap.password }}"
      project_name: "{{ keystone.bootstrap.project_name | default('admin') }}"
      project_domain_id: "default"
      user_domain_id: "default"
  environment: "{{ venv }}"
  no_log: true

- name: "Create baremetal project"
  os_project:
    name: "baremetal"
    state: present
    description: "Baremetal Project"
    domain_id: "default"
    enabled: yes
    auth:
      auth_url: "{{ ironic.service_catalog.auth_url | default('http://127.0.0.1:5000/') }}"
      username: "{{ keystone.bootstrap.username }}"
      password: "{{ keystone.bootstrap.password }}"
      project_name: "{{ keystone.bootstrap.project_name | default('admin') }}"
      project_domain_id: "default"
      user_domain_id: "default"
  environment: "{{ venv }}"
  no_log: true

- name: "Create bifrost user"
  os_user:
    name: "{{ ironic.keystone.default_username }}"
    password: "{{ ironic.keystone.default_password }}"
    default_project: "baremetal"
    domain: "default"
    auth:
      auth_url: "{{ ironic.service_catalog.auth_url | default('http://127.0.0.1:5000/') }}"
      username: "{{ keystone.bootstrap.username }}"
      password: "{{ keystone.bootstrap.password }}"
      project_name: "{{ keystone.bootstrap.project_name | default('admin') }}"
      project_domain_id: "default"
      user_domain_id: "default"
    wait: yes
  environment: "{{ venv }}"
  no_log: true

- name: "Associate bifrost user with baremetal_admin"
  os_user_role:
    user: "{{ ironic.keystone.default_username }}"
    role: "baremetal_admin"
    project: "baremetal"
    auth:
      auth_url: "{{ ironic.service_catalog.auth_url | default('http://127.0.0.1:5000/') }}"
      username: "{{ keystone.bootstrap.username }}"
      password: "{{ keystone.bootstrap.password }}"
      project_name: "{{ keystone.bootstrap.project_name | default('admin') }}"
      project_domain_id: "default"
      user_domain_id: "default"
    wait: yes
  environment: "{{ venv }}"
  no_log: true

**********
DECISION===>: Insufficient Logging
**********
=========================:::155:::END!!!=========================
=========================:::156:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-ironic-install/tasks/start.yml
**********
# Copyright (c) 2015 Hewlett-Packard Development Company, L.P.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.
---
- name: "Reload systemd configuration"
  command: systemctl daemon-reload
  when: init_template == 'systemd_template.j2'

- name: "Ensure rsyslog is running with current config"
  service: name=rsyslog state=restarted
  when: remote_syslog_server is defined and remote_syslog_server != ""

- name: "Start database service"
  service: name={{ mysql_service_name }} state=started enabled=yes

- name: "Start rabbitmq-server"
  service: name=rabbitmq-server state=started enabled=yes

- name: "start ironic-inspector"
  include: inspector_start.yml
  when: enable_inspector | bool == true

- name: "Start ironic-conductor"
  service: name=ironic-conductor state=started enabled=yes

- name: "Start ironic-api"
  service: name=ironic-api state=started enabled=yes

- name: "Start ironic-conductor"
  service: name=ironic-conductor state=restarted

- name: "Start ironic-api"
  service: name=ironic-api state=restarted

# NOTE(Shrews) When testing, we want to use our custom dnsmasq.conf file,
# not the one supplied by libvirt. And the libvirt started dnsmasq processes
# are not controlled by upstart, so we need to manually kill those.
- name: "Stop existing libvirt dnsmasq processes"
  command: killall -w dnsmasq
  when: testing | bool == true and include_dhcp_server | bool == true
  ignore_errors: yes

- name: "Ensure services are running with current config"
  service: name={{ item }} state=restarted enabled=yes
  with_items:
    - xinetd
    - nginx

- name: "Ensure dnsmasq is running with current config"
  service: name={{ item }} state=restarted enabled=yes
  with_items:
    - dnsmasq
  when: include_dhcp_server | bool == true

- name: "Send services a reload signal"
  service: name={{ item }} state=reloaded
  with_items:
    - xinetd
    - nginx

- name: "Send services a force-reload signal"
  service: name=dnsmasq state=restarted
  when: include_dhcp_server | bool == true

**********
DECISION===>: PASS
**********
=========================:::156:::END!!!=========================
=========================:::157:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-ironic-install/tasks/download_ipa_image.yml
**********
# Copyright (c) 2015 Hewlett-Packard Development Company, L.P.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.
---
# This is overly complex, however get_url will always re-retrieve the file
# if it already exists, and this is to prevent that behavior.
- import_role:
    name: venv_python_path

- name: "Test if IPA kernel is present"
  stat: path={{ ipa_kernel }}
  register: test_ipa_kernel_present

- block:
  - name: "Download IPA kernel checksum file"
    get_url: url="{{ ipa_kernel_upstream_checksum_url }}" dest="{{ ipa_kernel }}.{{ ipa_kernel_upstream_checksum_algo }}" timeout=300
    register: ipa_kernel_checksum_result
    ignore_errors: yes
    environment: "{{ venv }}"
  - debug: msg="WARNING!!! {{ ipa_kernel_upstream_checksum_algo }} file not found at {{ ipa_kernel_upstream_checksum_url }}"
    when: ipa_kernel_checksum_result is defined and ipa_kernel_checksum_result.status_code is defined and ipa_kernel_checksum_result.status_code == 404
  - fail: msg="FATAL {{ ipa_kernel_upstream_checksum_algo }} file not found at {{ ipa_kernel_upstream_checksum_url }} GOT {{ ipa_kernel_checksum_result }}"
    when: ipa_kernel_checksum_result is not defined or ipa_kernel_checksum_result.changed is not defined or
          (ipa_kernel_checksum_result.changed and ipa_kernel_checksum_result.status_code != 404 and ipa_kernel_checksum_result.status_code != 200)
  - name: "Extract IPA kernel checksum"
    shell: awk '/{{ ipa_kernel_upstream_url | basename }}/{print $1}' "{{ ipa_kernel }}.{{ ipa_kernel_upstream_checksum_algo }}"
    register: parsed_ipa_kernel_checksum
    when: not ipa_kernel_checksum_result|failed
  - fail:
      msg: "Failed to extract checksum for {{ ipa_kernel_upstream_url | basename }}"
    when: not ipa_kernel_checksum_result|failed and parsed_ipa_kernel_checksum.stdout == ""
  - set_fact:
      ipa_kernel_checksum: "{{ ipa_kernel_upstream_checksum_algo }}:{{ parsed_ipa_kernel_checksum.stdout }}"
    when: not ipa_kernel_checksum_result|failed
  when: ipa_kernel_upstream_checksum_url != ""

- name: "Download IPA kernel"
  get_url:
    url: "{{ ipa_kernel_upstream_url }}"
    dest: "{{ ipa_kernel }}"
    checksum: "{{ ipa_kernel_checksum | default(omit) }}"
    timeout: 300
    # Keep downloading it until we get a good copy
    force: yes
  register: ipa_kernel_download_done
  until: ipa_kernel_download_done|succeeded or
         (ipa_kernel_download_done|failed and ipa_kernel_download_done.status_code == 404)
  retries: 5
  delay: 10
  environment: "{{ venv }}"
  when: test_ipa_kernel_present.stat.exists == false

- name: "Test if IPA image is present"
  stat: path={{ ipa_ramdisk }}
  register: test_ipa_image_present

- block:
  - name: "Download IPA image checksum"
    get_url: url="{{ ipa_ramdisk_upstream_checksum_url }}" dest="{{ ipa_ramdisk }}.{{ ipa_ramdisk_upstream_checksum_algo }}" timeout=300
    register: ipa_ramdisk_checksum_result
    ignore_errors: yes
    environment: "{{ venv }}"
  - debug: msg="WARNING!!! {{ ipa_ramdisk_upstream_checksum_algo }} file not found at {{ ipa_ramdisk_upstream_checksum_url }}"
    when: ipa_ramdisk_checksum_result is defined and ipa_ramdisk_checksum_result.status_code is defined and ipa_ramdisk_checksum_result.status_code == 404
  - fail: msg="FATAL {{ ipa_ramdisk_upstream_checksum_algo }} file not found at {{ ipa_ramdisk_upstream_checksum_url }}"
    when: ipa_ramdisk_checksum_result is not defined or ipa_ramdisk_checksum_result.changed is not defined or
          (ipa_ramdisk_checksum_result.changed and ipa_ramdisk_checksum_result.status_code != 404 and ipa_ramdisk_checksum_result.status_code != 200)
  - name: "Extract IPA ramdisk checksum"
    shell: awk '/{{ ipa_ramdisk_upstream_url | basename }}/{print $1}' "{{ ipa_ramdisk }}.{{ ipa_ramdisk_upstream_checksum_algo }}"
    register: parsed_ipa_ramdisk_checksum
    when: not ipa_ramdisk_checksum_result|failed
  - fail:
      msg: "Failed to extract checksum for {{ ipa_ramdisk_upstream_url | basename }}"
    when: not ipa_ramdisk_checksum_result|failed and parsed_ipa_ramdisk_checksum.stdout == ""
  - set_fact:
      ipa_ramdisk_checksum: "{{ ipa_ramdisk_upstream_checksum_algo }}:{{ parsed_ipa_ramdisk_checksum.stdout }}"
    when: not ipa_ramdisk_checksum_result|failed
  when: ipa_ramdisk_upstream_checksum_url != ""

- name: "Download IPA image"
  get_url:
    url: "{{ ipa_ramdisk_upstream_url }}"
    dest: "{{ ipa_ramdisk }}"
    checksum: "{{ ipa_ramdisk_checksum | default(omit) }}"
    timeout: 300
    # Keep downloading it until we get a good copy
    force: yes
  register: ipa_ramdisk_download_done
  until: ipa_ramdisk_download_done|succeeded or
         (ipa_ramdisk_download_done|failed and ipa_ramdisk_download_done.status_code == 404)
  retries: 5
  delay: 10
  environment: "{{ venv }}"
  when: test_ipa_image_present.stat.exists == false

**********
DECISION===>: PASS
**********
=========================:::157:::END!!!=========================
=========================:::158:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-ironic-install/tasks/keystone_setup_inspector.yml
**********
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.
---

# TODO(TheJulia): The user and project domains are hardcoded in this.
# We should likely address that at some point, however I think a user
# should be the driver of that work.

- name: "Initialize default venv"
  set_fact:
    venv:
      OS_IDENTITY_API_VERSION: "3"

- name: "Error if credentials are undefined."
  fail:
    msg: |
        Credentials are missing or undefined, unable to proceed.
        Please consult roled defaults/main.yml.
  when: >
      keystone is undefined or keystone.bootstrap is undefined or
      keystone.bootstrap.username is undefined or
      keystone.bootstrap.password is undefined or
      keystone.bootstrap.project_name is undefined or
      ironic_inspector.service_catalog.auth_url is undefined or
      ironic_inspector.service_catalog.username is undefined or
      ironic_inspector.service_catalog.password is undefined or
      ironic_inspector.keystone is undefined or
      ironic_inspector.keystone.default_username is undefined or
      ironic_inspector.keystone.default_password is undefined

- import_role:
    name: venv_python_path

- name: "Create service user for ironic-inspector"
  os_user:
    name: "{{ ironic_inspector.service_catalog.username }}"
    password: "{{ ironic_inspector.service_catalog.password }}"
    state: present
    domain: "default"
    default_project: "{{ ironic_inspector.service_catalog.project_name | default('service') }}"
    auth:
      auth_url: "{{ ironic.service_catalog.auth_url | default('http://127.0.0.1:5000/') }}"
      username: "{{ keystone.bootstrap.username }}"
      password: "{{ keystone.bootstrap.password }}"
      project_name: "admin"
      project_domain_id: "default"
      user_domain_id: "default"
    wait: yes
  environment: "{{ venv }}"
  no_log: true

- name: "Associate ironic_inspector user to admin role"
  os_user_role:
    user: "{{ ironic_inspector.service_catalog.username }}"
    role: admin
    project: "{{ ironic_inspector.service_catalog.project_name | default('service') }}"
    auth:
      auth_url: "{{ ironic_inspector.service_catalog.auth_url | default('http://127.0.0.1:5000/') }}"
      username: "{{ keystone.bootstrap.username }}"
      password: "{{ keystone.bootstrap.password }}"
      project_name: "admin"
      project_domain_id: "default"
      user_domain_id: "default"
    wait: yes
  environment: "{{ venv }}"
  no_log: true

- name: "Create keystone service record for ironic-inspector"
  os_keystone_service:
    state: present
    name: ironic-inspector
    service_type: baremetal-introspection
    description: OpenStack Baremetal Introspection Service
    auth:
      auth_url: "{{ ironic.service_catalog.auth_url | default('http://127.0.0.1:5000/') }}"
      username: "{{ keystone.bootstrap.username }}"
      password: "{{ keystone.bootstrap.password }}"
      project_name: "admin"
      project_domain_id: "default"
      user_domain_id: "default"
    wait: yes
  environment: "{{ venv }}"
  no_log: true

- name: "Check ironic-inspector admin endpoint exists"
  command: |
    openstack
    --os-identity-api-version 3
    --os-username "{{ keystone.bootstrap.username }}"
    --os-password "{{ keystone.bootstrap.password }}"
    --os-auth-url "{{ ironic.service_catalog.auth_url | default('http://127.0.0.1:5000/') }}"
    --os-project-name admin
    endpoint list -f json --noindent --service baremetal-introspection --interface admin
    --region "{{ keystone.bootstrap.region_name | default('RegionOne') }}"
  no_log: true
  register: test_ironic_inspector_admin_endpoint
  environment: "{{ bifrost_venv_env if enable_venv else {} }}"

- name: "Check ironic-inspector public endpoint exists"
  command: |
    openstack
    --os-identity-api-version 3
    --os-username "{{ keystone.bootstrap.username }}"
    --os-password "{{ keystone.bootstrap.password }}"
    --os-auth-url "{{ ironic.service_catalog.auth_url | default('http://127.0.0.1:5000/') }}"
    --os-project-name admin
    endpoint list -f json --noindent --service baremetal-introspection --interface public
    --region "{{ keystone.bootstrap.region_name | default('RegionOne') }}"
  no_log: true
  register: test_ironic_inspector_public_endpoint
  environment: "{{ bifrost_venv_env if enable_venv else {} }}"

- name: "Check ironic-inspector internal endpoint exists"
  command: |
    openstack
    --os-identity-api-version 3
    --os-username "{{ keystone.bootstrap.username }}"
    --os-password "{{ keystone.bootstrap.password }}"
    --os-auth-url "{{ ironic.service_catalog.auth_url | default('http://127.0.0.1:5000/') }}"
    --os-project-name admin
    endpoint list -f json --noindent --service baremetal-introspection --interface internal
    --region "{{ keystone.bootstrap.region_name | default('RegionOne') }}"
  no_log: true
  register: test_ironic_inspector_internal_endpoint
  environment: "{{ bifrost_venv_env if enable_venv else {} }}"

- name: "Create ironic-inspector admin endpoint"
  command: |
    openstack
    --os-identity-api-version 3
    --os-username "{{ keystone.bootstrap.username }}"
    --os-password "{{ keystone.bootstrap.password }}"
    --os-auth-url "{{ ironic_inspector.service_catalog.auth_url | default('http://127.0.0.1:5000/') }}"
    --os-project-name admin
    endpoint create --region "{{ keystone.bootstrap.region_name | default('RegionOne') }}"
    baremetal-introspection admin "{{ ironic_inspector.keystone.admin_url | default('http://127.0.0.1:5050/') }}"
  no_log: true
  environment: "{{ bifrost_venv_env if enable_venv else {} }}"
  when: test_ironic_inspector_admin_endpoint.rc != 0 or test_ironic_inspector_admin_endpoint.stdout == '[]'

- name: "Setting external ironic-inspector public URL"
  set_fact:
    ironic_inspector_public_url: "{{ ironic_inspector.keystone.public_url | default('http://127.0.0.1:5050/') | replace('127.0.0.1', public_ip | default(hostvars[inventory_hostname]['ansible_' + ans_network_interface]['ipv4']['address'])) }}"
  when: use_public_urls | default(false) | bool

# NOTE(TheJulia): This seems like something that should be
# to admin or internal interfaces. Perhaps we should attempt
# remove it after we have a working keystone integrated CI job.
- name: "Create ironic-inspector public endpoint"
  command: |
    openstack
    --os-identity-api-version 3
    --os-username "{{ keystone.bootstrap.username }}"
    --os-password "{{ keystone.bootstrap.password }}"
    --os-auth-url "{{ ironic.service_catalog.auth_url | default('http://127.0.0.1:5000/') }}"
    --os-project-name admin
    endpoint create --region "{{ keystone.bootstrap.region_name | default('RegionOne') }}"
    baremetal-introspection public "{{ ironic_inspector_public_url | default(ironic_inspector.keystone.public_url) | default('http://127.0.0.1:5050/') }}"
  no_log: true
  environment: "{{ bifrost_venv_env if enable_venv else {} }}"
  when: test_ironic_inspector_public_endpoint.rc != 0 or test_ironic_inspector_public_endpoint.stdout == '[]'

- name: "Setting internal ironic-inspector URL"
  set_fact:
    ironic_inspector_private_url: "{{ ironic_inspector.keystone.internal_url | default('http://127.0.0.1:5050/') | replace('127.0.0.1', private_ip) }}"
  when: private_ip is defined and private_ip | length > 0

- name: "Create ironic-inspector internal endpoint"
  command: |
    openstack
    --os-identity-api-version 3
    --os-username "{{ keystone.bootstrap.username }}"
    --os-password "{{ keystone.bootstrap.password }}"
    --os-auth-url "{{ ironic.service_catalog.auth_url | default('http://127.0.0.1:5000/') }}"
    --os-project-name admin
    endpoint create --region "{{ keystone.bootstrap.region_name | default('RegionOne') }}"
    baremetal-introspection internal "{{ ironic_inspector_private_url | default(ironic_inspector.keystone.internal_url) | default('http://127.0.0.1:5050/') }}"
  no_log: true
  environment: "{{ bifrost_venv_env if enable_venv else {} }}"
  when: test_ironic_inspector_internal_endpoint.rc != 0 or test_ironic_inspector_internal_endpoint.stdout == '[]'

- name: "Create inspector_user user"
  os_user:
    name: "{{ ironic_inspector.keystone.default_username }}"
    password: "{{ ironic_inspector.keystone.default_password }}"
    default_project: "baremetal"
    domain: "default"
    auth:
      auth_url: "{{ ironic_inspector.service_catalog.auth_url | default('http://127.0.0.1:5000/') }}"
      username: "{{ keystone.bootstrap.username }}"
      password: "{{ keystone.bootstrap.password }}"
      project_name: admin
      project_domain_id: "default"
      user_domain_id: "default"
    wait: yes
  environment: "{{ venv }}"
  no_log: true

- name: "Associate inspector_user with baremetal_admin"
  os_user_role:
    user: "{{ ironic_inspector.keystone.default_username }}"
    role: "baremetal_admin"
    project: baremetal
    auth:
      auth_url: "{{ ironic_inspector.service_catalog.auth_url | default('http://127.0.0.1:5000/') }}"
      username: "{{ keystone.bootstrap.username }}"
      password: "{{ keystone.bootstrap.password }}"
      project_name: admin
      project_domain_id: "default"
      user_domain_id: "default"
    wait: yes
  environment: "{{ venv }}"
  no_log: true

**********
DECISION===>: Insufficient Logging
**********
=========================:::158:::END!!!=========================
=========================:::159:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-ironic-install/tasks/pip_install.yml
**********
# Copyright (c) 2015 Hewlett Packard Enterprise Development LP.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.
---

- name: set virtualenv_command
  set_fact:
    venv_command: "{{ hostvars[inventory_hostname].ansible_python.executable }} -m virtualenv"
  when: enable_venv|bool

- name: "Install {{ package }} package from pip using virtualenv"
  pip:
    name: "{{ package }}"
    state: "{{ state | default(omit) }}"
    version: "{{ version | default(omit) }}"
    virtualenv: "{{ bifrost_venv_dir }}"
    virtualenv_command: "{{ venv_command | default(omit) }}"
    extra_args: "{{ extra_args | default(omit) }}"
    requirements: "{{ requirements_file | default(omit) }}"
  register: pip_package_install_done
  until: pip_package_install_done|succeeded
  retries: 5
  delay: 10
  when: (source_install is not defined or source_install == false) and enable_venv|bool

- name: "Install {{ package }} package from pip without virtualenv"
  pip:
    name: "{{ package }}"
    state: "{{ state | default(omit) }}"
    version: "{{ version | default(omit) }}"
    extra_args: "{{ extra_args | default(omit) }}"
    requirements: "{{ requirements_file | default(omit) }}"
  register: pip_package_install_done
  until: pip_package_install_done|succeeded
  retries: 5
  delay: 10
  when: (source_install is not defined or source_install == false) and not enable_venv|bool

# NOTE (cinerama): We should be able to use the pip module here and
# possibly merge these two tasks when
# https://github.com/ansible/ansible-modules-core/pull/2600 lands.
- name: "Install from {{ sourcedir }} using pip"
  command: pip install {{ sourcedir }} {{ extra_args | default('') }}
  register: pip_package_install_done
  until: pip_package_install_done|succeeded
  retries: 5
  delay: 10
  when: source_install is defined and (source_install | bool == true)
  environment: "{{ bifrost_venv_env if enable_venv else {} }}"

**********
DECISION===>: PASS
**********
=========================:::159:::END!!!=========================
=========================:::160:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-ironic-install/tasks/inspector_start.yml
**********
# Copyright (c) 2015 Hewlett-Packard Development Company, L.P.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.
---
- name: "Inspector - (re)starting ironic-inspector service"
  service:
    name=ironic-inspector
    state=restarted
    enabled=yes

**********
DECISION===>: PASS
**********
=========================:::160:::END!!!=========================
=========================:::161:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-ironic-install/tasks/create_tftpboot.yml
**********
# Copyright (c) 2015 Hewlett-Packard Development Company, L.P.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.
---
# TODO(TheJulia): The pxelinux folder is statically coded in ironic.
# For now, we need to use it, but we can patch that.
- name: "Set up PXE and iPXE folders"
  file: name={{item}} owner=ironic group=ironic state=directory mode=0755
  with_items:
    - /tftpboot
    - /tftpboot/pxelinux.cfg
    - "{{ http_boot_folder }}"
    - "{{ http_boot_folder }}/pxelinux.cfg"

- name: "Place tftpd map-file"
  copy: src=tftpboot-map-file dest=/tftpboot/map-file owner=ironic group=ironic

- name: "Disable service {{ tftp_service_name }}"
  service: name="{{ tftp_service_name }}" state=stopped enabled=no

- name: "Place boot.ipxe helper script /etc/ironic"
  copy: src=boot.ipxe dest=/etc/ironic/boot.ipxe owner=ironic group=ironic mode=0744

- name: "Place tftp config file"
  copy: src=xinetd.tftp dest=/etc/xinetd.d/tftp

- name: "Download ipxe files if asked"
  include: get_ipxe.yml
  when: download_ipxe | bool == true

- name: "Copy iPXE image into place"
  copy: src={{ ipxe_dir }}/undionly.kpxe dest=/tftpboot/ remote_src=true

# NOTE(TheJulia): Copy full iPXE chain loader images in case they are required.
- name: "Copy full iPXE image into {{ http_boot_folder }}/"
  copy: src={{ ipxe_dir }}/{{ ipxe_full_binary }} dest={{ http_boot_folder }}/ remote_src=true

- name: "Copy full iPXE image into /tftpboot"
  copy: src={{ ipxe_dir }}/{{ ipxe_full_binary }} dest=/tftpboot/ remote_src=true

- name: "Set up iPXE for EFI booting"
  block:
    - name: "Check if the iPXE EFI image is present"
      stat:
        path: "{{ ipxe_dir }}/{{ ipxe_efi_binary }}"
        get_md5: false
      register: test_ipxe_efi_binary_path
      ignore_errors: true

    - name: "Abort if iPXE EFI image is missing"
      fail:
        msg: >
          Aborting installation: The {{ ipxe_efi_binary }} image was not found
          at the {{ ipxe_dir }} location.  Please place this file or consider
          re-running with download_ipxe set to a value of true.
      when:
        - test_ipxe_efi_binary_path.stat.exists | bool == false

    - name: "Copy iPXE EFI image into {{ http_boot_folder }}/"
      copy: src={{ ipxe_dir }}/{{ ipxe_efi_binary }} dest={{ http_boot_folder }}/ remote_src=true

    - name: "Copy iPXE EFI image into /tftpboot"
      copy: src={{ ipxe_dir }}/{{ ipxe_efi_binary }} dest=/tftpboot/ remote_src=true
  when: enable_uefi_ipxe | bool == true

# Similar logic to below can be utilized to retrieve files
- name: "Determine if folder exists, else create and populate folder."
  stat: path="{{ ironic_tftp_master_path }}"
  register: test_master_images

- name: "Create master_images folder"
  file: name="{{ ironic_tftp_master_path }}" state=directory owner=ironic group=ironic
  when: test_master_images.stat.exists == false

# TODO(TheJulia): The pxelinux folder is statically coded in ironic.
# For now, we need to use it, but we can patch that.
- name: "Inspector - Place default tftp boot file in {{ http_boot_folder}}/pxelinux.cfg/"
  template:
    src=inspector-default-boot-ipxe.j2
    dest="{{ http_boot_folder }}/pxelinux.cfg/default"
    owner=ironic
    group=ironic
  when: enable_inspector | bool == true

**********
DECISION===>: Suspicious Comment
**********
=========================:::161:::END!!!=========================
=========================:::162:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-ironic-install/tasks/ironic_config.yml
**********
# Copyright (c) 2015 Hewlett-Packard Development Company, L.P.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.
---
- name: "Interface name fact"
  set_fact:
    provisioning_itf_name: "{{ ('ansible_' ~ network_interface) | regex_replace('-', '_') }}"
- name: "Fail if the network interface does not exist"
  fail:
    msg: >
      The configured network interface {{ network_interface }} does
      not exist
  when: provisioning_itf_name not in hostvars[inventory_hostname]
- name: "Fail if the network interface has no IP address assigned"
  fail:
    msg: >
      The configured network interface {{ network_interface }} does
      not have an IP address assigned
  when: not hostvars[inventory_hostname][provisioning_itf_name].get('ipv4', {}).get('address')
- name: "Create ironic config"
  template:
    src="ironic.conf.j2"
    dest=/etc/ironic/ironic.conf
    owner=ironic
    group=ironic
    mode=0640
- name: "Symlinks from venv if using"
  file:
    state: link
    path: "{{ ironic_rootwrap_dir }}/{{ item | basename }}"
    src: "{{ item }}"
    owner: root
    group: root
  when: enable_venv | bool == true
  with_items:
    - "{{ bifrost_venv_dir }}/bin/ironic-rootwrap"
    - "{{ bifrost_venv_dir }}/bin/ironic-inspector-rootwrap"
- name: "Set sudoers for rootwrap"
  lineinfile:
    dest: /etc/sudoers
    regexp: "{{ item.regexp }}"
    line: "{{ item.line }}"
  with_items:
    - { regexp: '^ironic(.*)/ironic-rootwrap /etc/ironic/rootwrap.conf(.*)', line: "ironic ALL = (root) NOPASSWD: {{ ironic_rootwrap_dir }}/ironic-rootwrap /etc/ironic/rootwrap.conf *" }
    - { regexp: '^ironic(.*)/ironic-inspector-rootwrap /etc/ironic-inspector/rootwrap.conf(.*)', line: "ironic ALL = (root) NOPASSWD: {{ ironic_rootwrap_dir }}/ironic-inspector-rootwrap /etc/ironic-inspector/rootwrap.conf *" }

**********
DECISION===>: Hardcoded Secret
**********
=========================:::162:::END!!!=========================
=========================:::163:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-ironic-install/tasks/bootstrap.yml
**********
# Copyright (c) 2015 Hewlett-Packard Development Company, L.P.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.
---
- name: "Fail if authentication configuration conflicts."
  fail:
    msg: >
      noauth_mode and enable_keystone are mutually exclusive options.
      Please set one to "false".
  when: >
    noauth_mode | bool == true and enable_keystone is defined and
    enable_keystone | bool == true

- name: "If VENV is set in the environment, enable installation into venv"
  set_fact:
    enable_venv: true
  when: lookup('env', 'VENV') | length > 0

- name: "Ensure /etc/hosts has good defaults"
  lineinfile:
    dest: "/etc/hosts"
    regexp: "{{ item.regexp }}.*({{ ansible_hostname }}|localhost).*"
    line: "{{ item.contents }}"
  with_items:
    - { regexp: '^127\.0\.0\.1', contents: '127.0.0.1 {{ ansible_hostname }} {{ ansible_fqdn }} localhost' }
    - { regexp: '^::1', contents: '::1 {{ ansible_hostname }} {{ ansible_fqdn }} localhost ipv6-localhost ipv6-loopback' }

# NOTE(sean-k-mooney) only the RabbitMQ server and MySQL db are started
# during bootstrapping. all other services are started in the Start phase.
- name: "Start database service"
  service: name={{ mysql_service_name }} state=started enabled=yes
  when: ironic.database.host == 'localhost'

# NOTE(hwoarang): The erlang SUSE package forces epmd to listen on localhost
# address which breaks rabbitmq-server when listening on a different address.
# https://build.opensuse.org/package/view_file/devel:languages:erlang:Factory/erlang/README.SUSE?expand=1
- name: "Make epmd listen to all addresses on SUSE"
  block:
    - blockinfile:
        dest: "/etc/systemd/system/epmd.socket.d/port.conf"
        content: |
          [Socket]
          ListenStream=
          ListenStream=0.0.0.0:4369
        create: yes
        marker: "# {mark} ANSIBLE MANAGED BLOCK"

    - systemd: daemon_reload=yes

    - service: name={{ item }} state=stopped enabled=no
      with_items:
        - epmd.socket
        - epmd

  when: ansible_os_family == 'Suse'
- name: "Start rabbitmq-server"
  service: name=rabbitmq-server state=started enabled=yes

# NOTE(cinerama): on some systems, rabbit may not be ready when we want to
# make changes to users if we don't wait first
# TODO(TheJulia): This needs to be changed to a variable, however
# should update this playbook all at once with new variable structures.
- name: "Wait for rabbitmq"
  wait_for: port=5672 delay=5

- name: "Ensure guest user is removed from rabbitmq"
  rabbitmq_user:
    user: "guest"
    state: absent
    force: yes
- name: "Create ironic user in RabbitMQ"
  rabbitmq_user:
    user: "ironic"
    password: "{{ ironic_db_password }}"
    force: yes
    state: present
    configure_priv: ".*"
    write_priv: ".*"
    read_priv: ".*"
  no_log: true

- name: "Set mysql_username if environment variable mysql_user is set"
  set_fact:
    mysql_username: "{{ lookup('env', 'mysql_user') }}"
  when: lookup('env', 'mysql_user') | length > 0
  no_log: true

- name: "Set mysql_password if environment variable mysql_pass is set"
  set_fact:
    mysql_password: "{{ lookup('env', 'mysql_pass') }}"
  when: lookup('env', 'mysql_pass') | length > 0
  no_log: true

- name: Setting MySQL socket fact
  set_fact:
    mysql_socket_path: "/var/{% if ansible_os_family | lower == 'redhat' %}lib{% else %}run{% endif %}/{% if ansible_os_family | lower == 'debian' %}mysqld/mysqld.sock{% else %}mysql/mysql.sock{% endif %}"
  when: ansible_version.full is version_compare('2.6.5', '>=')

- name: "MySQL - Creating DB"
  mysql_db:
    login_unix_socket: "{{ mysql_socket_path | default(omit) }}"
    name: "{{ ironic.database.name }}"
    state: present
    encoding: utf8
    login_user: "{{ mysql_username | default(None) }}"
    login_password: "{{ mysql_password | default(None) }}"
  register: test_created_db
  when: ironic.database.host == 'localhost'

- name: "MySQL - Creating user for Ironic"
  mysql_user:
    login_unix_socket: "{{ mysql_socket_path | default(omit) }}"
    name: "{{ ironic.database.username }}"
    password: "{{ ironic.database.password }}"
    priv: "{{ ironic.database.name }}.*:ALL"
    state: present
    login_user: "{{ mysql_username | default(None) }}"
    login_password: "{{ mysql_password | default(None) }}"
  when: ironic.database.host == 'localhost'

- name: "Create an ironic service group"
  group:
    name: "ironic"
- name: "Create an ironic service user"
  user:
    name: "ironic"
    group: "ironic"
- name: "Ensure /etc/ironic exists"
  file:
    name: "/etc/ironic"
    state: directory
    owner: "ironic"
    group: "ironic"
    mode: 0755
# Note(TheJulia): The rootwrap copies will need to be re-tooled
# to possibly directly retreive current files if a source install
# is not utilized.
- name: "Copy rootwrap.conf from ironic source folder"
  copy:
    src: "{{ ironic_git_folder }}/etc/ironic/rootwrap.conf"
    dest: "/etc/ironic/rootwrap.conf"
    remote_src: yes
    mode: 0644
    owner: root
    group: root
  when: skip_install is not defined
# Note(ashestakov): "copy" module in ansible doesn't support recursive
# copying on remote host. "cp" command used instead.
- name: "Copy rootwrap.d contents from ironic source folder"
  command: cp -r "{{ ironic_git_folder }}/etc/ironic/rootwrap.d/" "/etc/ironic/rootwrap.d"
  when: skip_install is not defined

- name: "Populate keystone for Bifrost"
  include: keystone_setup.yml
  when: enable_keystone is defined and enable_keystone | bool == true

# NOTE(pas-ha) needed to e.g. pick up new interfaces after libvirt install
- name: "Refresh facts"
  setup:

- name: "Generate ironic Configuration"
  include: ironic_config.yml

- name: "Create ironic DB Schema"
  command: ironic-dbsync --config-file /etc/ironic/ironic.conf create_schema
  environment: "{{ bifrost_venv_env if enable_venv else {} }}"
  when: >
      ironic.database.host == 'localhost' and
      test_created_db.changed | bool == true

- name: "Upgrade ironic DB Schema"
  command: ironic-dbsync --config-file /etc/ironic/ironic.conf upgrade
  environment: "{{ bifrost_venv_env if enable_venv else {} }}"
  when: >
      ironic.database.host != 'localhost' or
      test_created_db.changed | bool == false

- name: "Create service folder if systemd template is defined"
  file:
    path: "{{ init_dest_dir }}"
    state: directory
    mode: 0755
  when: init_template == 'systemd_template.j2'

- name: "Install ironic-inspector to permit use of inspection interface"
  include: inspector_bootstrap.yml
  when: enable_inspector | bool == true

- name: "Get ironic-api & ironic-conductor install location"
  shell: echo $(dirname $(which ironic-api))
  register: ironic_install_prefix
  environment: "{{ bifrost_venv_env if enable_venv else {} }}"

- name: "Set permissions for /var/lib/ironic for the ironic user"
  file:
    path: "{{ item }}"
    state: directory
    mode: 0750
    owner: "ironic"
    group: "ironic"
  with_items:
    - "/var/lib/ironic"
    - "/var/lib/ironic/master_images"
    - "/var/lib/ironic/images"

- name: "Set permissions for /var/log/ironic for the ironic user"
  file:
    path: "{{ item }}"
    state: directory
    mode: 0755
    owner: "ironic"
    group: "ironic"
  with_items:
    - "/var/log/ironic"

- name: "Place ironic services"
  template:
    src: "{{ init_template }}"
    dest: "{{ init_dest_dir }}{{ item.service_name }}{{ init_ext }}"
    owner: "root"
    group: "root"
  with_items:
    - { service_path: "{{ ironic_install_prefix.stdout | default('') }}", service_name: 'ironic-api', username: 'ironic', args: '--config-file /etc/ironic/ironic.conf'}
    - { service_path: "{{ ironic_install_prefix.stdout | default('') }}", service_name: 'ironic-conductor', username: 'ironic', args: '--config-file /etc/ironic/ironic.conf'}
- name: "Create and populate /tftpboot"
  include: create_tftpboot.yml
- name: "Setup Inventory Hosts Directory"
  file:
    path: "/etc/dnsmasq.d/bifrost.hosts.d"
    state: directory
    owner: "root"
    group: "root"
    mode: 0755
  when: inventory_dhcp | bool == true
- name: "Setup Inventory DHCP Hosts Directory"
  file:
    path: "/etc/dnsmasq.d/bifrost.dhcp-hosts.d"
    state: directory
    owner: "root"
    group: "root"
    mode: 0755
  when: inventory_dhcp | bool == true
- name: "Retrieve interface IP informations"
  set_fact:
    itf_infos: "{{ hostvars[inventory_hostname]['ansible_' + ans_network_interface]['ipv4'] }}"
    dhcp_netaddr: "{{ dhcp_pool_start }}/{{ dhcp_static_mask }}"
  when: include_dhcp_server | bool == true
- name: "Compute interface and DHCP network informations"
  set_fact:
    itf_netaddr1: "{{ itf_infos['address'] }}/{{ itf_infos['netmask'] }}"
    itf_netaddr2: "{{ itf_infos['network'] }}/{{ itf_infos['netmask'] }}"
    itf_broadcast: "{{ itf_infos['broadcast'] }}/{{ itf_infos['netmask'] }}"
    dhcp_netaddr: "{{ dhcp_netaddr | ipaddr('network') }}/{{ dhcp_static_mask }}"
  when: include_dhcp_server | bool == true
- name: "Validate interface network addresses"
  fail: msg="Interface {{ ans_network_interface }} network incoherence {{ itf_netaddr1 | ipaddr('network') }}/{{ itf_netaddr1 | ipaddr('prefix') }} vs {{ itf_netaddr2 }}/{{ itf_netaddr2 | ipaddr('prefix') }}"
  when:
    - include_dhcp_server | bool == true
    - itf_netaddr1 | ipaddr('network') != itf_netaddr2 | ipaddr('network')
- name: "Validate interface broadcast addresses"
  fail: msg="Interface {{ ans_network_interface }} broadcast incoherence {{ itf_netaddr1 | ipaddr('broadcast') }}/{{ itf_netaddr1 | ipaddr('prefix') }} vs {{ itf_broadcast | ipaddr('broadcast') }}/{{ itf_broadcast | ipaddr('prefix') }}"
  when:
    - include_dhcp_server | bool == true
    - itf_netaddr1 | ipaddr('broadcast') != itf_broadcast | ipaddr('broadcast')
- name: "Validate DHCP and interface addresses"
  debug: msg="Interface {{ ans_network_interface }} and DHCP networks are incoherent {{ itf_netaddr2 | ipaddr('network') }}/{{ itf_netaddr2 | ipaddr('prefix') }} {{ dhcp_netaddr | ipaddr('network') }}/{{ dhcp_netaddr | ipaddr('prefix') }} overriding DHCP with interface settings"
  when:
    - include_dhcp_server | bool == true
    - itf_netaddr2 | ipaddr('network') != dhcp_netaddr | ipaddr('network')
- name: "Computing new DHCP informations"
  set_fact:
    dhcp_start_ip: "{{ dhcp_pool_start.split('.')[-1] }}"
    dhcp_end_ip: "{{ dhcp_pool_end.split('.')[-1] }}"
    dhcp_netaddr: "{{ itf_netaddr1 | ipaddr('network') }}"
  when:
    - include_dhcp_server | bool == true
    - itf_netaddr2 | ipaddr('network') != dhcp_netaddr | ipaddr('network')
# Note(olivierbourdon38): we could do much more complex network
# computation to derive exact (or way closer to exact) range for
# the new network depending on netmasks and indexes.
- name: "Computing new DHCP range"
  set_fact:
     dhcp_pool_start: "{{ '.'.join(dhcp_netaddr.split('.')[0:-1]) }}.{{ dhcp_start_ip }}"
     dhcp_pool_end: "{{ '.'.join(dhcp_netaddr.split('.')[0:-1]) }}.{{ dhcp_end_ip }}"
  when:
    - include_dhcp_server | bool == true
    - itf_netaddr2 | ipaddr('network') != dhcp_netaddr | ipaddr('network')
- name: "Deploy dnsmasq configuration file"
  template: src=dnsmasq.conf.j2 dest=/etc/dnsmasq.conf
  when: include_dhcp_server | bool == true
# NOTE(Shrews) When testing, we want to use our custom dnsmasq.conf file,
# not the one supplied by libvirt.
- name: "Look for libvirt dnsmasq config"
  stat: path=/etc/dnsmasq.d/libvirt-bin
  register: test_libvirt_dnsmasq
  when: include_dhcp_server | bool == true
- name: "Disable libvirt dnsmasq config"
  command: mv /etc/dnsmasq.d/libvirt-bin /etc/dnsmasq.d/libvirt-bin~
  when: >
     include_dhcp_server | bool == true and
     test_libvirt_dnsmasq.stat.exists | bool == true and
     testing | bool == true
- name: "Deploy nginx configuration file for serving HTTP requests"
  template: src=nginx.conf.j2 dest=/etc/nginx/nginx.conf
- name: "Ensure inspector object storage directory exists"
  file:
    path: "{{ http_boot_folder }}/ironic-inspector"
    state: directory
    owner: "{{ nginx_user }}"
    group: "{{ nginx_user }}"
  when:
    - enable_inspector | bool
    - inspector_store_data_in_nginx | bool
- name: "Download Ironic Python Agent kernel & image"
  include: download_ipa_image.yml
  when: create_ipa_image | bool == false and download_ipa | bool == true
- name: "Download cirros to use for deployment if requested"
  get_url:
    url: "{{ cirros_deploy_image_upstream_url }}"
    dest: "{{ deploy_image }}"
  when: use_cirros | bool == true
- name: >
    "Explicitly permit nginx port (TCP) for file downloads from nodes to be provisioned
     and TCP/6385 for IPA callback"
  iptables:
    chain: INPUT
    action: insert
    protocol: tcp
    destination_port: "{{ item }}"
    in_interface: "{{ network_interface }}"
    jump: ACCEPT
  with_items:
    - "{{ file_url_port }}"
    - 6385
- block:
    - name: "Explicitly allow nginx and IPA port (TCP) on selinux"
      seport:
        ports: "{{ file_url_port }},6385"
        proto: tcp
        setype: http_port_t
        state: present

    - name: "Add proper context on created data for http_boot"
      sefcontext:
        target: "{{ http_boot_folder }}(/.*)?"
        setype: httpd_sys_content_t
        state: present

    - name: "Add proper context on inspector data store"
      sefcontext:
        target: "{{ http_boot_folder }}/ironic-inspector(/.*)?"
        setype: httpd_sys_rw_content_t
        state: present
      when:
        - enable_inspector | bool
        - inspector_store_data_in_nginx | bool

    - name: Copy ironic policy file to temporary directory
      copy:
        src: ironic_policy.te
        dest: /tmp/ironic_policy.te

    - name: Check ironic policy module
      command: checkmodule -M -m -o /tmp/ironic_policy.mod /tmp/ironic_policy.te

    - name: Package ironic policy module
      command: semodule_package -m /tmp/ironic_policy.mod -o /tmp/ironic_policy.pp

    - name: Include ironic policy module
      command: semodule -i /tmp/ironic_policy.pp

    - name: Enable ironic policy module
      command: semodule -e ironic_policy
  when: (ansible_os_family == 'RedHat' or ansible_os_family == 'Suse') and
         ansible_selinux.status == 'enabled' and ansible_selinux.mode == "enforcing"
- name: "Configure remote logging"
  template: src=10-rsyslog-remote.conf.j2 dest=/etc/rsyslog.d/10-rsyslog-remote.conf
  when: remote_syslog_server is defined and remote_syslog_server != ""

**********
DECISION===>: PASS
**********
=========================:::163:::END!!!=========================
=========================:::164:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-ironic-install/tasks/inspector_install.yml
**********
# Copyright (c) 2015 Hewlett-Packard Development Company, L.P.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.
---
- name: "Inspector - PIP Install"
  include: pip_install.yml
    package=ironic-inspector
    state=latest
    sourcedir={{ ironicinspector_git_folder }}
    source_install={{ ironicinspector_source_install }}
    extra_args="--no-cache-dir --upgrade {{ pip_opts }} -c {{ upper_constraints_file }}"

- name: "Inspector - PIP client install"
  include: pip_install.yml
    package=python-ironic-inspector-client
    state=latest
    sourcedir={{ ironicinspectorclient_git_folder }}
    source_install={{ ironicinspectorclient_source_install }}
    extra_args="--no-cache-dir --upgrade {{ pip_opts }} -c {{ upper_constraints_file }}"

**********
DECISION===>: PASS
**********
=========================:::164:::END!!!=========================
=========================:::165:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-ironic-install/tasks/inspector_bootstrap.yml
**********
# Copyright (c) 2015 Hewlett-Packard Development Company, L.P.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.
---
- name: Setting MySQL socket fact
  set_fact:
    mysql_socket_path: "/var/{% if ansible_os_family | lower == 'redhat' %}lib{% else %}run{% endif %}/{% if ansible_os_family | lower == 'debian' %}mysqld/mysqld.sock{% else %}mysql/mysql.sock{% endif %}"
  when: ansible_version.full is version_compare('2.6.5', '>=')

- name: "MySQL - Create database"
  mysql_db:
    login_unix_socket: "{{ mysql_socket_path | default(omit) }}"
    login_user: "{{ mysql_username }}"
    login_password: "{{ mysql_password }}"
    name: "{{ ironic_inspector.database.name }}"
    state: present
    encoding: utf8
  when: ironic_inspector.database.host == 'localhost'

- name: "MySQL - Create user for inspector"
  mysql_user:
    login_unix_socket: "{{ mysql_socket_path | default(omit) }}"
    login_user: "{{ mysql_username }}"
    login_password: "{{ mysql_password }}"
    name: "{{ ironic_inspector.database.username }}"
    password: "{{ ironic_inspector.database.password }}"
    priv: "{{ ironic_inspector.database.name }}.*:ALL"
    state: present
  when: ironic_inspector.database.host == 'localhost'

- name: "Inspector - Ensure /etc/ironic-inspector/ exists"
  file:
    dest=/etc/ironic-inspector
    owner=ironic
    group=ironic
    mode=0755
    state=directory
# Note(TheJulia): The rootwrap copies will need to be re-tooled
# to possibly directly retreive current files if a source install
# is not utilized.
- name: "Copy rootwrap.conf from ironic-inspector source folder"
  copy:
    src: "{{ ironicinspector_git_folder }}/rootwrap.conf"
    dest: "/etc/ironic-inspector/rootwrap.conf"
    remote_src: yes
    mode: 0644
    owner: root
    group: root
# Note(ashestakov): "copy" module in ansible doesn't support recursive
# copying on remote host. "cp" command used instead.
- name: "Copy rootwrap.d contents from ironic-inspector source folder"
  command: cp -r "{{ ironicinspector_git_folder }}/rootwrap.d/" "/etc/ironic-inspector/rootwrap.d"

- name: "Populate keystone for ironic-inspector "
  include: keystone_setup_inspector.yml
  when: enable_keystone is defined and enable_keystone | bool == true

- name: "Inspector - Place Configuration"
  template:
    src=ironic-inspector.conf.j2
    dest=/etc/ironic-inspector/inspector.conf
    owner=ironic
    group=ironic
    mode=0740
- name: "Inspector - create data folder"
  file:
    name="{{ inspector_data_dir }}"
    state=directory
    owner=ironic
    group=ironic
    mode=0755
- name: "Inspector - create log folder"
  file:
    name="{{ inspector_data_dir }}/log"
    state=directory
    owner=ironic
    group=ironic
    mode=0755
- name: "Upgrade inspector DB Schema"
  shell: ironic-inspector-dbsync --config-file /etc/ironic-inspector/inspector.conf upgrade
  become: true
  environment: "{{ bifrost_venv_env if enable_venv else {} }}"
- name: "Inspector - Get ironic-inspector install location"
  shell: echo $(dirname $(which ironic-inspector))
  register: ironic_install_prefix
  environment: "{{ bifrost_venv_env if enable_venv else {} }}"
- name: "Inspector - Place service"
  template: src={{ init_template }} dest={{ init_dest_dir }}{{item.service_name}}{{ init_ext }} owner=root group=root
  with_items:
    - { service_path: "{{ ironic_install_prefix.stdout | default('') }}", service_name: 'ironic-inspector', username: 'ironic', args: '--config-file /etc/ironic-inspector/inspector.conf'}
- name: "Inspector - Explicitly permit TCP/5050 for ironic-inspector callback"
  command: iptables -I INPUT -p tcp --dport 5050 -i {{network_interface}} -j ACCEPT

**********
DECISION===>: PASS
**********
=========================:::165:::END!!!=========================
=========================:::166:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-ironic-install/tasks/staging_install.yml
**********
# Copyright (c) 2016 Mirantis Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.
---
- name: "Ironic-staging-drivers - PIP Install"
  include: pip_install.yml
    package=ironic-staging-drivers
    state=latest
    sourcedir={{ staging_drivers_git_folder }}
    source_install={{ staging_drivers_source_install }}
    extra_args="--no-cache-dir --upgrade --upgrade-strategy only-if-needed -c {{ upper_constraints_file }}"

**********
DECISION===>: PASS
**********
=========================:::166:::END!!!=========================
=========================:::167:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-ironic-install/tasks/set_ssh_private_key.yml
**********
---
- name: "Defined ssh_private_key_path - Check to see if there is a file where the ssh_private_key_path is defined"
  local_action: stat path={{ ssh_private_key_path }}
  register: test_ssh_private_key_path

- name: "Defined ssh_private_key_path - Error if ssh_private_key_path is not valid"
  local_action: fail msg="ssh_private_key_path is not valid."
  when: test_ssh_private_key_path.stat.exists == false

- name: "Defined ssh_private_key_path - Read SSH private key in"
  set_fact: ssh_private_key="{{ lookup('file', ssh_private_key_path ) }}"
  no_log: true

**********
DECISION===>: PASS
**********
=========================:::167:::END!!!=========================
=========================:::168:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-ironic-install/tasks/install.yml
**********
# Copyright (c) 2015 Hewlett-Packard Development Company, L.P.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.
---
- import_role:
    name: venv_python_path

- name: "Update Package Cache"
  apt: update_cache=yes
  environment: "{{ venv }}"
  when: ansible_os_family == 'Debian'

- name: "Install packages"
  action: "{{ ansible_pkg_mgr }} name={{ item }} state=present"
  environment: "{{ venv }}"
  with_items: "{{ required_packages }}"

- name: "If running in CI, set source install facts just to be sure"
  set_fact:
    shade_source_install: true
    ironicclient_source_install: true
  when: ci_testing | bool == true

# NOTE(TheJulia) While we don't necessarilly require /opt/stack any longer
# and it should already be created by the Ansible setup, we will leave this
# here for the time being.
- name: "Ensure /opt/stack is present"
  file: name=/opt/stack state=directory owner=root group=root

- name: "OpenStack Client - Install"
  include: pip_install.yml
    package=python-openstackclient
    extra_args="-c {{ upper_constraints_file }}"
  when: skip_install is not defined

- name: "proliantutils - Install from pip"
  include: pip_install.yml
     package=proliantutils
     state=present
     extra_args="-c {{ upper_constraints_file }}"
  environment: "{{ venv }}"
  when: skip_install is not defined

- name: "UcsSdk - Install from pip"
  include: pip_install.yml
    package=UcsSdk
    version=0.8.1.9
    extra_args="-c {{ upper_constraints_file }}"
  environment: "{{ venv }}"
  when: skip_install is not defined

# TODO(dtantsur): only do this is the iscsi deploy interface is enabled
- name: "Install iSCSI client if PXE driver support is enabled"
  action: "{{ ansible_pkg_mgr }} name={{ iscsi_client_package }} state=present"
  environment: "{{ venv }}"
  when: skip_install is not defined

- name: "Diskimage-builder - Install"
  include: pip_install.yml
    package=diskimage-builder
    sourcedir={{ dib_git_folder }}
    source_install=true
    # NOTE(TheJulia): DIB is in upper-constraints and can't be constrainted
    # as a result.
  when: skip_install is not defined and install_dib | bool == true

- name: "Ironic Client - Install"
  include: pip_install.yml
    package=python-ironicclient
    state=latest
    sourcedir={{ ironicclient_git_folder }}
    source_install={{ ironicclient_source_install }}
    # NOTE(TheJulia): We do not explicitly define an upper constraints file
    # to be utilized in order to allow newer versions to be installed.
  when: skip_install is not defined

- name: "Install configparser in venv if using"
  include: pip_install.yml
    package=configparser
    virtualenv={{ bifrost_venv_dir }}
    extra_args="-c {{ upper_constraints_file }}"
  when: skip_install is not defined and (enable_venv | bool == true)

- name: "Install pymysql in venv if using"
  include: pip_install.yml
    package=pymysql
    virtualenv={{ bifrost_venv_dir }}
    extra_args="-c {{ upper_constraints_file }}"
  when: skip_install is not defined and (enable_venv | bool == true)

# NOTE(hwoarang): The python-pymysql package is not available on the CentOS7
# and old Debian/Ubuntu repositories so we need to get it via pip
- name: "Install pymysql on CentOS/Ubuntu if necessary"
  include: pip_install.yml
    package=pymysql
    extra_args="-c {{ upper_constraints_file }}"
  when:
    - skip_install is not defined
    - enable_venv | bool == false
    - (ansible_distribution == 'CentOS' and ansible_distribution_major_version|version_compare('7', '<=')) or
      (ansible_distribution == 'Ubuntu' and ansible_distribution_version|version_compare('14.10', '==')) or
      (ansible_distribution == 'Fedora' and ansible_distribution_version|version_compare('25', '>='))

- name: "Install extra packages for ironic"
  include: pip_install.yml
    package={{ item }}
    extra_args="-c {{ upper_constraints_file }}"
  with_items: "{{ ironic_extra_packages }}"

- name: "Install Ironic using pip"
  include: pip_install.yml
    package=ironic
    state=latest
    sourcedir={{ ironic_git_folder }}
    source_install=true
    extra_args="--no-cache-dir --upgrade {{ pip_opts }} -c {{ upper_constraints_file }}"
  when: skip_install is not defined

- name: "Install ironic-inspector to permit use of inspection interface"
  include: inspector_install.yml
  when: skip_install is not defined and enable_inspector | bool == true

- name: "Install ironic-staging-drivers"
  include: staging_install.yml
  when: skip_install is not defined and staging_drivers_include | bool == true

# NOTE(pas-ha) even when install into virtualenv is requested,
# we need to install shade into system for enroll-dynamic to succeed
- block:
  - name: install pyOpenSSL>18.0.0 from PyPI
    command: "{{ hostvars[inventory_hostname].ansible_python.executable }} -m pip install pyOpenSSL>=18.0.0"
  - name: install shade from PyPI
    command: "{{ hostvars[inventory_hostname].ansible_python.executable }} -m pip install shade"
    when: not (shade_source_install | default(false) | bool)
  - name: install shade from source
    command: "{{ hostvars[inventory_hostname].ansible_python.executable }} -m pip install {{ shade_git_folder }}"
    when: shade_source_install | default(false) | bool
  when: skip_install is not defined

# NOTE(TheJulia): Install openstacksdk since shade wraps to openstacksdk and the
# logic is largely going into openstacksdk as time goes on.
- block:
  - name: install openstacksdk from PyPI
    command: "{{ hostvars[inventory_hostname].ansible_python.executable }} -m pip install openstacksdk"
    when: not (openstacksdk_source_install | default(false) | bool)
  - name: install openstacksdk from source
    command: "{{ hostvars[inventory_hostname].ansible_python.executable }} -m pip install {{ openstacksdk_git_folder }}"
    when: openstacksdk_source_install | default(false) | bool
  when: skip_install is not defined


**********
DECISION===>: PASS
**********
=========================:::168:::END!!!=========================
=========================:::169:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-ironic-install/tasks/main.yml
**********
# Copyright (c) 2015 Hewlett-Packard Development Company, L.P.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.
---
# NOTE(cinerama) openSUSE Tumbleweed & Leap have different distribution
# IDs which are not currently accounted for in Ansible, so adjust facts
# so we can have shared defaults for the whole SuSE family.
# This change can be removed when the pull request at
# https://github.com/ansible/ansible/pull/17575 lands in a new version.
- name: Ensure openSUSE Tumbleweed has the correct family
  set_fact:
    ansible_os_family: "Suse"
  when: ansible_os_family | search("openSUSE Tumbleweed")

- name: Ensure openSUSE Leap has the correct family
  set_fact:
    ansible_os_family: "Suse"
  when: (ansible_os_family | search("SUSE LINUX")) or
        (ansible_os_family | search("openSUSE Leap"))

# NOTE(cinerama) dummy-defaults.yml is an empty defaults file. We use it
# here to ensure that with_first_found won't fail should we not have
# defaults for a particular distribution, version, etc.
- name: Include OS family-specific defaults
  include_vars: "{{ item }}"
  with_first_found:
    - "../defaults/required_defaults_{{ ansible_os_family }}_family.yml"
    - "../defaults/dummy-defaults.yml"

- name: Include OS distribution-specific defaults
  include_vars: "{{ item }}"
  with_first_found:
    - "../defaults/required_defaults_{{ ansible_distribution | regex_replace(' ', '_') }}.yml"
    - "../defaults/dummy-defaults.yml"

- name: Include OS version-specific defaults
  include_vars: "{{ item }}"
  with_first_found:
    - "../defaults/required_defaults_{{ ansible_distribution | regex_replace(' ', '_') }}_{{ ansible_distribution_release }}.yml"
    - "../defaults/required_defaults_{{ ansible_distribution | regex_replace(' ', '_') }}_{{ ansible_distribution_version }}.yml"
    - "../defaults/dummy-defaults.yml"

- name: "Install Ironic deps"
  include: install.yml
  when: skip_package_install | bool != True

- name: "Bootstrap Ironic"
  include: bootstrap.yml
  when: skip_bootstrap | bool != True

- name: "Start Ironic services"
  include: start.yml
  when: skip_start | bool != True

**********
DECISION===>: PASS
**********
=========================:::169:::END!!!=========================
=========================:::170:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-ironic-install/meta/main.yml
**********
---
galaxy_info:
  author: Ironic Developers
  description: Install Ironic for Bifrost
  company: OpenStack
  license: Apache
  min_ansible_version: 1.9
  platforms:
  - name: EL
    versions:
    - 7
  - name: Debian
    versions:
    - wheezy
  - name: Ubuntu
    versions:
    - trusty
    - utopic
  categories:
  - cloud
  - cloud:openstack
dependencies: []

**********
DECISION===>: PASS
**********
=========================:::170:::END!!!=========================
=========================:::171:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-ironic-install/defaults/required_defaults_Debian_jessie.yml
**********
---
init_template: systemd_template.j2
init_dest_dir: /usr/lib/systemd/system/
init_ext: .service
ipxe_dir: /usr/lib/ipxe/
ipxe_full_binary: ipxe.pxe
nginx_user: www-data
mysql_service_name: mysql
required_packages:
  - mysql-server
  - rabbitmq-server
  - python-dev
  - python-mysqldb
  - python-configparser
  - libffi-dev
  - libxslt1-dev
  - libssl-dev
  - libxml2-dev
  - ipxe
  - tftpd-hpa
  - tftp-hpa
  - xinetd
  - parted
  - ipmitool
  - psmisc
  - nginx
  - wget
  - genisoimage
  - kpartx
  - qemu-utils
  - debootstrap
  - uuid-runtime
  - dnsmasq
# NOTE(TheJulia): The above entry for dnsmasq must be the last entry in the
# package list as the installation causes name resolution changes that can
# temporarily block packages following it while the system is being
# reconfigured. See: https://review.openstack.org/#/c/223813


**********
DECISION===>: PASS
**********
=========================:::171:::END!!!=========================
=========================:::172:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-ironic-install/defaults/required_defaults_RedHat_family.yml
**********
---
init_template: systemd_template.j2
init_dest_dir: /usr/lib/systemd/system/
init_ext: .service
ipxe_dir: /usr/share/ipxe/
ipxe_full_binary: ipxe.lkrn
ironic_rootwrap_dir: /usr/bin/
nginx_user: nginx
mysql_service_name: mariadb
tftp_service_name: tftp
required_packages:
  - mariadb-server
  - dnsmasq
  - rabbitmq-server
  - python-devel
  - MySQL-python
  - python-iniparse
  - libffi-devel
  - libxslt-devel
  - openssl-devel
  - libxml2-devel
  - ipxe-bootimgs
  - tftp-server
  - xinetd
  - parted
  - ipmitool
  - psmisc
  - nginx
  - wget
  - genisoimage
  - kpartx
  - qemu-kvm-tools
  - qemu-img
  - openwsman-python
  - libselinux-python
  - policycoreutils-python
  - debootstrap
  - gcc
  - python2-pip
  - socat
iscsi_client_package: "iscsi-initiator-utils"

**********
DECISION===>: PASS
**********
=========================:::172:::END!!!=========================
=========================:::173:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-ironic-install/defaults/required_defaults_Fedora_22.yml
**********
---
# NOTE(cinerama): On Fedora 22, ansible 1.9, ansible_pkg_mgr
# defaults to yum, which may not be installed. This can be safely
# removed when we start using an ansible release which prefers dnf.
ansible_pkg_mgr: "dnf"

**********
DECISION===>: PASS
**********
=========================:::173:::END!!!=========================
=========================:::174:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-ironic-install/defaults/required_defaults_Fedora_26.yml
**********
---
init_template: systemd_template.j2
init_dest_dir: /usr/lib/systemd/system/
init_ext: .service
ipxe_dir: /usr/share/ipxe/
ipxe_full_binary: ipxe.lkrn
ironic_rootwrap_dir: /usr/bin/
nginx_user: nginx
mysql_service_name: mariadb
tftp_service_name: tftp
required_packages:
  - mariadb-server
  - dnsmasq
  - rabbitmq-server
  - python-devel
  - MySQL-python
  - libselinux-python
  - python-iniparse
  - libffi-devel
  - libxslt-devel
  - openssl-devel
  - libxml2-devel
  - ipxe-bootimgs
  - tftp-server
  - xinetd
  - parted
  - ipmitool
  - psmisc
  - nginx
  - wget
  - genisoimage
  - kpartx
  - qemu-kvm
  - qemu-img
  - openwsman-python
  - libselinux-python
  - policycoreutils-python
  - policycoreutils-python-utils
  - debootstrap
  - gcc
  - socat
iscsi_client_package: "iscsi-initiator-utils"

**********
DECISION===>: PASS
**********
=========================:::174:::END!!!=========================
=========================:::175:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-ironic-install/defaults/required_defaults_Fedora_27.yml
**********
---
init_template: systemd_template.j2
init_dest_dir: /usr/lib/systemd/system/
init_ext: .service
ipxe_dir: /usr/share/ipxe/
ipxe_full_binary: ipxe.lkrn
ironic_rootwrap_dir: /usr/bin/
nginx_user: nginx
mysql_service_name: mariadb
tftp_service_name: tftp
required_packages:
  - mariadb-server
  - dnsmasq
  - rabbitmq-server
  - python-devel
  - MySQL-python
  - libselinux-python
  - python-iniparse
  - libffi-devel
  - libxslt-devel
  - openssl-devel
  - libxml2-devel
  - ipxe-bootimgs
  - tftp-server
  - xinetd
  - parted
  - ipmitool
  - psmisc
  - nginx
  - wget
  - genisoimage
  - kpartx
  - qemu-kvm
  - qemu-img
  - openwsman-python
  - libselinux-python
  - policycoreutils-python
  - policycoreutils-python-utils
  - debootstrap
  - gcc
  - socat
iscsi_client_package: "iscsi-initiator-utils"

**********
DECISION===>: PASS
**********
=========================:::175:::END!!!=========================
=========================:::176:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-ironic-install/defaults/required_defaults_Fedora_25.yml
**********
---
init_template: systemd_template.j2
init_dest_dir: /usr/lib/systemd/system/
init_ext: .service
ipxe_dir: /usr/share/ipxe/
ipxe_full_binary: ipxe.lkrn
ironic_rootwrap_dir: /usr/bin/
nginx_user: nginx
mysql_service_name: mariadb
tftp_service_name: tftp
required_packages:
  - mariadb-server
  - dnsmasq
  - rabbitmq-server
  - python-devel
  - MySQL-python
  - libselinux-python
  - python-iniparse
  - libffi-devel
  - libxslt-devel
  - openssl-devel
  - libxml2-devel
  - ipxe-bootimgs
  - tftp-server
  - xinetd
  - parted
  - ipmitool
  - psmisc
  - nginx
  - wget
  - genisoimage
  - kpartx
  - qemu-kvm
  - qemu-img
  - openwsman-python
  - libselinux-python
  - policycoreutils-python
  - debootstrap
  - gcc
  - socat
iscsi_client_package: "iscsi-initiator-utils"

**********
DECISION===>: PASS
**********
=========================:::176:::END!!!=========================
=========================:::177:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-ironic-install/defaults/dummy-defaults.yml
**********
---
# NOTE(cinerama) This file is intentionally left blank - do not
# add variables here.

**********
DECISION===>: PASS
**********
=========================:::177:::END!!!=========================
=========================:::178:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-ironic-install/defaults/required_defaults_Suse_family.yml
**********
---
init_template: systemd_template.j2
init_dest_dir: /usr/lib/systemd/system/
init_ext: .service
# NOTE (cinerama): The iPXE binaries are not currently packaged for SuSE,
# so we download them and install them to /usr/local/share/ipxe. If the
# files are packaged, download_ipxe can be removed and ipxe_dir set to
# the location of the packaged files.
download_ipxe: true
ipxe_dir: /usr/local/share/ipxe
ipxe_full_binary: ipxe.pxe
ironic_rootwrap_dir: /usr/bin/
nginx_user: nginx
mysql_service_name: mysql
tftp_service_name: tftp
required_packages:
  - python-selinux
  - mariadb-server
  - dnsmasq
  - rabbitmq-server
  - python-devel
  - python-MySQL-python
  - python-iniparse
  - libffi-devel
  - libxslt-devel
  - openssl-devel
  - libxml2-devel
  - qemu-ipxe
  - tftp
  - xinetd
  - parted
  - ipmitool
  - psmisc
  - nginx
  - wget
  - genisoimage
  - kpartx
  - qemu-tools
  - openwsman-python
  - policycoreutils-python
  - debootstrap
  - iptables
  - tar
  - curl
  - socat
  - python-pip
  - gcc
  - python-PyMySQL
iscsi_client_package: "open-iscsi"

**********
DECISION===>: PASS
**********
=========================:::178:::END!!!=========================
=========================:::179:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-ironic-install/defaults/required_defaults_Ubuntu_16.04.yml
**********
---
init_template: systemd_template.j2
init_dest_dir: /lib/systemd/system/
init_ext: .service
required_packages:
  - mysql-server
  - rabbitmq-server
  - python-dev
  - python-mysqldb
  - python-configparser
  - libffi-dev
  - libxslt1-dev
  - libssl-dev
  - libxml2-dev
  - ipxe
  - tftpd-hpa
  - tftp-hpa
  - xinetd
  - parted
  - ipmitool
  - psmisc
  - nginx
  - wget
  - genisoimage
  - kpartx
  - qemu-utils
  - python-openwsman
  - debootstrap
  - uuid-runtime
  - curl
  - python-pip
  - python-pymysql
  - dnsmasq
# NOTE(TheJulia): The above entry for dnsmasq must be the last entry in the
# package list as the installation causes name resolution changes that can
# temporarily block packages following it while the system is being
# reconfigured. See: https://review.openstack.org/#/c/223813

**********
DECISION===>: PASS
**********
=========================:::179:::END!!!=========================
=========================:::180:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-ironic-install/defaults/required_defaults_openSUSE_Leap_15.0.yml
**********
---
init_template: systemd_template.j2
init_dest_dir: /usr/lib/systemd/system/
init_ext: .service
# NOTE (cinerama): The iPXE binaries are not currently packaged for SuSE,
# so we download them and install them to /usr/local/share/ipxe. If the
# files are packaged, download_ipxe can be removed and ipxe_dir set to
# the location of the packaged files.
download_ipxe: true
ipxe_dir: /usr/local/share/ipxe
ipxe_full_binary: ipxe.pxe
ironic_rootwrap_dir: /usr/bin/
nginx_user: nginx
mysql_service_name: mysql
tftp_service_name: tftp
required_packages:
  - python-selinux
  - mariadb-server
  - dnsmasq
  - rabbitmq-server
  - python-devel
  - python-iniparse
  - libffi-devel
  - libxslt-devel
  - openssl-devel
  - libxml2-devel
  - qemu-ipxe
  - tftp
  - xinetd
  - parted
  - ipmitool
  - psmisc
  - nginx
  - wget
  - mkisofs
  - kpartx
  - qemu-tools
  - python3-openwsman
  - policycoreutils-python
  - debootstrap
  - iptables
  - tar
  - curl
  - socat
  - python-pip
  - gcc
  - python-PyMySQL
iscsi_client_package: "open-iscsi"

**********
DECISION===>: PASS
**********
=========================:::180:::END!!!=========================
=========================:::181:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-ironic-install/defaults/required_defaults_Debian_family.yml
**********
---
init_template: upstart_template.j2
init_dest_dir: /etc/init/
init_ext: .conf
ipxe_dir: /usr/lib/ipxe/
ipxe_full_binary: ipxe.pxe
ironic_rootwrap_dir: /usr/local/bin/
nginx_user: www-data
mysql_service_name: mysql
tftp_service_name: tftpd-hpa
required_packages:
  - mysql-server
  - rabbitmq-server
  - python-dev
  - python-mysqldb
  - python-configparser
  - libffi-dev
  - libxslt1-dev
  - libssl-dev
  - libxml2-dev
  - ipxe
  - tftpd-hpa
  - tftp-hpa
  - xinetd
  - parted
  - ipmitool
  - psmisc
  - nginx
  - wget
  - genisoimage
  - kpartx
  - qemu-utils
  - python-openwsman
  - debootstrap
  - uuid-runtime
  - curl
  - socat
  - python-pip
  - gcc
  - dnsmasq
# NOTE(TheJulia): The above entry for dnsmasq must be the last entry in the
# package list as the installation causes name resolution changes that can
# temporarily block packages following it while the system is being
# reconfigured. See: https://review.openstack.org/#/c/223813
iscsi_client_package: "open-iscsi"

**********
DECISION===>: PASS
**********
=========================:::181:::END!!!=========================
=========================:::182:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-ironic-install/defaults/main.yml
**********
---
# Cleaning turns on ironic conductor clean_nodes flag
# which causes the nodes to be wiped after deletion.
cleaning: false
http_boot_folder: /httpboot
ironic_tftp_master_path: /var/lib/ironic/master_images
staging_drivers_include: false
file_url_port: "8080"
ironicclient_source_install: false
openstacksdk_source_install: true
shade_source_install: true
ironicinspector_source_install: true
ironicinspectorclient_source_install: false
staging_drivers_source_install: false
# Setting to utilize diskimage-builder to create a bootable image.
create_image_via_dib: true
dib_image_type: vm
# Setting to install diskimage-builder
install_dib: "{{ create_image_via_dib }}"
# Setting to prepend a partition image with a boot sector and partition table.
transform_boot_image: false
# If testing is true, then the environment is setup for using libvirt
# virtual machines for the hardware instead of real hardware.
testing: false
ci_testing: false

# set to true to skip installing ironic dependencies
skip_package_install: False
# set to true to skip generation of configs, ironic db and rabbitmq configuration
skip_bootstrap: False
# set to true to skip starting ironic services and dependencies
skip_start: False

# Default network interface that bifrost will be attached to.
# This is used in ipa_* so it must be before
network_interface: "virbr0"
ans_network_interface: "{{ network_interface | replace('-', '_') }}"

# Normally this would setting would be http in a bifrost installation
# without TLS. This setting allows a user to override the setting in case
# the local webserver has been updated to support HTTPS.
# Note: Users wishing to leverage HTTPS should reference the iPXE
# documentation at https://ipxe.org/crypto
ipa_file_protocol: "http"

ipa_upstream_release: "master"

enable_uefi_ipxe: true
ipxe_efi_binary: ipxe.efi

ipa_kernel: "{{http_boot_folder}}/ipa.vmlinuz"
ipa_ramdisk: "{{http_boot_folder}}/ipa.initramfs"
ipa_kernel_url: "{{ ipa_file_protocol }}://{{ hostvars[inventory_hostname]['ansible_' + ans_network_interface]['ipv4']['address'] }}:{{file_url_port}}/ipa.vmlinuz"
ipa_kernel_upstream_url: "https://tarballs.openstack.org/ironic-python-agent/tinyipa/files/tinyipa-{{ ipa_upstream_release }}.vmlinuz"
ipa_kernel_upstream_checksum_algo: "sha256"
ipa_kernel_upstream_checksum_url: "{{ ipa_kernel_upstream_url }}.{{ ipa_kernel_upstream_checksum_algo }}"
ipa_ramdisk_url: "{{ ipa_file_protocol }}://{{ hostvars[inventory_hostname]['ansible_' + ans_network_interface]['ipv4']['address'] }}:{{file_url_port}}/ipa.initramfs"
ipa_ramdisk_upstream_url: "https://tarballs.openstack.org/ironic-python-agent/tinyipa/files/tinyipa-{{ ipa_upstream_release }}.gz"
ipa_ramdisk_upstream_checksum_algo: "sha256"
ipa_ramdisk_upstream_checksum_url: "{{ ipa_ramdisk_upstream_url }}.{{ ipa_ramdisk_upstream_checksum_algo }}"
deploy_image_filename: "deployment_image.qcow2"
deploy_image: "{{http_boot_folder}}/{{deploy_image_filename}}"
# Use cirros instead of building an image via diskimage-builder
use_cirros: false
# Download IPA by default
download_ipa: true
cirros_deploy_image_upstream_url: https://download.cirros-cloud.net/0.3.4/cirros-0.3.4-x86_64-disk.img
# By default bifrost will deploy dnsmasq to utilize as an integrated DHCP
# server.  If you already have a DHCP server, you will need to disable
# this setting, and perform manual configuration of your DHCP server.
include_dhcp_server: true
# *_git_url can be overridden by local clones for offline installs
dib_git_url: https://git.openstack.org/openstack/diskimage-builder
ironicclient_git_url: https://git.openstack.org/openstack/python-ironicclient
openstacksdk_git_url: https://git.openstack.org/openstack/openstacksdk
shade_git_url: https://git.openstack.org/openstack-infra/shade
ironic_git_url: https://git.openstack.org/openstack/ironic
ironicinspector_git_url: https://github.com/openstack/ironic-inspector
ironicinspectorclient_git_url: https://github.com/openstack/python-ironic-inspector-client
mysql_username: "root"
mysql_password: ""
# NOTE(TheJulia): While we have indicated we're going to deprecate ironic_db_password,
# we didn't properly notate it from what I can see at a glance, and we seem to have
# an odd variable expansion issue on fedora blocking migration to fedora-27 that this
# should fix....
ironic_db_password: aSecretPassword473z
disable_dnsmasq_dns: False
ironic_git_folder: /opt/stack/ironic
ironicclient_git_folder: /opt/stack/python-ironicclient
openstacksdk_git_folder: /opt/stack/openstacksdk
shade_git_folder: /opt/stack/shade
dib_git_folder: /opt/stack/diskimage-builder
reqs_git_folder: /opt/stack/requirements
upper_constraints_file: "{{ lookup('env', 'UPPER_CONSTRAINTS_FILE') | default(reqs_git_folder + '/upper-constraints.txt', True) }}"
staging_drivers_git_folder: /opt/stack/ironic-staging-drivers
ironicinspector_git_folder: /opt/stack/ironic-inspector
ironicinspectorclient_git_folder: /opt/stack/python-ironic-inspector-client
staging_drivers_git_url: https://git.openstack.org/cgit/openstack/ironic-staging-drivers

# TODO(TheJulia): Add redfish to this list.
enabled_hardware_types: "ipmi,ilo,cisco-ucs-managed"
default_deploy_interface: "direct"
enabled_boot_interfaces: "ilo-virtual-media,pxe"
enabled_management_interfaces: "ilo,ipmitool,ucsm"
enabled_power_interfaces: "ilo,ipmitool,ucsm"
enabled_deploy_interfaces: "iscsi,direct"

# Extra pip packages to install with ironic
# This should be a list of pip-installable references.
# default: empty list
ironic_extra_packages: []

# DHCP pool for requests -- ignored if inventory_dhcp is set to True
# since IP allocation will be static.
dhcp_pool_start: 192.168.1.200
dhcp_pool_end: 192.168.1.250
dhcp_lease_time: 12h
dhcp_static_mask: 255.255.255.0
# Dnsmasq default route for clients. If not defined, dnsmasq will push to clients
# as default route the same IP of the dnsmasq server.
# If set to false, it will disable default route creation in clients.
# Default: undefined
# dnsmasq_router:

# Dnsmasq default dns servers for clients. If defined, dnsmasq will use the specified
# DNS servers for name resolving.
# dnsmasq_dns_servers: 8.8.8.8,8.8.4.4

# Support for CORS configuration
# By default CORS support is disabled.
enable_cors: false
# Origin to accept for CORS requests
cors_allowed_origin: "http://localhost:8000"
# bifrost utilizes noauth mode by default and as such
# the setting should be set to false. This setting should
# not need to be modified by the user.
enable_cors_credential_support: false

# Set this to true to configure dnsmasq to respond to requests from the
# hosts in your dynamic inventory.
inventory_dhcp: False

# Set this to true to configure dnsmasq to resolv to ipv4_address from the
# hosts in your dynamic inventory.
inventory_dns: False

# Settings to enable the use of inspector
enable_inspector: true
inspector_auth: "noauth"
# Deprecated: inspector_auth will be removed in Pike, and is
# overridden when enable_keystone is set to true.
#inspector_auth: "noauth"
inspector_debug: true
inspector_manage_firewall: false

# Deprecated: ironic_auth_strategy will be removed in Pike.
ironic_auth_strategy: "noauth"

# Set ironic_log_dir to use a non-default log directory for ironic.
#ironic_log_dir:

# Set inspector_log_dir to use a non-default log directory for inspector.
#inspector_log_dir:

# Set nginx_log_dir to use a non-default log directory for nginx.
nginx_log_dir: /var/log/nginx

inspector_data_dir: "/opt/stack/ironic-inspector/var"
inspector_store_ramdisk_logs: true
# Note: inspector_port_addition has three valid values: all, active, pxe
inspector_port_addition: "pxe"

# Note: inspector_keep_ports has three valid values: all, present, added
inspector_keep_ports: "present"

# String value containing extra kernel parameters for the inspector default
# PXE configuration.
#inspector_extra_kernel_options:

# Set inspector_processing_hooks to specify a non-default comma-separated
# list of processing hooks for inspector.
#inspector_processing_hooks:

# Whether to store introspection data using the local Nginx web server as an
# object storage service.
inspector_store_data_in_nginx: true

# When inspector_store_data_in_nginx is true, this is the URL of the Nginx
# 'Swift' API endpoint.
inspector_store_data_url: "http://localhost:{{ file_url_port }}"

# Inspector defaults
inspector:
  discovery:
    enabled: "{{ enable_inspector_discovery | default(true) }}"
    default_node_driver: "{{ inspector_default_node_driver | default('ipmi')}}"

# We may not have packaged iPXE files on some distros, or may want to
# download them on their own.
download_ipxe: false

# Settings related to installing bifrost in a virtual environment
enable_venv: false
bifrost_venv_dir: "{{ lookup('env', 'VENV') | default('/opt/stack/bifrost') }}"
bifrost_venv_env:
  VIRTUAL_ENV: "{{ bifrost_venv_dir }}"
  PATH: "{{ bifrost_venv_dir }}/bin:{{ ansible_env.PATH }}" # include regular path via lookup env
  pydoc: "python -m pydoc"

# Authentication support
# By default, bifrost was developed around being a toolkit
# for noauth mode. Since we are introducing the concept of
# authentication, we need to record the default for
# conditional statements in the playbooks.
noauth_mode: true

# Keystone Support
# Default parameter if keystone is enabled, or disabled.
enable_keystone: false

# NOTE: The keystone support in this role
# expects the keystone.bootstrap variables to
# either be loaded OR present from keystone
# installation. The keystone settings below
# should only be used if the role is utilized
# independently of the keystone installation
# role, such as leveraging a pre-existing
# keystone installation.
# WARNING: Using a pre-existing keystone has
# not been tested.
#
#keystone:
#  debug: true
#  bootstrap:
#    enabled: true
#    username: admin
#    password: ChangeThisPa55w0rd
#    project_name: admin
#    admin_url: "http://127.0.0.1:35357/v3/"
#    public_url: "http://127.0.0.1:5000/v3/"
#    internal_url: "http://127.0.0.1:5000/v3/"
#    region_name: "RegionOne"
#  message_queue:
#    username: keystone
#    password: ChangeThisPa55w0rd
#    host: 127.0.0.1
#  database:
#    name: keystone
#    username: keystone
#    password: ChangeThisPa55w0rd
#    host: 127.0.0.1

ironic:
  service_catalog:
    username: "ironic"
    password: "ChangeThisPa55w0rd"
    auth_url: "http://127.0.0.1:5000/v3"
    project_name: "service"
  keystone:
    default_username: "bifrost_user"
    default_password: "ChangeThisPa55w0rd"
  database:
    name: "ironic"
    username: "ironic"
    password: "{{ ironic_db_password }}"
    host: "localhost"

ironic_inspector:
  service_catalog:
    username: "ironic_inspector"
    password: "ChangeThisPa55w0rd"
    auth_url: "http://127.0.0.1:5000/v3"
    project_name: "service"
  keystone:
    default_username: "inspector_user"
    default_password: "ChangeThisPa55w0rd"
  database:
    name: "inspector"
    username: "inspector"
    password: "{{ ironic_db_password }}"
    host: "localhost"
    # DEPRECATED(TheJulia): Inheritance of ironic_db_password params
    # should be removed in Queens.

# NOTE(hwoarang): openSUSE distros may come with recent pip versions so
# upgrade only what's necessary
pip_opts: "{{ ((ansible_os_family | lower == 'suse') or (enable_venv | bool)) | ternary('--upgrade-strategy only-if-needed', '--force-reinstall') }}"

**********
DECISION===>: Hardcoded Secret, Empty password
**********
=========================:::182:::END!!!=========================
=========================:::183:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-ironic-install/defaults/required_defaults_Ubuntu_15.04.yml
**********
---
init_template: systemd_template.j2
init_dest_dir: /lib/systemd/system/
init_ext: .service

**********
DECISION===>: PASS
**********
=========================:::183:::END!!!=========================
=========================:::184:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-ironic-install/defaults/required_defaults_Ubuntu_15.10.yml
**********
---
init_template: systemd_template.j2
init_dest_dir: /lib/systemd/system/
init_ext: .service

**********
DECISION===>: PASS
**********
=========================:::184:::END!!!=========================
=========================:::185:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-create-dib-image/vars/main.yml
**********
# Copyright (c) 2017 SUSE Linux GmbH.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.
dib_host_required_packages:
  - dosfstools
  - e2fsprogs
  - gdisk

**********
DECISION===>: PASS
**********
=========================:::185:::END!!!=========================
=========================:::186:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-create-dib-image/tasks/main.yml
**********
# Copyright (c) 2015 Hewlett-Packard Development Company, L.P.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.
---
- import_role:
    name: venv_python_path
- name: Ensure required packages are installed
  package:
    name: "{{ dib_host_required_packages }}"
    state: present
  environment: "{{ venv }}"
# If attempting to utilize a base Ubuntu image, diskimage-builder
# is the recommended, and default path.
- name: "Test if image is present"
  stat: path={{ dib_imagename }}
  register: test_image_present
- name: "Test if image is present - {{ dib_imagename }}.{{ dib_imagetype | default('qcow2') }}"
  stat: path={{ dib_imagename }}.{{ dib_imagetype | default('qcow2') }}
  register: test_image_dib_present
  when: test_image_present.stat.exists == false
  # Note(TheJulia): We need to explicitly test for initramfs in the case
  # that the ironic-agent element is used to build the image.
- name: "Test if image is present - {{ dib_imagename }}.initramfs"
  stat: path={{ dib_imagename }}.initramfs
  register: test_image_initramfs_present
  when: test_image_present.stat.exists == false and test_image_dib_present.stat.exists == false
- name: "Build tracing (-x) option for disk-image-create"
  set_fact:
    dib_trace_arg: "-x"
  when: dib_trace == true
- name: "Build uncompressed (-u) option for disk-image-create"
  set_fact:
    dib_uncompressed_arg: "-u"
  when: dib_uncompressed == true
- name: "Build clear environment (-c) option for disk-image-create"
  set_fact:
    dib_clearenv_arg: "-c"
  when: dib_clearenv == true
- name: "Build no tmpfs (--no-tmpfs) option for disk-image-create"
  set_fact:
    dib_notmpfs_arg: "--no-tmpfs"
  when: dib_notmpfs == true
- name: "Build offline (--offline) option for disk-image-create"
  set_fact:
    dib_offline_arg: "--offline"
  when: dib_offline == true
- name: "Build skip default base element (-n) option for disk-image-create"
  set_fact:
    dib_skipbase_arg: "-n"
  when: dib_skipbase == true
- name: "Build architecture (-a) option for disk-image-create"
  set_fact:
    dib_arch_arg: "-a {{dib_arch}}"
  when: dib_arch is defined
- name: "Build image name (-o) option for disk-image-create"
  set_fact:
    dib_imagename_arg: "-o {{dib_imagename}}"
  when: dib_imagename is defined
- name: "Build image type (-t) option for disk-image-create"
  set_fact:
    dib_imagetype_arg: "-t {{dib_imagetype}}"
  when: dib_imagetype is defined
- name: "Build image size (--image-size) option for disk-image-create"
  set_fact:
    dib_imagesize_arg: "--image-size {{dib_imagesize}}"
  when: dib_imagesize is defined
- name: "Build image cache (--image-cache) option for disk-image-create"
  set_fact:
    dib_imagecache_arg: "--image-cache {{dib_imagecache}}"
  when: dib_imagecache is defined
- name: "Build max online resize (--max-online-resize) option for disk-image-create"
  set_fact:
    dib_maxresize_arg: "--max-online-resize {{dib_maxresize}}"
  when: dib_maxresize is defined
- name: "Build minimum tmpfs size (--min-tmpfs) option for disk-image-create"
  set_fact:
    dib_mintmpfs_arg: "--min-tmpfs {{dib_mintmpfs}}"
  when: dib_mintmpfs is defined
- name: "Build mkfs options (--mkfs-options) option for disk-image-create"
  set_fact:
    dib_mkfsfopts_arg: "-mkfs-options {{dib_mkfsopts}}"
  when: dib_mkfsopts is defined
- name: "Build qemu image options (--qemu-img-options) option for disk-image-create"
  set_fact:
    dib_qemuopts_arg: "--qemu-img-options {{dib_qemuopts}}"
  when: dib_qemuopts is defined
- name: "Build root label (--root-label) option for disk-image-create"
  set_fact:
    dib_rootlabel_arg: "--root-label {{dib_rootlabel}}"
  when: dib_rootlabel is defined
- name: "Build ramdisk element (--ramdisk-element) option for disk-image-create"
  set_fact:
    dib_rdelement_arg: "--ramdisk-element {{dib_rdelement}}"
  when: dib_rdelement is defined
- name: "Build install type (--install-type) option for disk-image-create"
  set_fact:
    dib_installtype_arg: "-t {{dib_installtype}}"
  when: dib_installtype is defined
- name: "Build packages (-p) option for disk-image-create"
  set_fact:
    dib_packages_arg: "-p {{dib_packages}}"
  when: dib_packages is defined and dib_packages != ""
- name: "Set default of Debian Jessie if building debian and not explicitly set, overwride with dib_os_release setting"
  set_fact:
    dib_os_release: "jessie"
  when: dib_os_element == "debian" and dib_os_release is undefined
- name: "Initialize the DIB environment variables fact"
  set_fact:
    dib_env_vars_final: "{{dib_env_vars}}"
- name: "Set the DIB_RELEASE environment variable if set"
  set_fact:
    dib_env_vars_final: "{{dib_env_vars_final | combine({'DIB_RELEASE':dib_os_release}) }}"
  when: dib_os_release is defined
- name: "Set partitioning information if set"
  slurp:
    src: "{{ partitioning_file }}"
  register: partition_info
  when: partitioning_file is defined
- name: "Set partitioning information string if set"
  set_fact:
    dib_partitioning: "{{ partition_info['content'] | b64decode }}"
  when: partition_info is defined and 'content' in partition_info
- name: "Build argument list"
  set_fact:
    dib_arglist: "{{dib_trace_arg|default('')}} {{dib_uncompressed_arg|default('')}} {{dib_clearenv_arg|default('')}} {{dib_notmpfs_arg|default('')}} {{dib_offline_arg|default('')}} {{dib_skipbase_arg|default('')}} {{dib_arch_arg|default('')}} {{dib_imagename_arg|default('')}} {{dib_imagetype_arg|default('')}} {{dib_imagesize_arg|default('')}} {{dib_imagecache_arg|default('')}} {{dib_maxresize_arg|default('')}} {{dib_mintmpfs_arg|default('')}} {{dib_mkfsopts_arg|default('')}} {{dib_qemuopts_arg|default('')}} {{dib_rootlabel_arg|default('')}} {{dib_rdelement_arg|default('')}} {{dib_installtype_arg|default('')}} {{dib_packages_arg|default('')}} {{dib_os_element}} {{dib_elements|default('')}}"
- name: "Initiate image build"
  command: disk-image-create {{dib_arglist}}
  environment: "{{ dib_env_vars_final | combine(bifrost_venv_env if enable_venv|bool else {}) | combine({'DIB_BLOCK_DEVICE_CONFIG': dib_partitioning} if dib_partitioning is defined and dib_partitioning|length > 0 else {}) }}"
  when: build_ramdisk | bool == false and test_image_present.stat.exists == false and test_image_dib_present.stat.exists == false and test_image_initramfs_present.stat.exists == false
- name: "Initiate ramdisk build"
  command: ramdisk-image-create {{dib_arglist}}
  environment: "{{ dib_env_vars_final | combine(bifrost_venv_env if enable_venv|bool else {}) }}"
  when: build_ramdisk | bool == true and test_image_present.stat.exists == false and test_image_dib_present.stat.exists == false and test_image_initramfs_present.stat.exists == false
- name: "Update permission of generated image"
  file:
    path: "{{ http_boot_folder }}"
    mode: u=rwX,g=rX,o=rX
    recurse: yes
    state: directory
  when: http_boot_folder is defined and http_boot_folder != ''
- name: "Restore proper context on created data for http_boot"
  command: restorecon -R {{ http_boot_folder }}
  when: (ansible_os_family == 'RedHat' or ansible_os_family == 'Suse') and
         ansible_selinux.status == 'enabled' and ansible_selinux.mode == "enforcing"

**********
DECISION===>: PASS
**********
=========================:::186:::END!!!=========================
=========================:::187:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-create-dib-image/meta/main.yml
**********
---
galaxy_info:
  author: Ironic Developers
  description: Create image with diskimage-builder for Bifrost
  company: OpenStack
  license: Apache
  min_ansible_version: 2.0
  platforms:
  - name: EL
    versions:
    - 7
  - name: Debian
    versions:
    - wheezy
    - jessie
  - name: Ubuntu
    versions:
    - trusty
    - utopic
  categories:
  - cloud
  - cloud:openstack
dependencies: []

**********
DECISION===>: PASS
**********
=========================:::187:::END!!!=========================
=========================:::188:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-create-dib-image/defaults/main.yml
**********
---
dib_os_element: "debian"
dib_init_element: "simple-init"
dib_env_vars:
  http_proxy: "{{ lookup('env','http_proxy') }}"
  https_proxy: "{{ lookup('env','https_proxy') }}"
  DIB_INSTALLTYPE_simple_init: repo
  LANG: C
  LC_ALL: C
  LC_MESSAGES: C
build_ramdisk: false
dib_trace: false
dib_uncompressed: false
dib_clearenv: false
dib_notmpfs: false
dib_offline: false
dib_skipbase: false
dib_packages: ""
# Settings related to installing bifrost in a virtual environment
enable_venv: false
bifrost_venv_dir: "{{ lookup('env', 'VENV') | default('/opt/stack/bifrost') }}"
bifrost_venv_env:
  VIRTUAL_ENV: "{{ bifrost_venv_dir }}"
  PATH: "{{ bifrost_venv_dir }}/bin:{{ ansible_env.PATH }}" # include regular path via lookup env

**********
DECISION===>: PASS
**********
=========================:::188:::END!!!=========================
=========================:::189:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-openstack-ci-prep/vars/main.yml
**********
---
# vars file for bifrost-openstack-ci-prep

**********
DECISION===>: PASS
**********
=========================:::189:::END!!!=========================
=========================:::190:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-openstack-ci-prep/tasks/main.yml
**********
# Copyright (c) 2015 Hewlett-Packard Development Company, L.P.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
# implied.
# See the License for the specific language governing permissions and
# limitations under the License.
---
# NOTE(TheJulia): Override the stored fact values for username/password when operating
# in OpenStack CI.
- name: "Set facts for OpenStack CI"
  set_fact:
    mysql_username: "openstack_citest"
    mysql_password: "openstack_citest"
    disable_dnsmasq_dns: True
  when: ci_testing_zuul_changes is defined

- name: "Determine if OpenStack CI is missing an SSH key"
  stat: path={{ssh_public_key_path}}
  register: test_ssh_public_key_path
  when: ci_testing_zuul is defined

- name: "Create an SSH key for Jenkins user if operating in OpenStack CI"
  shell: ssh-keygen -f ~/.ssh/id_rsa -N ""
  when: >
    ci_testing_zuul is defined and
    test_ssh_public_key_path.stat.exists |bool  == false

- name: >
    "Create an empty SSH known_hosts file for Jenkins user
    if operating in OpenStack CI"
  file:
    path: "~/.ssh/known_hosts"
    state: touch
    mode: 0600
  when: >
    ci_testing_zuul is defined and
    test_ssh_public_key_path.stat.exists | bool == false

**********
DECISION===>: PASS
**********
=========================:::190:::END!!!=========================
=========================:::191:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-openstack-ci-prep/meta/main.yml
**********
---
galaxy_info:
  author: Ironic Developers
  description: Prepare and set CI node settings for OpenStack CI tests.
  company: OpenStack
  license: Apache
  min_ansible_version: 1.9
  platforms:
  - name: Ubuntu
    versions:
    - trusty
  categories:
  - cloud
  - cloud:openstack
dependencies: []

**********
DECISION===>: PASS
**********
=========================:::191:::END!!!=========================
=========================:::192:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-openstack-ci-prep/defaults/main.yml
**********
---
# Default location of the ssh public key for the user operating Bifrost.
ssh_public_key_path: "{{ ansible_env.HOME }}/.ssh/id_rsa.pub"

**********
DECISION===>: PASS
**********
=========================:::192:::END!!!=========================
=========================:::193:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-unprovision-node-dynamic/vars/main.yml
**********
---
# vars file for bifrost-unprovision-node-dynamic

**********
DECISION===>: PASS
**********
=========================:::193:::END!!!=========================
=========================:::194:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-unprovision-node-dynamic/tasks/main.yml
**********
# Copyright (c) 2015 Hewlett-Packard Development Company, L.P.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
---
- name: "If in noauth mode, unset authentication parameters."
  set_fact:
    auth_type: None
    auth: {}
  when: noauth_mode is defined and noauth_mode | bool == true

- name: "Execute os_client_config to collect facts"
  os_client_config:
  no_log: yes

# NOTE(TheJulia): The first record returned by os_client_config
# is utilized as the default. A user can still define the parameters
# if so desired.
- name: "Set os_client_config's auth parameters if not already set."
  set_fact:
    auth: "{{ openstack.clouds[0].auth }}"
    auth_type: "{{ openstack.clouds[0].auth_type }}"
  when: auth is undefined
  no_log: yes
  when: noauth_mode is defined and noauth_mode | bool == false

- name: "Unprovision node"
  os_ironic_node:
    cloud: "{{ cloud_name | default(omit) }}"
    auth_type: "{{ auth_type | default(omit) }}"
    auth: "{{ auth | default(omit) }}"
    ironic_url: "{{ ironic_url | default(omit) }}"
    uuid: "{{ uuid | default() }}"
    name: "{{ name | default() }}"
    state: absent
    instance_info: "{}"

**********
DECISION===>: PASS
**********
=========================:::194:::END!!!=========================
=========================:::195:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-unprovision-node-dynamic/meta/main.yml
**********
---
galaxy_info:
  author: Ironic Developers
  description: Unprovisions nodes in Ironic
  company: OpenStack
  license: Apache
  min_ansible_version: 2.0
  platforms:
  - name: EL
    versions:
    - 7
  - name: Debian
    versions:
    - wheezy
  - name: Ubuntu
    versions:
    - trusty
    - utopic
  categories:
  - cloud
  - cloud:openstack
dependencies: []

**********
DECISION===>: PASS
**********
=========================:::195:::END!!!=========================
=========================:::196:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-unprovision-node-dynamic/defaults/main.yml
**********
---
ironic_url: "http://localhost:6385/"
noauth_mode: true

**********
DECISION===>: PASS
**********
=========================:::196:::END!!!=========================
=========================:::197:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-unprovision-node-dynamic/handlers/main.yml
**********
---
# handlers file for bifrost-unprovision-node-dynamic

**********
DECISION===>: PASS
**********
=========================:::197:::END!!!=========================
=========================:::198:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/ironic-inspect-node/vars/main.yml
**********
---
# vars file for ironic-inspect-node

**********
DECISION===>: PASS
**********
=========================:::198:::END!!!=========================
=========================:::199:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/ironic-inspect-node/tasks/main.yml
**********
# Copyright (c) 2015 Hewlett-Packard Development Company, L.P.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
---
- name: "Collect facts"
  setup:

- name: "If in noauth mode, unset authentication parameters."
  set_fact:
    auth_type: None
    auth: {}
  when: noauth_mode is defined and noauth_mode | bool == true

- name: "Execute os_client_config to collect facts"
  os_client_config:
  no_log: yes
  when: noauth_mode is defined and noauth_mode | bool == false

# NOTE(TheJulia): The first record returned by os_client_config
# is utilized as the default. A user can still define the parameters
# if so desired.
- name: "Set os_client_config's auth parameters if not already set."
  set_fact:
    auth: "{{ openstack.clouds[0].auth }}"
    auth_type: "{{ openstack.clouds[0].auth_type }}"
  when: auth is undefined
  no_log: yes

- name: "Setup DHCP for nodes."
  template:
    src: dhcp-host.j2
    dest: "/etc/dnsmasq.d/bifrost.dhcp-hosts.d/{{ inventory_hostname }}"
    owner: root
    group: root
    mode: 0644
  when: inventory_dhcp | bool == true
  become: yes
- name: "Setup DNS address for nodes."
  template:
    src: dns-address.j2
    dest: "/etc/dnsmasq.d/host_record_{{ inventory_hostname }}"
    owner: root
    group: root
    mode: 0644
  when: inventory_dns | bool == true
  become: yes
- name: "Sending dnsmasq HUP"
  # Note(TheJulia): We need to actually to send a hup signal directly as
  # Ansible's reloaded state does not pass through to the init script.
  command: killall -HUP dnsmasq
  become: yes
  when: (inventory_dhcp | bool == true) or (inventory_dns | bool == true)

- name: "Execute node introspection - noauth_mode"
  os_ironic_inspect:
    cloud: "{{ cloud_name | default(omit) }}"
    auth_type: "{{ auth_type | default(omit) }}"
    auth: "{{ auth | default(omit) }}"
    ironic_url: "{{ ironic_url | default(omit) }}"
    uuid: "{{ uuid | default('') }}"
    name: "{{ name | default('') }}"
    timeout: "{{ inspection_wait_timeout }}"
  when: noauth_mode is not defined or noauth_mode | bool == True

# NOTE(TheJulia): Some behavior appears to have changed in ansible at
# some point where arguments are passed that are part of the spec for,
# which raises a bug in the inspection module where auth_type must be
# defined, as it is otherwise always sent as a null value.
- name: "Execute node introspection"
  os_ironic_inspect:
    cloud: "{{ cloud_name | default(omit) }}"
    auth_type: "{{ auth_type | default('password') }}"
    auth: "{{ auth | default(omit) }}"
    ironic_url: "{{ ironic_url | default(omit) }}"
    uuid: "{{ uuid | default('') }}"
    name: "{{ name | default('') }}"
    timeout: "{{ inspection_wait_timeout }}"
  when: noauth_mode is defined and noauth_mode | bool == False

**********
DECISION===>: Insufficient Logging
**********
=========================:::199:::END!!!=========================
=========================:::200:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/ironic-inspect-node/meta/main.yml
**********
---
galaxy_info:
  author: Ironic Developers
  description: Invoke ironic node hardware introspection.
  company: OpenStack
  license: Apache
  min_ansible_version: 2.0
  platforms:
  - name: EL
    versions:
    - 7
  - name: Fedora
    versions:
    - 20
  - name: Ubuntu
    versions:
    - trusty
  - name: Debian
    versions:
    - wheezy
  categories:
  - cloud
  - cloud:openstack
dependencies: []

**********
DECISION===>: PASS
**********
=========================:::200:::END!!!=========================
=========================:::201:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/ironic-inspect-node/defaults/main.yml
**********
---
# defaults file for ironic-inspect-node
noauth_mode: true
inspection_wait_timeout: 1800
inventory_dhcp: false
inventory_dhcp_static_ip: true
inventory_dns: false

**********
DECISION===>: PASS
**********
=========================:::201:::END!!!=========================
=========================:::202:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/ironic-inspect-node/handlers/main.yml
**********
---
# handlers file for ironic-inspect-node

**********
DECISION===>: PASS
**********
=========================:::202:::END!!!=========================
=========================:::203:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-test-vm/vars/main.yml
**********
---
# vars file for bifrost-test-vm

**********
DECISION===>: PASS
**********
=========================:::203:::END!!!=========================
=========================:::204:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-test-vm/tasks/main.yml
**********
# Copyright (c) 2015 Hewlett-Packard Development Company, L.P.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
---
- name: >
    "Execute ping step to verify connectivity and login to the host.
    If this fails, the configdrive may not have loaded."
  # NOTE(TheJulia): This is executed as a raw command to validate the remote
  # hostname. This is because cirros lacks sftp support.
  raw: hostname
  register: instance_hostname

- name: >
    'Error if hostname is set to "ubuntu", "cirros", "debian", or "centos"'
  # TODO: Presently this step is unable to cycle through each host and verify
  # its hostname is properly set. Perhaps if there was some way to extract
  # the data on each host from ironic's DB and then verify that information
  # as a host-level fact that can be verified.
  #
  # TODO: As time goes on, we may move to leveraging inventory information
  # which will allow this role to do validation of the remote node.
  # NOTE(TheJulia): If we go down the path of additional validation, we need
  # to keep things like Cirros in mind.
  fail: >
    msg='Check if hostname was changed from the default value.
    If this fails, the configdrive may not have been used.'
  when: >
    "ubuntu" in instance_hostname.stdout or
    "cirros" in instance_hostname.stdout or
    "debian" in instance_hostname.stdout or
    "centos" in instance_hostname.stdout

**********
DECISION===>: PASS
**********
=========================:::204:::END!!!=========================
=========================:::205:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-test-vm/meta/main.yml
**********
---
galaxy_info:
  author: Ironic Developers
  description: Basic connectivity test of nodes created by Bifrost.
  company: OpenStack
  license: Apache
  min_ansible_version: 1.9
  #
  # Below are all platforms currently available. Just uncomment
  # the ones that apply to your role. If you don't see your
  # platform on this list, let us know and we'll get it added!
  #
  platforms:
  #- name: EL
  #  versions:
  #  - all
  #  - 5
  #  - 6
  #  - 7
  #- name: GenericUNIX
  #  versions:
  #  - all
  #  - any
  #- name: Fedora
  #  versions:
  #  - all
  #  - 16
  #  - 17
  #  - 18
  #  - 19
  #  - 20
  #- name: SmartOS
  #  versions:
  #  - all
  #  - any
  #- name: opensuse
  #  versions:
  #  - all
  #  - 12.1
  #  - 12.2
  #  - 12.3
  #  - 13.1
  #  - 13.2
  #- name: Amazon
  #  versions:
  #  - all
  #  - 2013.03
  #  - 2013.09
  #- name: GenericBSD
  #  versions:
  #  - all
  #  - any
  #- name: FreeBSD
  #  versions:
  #  - all
  #  - 8.0
  #  - 8.1
  #  - 8.2
  #  - 8.3
  #  - 8.4
  #  - 9.0
  #  - 9.1
  #  - 9.1
  #  - 9.2
  #- name: Ubuntu
  #  versions:
  #  - all
  #  - lucid
  #  - maverick
  #  - natty
  #  - oneiric
  #  - precise
  #  - quantal
  #  - raring
  #  - saucy
    - trusty
  #- name: SLES
  #  versions:
  #  - all
  #  - 10SP3
  #  - 10SP4
  #  - 11
  #  - 11SP1
  #  - 11SP2
  #  - 11SP3
  #- name: GenericLinux
  #  versions:
  #  - all
  #  - any
  #- name: Debian
  #  versions:
  #  - all
  #  - etch
  #  - lenny
  #  - squeeze
  #  - wheezy
  #
  # Below are all categories currently available. Just as with
  # the platforms above, uncomment those that apply to your role.
  #
  categories:
  - cloud
  - cloud:openstack
  #- cloud:gce
  #- cloud:rax
  #- clustering
  #- database
  #- database:nosql
  #- database:sql
  #- development
  #- monitoring
  #- networking
  #- packaging
  #- system
  #- web
dependencies: []

**********
DECISION===>: PASS
**********
=========================:::205:::END!!!=========================
=========================:::206:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-test-vm/defaults/main.yml
**********
---
# defaults file for bifrost-test-vm

**********
DECISION===>: PASS
**********
=========================:::206:::END!!!=========================
=========================:::207:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-test-vm/handlers/main.yml
**********
---
# handlers file for bifrost-test-vm

**********
DECISION===>: PASS
**********
=========================:::207:::END!!!=========================
=========================:::208:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/ironic-delete-dynamic/vars/main.yml
**********
---
# vars file for ironic-delete-dynamic

**********
DECISION===>: PASS
**********
=========================:::208:::END!!!=========================
=========================:::209:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/ironic-delete-dynamic/tasks/main.yml
**********
# Copyright (c) 2015 Hewlett-Packard Development Company, L.P.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
---
- name: "If in noauth mode, unset authentication parameters."
  set_fact:
    auth_type: None
    auth: {}
  when: noauth_mode is defined and noauth_mode | bool == true

- name: "Execute os_client_config to collect facts"
  os_client_config:
  no_log: yes
  when: noauth_mode is defined and noauth_mode | bool == false

# NOTE(TheJulia): The first record returned by os_client_config
# is utilized as the default. A user can still define the parameters
# if so desired.
- name: "Set os_client_config's auth parameters if not already set."
  set_fact:
    auth: "{{ openstack.clouds[0].auth }}"
    auth_type: "{{ openstack.clouds[0].auth_type }}"
  when: auth is undefined
  no_log: yes

- name: "Delete hardware"
  os_ironic:
    cloud: "{{ cloud_name | default(omit) }}"
    auth_type: "{{ auth_type | default(omit) }}"
    auth: "{{ auth | default(omit) }}"
    ironic_url: "{{ ironic_url | default(omit) }}"
    driver: ""
    uuid: "{{ uuid | default() }}"
    name: "{{ name | default() }}"
    state: absent
    nics: "{{ nics }}"
    driver_info: "{}"

**********
DECISION===>: PASS
**********
=========================:::209:::END!!!=========================
=========================:::210:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/ironic-delete-dynamic/meta/main.yml
**********
---
galaxy_info:
  author: Ironic Developers
  description: Removes enrolled nodes from Ironic
  company: OpenStack
  license: Apache
  min_ansible_version: 2.0
  platforms:
  - name: EL
    versions:
    - 7
  - name: Debian
    versions:
    - wheezy
  - name: Ubuntu
    versions:
    - trusty
    - utopic
  categories:
  - cloud
  - cloud:openstack
dependencies: []

**********
DECISION===>: PASS
**********
=========================:::210:::END!!!=========================
=========================:::211:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/ironic-delete-dynamic/defaults/main.yml
**********
---
ironic_url: "http://localhost:6385/"
noauth_mode: true

**********
DECISION===>: PASS
**********
=========================:::211:::END!!!=========================
=========================:::212:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/ironic-delete-dynamic/handlers/main.yml
**********
---
# handlers file for ironic-delete-dynamic

**********
DECISION===>: PASS
**********
=========================:::212:::END!!!=========================
=========================:::213:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-deploy-nodes-dynamic/vars/main.yml
**********
---
# vars file for bifrost-deploy-nodes-dynamic

**********
DECISION===>: PASS
**********
=========================:::213:::END!!!=========================
=========================:::214:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-deploy-nodes-dynamic/tasks/main.yml
**********
# Copyright (c) 2015 Hewlett-Packard Development Company, L.P.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
---
# TODO(TheJulia) It would make sense to perform basic validation prior
# to deployment, although direct definition of instance info on
# the pass-through could mean that the user could deploy
# things that are not directly accessible or reasonable
# to be inspected.
- name: "Obtain setup facts"
  setup:

- name: "If in noauth mode, unset authentication parameters."
  set_fact:
    auth_type: None
    auth: {}
  when: noauth_mode is defined and noauth_mode | bool == true

- name: "Execute os_client_config to collect facts"
  os_client_config:
  no_log: yes
  when: noauth_mode is defined and noauth_mode | bool == false

# NOTE(TheJulia): The first record returned by os_client_config
# is utilized as the default. A user can still define the parameters
# if so desired.
- name: "Set os_client_config's auth parameters if not already set."
  set_fact:
    auth: "{{ openstack.clouds[0].auth }}"
    auth_type: "{{ openstack.clouds[0].auth_type }}"
  when: auth is undefined
  no_log: yes

- name: "Setup DHCP for nodes."
  template:
    src: dhcp-host.j2
    dest: "/etc/dnsmasq.d/bifrost.dhcp-hosts.d/{{ inventory_hostname }}"
    owner: root
    group: root
    mode: 0644
  when: inventory_dhcp | bool == true
  become: yes
- name: "Setup DNS address for nodes."
  template:
    src: dns-address.j2
    dest: "/etc/dnsmasq.d/host_record_{{ inventory_hostname }}"
    owner: root
    group: root
    mode: 0644
  when: inventory_dns | bool == true
  become: yes
- name: "Sending dnsmasq HUP"
  # Note(TheJulia): We need to actually to send a hup signal directly as
  # Ansible's reloaded state does not pass through to the init script.
  command: killall -HUP dnsmasq
  become: yes
  when: (inventory_dhcp | bool == true) or (inventory_dns | bool == true)
- name: "Deploy to hardware - Using custom instance_info."
  os_ironic_node:
    auth_type: "{{ auth_type | default(omit) }}"
    auth: "{{ auth | default(omit) }}"
    ironic_url: "{{ ironic_url }}"
    uuid: "{{ uuid }}"
    state: present
    config_drive: "{{ deploy_url_protocol }}://{{ hostvars[inventory_hostname]['ansible_' + ans_network_interface]['ipv4']['address'] }}:{{ file_url_port }}/configdrive-{{ uuid }}.iso.gz"
    instance_info: "{{ instance_info }}"
    wait: "{{ wait_for_node_deploy }}"
    timeout: " {{ wait_timeout | default(1800) }}"
  when: instance_info is defined and instance_info | to_json != '{}'
- name: "Collect the checksum of the deployment image."
  stat:
    path: "{{ deploy_image }}"
    get_checksum: yes
    checksum_algorithm: md5
  register: test_deploy_image
  when: instance_info is not defined or ( instance_info is defined and instance_info | to_json == '{}' )
- name: "Error if deploy_image is not present, and instance_info is not defined"
  fail: msg="The user-defined deploy_image, which is the image to be written to the remote node(s) upon deployment, was not found. Cannot proceed."
  when: instance_info is not defined and test_deploy_image.stat.exists | bool == false
- name: "Deploy to hardware - bifrost default"
  os_ironic_node:
    cloud: "{{ cloud_name | default(omit) }}"
    auth_type: "{{ auth_type | default(omit) }}"
    auth: "{{ auth | default(omit) }}"
    ironic_url: "{{ ironic_url | default(omit) }}"
    uuid: "{{ uuid }}"
    state: present
    config_drive: "{{ deploy_url_protocol }}://{{ hostvars[inventory_hostname]['ansible_' + ans_network_interface]['ipv4']['address'] }}:{{ file_url_port }}/configdrive-{{ uuid }}.iso.gz"
    instance_info:
      image_source: "{{ deploy_url_protocol }}://{{ hostvars[inventory_hostname]['ansible_' + ans_network_interface]['ipv4']['address'] }}:{{ file_url_port }}/{{deploy_image_filename}}"
      image_checksum: "{{ test_deploy_image.stat.checksum }}"
      image_disk_format: "qcow2"
      root_gb: 10
    wait: "{{ wait_for_node_deploy }}"
    timeout: " {{ wait_timeout | default(1800) }}"
  when: instance_info is not defined or ( instance_info is defined and instance_info | to_json == '{}' )

**********
DECISION===>: Weak Hash Algorithm
**********
=========================:::214:::END!!!=========================
=========================:::215:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-deploy-nodes-dynamic/meta/main.yml
**********
---
galaxy_info:
  author: Ironic Developers
  description: Deploys the image on to nodes in Ironic
  company: OpenStack
  license: Apache
  min_ansible_version: 2.0
  platforms:
  - name: EL
    versions:
    - 7
  - name: Debian
    versions:
    - wheezy
    - jessie
  - name: Ubuntu
    versions:
    - trusty
    - utopic
  categories:
  - cloud
  - cloud:openstack
dependencies: []

**********
DECISION===>: PASS
**********
=========================:::215:::END!!!=========================
=========================:::216:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-deploy-nodes-dynamic/defaults/main.yml
**********
---
# defaults file for bifrost-deploy-nodes-dynamic
ironic_url: "http://localhost:6385/"
file_url_port: "8080"
network_interface: "virbr0"
ans_network_interface: "{{ network_interface | replace('-', '_') }}"
http_boot_folder: "/httpboot"
deploy_image_filename: "deployment_image.qcow2"
deploy_image: "{{http_boot_folder}}/{{deploy_image_filename}}"
inventory_dhcp: false
inventory_dhcp_static_ip: true
inventory_dns: false
deploy_url_protocol: "http"
noauth_mode: true

# Under normal circumstances, the os_ironic_node module does not wait for
# the node to reach active state before continuing with the deployment
# process.  This means we may have to timeout, to figure out a deployment
# failed.  Change wait_for_node_deploy to true to cause bifrost to wait for
# Ironic to show the instance in Active state.
wait_for_node_deploy: false
wait_timeout: 1800

**********
DECISION===>: PASS
**********
=========================:::216:::END!!!=========================
=========================:::217:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/playbooks/roles/bifrost-deploy-nodes-dynamic/handlers/main.yml
**********
---
# handlers file for bifrost-deploy-nodes-dynamic

**********
DECISION===>: PASS
**********
=========================:::217:::END!!!=========================
=========================:::218:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/releasenotes/notes/inventory-functional-tests-998796326c2a92ff.yaml
**********
---
fixes:
  - Functional tests were added for the inventory module
    that leverage JSON and YAML parsing to ensure that the
    input is same as the expected output of the conversion
    being leveraged.
  - A functional test was added that reconsumes JSON data
    generated by the CSV file format to help identify any
    logic parity breaks between the logic present in each
    data parsing method.

**********
DECISION===>: PASS
**********
=========================:::218:::END!!!=========================
=========================:::219:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/releasenotes/notes/fix-inspection-with-inventory-dhcp-cfc236974bf4ed0a.yaml
**********
---
fixes:
  - Added dhcp configuration tasks to inspection role.
    In case when inventory_dhcp is enabled and node is not deployed yet,
    inspection is not working because dnsmasq ignores requests from unknown
    address. This fix introduces tasks which configures dhcp before
    inspection.

**********
DECISION===>: PASS
**********
=========================:::219:::END!!!=========================
=========================:::220:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/releasenotes/notes/inventory_dhcp_provisioning_ipv4_address-d2779f1abc38324a.yaml
**********
---
features:
  -
    The inventory_dhcp feature permits configuration
    of dnsmasq to provide the IP configuration on
    servers deployed by Bifrost, rather than setting
    that information into the config drive.
    Previously, the feature assumed the IP set by
    dnsmasq was both the provisioning and the
    management IP, but on some scenarios that is
    not always the case.
    With the inclusion of the inventory_dhcp_static_ip
    option a user can provide an specific provisioning 
    IP via the JSON/YAML/CSV inventory in a server by
    server basis, which will be used just for the
    provisioning.

**********
DECISION===>: PASS
**********
=========================:::220:::END!!!=========================
=========================:::221:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/releasenotes/notes/bifrost-role-auth-support-ea6b5571cd339aa2.yaml
**********
---
features:
  - Allows to choose to leverage authentication with roles that
    interact with ironic services via ansible modules. This is
    limited to sessions that obtain authentication information
    via os-client-config. The role defaults ultimately remain
    unchanged and default to noauth mode.  More information on
    os-client-config can be found at
    https://docs.openstack.org/developer/os-client-config/
issues:
  - Users wishing to utilize authentication without leveraging
    os-client-config, will need to manually update the playbooks
    in order to set the appropriate module settings.

**********
DECISION===>: PASS
**********
=========================:::221:::END!!!=========================
=========================:::222:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/releasenotes/notes/inventory_dns-921195abbc5e65ef.yaml
**********
---
features:
  - Adds new feature to manage DNS with the settings
    on the inventory. When ``inventory_dns`` setting is
    True, it will populate a set of record-host entries,
    for each of the hostnames present on the inventory,
    matching the ``ipv4_address``.  This will override
    the default dnsmasq behaviour, that will associate
    hostnames with IP present on the leases file.

**********
DECISION===>: PASS
**********
=========================:::222:::END!!!=========================
=========================:::223:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/releasenotes/notes/merge-test-playbooks-aeabc7a614cbce29.yaml
**********
---

upgrade:
  - A new test playbook, test-bifrost.yaml, has been added.
    This playbook merges the functionality of the existing
    test-bifrost-dynamic.yaml and test-bifrost-dhcp.yaml
    playbooks.

deprecations:
  - test-bifrost-dynamic.yaml and test-bifrost-dhcp.yaml
    have been superseded by test-bifrost.yaml and will be
    removed in the Ocata release.

**********
DECISION===>: PASS
**********
=========================:::223:::END!!!=========================
=========================:::224:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/releasenotes/notes/dhcp_ignore_inventory_dhcp-44668e3fe710c134.yaml
**********
---
fixes:
  - Dnsmasq option was added to only offer DHCP leases
    to known mac addresses when inventory_dhcp is being used.

**********
DECISION===>: PASS
**********
=========================:::224:::END!!!=========================
=========================:::225:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/releasenotes/notes/test-with-json-inventory-b05204009f880431.yaml
**********
---
features:
  - |
    Bifrost's testing has been moved to use JSON-formatted baremetal inventory
    file instead of deprecated CSV-formatted one.
    The ``bifrost-create-vm-nodes`` role still accepts ``baremetal_csv_file``
    variable as path to where to write inventory, but the file content will
    always be in JSON format.
    A new variable ``baremetal_json_file`` should instead be used
    as a location to where to write the test baremetal inventory file.
upgrade:
  - |
    The ``baremetal_csv_file`` variable in ``bifrost-create-vm-nodes`` role
    has been deprecated and will be removed in the Queens release.
    The inventory file written to this location by this role is now always
    in JSON format.
    The variable ``baremetal_json_file`` should be used instead of
    ``baremetal_csv_file``.
    This concerns only those operators who run tests for bifrost on
    virtual hardware using ``bifrost-create-vm-nodes`` role and out-of-tree
    scripts to process the baremetal inventory file produced by this role.
    If such scripts do rely on this file being in CSV format,
    they must be updated to use JSON format instead.
deprecations:
  - |
    The CSV format for baremetal inventory file is deprecated and using
    it will be impossible in the Queens release.
    During deprecation period it's handling is still supported by bifrost's
    dynamic inventory, but this functionality will be removed in the Queens
    release.

**********
DECISION===>: PASS
**********
=========================:::225:::END!!!=========================
=========================:::226:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/bifrost/releasenotes/notes/decompose-ironic-install-role-75b9a431bba88bad.yaml
**********
---
features:
  - The ironic install role has been split into 3 phases.
    ``install`` phase installs all ironic packages and
    dependencies. ``bootstrap`` phase generates configs
    and initializes the ironic db. ``start`` phase starts
    all ironic services and dependencies. Each phase is run
    by default and can be skipped by defining skip_package_install,
    skip_bootstrap and skip_start respectively.

**********
DECISION===>: PASS
**********
=========================:::226:::END!!!=========================
=========================:::227:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/oooq/roles/pre-install-setup/tasks/main.yml
**********
---

- name: Make sure dependencies are installed
  package: name={{item}} state=present
  become: true
  with_items: "{{ browbeat_dependencies }}"

- name: Copy browbeat to the undercloud
  synchronize: "src={{ local_working_dir }}/browbeat dest={{ ansible_env.HOME }}/ use_ssh_args=yes"
  when: ansible_user != "zuul"

- name: Register the working directory to copy from
  stat:
    path: "/home/zuul/workspace/"
  register: zuul_workspace

- name: Copy browbeat to the undercloud - zuul v3
  synchronize: "src={{ ansible_user_dir }}/{{ zuul.projects['git.openstack.org/openstack/browbeat'].src_dir }} dest={{ ansible_env.HOME }}/"
  when: ansible_user == "zuul" and zuul_workspace.stat.exists and zuul is defined and zuul.projects is defined

- name: Copy browbeat to the undercloud - zuul legacy
  synchronize: "src={{ ansible_user_dir }}/workspace/openstack/browbeat dest={{ ansible_env.HOME }}/"
  when: ansible_user == "zuul" and zuul_workspace.stat.exists and zuul is not defined and zuul.projects is not defined

- name: Copy browbeat to the undercloud - zuul user reproducer
  synchronize: "src=/opt/stack/browbeat dest={{ ansible_env.HOME }}/"
  when: ansible_user == "zuul" and not zuul_workspace.stat.exists

- name: Set hosts gen as executable
  shell: "chmod +x {{ ansible_env.HOME }}/browbeat/ansible/generate_tripleo_hostfile.sh"

- name: Fetch Browbeat vars file
  fetch:
    "src={{ ansible_env.HOME }}/browbeat/ansible/install/group_vars/all.yml \
     dest=/tmp/all.yml \
     flat=yes"
  when: ansible_user != "zuul"

- name: Fetch Browbeat vars file - zuul
  fetch:
    "src={{ ansible_env.HOME }}/browbeat/ansible/install/group_vars/zuul_all.yml \
     dest=/tmp/all.yml \
     flat=yes"
  when: ansible_user == "zuul"

- name: Load Browbeat vars
  include_vars: /tmp/all.yml

**********
DECISION===>: Hardcoded Secret
**********
=========================:::227:::END!!!=========================
=========================:::228:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/oooq/roles/pre-install-setup/defaults/main.yml
**********
browbeat_dependencies:
                  - rsync
                  - ansible

**********
DECISION===>: PASS
**********
=========================:::228:::END!!!=========================
=========================:::229:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/oooq/roles/gather-metadata/tasks/main.yml
**********
---
#Gathers Browbeat metdata and inserts it into elasticsearch
# and flat files in browbeat/results

- name: Gather Metadata
  shell:
    "cd {{ ansible_env.HOME }}/browbeat/ansible; \
     ansible-playbook -i hosts \
     gather/site.yml > {{ ansible_env.HOME }}/browbeat/results/metadata.log"
  register: metadata_run
  until: metadata_run.rc == 0
  retries: 2
  delay: 60
  environment:
    ANSIBLE_SSH_ARGS: "-F {{ ansible_env.HOME }}/browbeat/ansible/ssh-config"

**********
DECISION===>: PASS
**********
=========================:::229:::END!!!=========================
=========================:::230:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/oooq/roles/ci-network/tasks/main.yml
**********
---
#
# Setup network using tripleo-environments params
#

- name: Create browbeat public network
  shell: ". {{overcloudrc}}; neutron net-create {{browbeat_pub_net_name}} --shared --router:external --provider:network-type flat --provider:physical-network datacentre | grep -E ' id ' | awk '{print $4}'"
  register: public_net_id

- name: Create browbeat public subnet
  shell: ". {{overcloudrc}}; neutron subnet-create {{public_net_id.stdout}} {{browbeat_pub_subnet}} --allocation-pool start={{browbeat_pub_pool_start}},end={{browbeat_pub_pool_end}} --gateway={{browbeat_pub_pool_gw}} --disable-dhcp"

- name: Create browbeat private network
  shell: ". {{overcloudrc}}; neutron net-create {{browbeat_pri_net_name}} --shared | grep -E ' id ' | awk '{print $4}'"
  register: private_net_id

- name: Create browbeat private subnet
  shell: ". {{overcloudrc}}; neutron subnet-create {{private_net_id.stdout}} 192.168.0.0/24 | grep -E ' id ' | awk '{print $4}'"
  register: private_subnet_id

- name: Create browbeat router
  shell: ". {{overcloudrc}}; neutron router-create {{browbeat_router_name}} | grep -E ' id ' | awk '{print $4}'"
  register: router_id

- name: Set browbeat router gateway
  shell: ". {{overcloudrc}}; neutron router-gateway-set {{router_id.stdout}} {{public_net_id.stdout}}"

- name: Add browbeat router interface to browbeat private network
  shell: ". {{overcloudrc}}; neutron router-interface-add {{router_id.stdout}} {{private_subnet_id.stdout}}"

**********
DECISION===>: PASS
**********
=========================:::230:::END!!!=========================
=========================:::231:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/oooq/roles/ci-network/defaults/main.yml
**********
---
# Public network that perfkit and shaker utilize
browbeat_pub_net_name: browbeat_public
browbeat_pub_subnet: 1.1.1.1/22
browbeat_pub_pool_start: 1.1.1.1
browbeat_pub_pool_end: 1.1.1.1
browbeat_pub_pool_gw: 1.1.1.1
# Private subnet
browbeat_pri_net_name: browbeat_private
browbeat_pri_subnet: 172.16.10.0/24
browbeat_pri_pool_start: 172.16.10.2
browbeat_pri_pool_end: 172.16.10.100
browbeat_pri_pool_gw: 172.16.10.1
browbeat_pri_pool_dns: 8.8.8.8

browbeat_router_name: browbeat_router

**********
DECISION===>: PASS
**********
=========================:::231:::END!!!=========================
=========================:::232:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/oooq/roles/browbeat-classify/tasks/main.yml
**********
---

- name: Copy bash file
  copy:
    src: uuid_extract.sh
    dest: /tmp

- name: Parse uuid from variable
  shell: "sh /tmp/uuid_extract.sh {{ ansible_env.HOME }}/browbeat/log/debug.log"
  register: browbeat_uuid

- name: Clone and Install Browbeat-ML dependencies
  pip:
    name: "git+https://github.com/aakarshg/Browbeat-ML.git@elastic5#egg=bml"
    virtualenv: "{{ ansible_env.HOME }}/browbeat-venv"

- name: Run Browbeat-ML on uuid
  shell: "source {{ ansible_env.HOME }}/browbeat-venv/bin/activate; bml --summary-uuid {{browbeat_uuid.stdout}} --update-db True "
  register: browbeatml_summary

- debug: msg="{{ browbeatml_summary.stdout_lines }}"

- name: Upload timeseries data summaries to cockroach db
  shell: "source {{ ansible_env.HOME }}/browbeat-venv/bin/activate; bml --upload-timesummary {{browbeat_uuid.stdout}}"

- name: Upload log data summaries to cockroach db
  shell: "source {{ ansible_env.HOME }}/browbeat-venv/bin/activate; bml --upload-logsummary {{browbeat_uuid.stdout}}"

**********
DECISION===>: PASS
**********
=========================:::232:::END!!!=========================
=========================:::233:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/oooq/roles/bug-check/tasks/main.yml
**********
---
# Checks the cloud for known bugs and produces a bug report
#  not functional on osp8 or earlier, therefore errors are ignored

- name: Check Cloud for Bugs
  shell:
    "cd {{ ansible_env.HOME }}/browbeat/ansible; \
     ansible-playbook -i hosts \
     check/site.yml > {{ ansible_env.HOME }}/browbeat/results/check.log"
  register: check_run
  ignore_errors: true
  until: check_run.rc == 0
  retries: 2
  delay: 60
  environment:
    ANSIBLE_SSH_ARGS: "-F {{ ansible_env.HOME }}/browbeat/ansible/ssh-config"

**********
DECISION===>: PASS
**********
=========================:::233:::END!!!=========================
=========================:::234:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/oooq/roles/browbeat-run/tasks/main.yml
**********
---

- name: Run Browbeat
  shell:
    "source {{ ansible_env.HOME }}/browbeat/.browbeat-venv/bin/activate; \
     cd {{ ansible_env.HOME }}/browbeat/; \
     python browbeat.py all | tee {{ ansible_env.HOME }}/browbeat/log/stdout-ci-run.log"

**********
DECISION===>: PASS
**********
=========================:::234:::END!!!=========================
=========================:::235:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/oooq/roles/grafana-dashboard-setup/vars/main.yml
**********
grafana_enabled_template: false
grafana_host_template: 1.2.3.4
grafana_username_template: admin
grafana_password_template: admin
graphite_prefix_template: "browbeat-ci"


**********
DECISION===>: Hardcoded Secret
**********
=========================:::235:::END!!!=========================
=========================:::236:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/oooq/roles/grafana-dashboard-setup/tasks/main.yml
**********
---
# Sets up Grafana dashboards for the system data. this must be run after
#  the overcloud setup because it checks the hosts file to determine what
#  hosts exist to be dasboarded

- name: Setup Grafana Dashboards
  shell:
    "cd {{ ansible_env.HOME }}/browbeat/ansible; \
     ansible-playbook -vvv -i hosts \
     --extra-vars grafana_host={{ grafana_host_template }} \
     --extra-vars grafana_username={{ grafana_username_template }} \
     --extra-vars grafana_password={{ grafana_password_template }} \
     --extra-vars dashboard_cloud_name={{ graphite_prefix_template }} \
     install/grafana-dashboards.yml > {{ ansible_env.HOME }}/browbeat/results/dashboards.log"
  environment:
    ANSIBLE_SSH_ARGS: "-F {{ ansible_env.HOME }}/browbeat/ansible/ssh-config"
  when: "{{ grafana_enabled_template }}"

**********
DECISION===>: PASS
**********
=========================:::236:::END!!!=========================
=========================:::237:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/oooq/roles/oooq-metadata/vars/main.yml
**********
dlrn_hash: "Not a pipeline build"
rhos_puddle: "Not a pipeline build"
logs_link: "https://thirdparty.logs.rdoproject.org/jenkins-{{ lookup('env','JOB_NAME') }}-{{ lookup('env','BUILD_NUMBER') }}/"
instackenv: "/home/stack/instackenv.json"

**********
DECISION===>: PASS
**********
=========================:::237:::END!!!=========================
=========================:::238:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/oooq/roles/oooq-metadata/tasks/main.yml
**********
---
#Collect and template Metadata about the deployment

- name: Get Overcloud Image Build date
  shell: "curl -s -v -X HEAD {{ overcloud_image_url }} 2>&1 | grep '^< Date:'"
  register: build
  ignore_errors: true

- name: Determine if docker is running
  shell: docker ps | wc -l
  register: docker_ps
  delegate_to: overcloud-controller-0
  when: "'overcloud' in group_names"
  ignore_errors: True

- name: Set var for container deployment
  set_fact:
    containers: True
  when: docker_ps.stdout|int > 1
  ignore_errors: True

- name: Set fact for non-container deployment
  set_fact:
    containers: False
  when: docker_ps.stdout|int < 2
  ignore_errors: True

- name: Count nodes in Instackenv.json
  shell: "grep pm_addr {{instackenv}} | wc -l"
  register: num_nodes

- name: Make sure the results directory exists
  file: "path={{ ansible_env.HOME }}/browbeat/metadata state=directory"

- name: Template Deployment Metadata
  template:
    "src=version.json.j2 \
     dest={{ ansible_env.HOME }}/browbeat/metadata/version.json"

**********
DECISION===>: PASS
**********
=========================:::238:::END!!!=========================
=========================:::239:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/oooq/roles/template-configs/vars/main.yml
**********
elastic_enabled: false
elastic_host: "1.2.3.4.5"
grafana_enabled: false
grafana_host: "1.2.3.4.5"
browbeat_config_file: "browbeat-basic.yaml.j2"
browbeat_cloud_name: "browbeat_ci"
overcloud_size: "{{num_nodes.stdout|int}}"
ntp_server: "pool.ntp.org"

**********
DECISION===>: PASS
**********
=========================:::239:::END!!!=========================
=========================:::240:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/oooq/roles/template-configs/tasks/main.yml
**********
---
- name: Template Browbeat configuration
  template:
    "src={{ browbeat_config_file }} \
     dest={{ ansible_env.HOME }}/browbeat/browbeat-config.yaml"

**********
DECISION===>: PASS
**********
=========================:::240:::END!!!=========================
=========================:::241:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/oooq/roles/collectd-undercloud/vars/main.yml
**********
graphite_host_template: "1.2.3.4.5"
graphite_prefix_template: "CI"

**********
DECISION===>: PASS
**********
=========================:::241:::END!!!=========================
=========================:::242:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/oooq/roles/collectd-undercloud/tasks/main.yml
**********
- name: Template undercloud only hosts file
  template:
    "src=hosts.j2 \
     dest={{ ansible_env.HOME }}/browbeat/ansible/hosts"

- name: Template ssh-config
  template:
    "src=ssh-config.j2 \
     dest={{ ansible_env.HOME }}/browbeat/ansible/ssh-config"

- name: Install CollectD
  shell:
    "cd {{ ansible_env.HOME }}/browbeat/ansible; \
     ansible-playbook -i hosts -c local \
     --extra-vars graphite_host={{ graphite_host_template }} \
     --extra-vars graphite_prefix={{ graphite_prefix_template }} \
     install/collectd-openstack.yml \
     > {{ ansible_env.HOME }}/browbeat/results/collecd_install.log"
  register: collectd_install
  until: collectd_install.rc == 0
  retries: 2
  delay: 60
  environment:
    ANSIBLE_SSH_ARGS: "-F {{ ansible_env.HOME }}/browbeat/ansible/ssh-config"

**********
DECISION===>: PASS
**********
=========================:::242:::END!!!=========================
=========================:::243:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/oooq/roles/collectd/vars/main.yml
**********
graphite_host_template: "1.2.3.4.5"
graphite_prefix_template: "CI"

**********
DECISION===>: PASS
**********
=========================:::243:::END!!!=========================
=========================:::244:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/oooq/roles/collectd/tasks/main.yml
**********
---
#role to install CollectD on all nodes

- name: Install CollectD
  shell:
    "cd {{ ansible_env.HOME }}/browbeat/ansible; \
     ansible-playbook -i hosts \
     --extra-vars collectd_compute=true \
     --extra-vars graphite_host={{ graphite_host_template }} \
     --extra-vars graphite_prefix={{ graphite_prefix_template }} \
     --extra-vars dns_server={{ dns_server }} \
     install/collectd-openstack.yml \
     > {{ ansible_env.HOME }}/browbeat/results/collecd_install.log"
  register: collectd_install
  until: collectd_install.rc == 0
  retries: 2
  delay: 60
  environment:
    ANSIBLE_SSH_ARGS: "-F {{ ansible_env.HOME }}/browbeat/ansible/ssh-config"

**********
DECISION===>: PASS
**********
=========================:::244:::END!!!=========================
=========================:::245:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/gather/roles/cinder/tasks/main.yml
**********
---
#
# Tasks to get cinder facts
#
- name: Parse Cinder config
  become: true
  command: python /tmp/openstack-config-parser.py cinder /tmp/out.yml
  register: cinder_parsed
  ignore_errors: true

- name: Fetch output
  fetch: src=/tmp/out.yml dest=/tmp/out-{{ inventory_hostname }}.yml flat=yes
  when: cinder_parsed is succeeded

- name: Load configuration variables
  include_vars: /tmp/out-{{ inventory_hostname }}.yml
  when: cinder_parsed is succeeded

**********
DECISION===>: Pathname Traversal
**********
=========================:::245:::END!!!=========================
=========================:::246:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/gather/roles/gnocchi/tasks/main.yml
**********
---
#
# Tasks to get gnocchi config data
#

- name: Parse Gnocchi config
  become: true
  command: python /tmp/openstack-config-parser.py gnocchi /tmp/out.yml
  register: gnocchi_parsed
  ignore_errors: true

- name: Fetch output
  fetch: src=/tmp/out.yml dest=/tmp/out-{{ inventory_hostname }}.yml flat=yes
  when: gnocchi_parsed is succeeded

- name: Load configuration variables
  include_vars: /tmp/out-{{ inventory_hostname }}.yml
  when: gnocchi_parsed is succeeded

**********
DECISION===>: Pathname Traversal
**********
=========================:::246:::END!!!=========================
=========================:::247:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/gather/roles/heat/tasks/main.yml
**********
---
#
# Tasks to get heat facts
#

- name: Parse Heat config
  become: true
  command: python /tmp/openstack-config-parser.py heat /tmp/out.yml
  register: heat_parsed
  ignore_errors: true

- name: Fetch output
  fetch: src=/tmp/out.yml dest=/tmp/out-{{ inventory_hostname }}.yml flat=yes
  when: heat_parsed is succeeded

- name: Load configuration variables
  include_vars: /tmp/out-{{ inventory_hostname }}.yml
  when: heat_parsed is succeeded

**********
DECISION===>: Pathname Traversal
**********
=========================:::247:::END!!!=========================
=========================:::248:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/gather/roles/gather/tasks/main.yml
**********
---
#
# Tasks to get facts
#

- name: Check for the config - container
  become: true
  stat: path="container_config_paths[item].config"
  register: config_containers
  when: hostvars[inventory_hostname]['containers'] is defined
  with_items: "{{ container_config_paths }}"

- name: Check for the config
  become: true
  stat: path="{{hostvars[inventory_hostname]['config_path']}}nova/nova.conf"
  register: config
  when: hostvars[inventory_hostname]['containers'] is not defined

- name: Create tmp dir
  become: true
  shell: mktemp -d -p /tmp -t XXX-metadata
  register: tmp

- name: Parse config - containers
  become: true
  shell: "python /tmp/openstack-config-parser.py {{item}} {{container_config_paths[item].config}} {{tmp.stdout}}/{{item}}.yml"
  when: hostvars[inventory_hostname]['containers'] is defined
  ignore_errors: true
  with_items: "{{ container_config_paths }}"

- name: Parse config
  become: true
  shell: python /tmp/openstack-config-parser.py {{config_paths[item]}} {{hostvars[inventory_hostname]['config_path']}}/nova/nova.conf /tmp/out.yml
  when: config.stat.exists and hostvars[inventory_hostname]['containers'] is not defined
  ignore_errors: true

- name: Create local tmp dir
  become: false
  local_action: shell mktemp -d -p /tmp -t XXX-metadata
  register: localtmp

- name: Fetch output - containers
  fetch: src={{tmp.stdout}}/{{item}}.yml dest={{localtmp.stdout}}/{{item}}.yml flat=yes
  when: hostvars[inventory_hostname]['containers'] is defined
  ignore_errors: true
  with_items: "{{ container_config_paths }}"

- name: Assemble metadata - containers
  local_action: assemble src="{{localtmp.stdout}}" dest="{{localtmp.stdout}}/out.yml"

- name: Load configuration variables - containers
  include_vars: "{{localtmp.stdout}}/out.yml"
  when: hostvars[inventory_hostname]['containers'] is defined
  ignore_errors: true

- name: Fetch output
  fetch: src=/tmp/out.yml dest=/tmp/out-{{ inventory_hostname }}.yml flat=yes
  when: hostvars[inventory_hostname]['containers'] is not defined
  ignore_errors: true

- name: Load configuration variables
  include_vars: /tmp/out-{{ inventory_hostname }}.yml
  when: hostvars[inventory_hostname]['containers'] is not defined
  ignore_errors: true


**********
DECISION===>: Pathname Traversal
**********
=========================:::248:::END!!!=========================
=========================:::249:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/gather/roles/undercloud/tasks/main.yml
**********
---
#
# Tasks to set undercloud facts
#


  - name: Check that the undercloud.conf exists
    become: true
    stat: path=/home/stack/undercloud.conf
    register: undercloud_conf

  - name: Undercloud.conf
    become: true
    command: python /tmp/openstack-config-parser.py undercloud /tmp/out.yml
    when: undercloud_conf.stat.exists

  - name: Fetch output
    fetch: src=/tmp/out.yml dest=/tmp/out-{{ inventory_hostname }}.yml flat=yes
    when: undercloud_conf.stat.exists

  - name: Load configuration variables
    include_vars: /tmp/out-{{ inventory_hostname }}.yml
    when: undercloud_conf.stat.exists

  - name: Get max_connections on the database
    shell: mysql -e "show variables like 'max_connections';" | grep max_connections | awk '{print $2}'
    register: max_conn
    ignore_errors: true
    when: undercloud_conf.stat.exists

  - name: Set max database connections
    set_fact:
      openstack_mysql_max_connections: "{{ max_conn.stdout }}"
    when: undercloud_conf.stat.exists

  - name : Get file descriptors for the mysql process
    shell: cat /proc/$(pgrep mysqld_safe)/limits | grep "open files" | awk '{print $4}'
    register: mysql_desc
    when: undercloud_conf.stat.exists

  - name: Set file descriptors fact for mysql
    set_fact:
      openstack_mysql_file_descriptors: "{{ mysql_desc.stdout }}"
    when: undercloud_conf.stat.exists

  - name : Get rabbitmq file descriptors
    shell: rabbitmqctl status | grep total_limit |  awk -F',' '{print $2}' | sed 's/.$//'
    register: rabbitmq_desc
    ignore_errors: true
    when: undercloud_conf.stat.exists

  - name: Set rabbitmq file descriptors
    set_fact:
      openstack_rabbitmq_file_descriptors: "{{ rabbitmq_desc.stdout  }}"
    when: undercloud_conf.stat.exists

  - name: Get Controller Nodes number
    shell: source {{ ansible_env.HOME }}/stackrc; nova list | grep controller | grep ACTIVE | wc -l
    register: controller_count
    when: undercloud_conf.stat.exists

  - name : Set Controler number fact
    set_fact:
      osp_controllers_number: "{{ controller_count.stdout }}"
    when: undercloud_conf.stat.exists

  - name: Get Compute Nodes number
    shell: source {{ ansible_env.HOME }}/stackrc; nova list | grep compute | grep ACTIVE | wc -l
    register: compute_count
    when: undercloud_conf.stat.exists

  - name : Set Commpute number fact
    set_fact:
      osp_computes_number: "{{ compute_count.stdout }}"
    when: undercloud_conf.stat.exists

**********
DECISION===>: Pathname Traversal
**********
=========================:::249:::END!!!=========================
=========================:::250:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/gather/roles/ceilometer/tasks/main.yml
**********
---
#
# Tasks to get ceilometer facts
#
- name: Parse Ceilometer config
  become: true
  command: python /tmp/openstack-config-parser.py ceilometer /tmp/out.yml
  register: ceilometer_parsed
  ignore_errors: true

- name: Fetch output
  fetch: src=/tmp/out.yml dest=/tmp/out-{{ inventory_hostname }}.yml flat=yes
  when: ceilometer_parsed is succeeded

- name: Load configuration variables
  include_vars: /tmp/out-{{ inventory_hostname }}.yml
  when: ceilometer_parsed is succeeded

**********
DECISION===>: Pathname Traversal
**********
=========================:::250:::END!!!=========================
=========================:::251:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/gather/roles/nova/tasks/main.yml
**********
---
#
# Tasks to get nova facts
#

- name: Parse Nova config
  become: true
  command: python /tmp/openstack-config-parser.py nova /tmp/out.yml
  register: nova_parsed
  ignore_errors: true

- name: Fetch output
  fetch: src=/tmp/out.yml dest=/tmp/out-{{ inventory_hostname }}.yml flat=yes
  when: nova_parsed is succeeded

- name: Load configuration variables
  include_vars: /tmp/out-{{ inventory_hostname }}.yml
  when: nova_parsed is succeeded

**********
DECISION===>: Pathname Traversal
**********
=========================:::251:::END!!!=========================
=========================:::252:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/gather/roles/neutron/tasks/main.yml
**********
---
#
# Tasks to get neutron facts
#

- name: Parse Neutron config
  become: true
  command: python /tmp/openstack-config-parser.py neutron /tmp/out.yml
  register: neutron_parsed
  ignore_errors: true

- name: Fetch output
  fetch: src=/tmp/out.yml dest=/tmp/out-{{ inventory_hostname }}.yml flat=yes
  when: neutron_parsed is succeeded

- name: Load configuration variables
  include_vars: /tmp/out-{{ inventory_hostname }}.yml
  when: neutron_parsed is succeeded

**********
DECISION===>: Pathname Traversal
**********
=========================:::252:::END!!!=========================
=========================:::253:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/gather/roles/rabbitmq/tasks/main.yml
**********
---
#
# Tasks to set rabbitmq facts for controllers
#
  - name : Get rabbitmq file descriptors
    shell: rabbitmqctl status | grep file_descriptors | awk -F',' '{print $3}' | sed 's/.$//'
    register: rabbitmq_desc
    ignore_errors: true
    when: hostvars[inventory_hostname]['containers'] is not defined

  - name : Get rabbitmq file descriptors - containers
    shell: docker exec rabbitmq rabbitmqctl status | grep total_limit | awk -F',' '{print $2}'| sed 's/.$//'
    register: rabbitmq_desc_container
    ignore_errors: true
    when: hostvars[inventory_hostname]['containers'] is defined

  - name: Set rabbitmq file descriptors
    set_fact:
      openstack_rabbitmq_file_descriptors: "{{ rabbitmq_desc.stdout }}"
    when: hostvars[inventory_hostname]['containers'] is not defined

  - name: Set rabbitmq file descriptors - containers
    set_fact:
      openstack_rabbitmq_file_descriptors: "{{ rabbitmq_desc_container.stdout }}"
    when: hostvars[inventory_hostname]['containers'] is defined

**********
DECISION===>: PASS
**********
=========================:::253:::END!!!=========================
=========================:::254:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/gather/roles/keystone/tasks/main.yml
**********
---
#
# Tasks to set keystone facts
#

- name: Parse Keystone config
  become: true
  command: python /tmp/openstack-config-parser.py keystone /tmp/out.yml
  register: keystone_parsed
  ignore_errors: true

- name: Fetch output
  fetch: src=/tmp/out.yml dest=/tmp/out-{{ inventory_hostname }}.yml flat=yes
  when: keystone_parsed is succeeded

- name: Load configuration variables
  include_vars: /tmp/out-{{ inventory_hostname }}.yml
  when: keystone_parsed is succeeded

- name: Determine if Keystone is deployed in eventlet
  shell: ps afx | grep "[Kk]eystone-all" -c
  register: keystone_in_eventlet
  changed_when: false
  ignore_errors: True

- name: Set keystone_deployment variable to httpd
  set_fact: openstack_keystone_deployment='httpd'
  when: keystone_in_eventlet.stdout|int == 0

- name: Set keystone_deployment variable to eventlet
  set_fact: openstack_keystone_deployment='eventlet'
  when: keystone_in_eventlet.stdout|int > 0

- name: Determine number of keystone admin processes for httpd
  shell: grep processes /etc/httpd/conf.d/10-keystone_wsgi_admin.conf | awk '{print $5}'| awk -F= '{print $2}'
  register: keystone_admin_worker_processes
  when: keystone_in_eventlet.stdout|int == 0

- name: Determine number of keystone admin threads for httpd
  shell: grep threads /etc/httpd/conf.d/10-keystone_wsgi_admin.conf | awk '{print $6}'| awk -F= '{print $2}'
  register: keystone_admin_worker_threads
  when: keystone_in_eventlet.stdout|int == 0

- name: Determine number of keystone main threads for httpd
  shell: grep threads /etc/httpd/conf.d/10-keystone_wsgi_main.conf | awk '{print $6}'| awk -F= '{print $2}'
  register: keystone_main_worker_threads
  when: keystone_in_eventlet.stdout|int == 0

- name: Determine number of keystone main processes for httpd
  shell: grep threads /etc/httpd/conf.d/10-keystone_wsgi_main.conf | awk '{print $5}'| awk -F= '{print $2}'
  register: keystone_main_worker_processes
  when: keystone_in_eventlet.stdout|int == 0

- name: Set keystone httpd worker facts
  set_fact:
    openstack_S_keystone_S_admin_workers_S_processes: "{{ keystone_admin_worker_processes.stdout }}"
    openstack_S_keystone_S_admin_workers_S_threads: "{{ keystone_admin_worker_threads.stdout }}"
    openstack_S_keystone_S_main_workers_S_processes: "{{ keystone_main_worker_processes.stdout }}"
    openstack_S_keystone_S_main_workers_S_threads: "{{ keystone_main_worker_threads.stdout }}"
  when: keystone_in_eventlet.stdout|int == 0

**********
DECISION===>: Pathname Traversal
**********
=========================:::254:::END!!!=========================
=========================:::255:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/gather/roles/common/tasks/main.yml
**********
---
- name: Copy config parser script to remote
  copy: src=openstack-config-parser.py dest=/tmp/openstack-config-parser.py
  notify:
     - cleanup script
     - cleanup varsfile

- name: Determine if docker is running
  shell: docker ps | wc -l
  register: docker_ps

- name: Set var for container deployment
  set_fact:
    containers: True
    config_path: /var/lib/config-data/puppet-generated/
  when: docker_ps.stdout|int > 1

- name: Set fact for non-container deployment
  set_fact:
    config_path: /etc
  when: docker_ps.stdout|int < 2

**********
DECISION===>: PASS
**********
=========================:::255:::END!!!=========================
=========================:::256:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/gather/roles/common/handlers/main.yml
**********
---
# Cleanup for gather common
# Required to prevent perms issues

- name: cleanup script
  file:
    path: /tmp/openstack-config-parser.py
    state: absent
  become: true

- name: cleanup varsfile
  file:
    path: /tmp/out.yml
    state: absent
  become: true

**********
DECISION===>: Pathname Traversal
**********
=========================:::256:::END!!!=========================
=========================:::257:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/gather/roles/compute/tasks/main.yml
**********
---
#
# Compute Tasks for gathering facts
#
- name: Get ovs version
  shell: ovs-vswitchd --version | grep vSwitch | awk {'print$4'}
  register: ovs_version

- name: Set ovs version fact
  set_fact:
    openstack_ovs_version: "{{ ovs_version.stdout }}"

- name: Get neutron ovs agent ovsdb setting
  command: crudini --get /etc/neutron/plugins/ml2/openvswitch_agent.ini ovs ovsdb_interface
  register: ovsdb_status
  ignore_errors: true

- name: Set Neutron OVS ovsdb fact
  set_fact:
    openstack_neutron_ovsdb: "{{ ovsdb_status.stdout }}"
  when: (ovsdb_status.stdout.find('native') != -1 or ovsdb_status.stdout.find('vsctl') != -1)

- name: Set Neutron OVS ovsdb fact
  set_fact:
    openstack_neutron_ovsdb: "vsctl"
  when: (ovsdb_status.stdout.find('native') == -1 and ovsdb_status.stdout.find('vsctl') == -1)


- name: Check for Nested Virtualization
  shell: cat /proc/cpuinfo | grep hypervisor
  register: nested_virt
  ignore_errors: true

- name: Set Nested Virtualization flag
  set_fact:
    openstack_nested_virt: true
  when: nested_virt.stdout != ""

- name: Set Nested Virtualization flag
  set_fact:
    openstack_nested_virt: false
  when: nested_virt.stdout == ""

**********
DECISION===>: PASS
**********
=========================:::257:::END!!!=========================
=========================:::258:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/gather/roles/mysql/tasks/main.yml
**********
---

#
# Get mysql facts
#
  - name: Get max_connections on the database
    shell: mysql -e "show variables like 'max_connections';" | grep max_connections | awk '{print $2}'
    register: max_conn
    ignore_errors: true
    when: hostvars[inventory_hostname]['containers'] is not defined

  - name: Get max_connections on the database
    shell: docker exec mysql cat /etc/my.cnf.d/galera.cnf| grep max_connections | awk -F ' = ' '{print $2}'
    register: max_conn_container
    ignore_errors: true
    when: hostvars[inventory_hostname]['containers'] is defined

  - name: Set max database connections
    set_fact:
      openstack_mysql_max_connections: "{{ max_conn.stdout }}"
    when: hostvars[inventory_hostname]['containers'] is not defined

  - name: Set max database connections
    set_fact:
      openstack_mysql_max_connections: "{{ max_conn_container.stdout }}"
    when: hostvars[inventory_hostname]['containers'] is defined

  - name : Get file descriptors for the mysql process
    shell: cat /proc/$(pgrep mysqld_safe)/limits | grep "open files" | awk '{print $4}'
    register: mysql_desc

  - name: Set file descriptors fact for mysql
    set_fact:
      openstack_mysql_file_descriptors: "{{ mysql_desc.stdout }}"

**********
DECISION===>: PASS
**********
=========================:::258:::END!!!=========================
=========================:::259:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/gather/roles/dump-facts/tasks/main.yml
**********
---
- name: Dump all vars
  template: src=dump_facts.j2 dest={{ browbeat_path }}/metadata/machine_facts.json

- name: Generate metadata jsons
  command: python {{ browbeat_path }}/browbeat/metadata.py {{ browbeat_path }}/metadata

**********
DECISION===>: PASS
**********
=========================:::259:::END!!!=========================
=========================:::260:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/gather/roles/glance/tasks/main.yml
**********
---
#
# Tasks to get Glance facts
#

- name: Parse Glance config files
  become: true
  command: "python /tmp/openstack-config-parser.py glance /tmp/out.yml"
  register: glance_parsed
  ignore_errors: true

- name: Fetch output
  fetch: src=/tmp/out.yml dest=/tmp/out-{{ inventory_hostname }}.yml flat=yes
  when: glance_parsed is succeeded

- name: Load configuration variables
  include_vars: /tmp/out-{{ inventory_hostname }}.yml
  when: glance_parsed is succeeded

**********
DECISION===>: Pathname Traversal
**********
=========================:::260:::END!!!=========================
=========================:::261:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/gather/roles/mistral/tasks/main.yml
**********
---
#
# Tasks to get mistral facts
#
- name: Parse Mistral config
  become: true
  command: python /tmp/openstack-config-parser.py mistral /tmp/out.yml
  register: mistral_parsed
  ignore_errors: true

- name: Fetch output
  fetch: src=/tmp/out.yml dest=/tmp/out-{{ inventory_hostname }}.yml flat=yes
  when: mistral_parsed is succeeded

- name: Load configuration variables
  include_vars: /tmp/out-{{ inventory_hostname }}.yml
  when: mistral_parsed is succeeded

**********
DECISION===>: Pathname Traversal
**********
=========================:::261:::END!!!=========================
=========================:::262:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/shaker/tasks/main.yml
**********
---
#
# Browbeat's Shaker Install
#

- name: Create shaker virtualenv
  command: virtualenv {{ shaker_venv }} creates={{ shaker_venv }}

- name: Setup shaker-venv CA certificate path
  lineinfile:
    dest: "{{ shaker_venv }}/bin/activate"
    line: 'export REQUESTS_CA_BUNDLE={{ overcloud_ca_path }}'
  when: overcloud_ca_path is defined

- name: Install shaker
  pip:
    name: pyshaker
    version: "{{ shaker_version }}"
    virtualenv: "{{ shaker_venv }}"

**********
DECISION===>: PASS
**********
=========================:::262:::END!!!=========================
=========================:::263:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/rsyslog-install/tasks/main.yml
**********
---
# Installs rsyslog packages, used with other rsyslog roles

- name: Install rsyslog and rsyslog-elasticsearch
  package:
    name: "{{item}}"
    state: present
  become: true
  with_items:
    - rsyslog
    - rsyslog-elasticsearch
    - rsyslog-mmjsonparse
  register: install_rsyslog
  ignore_errors: true

# ^ this will work on rhel/centos 7.4 or later, earlier than that
# we have rsyslog 7.x and must use a repo to get 8.x

# We can't just add the repo and do an upgrade do to irresolvable
# deps involving some rsyslog components have other package names
- name: Remove 7.x rsyslog packages
  package:
    name: "{{item}}"
    state: absent
  become: true
  with_items:
    - rsyslog
    - rsyslog-elasticsearch
    - rsyslog-mmjsonparse
    - rsyslog-mmutf8fix
  when: install_rsyslog|failed

- name: Add repository
  yum_repository:
    name: CentOS-7-Base
    description: Core CentOS7 Packages
    baseurl: http://mirror.centos.org/centos/7/os/$basearch/
  become: true
  when: install_rsyslog|failed

- name: Add key
  rpm_key:
    state: present
    key: https://www.centos.org/keys/RPM-GPG-KEY-CentOS-7
  become: true
  when: install_rsyslog|failed

- name: Install rsyslog 8 from external repo
  package:
    name: "{{item}}"
    state: present
    disablerepo: "*"
    enablerepo: "CentOS-7-Base"
  become: true
  with_items:
    - rsyslog
    - rsyslog-elasticsearch
    - rsyslog-mmjsonparse
  when: install_rsyslog|failed

**********
DECISION===>: PASS
**********
=========================:::263:::END!!!=========================
=========================:::264:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/fluentd/tasks/main.yml
**********
---
#
# Install/run fluentd for browbeat
#

- name: Copy fluentd yum repo file
  copy:
    src=fluentd.repo
    dest=/etc/yum.repos.d/fluentd.repo
    owner=root
    group=root
    mode=0644
  become: true

- name: Import fluentd GPG Key
  rpm_key:
    key=https://packages.treasuredata.com/GPG-KEY-td-agent
    state=present

- name: Install fluentd
  yum: name={{ item }} state=present
  become: true
  with_items:
    - td-agent

- name: Setup fluentd configuration files
  template:
    src=td-agent.conf.j2
    dest=/etc/td-agent/td-agent.conf
    owner=root
    group=root
    mode=0644
  become: true
  register: fluentd_needs_restart

### begin firewall settings here ###
# we need TCP/42185 and TCP/9919 open
# determine firewall status and take action
# 1) use firewall-cmd if firewalld is utilized
# 2) insert iptables rule if iptables is used

# Firewalld
- name: Determine if firewalld is in use
  shell: systemctl is-enabled firewalld.service | egrep -qv 'masked|disabled'
  ignore_errors: true
  register: firewalld_in_use
  no_log: true
  tags:
    # Skip ANSIBLE0012 Commands should not change things if nothing needs doing
    # Actually need to determine if firewalld is in use.
    - skip_ansible_lint

- name: Determine if firewalld is active
  shell: systemctl is-active firewalld.service | grep -vq inactive
  ignore_errors: true
  register: firewalld_is_active
  no_log: true
  tags:
    # Skip ANSIBLE0012 Commands should not change things if nothing needs doing
    # Need to know if firewalld is active.
    - skip_ansible_lint

- name: Determine if TCP/{{fluentd_syslog_port}} is already active
  shell: firewall-cmd --list-ports | egrep -q "^{{fluentd_syslog_port}}/tcp"
  ignore_errors: true
  register: firewalld_fluentd_syslog_port_exists
  no_log: true
  tags:
    # Skip ANSIBLE0012 Commands should not change things if nothing needs doing
    # Need to determine is port already in use.
    - skip_ansible_lint

# add firewall rule via firewall-cmd
- name: Add firewall rule for TCP/{{fluentd_syslog_port}} (firewalld)
  command: "{{ item }}"
  with_items:
    - firewall-cmd --zone=public --add-port={{fluentd_syslog_port}}/tcp --permanent
    - firewall-cmd --reload
  ignore_errors: true
  become: true
  when: firewalld_in_use.rc == 0 and firewalld_is_active.rc == 0 and firewalld_fluentd_syslog_port_exists.rc != 0

# iptables-services
- name: check firewall rules for TCP/{{fluentd_syslog_port}} (iptables-services)
  shell: grep "dport {{fluentd_syslog_port}} \-j ACCEPT" /etc/sysconfig/iptables | wc -l
  ignore_errors: true
  register: iptables_fluentd_syslog_port_exists
  failed_when: iptables_fluentd_syslog_port_exists == 127
  no_log: true
  tags:
    # Skip ANSIBLE0012 Commands should not change things if nothing needs doing
    # Need to check firewall rules.
    - skip_ansible_lint

- name: Add firewall rule for TCP/{{fluentd_syslog_port}} (iptables-services)
  lineinfile:
    dest: /etc/sysconfig/iptables
    line: '-A INPUT -p tcp -m tcp --dport {{fluentd_syslog_port}} -j ACCEPT'
    regexp: '^INPUT -i lo -j ACCEPT'
    insertbefore: '-A INPUT -i lo -j ACCEPT'
    backup: yes
  when: firewalld_in_use.rc != 0 and firewalld_is_active.rc != 0 and iptables_fluentd_syslog_port_exists.stdout|int == 0
  register: iptables_needs_restart

- name: Restart iptables-services for TCP/{{fluentd_syslog_port}} (iptables-services)
  shell: systemctl restart iptables.service
  ignore_errors: true
  when: iptables_needs_restart != 0 and firewalld_in_use.rc != 0 and firewalld_is_active.rc != 0
  tags:
    # Skip ANSIBLE0013 Use shell only when shell functionality is required
    # No systemctl module available in current stable release (Ansible 2.1)
    - skip_ansible_lint

- name: Determine if TCP/{{fluentd_http_port}} is already active
  shell: firewall-cmd --list-ports | egrep -q "^{{fluentd_http_port}}/tcp"
  ignore_errors: true
  register: firewalld_fluentd_http_port_exists
  no_log: true
  tags:
    # Skip ANSIBLE0012 Commands should not change things if nothing needs doing
    # Need to check if port is already active
    - skip_ansible_lint

# add firewall rule via firewall-cmd
- name: Add firewall rule for TCP/{{fluentd_http_port}} (firewalld)
  command: "{{ item }}"
  with_items:
    - firewall-cmd --zone=public --add-port={{fluentd_http_port}}/tcp --permanent
    - firewall-cmd --reload
  ignore_errors: true
  become: true
  when: firewalld_in_use.rc == 0 and firewalld_is_active.rc == 0 and firewalld_fluentd_http_port_exists.rc != 0

# iptables-services
- name: check firewall rules for TCP/{{fluentd_http_port}} (iptables-services)
  shell: grep "dport {{fluentd_http_port}} \-j ACCEPT" /etc/sysconfig/iptables | wc -l
  ignore_errors: true
  register: iptables_fluentd_http_port_exists
  failed_when: iptables_fluentd_http_port_exists == 127
  no_log: true
  tags:
    # Skip ANSIBLE0012 Commands should not change things if nothing needs doing
    # Need to check if port is already active
    - skip_ansible_lint

- name: Add firewall rule for TCP/{{fluentd_http_port}} (iptables-services)
  lineinfile:
    dest: /etc/sysconfig/iptables
    line: '-A INPUT -p tcp -m tcp --dport {{fluentd_http_port}} -j ACCEPT'
    regexp: '^INPUT -i lo -j ACCEPT'
    insertbefore: '-A INPUT -i lo -j ACCEPT'
    backup: yes
  when: firewalld_in_use.rc != 0 and firewalld_is_active.rc != 0 and iptables_fluentd_http_port_exists.stdout|int == 0
  register: iptables_needs_restart

- name: Restart iptables-services for TCP/{{fluentd_http_port}} (iptables-services)
  shell: systemctl restart iptables.service
  ignore_errors: true
  when: iptables_needs_restart != 0 and firewalld_in_use.rc != 0 and firewalld_is_active.rc != 0
  tags:
    # Skip ANSIBLE0013 Use shell only when shell functionality is required
    # No systemctl module available in current stable release (Ansible 2.1)
    - skip_ansible_lint

### end firewall settings ###

- name: Install fluentd elasticsearch plugin
  gem:
    name=fluent-plugin-elasticsearch
    state=present
    include_dependencies=yes
    user_install=no
    executable=/usr/sbin/td-agent-gem
  become: true
  ignore_errors: false

- name: Install fluentd beats plugin
  gem:
    name=fluent-plugin-beats
    state=present
    include_dependencies=yes
    user_install=no
    executable=/usr/sbin/td-agent-gem
  become: true
  ignore_errors: false

- name: Load filebeat JSON index template
  uri:
    url: http://localhost:9200/_template/filebeat?pretty
    method: POST
    body: "{{ lookup('file', 'filebeat-index-template.json') }}"
    body_format: json
  ignore_errors: true
  become: true

- name: Start fluentd service
  systemd:
    name: td-agent.service
    state: started
  ignore_errors: true
  when: fluentd_needs_restart != 0

- name: Setup fluentd service
  service: name=td-agent state=started enabled=true
  become: true

**********
DECISION===>: PASS
**********
=========================:::264:::END!!!=========================
=========================:::265:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/epel/tasks/main.yml
**********
---
#
# Tasks install EPEL packages
#

- name: Remove old EPEL
  package:
    name: epel-release
    state: absent
  become: true

# The fedoraproject CDN has problems sometimes, this will keep trying
#  for up to 10 minutes before failing.
- name: Import EPEL GPG Key
  rpm_key:
    state: present
    key: "{{ epel7_rpmkey }}"
  become: true
  register: import_result
  until: import_result is success
  retries: 10
  delay: 10

# Same as above but with the Centos CDN
- name: Check for EPEL repo
  package:
    name: "{{ epel7_rpm }}"
    state: present
  become: true
  register: install_result
  until: install_result is success
  retries: 10
  delay: 10
  notify: remove_epel

**********
DECISION===>: PASS
**********
=========================:::265:::END!!!=========================
=========================:::266:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/epel/defaults/main.yml
**********
# epel7 rpm for collectd packages
epel7_rpm: https://download.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm
epel7_rpmkey: https://download.fedoraproject.org/pub/epel/RPM-GPG-KEY-EPEL-7

**********
DECISION===>: PASS
**********
=========================:::266:::END!!!=========================
=========================:::267:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/epel/handlers/main.yml
**********
---
#
# Handler to clean up EPEL whenever it is used
#
- name: remove_epel
  package:
    name: epel-release
    state: absent
  ignore_errors: true
  become: true

**********
DECISION===>: PASS
**********
=========================:::267:::END!!!=========================
=========================:::268:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/browbeat-results/tasks/main.yml
**********
---
#
# Browbeat Results via httpd
#

- name: Install httpd
  package:
    name: httpd
    state: present
  become: true

- name: Remove welcome.conf if it exists
  file:
    path: /etc/httpd/conf.d/welcome.conf
    state: absent
  become: true
  notify:
    - restart httpd

- name: Setup browbeat.conf in /etc/httpd/conf.d
  template:
    src: 00-browbeat.conf.j2
    dest: "/etc/httpd/conf.d/00-browbeat-{{browbeat_user}}.conf"
    owner: root
    group: root
    mode: 0644
  become: true
  notify:
    - restart httpd

- name: Set seboolean(httpd_read_user_content)
  seboolean:
    name: httpd_read_user_content
    state: yes
    persistent: yes
  become: true
  when: "ansible_selinux['status'] == 'enabled'"

- name: Allow httpd to serve content in "{{ home_dir }}"
  file:
    path: "{{ home_dir }}"
    state: directory
    mode: 0755

# (akrzos) Port 9000 is already in use by zaqar-server with Newton and thus the fact that likely the
# user will choose a port that is not enabled by selinux to allow httpd to listen, we need to modify
# the ports enabled by selinux for httpd.  If the port is already defined you will run into this
# issue if you use the "seport" ansible module:
# https://github.com/ansible/ansible-modules-extras/pull/2694
# This is not in upstream Ansible releases as of 2.1.1.0
- name: Allow httpd to listen to port ({{browbeat_results_port}})
  command: "/usr/sbin/semanage port -m -t http_port_t -p tcp {{browbeat_results_port}}"
  become: true
  register: seport_modified
  when: "ansible_selinux['status'] == 'enabled'"
  ignore_errors: true

# If port can not be modified, it likely has to be added (Ex. Port 9002)
- name: Allow httpd to listen to port ({{browbeat_results_port}}) via add
  command: "/usr/sbin/semanage port -a -t http_port_t -p tcp {{browbeat_results_port}}"
  become: true
  when: "(ansible_selinux['status'] == 'enabled') and (seport_modified.rc != 0)"

- name: Start httpd
  service:
    name: httpd
    state: started
    enabled: true
  become: true

**********
DECISION===>: PASS
**********
=========================:::268:::END!!!=========================
=========================:::269:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/browbeat-results/handlers/main.yml
**********
---
#
# Browbeat Results handlers
#

- name: restart httpd
  service:
    name: httpd
    state: restarted
  become: true

**********
DECISION===>: PASS
**********
=========================:::269:::END!!!=========================
=========================:::270:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/kibana/tasks/main.yml
**********
---
#
# Install/run kibana for browbeat
#

- name: Copy kibana yum repo file
  copy:
    src=kibana.repo
    dest=/etc/yum.repos.d/kibana.repo
    owner=root
    group=root
    mode=0644
  become: true

# We need to insert data to create an initial index, query if it exists
- name: Check elasticsearch index for content
  uri:
    url=http://localhost:9200/_cat/indices
    method=GET
    return_content=yes
  register: elasticsearch_index

# Populate elasticsearch with local logs if using logstash
- name: Populate elasticsearch index with local logs via logstash
  shell: cat /var/log/messages | /opt/logstash/bin/logstash -f /etc/logstash/conf.d/10-syslog.conf
  when: "'logstash-' not in elasticsearch_index.content"
  ignore_errors: true
  no_log: true

- name: Install local rsyslogd for fluentd
  package:
    name: "{{ item }}"
    state: present
  become: true
  with_items:
    - rsyslog
  when: (logging_backend == 'fluentd')

- name: Setup local rsyslogd for fluentd
  lineinfile: dest=/etc/rsyslog.conf \
          line="*.* @localhost:{{ fluentd_syslog_port }}"
  when: (logging_backend == 'fluentd')
  register: rsyslog_updated

- name: Populate elasticsearch index with local logs via fluentd
  systemd:
    name: rsyslog.service
    state: restarted
  ignore_errors: true
  when: rsyslog_updated != 0

- name: Install kibana rpms
  package:
    name: "{{ item }}"
    state: present
  become: true
  with_items:
    - kibana
    - unzip

- name: Check kibana filebeat dashboards
  stat: path=/tmp/filebeat-dashboards.zip
  ignore_errors: true
  register: kibana_dashboards_present

- name: Copy kibana filebeat dashboards
  copy:
    src=filebeat-dashboards.zip
    dest=/tmp/filebeat-dashboards.zip
    owner=root
    group=root
    mode=0644
  become: true
  ignore_errors: true
  when: kibana_dashboards_present != 0

- name: Install kibana filebeat dashboards
  unarchive: src=/tmp/filebeat-dashboards.zip dest=/tmp/ copy=no
  ignore_errors: true
  when: kibana_dashboards_present != 0

- name: Validate kibana load.sh script is available for use
  stat:
    path: /tmp/beats-dashboards-master/load.sh
  ignore_errors: true
  register: kibana_dashboards_load_sh_present

- name: Configure kibana filebeat dashboards
  shell: sh /tmp/beats-dashboards-master/load.sh -url "http://localhost:9200" -user "{{kibana_user}}:{{kibana_password}}"
  ignore_errors: true
  when: kibana_dashboards_load_sh_present != 0
  tags:
    # Skip ANSIBLE0013 Use shell only when shell functionality is required
    # Shell required here during script execution
    - skip_ansible_lint

- name: Check kibana users
  stat: path=/etc/nginx/htpasswd.users
  ignore_errors: true
  register: kibana_user_pwfile_exists

- name: Create kibana admin user
  command: htpasswd -b -c /etc/nginx/htpasswd.users {{kibana_user}} {{kibana_password}}
  ignore_errors: true
  when: kibana_user_pwfile_exists != 0

- name: Setup kibana service
  service: name=kibana state=started enabled=true
  become: true

- name: Check Filebeat forwarder SSL certificate
  stat: path=/etc/pki/tls/certs/filebeat-forwarder.crt
  ignore_errors: true
  register: filebeat_forwarder_ssl_exists

- name: Create client forwarder SSL certificate
  command: openssl req -subj '/CN={{ ansible_fqdn }}/' -config /etc/pki/tls/openssl_extras.cnf \
    -x509 -days 3650 -batch -nodes -newkey rsa:2048 -keyout /etc/pki/tls/private/filebeat-forwarder.key \
    -out /etc/pki/tls/certs/filebeat-forwarder.crt
  ignore_errors: true
  when: filebeat_forwarder_ssl_exists != 0

- name: Check Filebeat forwarder SSL certificate copy
  stat: path=/usr/share/nginx/html/filebeat-forwarder.crt
  ignore_errors: true
  register: filebeat_forwarder_ssl_client_copy_exists

- name: Copy Filebeat forwarder SSL certificate
  command: cp /etc/pki/tls/certs/filebeat-forwarder.crt /usr/share/nginx/html/filebeat-forwarder.crt
  ignore_errors: true
  when: filebeat_forwarder_ssl_client_copy_exists != 0

- name: Refresh logstash service
  systemd:
    name: logstash.service
    state: restarted
  ignore_errors: true
  when: (logging_backend != 'fluentd')

- name: Refresh fluentd service
  systemd:
    name: td-agent.service
    state: restarted
  when: (logging_backend == 'fluentd')
  become: true

- name: Print SSL post-setup information
  debug: msg="Filebeat SSL Certificate available at http://{{ ansible_fqdn }}:{{ elk_server_ssl_cert_port }}/filebeat-forwarder.crt"
  when: (logging_backend != 'fluentd')

- name: Print post-setup URL
  debug: msg="*** ELK Services available at http://{{ ansible_fqdn }}:{{ nginx_kibana_port }} ***"

- name: Print index creation instructions
  debug: msg="** 1) Navigate to http://{{ ansible_fqdn }}:{{ nginx_kibana_port }} and login with admin/admin, click 'create' on the green index button ***"

- name: Print filebeat openstack client setup instructions
  debug: msg="** 2) Run ansible-playbook -i hosts install/elk-openstack-client.yml --extra-vars 'elk_server={{ ansible_default_ipv4.address }}' to setup OpenStack clients ***"

- name: Print filebeat client setup instructions
  debug: msg="** 2) Run ansible-playbook -i hosts install/elk-client.yml --extra-vars 'elk_server={{ ansible_default_ipv4.address }}' to setup clients ***"

**********
DECISION===>: Use of HTTP without TLS
**********
=========================:::270:::END!!!=========================
=========================:::271:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/es-template/tasks/main.yml
**********
---

- name: Upload templates
  uri:
    url: http://{{ es_ip }}:{{ es_local_port }}/_template/{{ item | basename | regex_replace('\.json','') }}*
    method: PUT
    body: "{{ lookup('file', item) }}"
    body_format: json
  with_fileglob:
  - "{{ browbeat_path }}/elastic/templates/browbeat*"
  ignore_errors: true
  when: elastic5 == false


- name: Upload templates
  uri:
    url: http://{{ es_ip }}:{{ es_local_port }}/_template/{{ item | basename | regex_replace('\.json','') }}*
    method: PUT
    body: "{{ lookup('file', item) }}"
    body_format: json
  with_fileglob:
  - "{{ browbeat_path }}/elastic/v5templates/browbeat*"
  ignore_errors: true
  when: elastic5 == true

**********
DECISION===>: PASS
**********
=========================:::271:::END!!!=========================
=========================:::272:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/logstash/tasks/main.yml
**********
---
#
# Install/run logstash for browbeat
#

- name: Copy logstash yum repo file
  copy:
    src=logstash.repo
    dest=/etc/yum.repos.d/logstash.repo
    owner=root
    group=root
    mode=0644
  become: true

- name: Install logstash rpms
  package:
    name: "{{ item }}"
    state: present
  become: true
  with_items:
    - logstash

- name: Copy logstash input filters
  copy:
    src=01-lumberjack-input.conf
    dest=/etc/logstash/conf.d/01-lumberjack-input.conf
    owner=root
    group=root
    mode=0644
  become: true

- name: Copy logstash output filters
  copy:
    src=30-elasticsearch-output.conf
    dest=/etc/logstash/conf.d/30-lumberjack-output.conf
    owner=root
    group=root
    mode=0644
  become: true

- name: Copy logstash syslog filters
  copy:
    src=10-syslog.conf
    dest=/etc/logstash/conf.d/10-syslog.conf
    owner=root
    group=root
    mode=0644
  become: true

- name: Copy logstash local syslog filter
  copy:
    src=10-syslog-filter.conf
    dest=/etc/logstash/conf.d/10-syslog-filter.conf
    owner=root
    group=root
    mode=0644
  become: true
  register: logstash_needs_restart

- name: Copy filebeat input filter
  template:
    src=02-beats-input.conf.j2
    dest=/etc/logstash/conf.d/02-beats-input.conf
    owner=root
    group=root
    mode=0644
  become: true

- name: Load OpenSSL CA Extended Configuration
  template:
    src=openssl_extras.cnf.j2
    dest=/etc/pki/tls/openssl_extras.cnf
    owner=root
    group=root
    mode=0644
  become: true

- name: Check OpenSSL SANs (SubjectAltName) entry for CA
  shell: grep "{{ ansible_default_ipv4.address }}" /etc/pki/tls/openssl.cnf | wc -l
  ignore_errors: true
  register: subjectAltName_exists
  tags:
    # Skip ANSIBLE0012 Commands should not change things if nothing needs doing
    # Need to understand if an entry exists
    - skip_ansible_lint

- name: Add OpenSSL SANs (SubjectAltName) entry for CA
  lineinfile:
    dest: /etc/pki/tls/openssl.cnf
    line: 'subjectAltName = "{{ ansible_default_ipv4.address }}"'
    regexp: '^ Extensions for a typical CA'
    insertbefore: '# Extensions for a typical CA'
    backup: yes
  when: subjectAltName_exists.stdout|int == 0

- name: Load filebeat JSON index template
  uri:
    url: http://localhost:9200/_template/filebeat?pretty
    method: POST
    body: "{{ lookup('file', 'filebeat-index-template.json') }}"
    body_format: json
  ignore_errors: true
  become: true

- name: Enable logstash service
  service: name=logstash state=started enabled=true
  become: true

# we need TCP/80 and TCP/8080 open
# determine firewall status and take action
# 1) use firewall-cmd if firewalld is utilized
# 2) insert iptables rule if iptables is used

# Firewalld
- name: Determine if firewalld is in use
  shell: systemctl is-enabled firewalld.service | egrep -qv 'masked|disabled'
  ignore_errors: true
  register: firewalld_in_use
  tags:
    # Skip ANSIBLE0012 Commands should not change things if nothing needs doing
    # Check if firewall is enabled
    - skip_ansible_lint

- name: Determine if firewalld is active
  shell: systemctl is-active firewalld.service | grep -vq inactive
  ignore_errors: true
  register: firewalld_is_active
  tags:
    # Skip ANSIBLE0012 Commands should not change things if nothing needs doing
    # Check if firewall is active
    - skip_ansible_lint

- name: Determine if TCP/{{logstash_syslog_port}} is already active
  shell: firewall-cmd --list-ports | egrep -q "^{{logstash_syslog_port}}/tcp"
  ignore_errors: true
  register: firewalld_logstash_syslog_port_exists
  tags:
    # Skip ANSIBLE0012 Commands should not change things if nothing needs doing
    # Need to validate if port already configured
    - skip_ansible_lint

# add firewall rule via firewall-cmd
- name: Add firewall rule for TCP/{{logstash_syslog_port}} (firewalld)
  command: "{{ item }}"
  with_items:
    - firewall-cmd --zone=public --add-port={{logstash_syslog_port}}/tcp --permanent
    - firewall-cmd --reload
  ignore_errors: true
  become: true
  when: firewalld_in_use.rc == 0 and firewalld_is_active.rc == 0 and firewalld_logstash_syslog_port_exists.rc != 0

# iptables-services
- name: check firewall rules for TCP/{{logstash_syslog_port}} (iptables-services)
  shell: grep "dport {{logstash_syslog_port}} \-j ACCEPT" /etc/sysconfig/iptables | wc -l
  ignore_errors: true
  register: iptables_logstash_syslog_port_exists
  failed_when: iptables_logstash_syslog_port_exists == 127
  tags:
    # Skip ANSIBLE0012 Commands should not change things if nothing needs doing
    # Need to validate if port already configured
    - skip_ansible_lint

- name: Add firewall rule for TCP/{{logstash_syslog_port}} (iptables-services)
  lineinfile:
    dest: /etc/sysconfig/iptables
    line: '-A INPUT -p tcp -m tcp --dport {{logstash_syslog_port}} -j ACCEPT'
    regexp: '^INPUT -i lo -j ACCEPT'
    insertbefore: '-A INPUT -i lo -j ACCEPT'
    backup: yes
  when: firewalld_in_use.rc != 0 and firewalld_is_active.rc != 0 and iptables_logstash_syslog_port_exists.stdout|int == 0
  register: iptables_needs_restart

- name: Restart iptables-services for TCP/{{logstash_syslog_port}} (iptables-services)
  shell: systemctl restart iptables.service
  ignore_errors: true
  when: iptables_needs_restart != 0 and firewalld_in_use.rc != 0 and firewalld_is_active.rc != 0
  tags:
    # Skip ANSIBLE0013 Use shell only when shell functionality is required
    # No systemctl module available in current stable release (Ansible 2.1)
    - skip_ansible_lint

**********
DECISION===>: PASS
**********
=========================:::272:::END!!!=========================
=========================:::273:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/images/tasks/main.yml
**********
---
#
# Obtain/Upload browbeat_guest_images to OpenStack Cloud
#

- name: Fetch image
  get_url:
    url: "{{ browbeat_guest_images[item].url }}"
    dest: "{{ home_dir }}/{{ browbeat_guest_images[item].name }}.{{ browbeat_guest_images[item].type }}"
  with_items: "{{ browbeat_guest_images }}"

- name: Determine if image exists
  shell: . {{ overcloudrc }}; openstack image list | grep '{{ browbeat_guest_images[item].name }}'
  register: image_exists
  ignore_errors: true
  changed_when: false
  with_items: "{{ browbeat_guest_images }}"

- name: Remove image from dictionary of images if image exists
  set_fact:
    browbeat_guest_images: "{{ browbeat_guest_images|dict_remove(item[0]) }}"
  when: item[0] in item[1].stdout and
        item[1] is defined and
        ansible_user != "zuul"
  with_nested:
    - "{{ browbeat_guest_images }}"
    - "{{ image_exists.results }}"

- name: Convert images to raw
  command: qemu-img convert -f {{browbeat_guest_images[item].type}} -O raw {{ home_dir }}/{{ browbeat_guest_images[item].name }}.{{ browbeat_guest_images[item].type }} {{ home_dir }}/{{ browbeat_guest_images[item].name }}.raw
  when: "browbeat_guest_images[item].convert_to_raw == true"
  with_items: "{{ browbeat_guest_images }}"

- name: Upload image into cloud (Newton and Ocata versions)
  shell: . {{ overcloudrc }}; openstack image create --public --disk-format={{ browbeat_guest_images[item].type }} --container-format=bare {{ browbeat_guest_images[item].name }} < {{ home_dir }}/{{ browbeat_guest_images[item].name }}.{{ browbeat_guest_images[item].type }}
  ignore_errors: true
  when: "browbeat_guest_images[item].convert_to_raw == false"
  with_items: "{{ browbeat_guest_images }}"

- name: Upload raw image into cloud (Newton and Ocata versions)
  shell: . {{ overcloudrc }}; openstack image create --public --disk-format=raw --container-format=bare {{ browbeat_guest_images[item].name }} < {{ home_dir }}/{{ browbeat_guest_images[item].name }}.raw
  ignore_errors: true
  when: "browbeat_guest_images[item].convert_to_raw == true"
  with_items: "{{ browbeat_guest_images }}"

**********
DECISION===>: PASS
**********
=========================:::273:::END!!!=========================
=========================:::274:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/filebeat/tasks/main.yml
**********
---
#
# install/run filebeat elk client for browbeat
#

- name: Copy filebeat yum repo file
  copy:
    src=filebeat.repo
    dest=/etc/yum.repos.d/filebeat.repo
    owner=root
    group=root
    mode=0644
  when: (logging_backend != 'fluentd')
  become: true

- name: Import Filebeat GPG Key
  become: true
  rpm_key: key=http://packages.elastic.co/GPG-KEY-elasticsearch
    state=present
  when: (logging_backend != 'fluentd')

- name: Install filebeat rpms
  package:
    name: "{{ item }}"
    state: present
  become: true
  with_items:
    - filebeat
  when: (logging_backend != 'fluentd')

- name: Generate filebeat configuration template
  template:
    src=filebeat.yml.j2
    dest=/etc/filebeat/filebeat.yml
    owner=root
    group=root
    mode=0644
  become: true
  when: (logging_backend != 'fluentd')
  register: filebeat_needs_restart

- name: Check ELK server SSL client certificate
  stat: path=/etc/pki/tls/certs/filebeat-forwarder.crt
  become: true
  ignore_errors: true
  register: elk_client_ssl_cert_exists
  when: (logging_backend != 'fluentd')

- name: Install ELK server SSL client certificate
  get_url:
    url=http://{{ elk_server }}:{{ elk_server_ssl_cert_port }}/filebeat-forwarder.crt
    dest=/etc/pki/tls/certs/filebeat-forwarder.crt
  become: true
  when: ((elk_client_ssl_cert_exists != 0) and (logging_backend != 'fluentd'))

- name: Start filebeat service
  systemd:
    name: filebeat.service
    state: started
  when: ((filebeat_needs_restart != 0) and (logging_backend != 'fluentd'))

- name: Setup filebeat service
  service: name=filebeat state=started enabled=true
  become: true
  when: (logging_backend != 'fluentd')

- name: Install rsyslogd for fluentd
  package:
    name: "{{ item }}"
    state: present
  become: true
  with_items:
    - rsyslog
  when: (logging_backend == 'fluentd')

- name: Setup rsyslogd for fluentd
  become: true
  lineinfile: dest=/etc/rsyslog.conf \
          line="*.* @{{ elk_server }}:{{ fluentd_syslog_port }}"
  when: (logging_backend == 'fluentd')
  register: rsyslog_updated

- name: Setup common OpenStack rsyslog logging
  template:
    src=rsyslog-openstack.conf.j2
    dest=/etc/rsyslog.d/openstack-logs.conf
    owner=root
    group=root
    mode=0644
  become: true
  register: rsyslog_updated
  when: (logging_backend == 'fluentd')

- name: Restarting rsyslog for fluentd
  systemd:
    name: rsyslog.service
    state: restarted
  when: rsyslog_updated != 0

**********
DECISION===>: Uuse of HTTP without TLS
**********
=========================:::274:::END!!!=========================
=========================:::275:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/collectd-generic/vars/main.yml
**********
---
#
# Vars for collectd-generic
#

collectd_packages:
  baremetal:
    - collectd
    - collectd-turbostat
  guest:
    - collectd
  graphite:
    - collectd
    - collectd-turbostat

**********
DECISION===>: PASS
**********
=========================:::275:::END!!!=========================
=========================:::276:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/collectd-generic/tasks/main.yml
**********
---
#
# Install/run Collectd for Browbeat (Generic)
#

- name: Install collectd rpms
  package:
    name: "{{ item }}"
    state: present
  become: true
  with_items: "{{collectd_packages[config_type]}}"

- name: Install package that provides semanage
  package:
    name: policycoreutils-python
    state: present
  become: true

- name: Configure collectd.conf
  template:
    src: "{{config_type}}.collectd.conf.j2"
    dest: /etc/collectd.conf
    owner: root
    group: root
    mode: 0644
  become: true

- name: Check for collectd permissive
  shell: semodule -l | grep -q permissive_collectd_t
  become: true
  register: collectd_permissive
  ignore_errors: true
  changed_when: false

- name: Set permissive for collectd
  command: semanage permissive -a collectd_t
  become: true
  when: collectd_permissive.rc != 0
  ignore_errors: true

- name: Setup collectd service
  service:
    name: collectd
    state: restarted
    enabled: true
  become: true

**********
DECISION===>: PASS
**********
=========================:::276:::END!!!=========================
=========================:::277:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/statsd-install/tasks/main.yml
**********
---
- name: Install StatsD
  package:
    name: statsd
    state: present
  become: True

- name: Create StatsD configuration folder
  file:
    path: /etc/statsd
    state: directory
  become: True

- name: Template configuration
  template:
    src: statsd_config.js.j2
    dest: /etc/statsd/config.js
  become: True

- name: Template StatsD service file
  template:
    src: statsd.service.j2
    dest: /etc/systemd/system/statsd.service.j2
    owner: root
    group: root
    mode: 0644
  become: True

- name: bounce systemd and setup StatsD to run on startup
  systemd:
    name: statsd
    enabled: yes
    state: restarted

**********
DECISION===>: PASS
**********
=========================:::277:::END!!!=========================
=========================:::278:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/grafana-dashboards/vars/main.yml
**********
---
#
# Vars for Dashboard Generation
#

dashboard_groups:
  - undercloud
  - controller
  - networker
  - blockstorage
  - objectstorage
  - cephstorage
  - compute

per_process_metrics:
  - name: "Process/Thread Counts"
    y1units: "short"
    metrics:
      - name: "Processes"
        query: ".ps_count.processes"
      - name: "Threads"
        query: ".ps_count.threads"
    nullPointMode: "null"
  - name: "Process CPU"
    y1units: "percent"
    metrics:
      - name: "System"
        query: ".ps_cputime.syst"
      - name: "User"
        query: ".ps_cputime.user"
    nullPointMode: "null"
  - name: "Process Memory"
    y1units: "bits"
    metrics:
      - name: "RSS"
        query: ".ps_rss"
      - name: "Virtual"
        query: ".ps_vm"
    nullPointMode: "connected"
  - name: "Process Page Faults"
    y1units: "short"
    metrics:
      - name: "Majflt"
        query: ".ps_pagefaults.majflt"
      - name: "Minflt"
        query: ".ps_pagefaults.minflt"
    nullPointMode: "null"
  - name: "Process IOPs(Estimated via SYSCALLS)"
    y1units: "iops"
    metrics:
      - name: "Read"
        query: ".io_ops.read"
      - name: "Write"
        query: ".io_ops.write"
    nullPointMode: "null"
  - name: "Process IO Throughput(Estimated via SYSCALLS)"
    y1units: "bytes"
    metrics:
      - name: "Rx"
        query: ".io_octets.rx"
      - name: "Tx"
        query: ".io_octets.tx"
    nullPointMode: "null"
  - name: "Process Disk IO Throughput(Estimated via SYSCALLS)"
    y1units: "bytes"
    metrics:
      - name: "Read"
        query: ".disk_octets.read"
      - name: "Write"
        query: ".disk_octets.write"
    nullPointMode: "null"

per_process_panels:

  #
  # This dashboard should only contain OpenStack Undercloud Node processes
  #
  OpenStack-Undercloud:
    - name: "Ansible"
      processes:
        - ansible-playbook
    - name: "Aodh"
      processes:
        - aodh-evaluator
        - aodh-listener
        - aodh-notifier
        - aodh_wsgi
    - name: "Ceilometer"
      processes:
        - ceilometer-agent-notification
        - ceilometer-api
        - ceilometer-collector
        - ceilometer-polling
        - ceilometer_wsgi
    - name: "Docker"
      processes:
        - docker-registry
        - dockerd-current
        - docker-containerd-current
    - name: "Everything Else"
      processes:
        - httpd
        - iscsid
        - memcached
        - mongod
        - mysqld
        - rabbitmq
    - name: "Glance"
      processes:
        - glance-api
        - glance-registry
    - name: "Gnocchi"
      processes:
        - gnocchi-metricd-master
        - gnocchi-metricd-scheduler
        - gnocchi-metricd-processing
        - gnocchi-metricd-reporting
        - gnocchi-metricd-janitor
        - gnocchi-statsd
        - gnocchi_wsgi
    - name: "Heat"
      processes:
        - heat-api
        - heat-api-cfn
        - heat-engine
        - heat_api_wsgi
        - heat_api_cfn_ws
    - name: "Ironic"
      processes:
        - ironic-api
        - ironic-conductor
        - ironic-inspector
        - dnsmasq-ironic
        - dnsmasq-ironicinspector
        - ironic_wsgi
    - name: "Keystone"
      processes:
        - keystone-admin
        - keystone-main
        - keystone-token-flush
    - name: "Mistral"
      processes:
        - mistral-server-api
        - mistral-server-engine
        - mistral-server-executor
    - name: "Neutron"
      processes:
        - neutron-dhcp-agent
        - neutron-l3-agent
        - neutron-openvswitch-agent
        - neutron-rootwrap-daemon
        - neutron-server
    - name: "Nova"
      processes:
        - nova-api
        - nova_api_wsgi
        - nova-cert
        - nova-compute
        - nova-conductor
        - nova-scheduler
        - placement_wsgi
    - name: "Open vSwitch"
      processes:
        - ovs-vswitchd
        - ovsdb-client
        - ovsdb-server
    - name: "Panko"
      processes:
        - panko_wsgi
    - name: "Swift"
      processes:
        - swift-account-auditor
        - swift-account-reaper
        - swift-account-replicator
        - swift-account-server
        - swift-container-auditor
        - swift-container-replicator
        - swift-container-server
        - swift-container-sync
        - swift-container-updater
        - swift-object-auditor
        - swift-object-expirer
        - swift-object-reconstructor
        - swift-object-replicator
        - swift-object-server
        - swift-object-updater
        - swift-proxy-server
    - name: "Zaqar"
      processes:
        - zaqar-server
        - zaqar_wsgi
    - name: "Collectd"
      processes:
        - collectd

  #
  # This dashboard should only contain OpenStack Controller Node processes
  #
  OpenStack-Controller:
    - name: "Aodh"
      processes:
        - aodh-evaluator
        - aodh-listener
        - aodh-notifier
        - aodh_wsgi
    - name: "Barbican"
      processes:
        - barbican_wsgi
        - barbican-keystone-listener
        - barbican-worker
    - name: "Ceilometer"
      processes:
        - ceilometer-agent-notification
        - ceilometer-collector
        - ceilometer-polling
        - ceilometer_wsgi
    - name: "Ceph"
      processes:
        - ceph-mon
    - name: "Cinder"
      processes:
        - cinder-api
        - cinder-scheduler
        - cinder-volume
        - cinder_wsgi
    - name: "Corosync/Pacemaker"
      processes:
        - attrd
        - cib
        - corosync
        - crmd
        - lrmd
        - pacemakerd
        - pcsd
        - pengine
        - stonithd
    - name: "Docker"
      processes:
        - dockerd-current
    - name: "Everything Else"
      processes:
        - dnsmasq
        - haproxy
        - httpd
        - keepalived
        - memcached
        - mongod
        - mysqld
        - rabbitmq
        - redis-server
        - karaf
    - name: "Glance"
      processes:
        - glance-api
        - glance-registry
    - name: "Gnocchi"
      processes:
        - gnocchi-metricd-master
        - gnocchi-metricd-scheduler
        - gnocchi-metricd-processing
        - gnocchi-metricd-reporting
        - gnocchi-metricd-janitor
        - gnocchi-statsd
        - gnocchi_wsgi
        # Old "proctitle" of metricd (osp_version =< Newton)
        - gnocchi-metricd
    - name: "Heat"
      processes:
        - heat-api
        - heat-api-cfn
        - heat-api-cloudwatch
        - heat-engine
        - heat_api_cfn
        - heat_api_cloudwatch
        - heat_api_wsgi
    - name: "Horizon"
      processes:
        - horizon
    - name: "Keystone"
      processes:
        - keystone-admin
        - keystone-main
        - keystone-token-flush
    - name: "Neutron"
      processes:
        - neutron-dhcp-agent
        - neutron-l3-agent
        - neutron-metadata-agent
        - neutron-ns-metadata-proxy
        - neutron-openvswitch-agent
        - neutron-rootwrap-daemon
        - neutron-server
    - name: "Nova"
      processes:
        - nova-api
        - nova-api-metadata
        - nova_api_wsgi
        - nova-conductor
        - nova-consoleauth
        - nova-novncproxy
        - nova-scheduler
        - placement_wsgi
    - name: "Octavia"
      processes:
        - octavia-worker
        - octavia-housekeeping
        - octavia-health-manager
        - octavia-api
    - name: "Open vSwitch"
      processes:
        - ovs-vswitchd
        - ovsdb-client
        - ovsdb-server
        - ovn-northd
        - ovn-controller
        - ovn-controller-vtep
    - name: "Panko"
      processes:
        - panko_wsgi
    - name: "Swift"
      processes:
        - swift-account-auditor
        - swift-account-reaper
        - swift-account-replicator
        - swift-account-server
        - swift-container-auditor
        - swift-container-replicator
        - swift-container-server
        - swift-container-updater
        - swift-object-auditor
        - swift-object-expirer
        - swift-object-replicator
        - swift-object-server
        - swift-object-updater
        - swift-proxy-server
    - name: "Collectd"
      processes:
        - collectd

  #
  # This dashboard should only contain OpenStack BlockStorage Node processes
  #
  OpenStack-BlockStorage:
    - name: "Cinder"
      processes:
        - cinder-volume
    - name: "Open vSwitch"
      processes:
        - ovs-vswitchd
        - ovsdb-server
    - name: "Collectd"
      processes:
        - collectd

  #
  # This dashboard should only contain OpenStack ObjectStorage Node processes
  #
  OpenStack-ObjectStorage:
    - name: "Open vSwitch"
      processes:
        - ovs-vswitchd
        - ovsdb-server
    - name: "Swift"
      processes:
        - swift-account-auditor
        - swift-account-reaper
        - swift-account-replicator
        - swift-account-server
        - swift-container-auditor
        - swift-container-replicator
        - swift-container-server
        - swift-container-updater
        - swift-object-auditor
        - swift-object-expirer
        - swift-object-replicator
        - swift-object-server
        - swift-object-updater
        - rsync
    - name: "Collectd"
      processes:
        - collectd

  #
  # This dashboard should only contain OpenStack CephStorage Node processes
  #
  OpenStack-CephStorage:
    - name: "Ceph"
      processes:
        - ceph-osd
    - name: "Open vSwitch"
      processes:
        - ovs-vswitchd
        - ovsdb-server
    - name: "Collectd"
      processes:
        - collectd

  #
  # This dashboard should only contain OpenStack Compute Node processes
  #
  OpenStack-Compute:
    - name: "Ceilometer"
      processes:
        - ceilometer-polling
    - name: "Neutron"
      processes:
        - neutron-l3-agent          # DVR enabled case, OSP 10
        - neutron-ns-metadata-proxy # DVR enabled case, OSP 10
        - neutron-metadata-agent    # DVR enabled case, OSP 10
        - neutron-openvswitch-agent
    - name: "Nova"
      processes:
        - nova-compute
        - privsep-helper
    - name: "Open vSwitch"
      processes:
        - ovs-vswitchd
        - ovsdb-client
        - ovsdb-server
        - ovn-controller
        - ovn-controller-vtep
    - name: "QEMU-KVM / Libvirt"
      processes:
        - qemu-kvm
        - libvirtd
        - virtlockd
        - virtlogd
    - name: "Collectd"
      processes:
        - collectd

  #
  # This dashboard "OpenStack" aims to be comprehensive with all processes across:
  # Undercloud, Controller, BlockStorage, ObjectStorage, CephStorage, Compute Nodes
  #
  OpenStack:
    - name: "Ansible"
      processes:
        - ansible-playbook
    - name: "Aodh"
      processes:
        - aodh-evaluator
        - aodh-listener
        - aodh-notifier
        - aodh_wsgi
    - name: "Barbican"
      processes:
        - barbican_wsgi
        - barbican-keystone-listener
        - barbican-worker
    - name: "Ceilometer"
      processes:
        - ceilometer-agent-notification
        - ceilometer-api
        - ceilometer-collector
        - ceilometer-polling
        - ceilometer_wsgi
    - name: "Ceph"
      processes:
        - ceph-mon
        - ceph-osd
    - name: "Cinder"
      processes:
        - cinder-api
        - cinder-scheduler
        - cinder-volume
        - cinder_wsgi
    - name: "Corosync/Pacemaker"
      processes:
        - attrd
        - cib
        - corosync
        - crmd
        - lrmd
        - pacemakerd
        - pcsd
        - pengine
        - stonithd
    - name: "Docker"
      processes:
        - docker-registry
        - dockerd-current
        - docker-containerd-current
    - name: "Everything Else"
      processes:
        - dnsmasq
        - haproxy
        - httpd
        - iscsid
        - keepalived
        - memcached
        - mongod
        - mysqld
        - rabbitmq
        - redis-server
        - karaf
    - name: "Glance"
      processes:
        - glance-api
        - glance-registry
    - name: "Gnocchi"
      processes:
        - gnocchi-metricd-master
        - gnocchi-metricd-scheduler
        - gnocchi-metricd-processing
        - gnocchi-metricd-reporting
        - gnocchi-metricd-janitor
        - gnocchi-statsd
        - gnocchi_wsgi
        # Old "proctitle" of metricd (osp_version =< Newton)
        - gnocchi-metricd
    - name: "Heat"
      processes:
        - heat-api
        - heat-api-cfn
        - heat-api-cloudwatch
        - heat-engine
        - heat_api_cfn
        - heat_api_cloudwatch
        - heat_api_wsgi
    - name: "Horizon"
      processes:
        - horizon
    - name: "Ironic"
      processes:
        - ironic-api
        - ironic-conductor
        - ironic-inspector
        - dnsmasq-ironic
        - dnsmasq-ironicinspector
        - ironic_wsgi
    - name: "Keystone"
      processes:
        - keystone-admin
        - keystone-main
        - keystone-token-flush
    - name: "Mistral"
      processes:
        - mistral-server-api
        - mistral-server-engine
        - mistral-server-executor
    - name: "Neutron"
      processes:
        - neutron-dhcp-agent
        - neutron-l3-agent
        - neutron-metadata-agent
        - neutron-ns-metadata-proxy
        - neutron-openvswitch-agent
        - neutron-rootwrap-daemon
        - neutron-server
    - name: "Nova"
      processes:
        - nova-api
        - nova-api-metadata
        - nova_api_wsgi
        - nova-cert
        - nova-compute
        - nova-conductor
        - nova-consoleauth
        - nova-novncproxy
        - nova-scheduler
        - placement_wsgi
        - privsep-helper
    - name: "Open vSwitch"
      processes:
        - ovs-vswitchd
        - ovsdb-client
        - ovsdb-server
        - ovn-northd
        - ovn-controller
        - ovn-controller-vtep
    - name: "Panko"
      processes:
        - panko_wsgi
    - name: "QEMU-KVM / Libvirt"
      processes:
        - qemu-kvm
        - libvirtd
        - virtlockd
        - virtlogd
    - name: "Swift"
      processes:
        - swift-account-auditor
        - swift-account-reaper
        - swift-account-replicator
        - swift-account-server
        - swift-container-auditor
        - swift-container-replicator
        - swift-container-server
        - swift-container-sync
        - swift-container-updater
        - swift-object-auditor
        - swift-object-expirer
        - swift-object-reconstructor
        - swift-object-replicator
        - swift-object-server
        - swift-object-updater
        - swift-proxy-server
        - rsync
    - name: "Zaqar"
      processes:
        - zaqar-server
        - zaqar_wsgi
    - name: "Collectd"
      processes:
        - collectd


  #
  # This dashboard is geared towards "Generic" Baremetal machines
  #
  Baremetal:
    - name: "httpd"
      processes:
        - httpd
    - name: "Collectd"
      processes:
        - collectd

  #
  # This dashboard is geared towards "Generic" VM Guests
  #
  Guest:
    - name: "httpd"
      processes:
        - httpd
    - name: "Collectd"
      processes:
        - collectd

  #
  # This dashboard is geared towards Carbon/Graphite/Grafana machines
  #
  Graphite:
    - name: "Summerized"
      processes:
        - carbon-cache
        - carbon-relay
        - carbon-aggregator
        - grafana-server
        - httpd
    - name: "Carbon"
      processes:
        - carbon-cache
        - carbon-relay
        - carbon-aggregator
    - name: "Grafana"
      processes:
        - grafana-server
    - name: "httpd"
      processes:
        - httpd
    - name: "Collectd"
      processes:
        - collectd

**********
DECISION===>: PASS
**********
=========================:::278:::END!!!=========================
=========================:::279:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/grafana-dashboards/tasks/main.yml
**********
---
#
# Generate & Upload Browbeat OpenStack Grafana Dashboards
#

# check that grafana_apikey is entered prior to playbook run
- name: Check Grafana API key
  fail:
    msg="** Edit grafana_apikey in ../install/group_vars/all.yml before running **"
  when: grafana_apikey is none

- name: Check Cloud Name
  fail:
    msg: "The Cloud name {{dashboard_cloud_name}} is reserved for a service, please use a different one"
  when: item == dashboard_cloud_name
  with_items: "{{forbidden_cloud_names}}"

# Templated Cloud Specific Dashboards
- name: Generate Cloud Specific CPU/Memory/Disk/Network/Log Dashboards from GrafYaml Templates
  template:
    src: "cloud_specific_{{item}}.yaml.j2"
    dest: "{{role_path}}/files/cloud_specific_{{item}}.yaml"
  when: upload_cloud_specific|bool
  with_items: "{{cloud_specific_dashboards}}"

- name: Upload Cloud Specific CPU/Memory/Disk/Network/Log Dashboards via GrafYaml
  shell: |
    . {{browbeat_venv}}/bin/activate
    grafana-dashboard --grafana-url http://{{grafana_host}}:{{grafana_port}} --grafana-apikey {{grafana_apikey}} update {{role_path}}/files/cloud_specific_{{item}}.yaml
  when: upload_cloud_specific|bool
  with_items: "{{cloud_specific_dashboards}}"

- name: Remove leftover yaml file(s) from Cloud Specific CPU/Memory/Disk/Network/Log Dashboards
  file:
    path: "{{role_path}}/files/cloud_specific_{{item}}.yaml"
    state: absent
  when: upload_cloud_specific|bool
  with_items: "{{cloud_specific_dashboards}}"

# Templated General Performance Dashboards
- name: Generate General Performance Dashboards
  template:
    src: "{{role_path}}/templates/{{item.template_name}}_general_system_performance.yaml.j2"
    dest: "{{role_path}}/files/{{item.process_list_name}}_general_system_performance.yaml"
  when: upload_general|bool
  with_items: "{{general_dashboards}}"

- name: Upload General Performance Dashboards to Grafana
  shell: |
    . {{browbeat_venv}}/bin/activate
    grafana-dashboard --grafana-url http://{{grafana_host}}:{{grafana_port}} --grafana-apikey {{grafana_apikey}} update {{role_path}}/files/{{item.process_list_name}}_general_system_performance.yaml
  when: upload_general|bool
  with_items: "{{general_dashboards}}"

- name: Remove leftover yaml file(s) from General Performance Dashboards
  file:
    path: "{{role_path}}/files/{{item.process_list_name}}_general_system_performance.yaml"
    state: absent
  when: upload_general|bool
  with_items: "{{general_dashboards}}"

# Static Dashboards:
- name: Upload Static Dashboards to Grafana via GrafYaml
  shell: |
    . {{browbeat_venv}}/bin/activate
    grafana-dashboard --grafana-url http://{{grafana_host}}:{{grafana_port}} --grafana-apikey {{grafana_apikey}} update {{role_path}}/files/{{item}}.yaml
  when: upload_static|bool
  with_items: "{{static_dashboards}}"

# Templated Dashboards
- name: Generate Templated Dashboards
  template:
    src: "{{item}}.yaml.j2"
    dest: "{{role_path}}/files/{{item}}.yaml"
  when: upload_templated|bool
  with_items: "{{templated_dashboards}}"

- name: Upload Generated Templated Dashboards via GrafYaml
  shell: |
    . {{browbeat_venv}}/bin/activate
    grafana-dashboard --grafana-url http://{{grafana_host}}:{{grafana_port}} --grafana-apikey {{grafana_apikey}} update {{role_path}}/files/{{item}}.yaml
  when: upload_templated|bool
  with_items: "{{templated_dashboards}}"

- name: Remove leftover yaml file(s) from Generated Templated Dashboards
  file:
    path: "{{role_path}}/files/{{item}}.yaml"
    state: absent
  when: upload_templated|bool
  with_items: "{{templated_dashboards}}"

**********
DECISION===>: Use of HTTP without TLS
**********
=========================:::279:::END!!!=========================
=========================:::280:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/grafana-dashboards/files/cloud_keystone_token_count.yaml
**********
---
dashboard:
  title: Cloud Keystone Token Count
  templating:
    - name: Cloud
      query: "*"
      refresh: true
      type: query
    - name: Node
      query: "$Cloud.*"
      refresh: true
      type: query
  time:
    from: now-1h
    to: now
  rows:
    - title: description row
      height: 50px
      panels:
        - title: Browbeat provided Dashboard
          content: "**This dashboard is provided by Browbeat and managed via Grafyaml**"
          type: text
    - title: Token Count
      height: 250px
      showTitle: true
      panels:
        - title: $Node Keystone Token Count
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: true
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          steppedLine: true
          targets:
            - target: alias($Cloud.$Node.dbi-keystone.gauge-token, 'Tokens')

**********
DECISION===>: PASS
**********
=========================:::280:::END!!!=========================
=========================:::281:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/grafana-dashboards/files/cloud_system_performance_comparsion.yaml
**********
---
dashboard:
  title: Cloud System Performance Comparsion
  templating:
    - name: Cloud1
      query: "*"
      refresh: true
      type: query
    - name: Cloud2
      query: "*"
      refresh: true
      type: query
    - name: Node1
      query: "$Cloud1.*"
      refresh: true
      type: query
    - name: Node2
      query: "$Cloud2.*"
      refresh: true
      type: query
    - name: Node1_Disk
      query: "$Cloud1.$Node1.disk-*"
      refresh: true
      type: query
    - name: Node2_Disk
      query: "$Cloud2.$Node2.disk-*"
      refresh: true
      type: query
    - name: Node1_Interface
      query: "$Cloud1.$Node1.interface-*"
      refresh: true
      type: query
    - name: Node2_Interface
      query: "$Cloud2.$Node2.interface-*"
      refresh: true
      type: query
    - name: Node1_Process
      query: "$Cloud1.$Node1.processes-*"
      refresh: true
      type: query
    - name: Node2_Process
      query: "$Cloud2.$Node2.processes-*"
      refresh: true
      type: query

    # - name: Node1_Timeshift
    #   current:
    #     text: "0m"
    #   options:
    #     - 0m
    #     - 1m
    #     - 10m
    #     - 30m
    #     - 1h
    #     - 2h
    #     - 3h
    #     - 4h
    #     - 6h
    #     - 12h
    #     - 1d
    #     - 2d
    #     - 3d
    #     - 4d
    #     - 5d
    #     - 6d
    #     - 7d
    #     - 14d
    #     - 30d
    #   type: custom
    # - name: Node2_Timeshift
    #   current:
    #     text: "0m"
    #   options:
    #     - 0m
    #     - 1m
    #     - 10m
    #     - 30m
    #     - 1h
    #     - 2h
    #     - 3h
    #     - 4h
    #     - 6h
    #     - 12h
    #     - 1d
    #     - 2d
    #     - 3d
    #     - 4d
    #     - 5d
    #     - 6d
    #     - 7d
    #     - 14d
    #     - 30d
    #   type: custom

  time:
    from: now-1h
    to: now
  rows:
    - title: description row
      height: 50px
      panels:
        - title: Browbeat provided Dashboard
          content: "**This dashboard is provided by Browbeat and managed via Grafyaml**"
          type: text
    - title: CPU Comparsion
      collapse: true
      height: 250px
      showTitle: true
      panels:
        - title: CPU Average
          type: graph
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          seriesOverrides:
            - alias: "/Node1/i"
              stack: A
            - alias: "/Node2/i"
              stack: B
          targets:
            - target: alias(averageSeries($Cloud1.$Node1.cpu-*.cpu-system), 'Node1 - System')
            - target: alias(averageSeries($Cloud1.$Node1.cpu-*.cpu-user), 'Node1 - User')
            - target: alias(averageSeries($Cloud1.$Node1.cpu-*.cpu-nice), 'Node1 - Nice')
            - target: alias(averageSeries($Cloud1.$Node1.cpu-*.cpu-steal), 'Node1 - Steal')
            - target: alias(averageSeries($Cloud1.$Node1.cpu-*.cpu-softirq), 'Node1 - SoftIRQ')
            - target: alias(averageSeries($Cloud1.$Node1.cpu-*.cpu-interrupt), 'Node1 - Interrupt')
            - target: alias(averageSeries($Cloud1.$Node1.cpu-*.cpu-wait), 'Node1 - Wait')
            - target: alias(averageSeries($Cloud1.$Node1.cpu-*.cpu-idle), 'Node1 - Idle')
            - target: alias(averageSeries($Cloud2.$Node2.cpu-*.cpu-system), 'Node2 - System')
            - target: alias(averageSeries($Cloud2.$Node2.cpu-*.cpu-user), 'Node2 - User')
            - target: alias(averageSeries($Cloud2.$Node2.cpu-*.cpu-nice), 'Node2 - Nice')
            - target: alias(averageSeries($Cloud2.$Node2.cpu-*.cpu-steal), 'Node2 - Steal')
            - target: alias(averageSeries($Cloud2.$Node2.cpu-*.cpu-softirq), 'Node2 - SoftIRQ')
            - target: alias(averageSeries($Cloud2.$Node2.cpu-*.cpu-interrupt), 'Node2 - Interrupt')
            - target: alias(averageSeries($Cloud2.$Node2.cpu-*.cpu-wait), 'Node2 - Wait')
            - target: alias(averageSeries($Cloud2.$Node2.cpu-*.cpu-idle), 'Node2 - Idle')
            # - target: alias(timeShift(averageSeries($Cloud1.$Node1.cpu-*.cpu-system), '$Node1_Timeshift'), 'Node1 - System')
            # - target: alias(timeShift(averageSeries($Cloud1.$Node1.cpu-*.cpu-user), '$Node1_Timeshift'), 'Node1 - User')
            # - target: alias(timeShift(averageSeries($Cloud1.$Node1.cpu-*.cpu-nice), '$Node1_Timeshift'), 'Node1 - Nice')
            # - target: alias(timeShift(averageSeries($Cloud1.$Node1.cpu-*.cpu-steal), '$Node1_Timeshift'), 'Node1 - Steal')
            # - target: alias(timeShift(averageSeries($Cloud1.$Node1.cpu-*.cpu-softirq), '$Node1_Timeshift'), 'Node1 - SoftIRQ')
            # - target: alias(timeShift(averageSeries($Cloud1.$Node1.cpu-*.cpu-interrupt), '$Node1_Timeshift'), 'Node1 - Interrupt')
            # - target: alias(timeShift(averageSeries($Cloud1.$Node1.cpu-*.cpu-wait), '$Node1_Timeshift'), 'Node1 - Wait')
            # - target: alias(timeShift(averageSeries($Cloud1.$Node1.cpu-*.cpu-idle), '$Node1_Timeshift'), 'Node1 - Idle')
            # - target: alias(timeShift(averageSeries($Cloud2.$Node2.cpu-*.cpu-system), '$Node2_Timeshift'), 'Node2 - System')
            # - target: alias(timeShift(averageSeries($Cloud2.$Node2.cpu-*.cpu-user), '$Node2_Timeshift'), 'Node2 - User')
            # - target: alias(timeShift(averageSeries($Cloud2.$Node2.cpu-*.cpu-nice), '$Node2_Timeshift'), 'Node2 - Nice')
            # - target: alias(timeShift(averageSeries($Cloud2.$Node2.cpu-*.cpu-steal), '$Node2_Timeshift'), 'Node2 - Steal')
            # - target: alias(timeShift(averageSeries($Cloud2.$Node2.cpu-*.cpu-softirq), '$Node2_Timeshift'), 'Node2 - SoftIRQ')
            # - target: alias(timeShift(averageSeries($Cloud2.$Node2.cpu-*.cpu-interrupt), '$Node2_Timeshift'), 'Node2 - Interrupt')
            # - target: alias(timeShift(averageSeries($Cloud2.$Node2.cpu-*.cpu-wait), '$Node2_Timeshift'), 'Node2 - Wait')
            # - target: alias(timeShift(averageSeries($Cloud2.$Node2.cpu-*.cpu-idle), '$Node2_Timeshift'), 'Node2 - Idle')
          yaxes:
            - format: percent
            - format: short
        - title: CPU Sum
          type: graph
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          seriesOverrides:
            - alias: "/Node1/i"
              stack: A
            - alias: "/Node2/i"
              stack: B
          targets:
            - target: alias(sumSeries($Cloud1.$Node1.cpu-*.cpu-system), 'Node1 - System')
            - target: alias(sumSeries($Cloud1.$Node1.cpu-*.cpu-user), 'Node1 - User')
            - target: alias(sumSeries($Cloud1.$Node1.cpu-*.cpu-nice), 'Node1 - Nice')
            - target: alias(sumSeries($Cloud1.$Node1.cpu-*.cpu-steal), 'Node1 - Steal')
            - target: alias(sumSeries($Cloud1.$Node1.cpu-*.cpu-softirq), 'Node1 - SoftIRQ')
            - target: alias(sumSeries($Cloud1.$Node1.cpu-*.cpu-interrupt), 'Node1 - Interrupt')
            - target: alias(sumSeries($Cloud1.$Node1.cpu-*.cpu-wait), 'Node1 - Wait')
            - target: alias(sumSeries($Cloud1.$Node1.cpu-*.cpu-idle), 'Node1 - Idle')
            - target: alias(sumSeries($Cloud2.$Node2.cpu-*.cpu-system), 'Node2 - System')
            - target: alias(sumSeries($Cloud2.$Node2.cpu-*.cpu-user), 'Node2 - User')
            - target: alias(sumSeries($Cloud2.$Node2.cpu-*.cpu-nice), 'Node2 - Nice')
            - target: alias(sumSeries($Cloud2.$Node2.cpu-*.cpu-steal), 'Node2 - Steal')
            - target: alias(sumSeries($Cloud2.$Node2.cpu-*.cpu-softirq), 'Node2 - SoftIRQ')
            - target: alias(sumSeries($Cloud2.$Node2.cpu-*.cpu-interrupt), 'Node2 - Interrupt')
            - target: alias(sumSeries($Cloud2.$Node2.cpu-*.cpu-wait), 'Node2 - Wait')
            - target: alias(sumSeries($Cloud2.$Node2.cpu-*.cpu-idle), 'Node2 - Idle')
            # - target: alias(timeShift(sumSeries($Cloud1.$Node1.cpu-*.cpu-system), '$Node1_Timeshift'), 'Node1 - System')
            # - target: alias(timeShift(sumSeries($Cloud1.$Node1.cpu-*.cpu-user), '$Node1_Timeshift'), 'Node1 - User')
            # - target: alias(timeShift(sumSeries($Cloud1.$Node1.cpu-*.cpu-nice), '$Node1_Timeshift'), 'Node1 - Nice')
            # - target: alias(timeShift(sumSeries($Cloud1.$Node1.cpu-*.cpu-steal), '$Node1_Timeshift'), 'Node1 - Steal')
            # - target: alias(timeShift(sumSeries($Cloud1.$Node1.cpu-*.cpu-softirq), '$Node1_Timeshift'), 'Node1 - SoftIRQ')
            # - target: alias(timeShift(sumSeries($Cloud1.$Node1.cpu-*.cpu-interrupt), '$Node1_Timeshift'), 'Node1 - Interrupt')
            # - target: alias(timeShift(sumSeries($Cloud1.$Node1.cpu-*.cpu-wait), '$Node1_Timeshift'), 'Node1 - Wait')
            # - target: alias(timeShift(sumSeries($Cloud1.$Node1.cpu-*.cpu-idle), '$Node1_Timeshift'), 'Node1 - Idle')
            # - target: alias(timeShift(sumSeries($Cloud2.$Node2.cpu-*.cpu-system), '$Node2_Timeshift'), 'Node2 - System')
            # - target: alias(timeShift(sumSeries($Cloud2.$Node2.cpu-*.cpu-user), '$Node2_Timeshift'), 'Node2 - User')
            # - target: alias(timeShift(sumSeries($Cloud2.$Node2.cpu-*.cpu-nice), '$Node2_Timeshift'), 'Node2 - Nice')
            # - target: alias(timeShift(sumSeries($Cloud2.$Node2.cpu-*.cpu-steal), '$Node2_Timeshift'), 'Node2 - Steal')
            # - target: alias(timeShift(sumSeries($Cloud2.$Node2.cpu-*.cpu-softirq), '$Node2_Timeshift'), 'Node2 - SoftIRQ')
            # - target: alias(timeShift(sumSeries($Cloud2.$Node2.cpu-*.cpu-interrupt), '$Node2_Timeshift'), 'Node2 - Interrupt')
            # - target: alias(timeShift(sumSeries($Cloud2.$Node2.cpu-*.cpu-wait), '$Node2_Timeshift'), 'Node2 - Wait')
            # - target: alias(timeShift(sumSeries($Cloud2.$Node2.cpu-*.cpu-idle), '$Node2_Timeshift'), 'Node2 - Idle')
          yaxes:
            - format: percent
            - format: short
    - title: Memory Comparsion
      collapse: true
      height: 250px
      showTitle: true
      panels:
        - title: Memory in Bytes
          type: graph
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          seriesOverrides:
            - alias: "/Node1/i"
              stack: A
            - alias: "/Node2/i"
              stack: B
          targets:
            - target: alias(averageSeries($Cloud1.$Node1.memory.memory-slab_unrecl), 'Node1 - Slab Unrecl')
            - target: alias(averageSeries($Cloud1.$Node1.memory.memory-used), 'Node1 - Used')
            - target: alias(averageSeries($Cloud1.$Node1.memory.memory-buffered), 'Node1 - Buffered')
            - target: alias(averageSeries($Cloud1.$Node1.memory.memory-slab_recl), 'Node1 - Slab Recl')
            - target: alias(averageSeries($Cloud1.$Node1.memory.memory-cached), 'Node1 - Cached')
            - target: alias(averageSeries($Cloud1.$Node1.memory.memory-free), 'Node1 - Free')
            - target: alias(averageSeries($Cloud2.$Node2.memory.memory-slab_unrecl), 'Node2 - Slab Unrecl')
            - target: alias(averageSeries($Cloud2.$Node2.memory.memory-used), 'Node2 - Used')
            - target: alias(averageSeries($Cloud2.$Node2.memory.memory-buffered), 'Node2 - Buffered')
            - target: alias(averageSeries($Cloud2.$Node2.memory.memory-slab_recl), 'Node2 - Slab Recl')
            - target: alias(averageSeries($Cloud2.$Node2.memory.memory-cached), 'Node2 - Cached')
            - target: alias(averageSeries($Cloud2.$Node2.memory.memory-free), 'Node2 - Free')
            # - target: alias(timeShift(averageSeries($Cloud1.$Node1.memory.memory-slab_unrecl), '$Node1_Timeshift'), 'Node1 - Slab Unrecl')
            # - target: alias(timeShift(averageSeries($Cloud1.$Node1.memory.memory-used), '$Node1_Timeshift'), 'Node1 - Used')
            # - target: alias(timeShift(averageSeries($Cloud1.$Node1.memory.memory-buffered), '$Node1_Timeshift'), 'Node1 - Buffered')
            # - target: alias(timeShift(averageSeries($Cloud1.$Node1.memory.memory-slab_recl), '$Node1_Timeshift'), 'Node1 - Slab Recl')
            # - target: alias(timeShift(averageSeries($Cloud1.$Node1.memory.memory-cached), '$Node1_Timeshift'), 'Node1 - Cached')
            # - target: alias(timeShift(averageSeries($Cloud1.$Node1.memory.memory-free), '$Node1_Timeshift'), 'Node1 - Free')
            # - target: alias(timeShift(averageSeries($Cloud2.$Node2.memory.memory-slab_unrecl), '$Node2_Timeshift'), 'Node2 - Slab Unrecl')
            # - target: alias(timeShift(averageSeries($Cloud2.$Node2.memory.memory-used), '$Node2_Timeshift'), 'Node2 - Used')
            # - target: alias(timeShift(averageSeries($Cloud2.$Node2.memory.memory-buffered), '$Node2_Timeshift'), 'Node2 - Buffered')
            # - target: alias(timeShift(averageSeries($Cloud2.$Node2.memory.memory-slab_recl), '$Node2_Timeshift'), 'Node2 - Slab Recl')
            # - target: alias(timeShift(averageSeries($Cloud2.$Node2.memory.memory-cached), '$Node2_Timeshift'), 'Node2 - Cached')
            # - target: alias(timeShift(averageSeries($Cloud2.$Node2.memory.memory-free), '$Node2_Timeshift'), 'Node2 - Free')
          yaxes:
            - format: bytes
            - format: short
        - title: Memory in Percentage
          type: graph
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          seriesOverrides:
            - alias: "/Node1/i"
              stack: A
            - alias: "/Node2/i"
              stack: B
          targets:
            - hide: true
              target: $Cloud1.$Node1.memory.memory-slab_unrecl
            - hide: true
              target: $Cloud1.$Node1.memory.memory-used
            - hide: true
              target: $Cloud1.$Node1.memory.memory-buffered
            - hide: true
              target: $Cloud1.$Node1.memory.memory-slab_recl
            - hide: true
              target: $Cloud1.$Node1.memory.memory-cached
            - hide: true
              target: $Cloud1.$Node1.memory.memory-free
            - hide: true
              target: sumSeries($Cloud1.$Node1.memory.*)
            # - hide: true
            #   target: timeShift($Cloud1.$Node1.memory.memory-slab_unrecl, '$Node1_Timeshift')
            # - hide: true
            #   target: timeShift($Cloud1.$Node1.memory.memory-used, '$Node1_Timeshift')
            # - hide: true
            #   target: timeShift($Cloud1.$Node1.memory.memory-buffered, '$Node1_Timeshift')
            # - hide: true
            #   target: timeShift($Cloud1.$Node1.memory.memory-slab_recl, '$Node1_Timeshift')
            # - hide: true
            #   target: timeShift($Cloud1.$Node1.memory.memory-cached, '$Node1_Timeshift')
            # - hide: true
            #   target: timeShift($Cloud1.$Node1.memory.memory-free, '$Node1_Timeshift')
            # - hide: true
            #   target: timeShift(sumSeries($Cloud1.$Node1.memory.*), '$Node1_Timeshift')
            - target: 'alias(asPercent(#A, #G), ''Node1 - Slab Unrecl'')'
            - target: 'alias(asPercent(#B, #G), ''Node1 - Used'')'
            - target: 'alias(asPercent(#C, #G), ''Node1 - Buffered'')'
            - target: 'alias(asPercent(#D, #G), ''Node1 - Slab Recl'')'
            - target: 'alias(asPercent(#E, #G), ''Node1 - Cached'')'
            - target: 'alias(asPercent(#F, #G), ''Node1 - Free'')'
            - hide: true
              target: $Cloud2.$Node2.memory.memory-slab_unrecl
            - hide: true
              target: $Cloud2.$Node2.memory.memory-used
            - hide: true
              target: $Cloud2.$Node2.memory.memory-buffered
            - hide: true
              target: $Cloud2.$Node2.memory.memory-slab_recl
            - hide: true
              target: $Cloud2.$Node2.memory.memory-cached
            - hide: true
              target: $Cloud2.$Node2.memory.memory-free
            - hide: true
              target: sumSeries($Cloud2.$Node2.memory.*)
            # - hide: true
            #   target: timeShift($Cloud2.$Node2.memory.memory-slab_unrecl, '$Node2_Timeshift')
            # - hide: true
            #   target: timeShift($Cloud2.$Node2.memory.memory-buffered, '$Node2_Timeshift')
            # - hide: true
            #   target: timeShift($Cloud2.$Node2.memory.memory-slab_recl, '$Node2_Timeshift')
            # - hide: true
            #   target: timeShift($Cloud2.$Node2.memory.memory-cached, '$Node2_Timeshift')
            # - hide: true
            #   target: timeShift($Cloud2.$Node2.memory.memory-free, '$Node2_Timeshift')
            # - hide: true
            #   target: timeShift(sumSeries($Cloud2.$Node2.memory.*), '$Node2_Timeshift')
            - target: 'alias(asPercent(#N, #T), ''Node2 - Slab Unrecl'')'
            - target: 'alias(asPercent(#O, #T), ''Node2 - Used'')'
            - target: 'alias(asPercent(#P, #T), ''Node2 - Buffered'')'
            - target: 'alias(asPercent(#Q, #T), ''Node2 - Slab Recl'')'
            - target: 'alias(asPercent(#R, #T), ''Node2 - Cached'')'
            - target: 'alias(asPercent(#S, #T), ''Node2 - Free'')'
          yaxes:
            - format: percent
            - format: short
    - title: Disk Comparsion
      collapse: true
      height: 250px
      showTitle: true
      panels:
        - title: iops
          type: graph
          legend:
            alignAsTable: true
            avg: true
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          seriesOverrides:
            - alias: Node1 - Write
              transform: negative-Y
            - alias: Node2 - Write
              transform: negative-Y
          targets:
            - target: alias($Cloud1.$Node1.$Node1_Disk.disk_ops.read, 'Node1 - Read')
            - target: alias($Cloud1.$Node1.$Node1_Disk.disk_ops.write, 'Node1 - Write')
            - target: alias($Cloud2.$Node2.$Node2_Disk.disk_ops.read, 'Node2 - Read')
            - target: alias($Cloud2.$Node2.$Node2_Disk.disk_ops.write, 'Node2 - Write')
            # - target: alias(timeShift($Cloud1.$Node1.$Node1_Disk.disk_ops.read, '$Node1_Timeshift'), 'Node1 - Read')
            # - target: alias(timeShift($Cloud1.$Node1.$Node1_Disk.disk_ops.write, '$Node1_Timeshift'), 'Node1 - Write')
            # - target: alias(timeShift($Cloud2.$Node2.$Node2_Disk.disk_ops.read, '$Node2_Timeshift'), 'Node2 - Read')
            # - target: alias(timeShift($Cloud2.$Node2.$Node2_Disk.disk_ops.write, '$Node2_Timeshift'), 'Node2 - Write')
          yaxes:
            - format: iops
            - format: short
        - title: Throughput
          type: graph
          legend:
            alignAsTable: true
            avg: true
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          seriesOverrides:
            - alias: Node1 - Write
              transform: negative-Y
            - alias: Node2 - Write
              transform: negative-Y
          targets:
            - target: alias($Cloud1.$Node1.$Node1_Disk.disk_octets.read, 'Node1 - Read')
            - target: alias($Cloud1.$Node1.$Node1_Disk.disk_octets.write, 'Node1 - Write')
            - target: alias($Cloud2.$Node2.$Node2_Disk.disk_octets.read, 'Node2 - Read')
            - target: alias($Cloud2.$Node2.$Node2_Disk.disk_octets.write, 'Node2 - Write')
            # - target: alias(timeShift($Cloud1.$Node1.$Node1_Disk.disk_octets.read, '$Node1_Timeshift'), 'Node1 - Read')
            # - target: alias(timeShift($Cloud1.$Node1.$Node1_Disk.disk_octets.write, '$Node1_Timeshift'), 'Node1 - Write')
            # - target: alias(timeShift($Cloud2.$Node2.$Node2_Disk.disk_octets.read, '$Node2_Timeshift'), 'Node2 - Read')
            # - target: alias(timeShift($Cloud2.$Node2.$Node2_Disk.disk_octets.write, '$Node2_Timeshift'), 'Node2 - Write')
          yaxes:
            - format: Bps
            - format: short
        - title: '% Time'
          type: graph
          legend:
            alignAsTable: true
            avg: true
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          targets:
            - target: alias(scale($Cloud1.$Node1.$Node1_Disk.disk_io_time.io_time, 0.1), 'Node1 - Time')
            - target: alias(scale($Cloud2.$Node2.$Node2_Disk.disk_io_time.io_time, 0.1), 'Node2 - Time')
            # - target: alias(timeShift(scale($Cloud1.$Node1.$Node1_Disk.disk_io_time.io_time, 0.1), '$Node1_Timeshift'), 'Node1 - Time')
            # - target: alias(timeShift(scale($Cloud2.$Node2.$Node2_Disk.disk_io_time.io_time, 0.1), '$Node2_Timeshift'), 'Node2 - Time')
          yaxes:
            - format: percent
            - format: short
    - title: Network Comparsion
      collapse: true
      height: 250px
      showTitle: true
      panels:
        - title: pps
          type: graph
          legend:
            alignAsTable: true
            avg: true
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          seriesOverrides:
            - alias: Node1 - RX
              transform: negative-Y
            - alias: Node2 - RX
              transform: negative-Y
          targets:
            - target: alias($Cloud1.$Node1.$Node1_Interface.if_packets.tx, 'Node1 - TX')
            - target: alias($Cloud1.$Node1.$Node1_Interface.if_packets.rx, 'Node1 - RX')
            - target: alias($Cloud2.$Node2.$Node2_Interface.if_packets.tx, 'Node2 - TX')
            - target: alias($Cloud2.$Node2.$Node2_Interface.if_packets.rx, 'Node2 - RX')
            # - target: alias(timeShift($Cloud1.$Node1.$Node1_Interface.if_packets.tx, '$Node1_Timeshift'), 'Node1 - TX')
            # - target: alias(timeShift($Cloud1.$Node1.$Node1_Interface.if_packets.rx, '$Node1_Timeshift'), 'Node1 - RX')
            # - target: alias(timeShift($Cloud2.$Node2.$Node2_Interface.if_packets.tx, '$Node2_Timeshift'), 'Node2 - TX')
            # - target: alias(timeShift($Cloud2.$Node2.$Node2_Interface.if_packets.rx, '$Node2_Timeshift'), 'Node2 - RX')
          yaxes:
            - format: pps
            - format: short
        - title: Throughput
          type: graph
          legend:
            alignAsTable: true
            avg: true
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          seriesOverrides:
            - alias: Node1 - RX
              transform: negative-Y
            - alias: Node2 - RX
              transform: negative-Y
          targets:
            - target: alias(scale($Cloud1.$Node1.$Node1_Interface.if_octets.tx, 8), 'Node1 - TX')
            - target: alias(scale($Cloud1.$Node1.$Node1_Interface.if_octets.rx, 8), 'Node1 - RX')
            - target: alias(scale($Cloud2.$Node2.$Node2_Interface.if_octets.tx, 8), 'Node2 - TX')
            - target: alias(scale($Cloud2.$Node2.$Node2_Interface.if_octets.rx, 8), 'Node2 - RX')
            # - target: alias(timeShift(scale($Cloud1.$Node1.$Node1_Interface.if_octets.tx, 8), '$Node1_Timeshift'), 'Node1 - TX')
            # - target: alias(timeShift(scale($Cloud1.$Node1.$Node1_Interface.if_octets.rx, 8), '$Node1_Timeshift'), 'Node1 - RX')
            # - target: alias(timeShift(scale($Cloud2.$Node2.$Node2_Interface.if_octets.tx, 8), '$Node2_Timeshift'), 'Node2 - TX')
            # - target: alias(timeShift(scale($Cloud2.$Node2.$Node2_Interface.if_octets.rx, 8), '$Node2_Timeshift'), 'Node2 - RX')
          yaxes:
            - format: bps
            - format: short
    - title: Node Process Comparsion
      collapse: true
      height: 250px
      showTitle: true
      panels:
        - title: Processes State
          type: graph
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          seriesOverrides:
            - alias: "/Node1/i"
              stack: A
            - alias: "/Node2/i"
              stack: B
          targets:
            - target: alias($Cloud1.$Node1.processes.ps_state-running, 'Node1 - Running')
            - target: alias($Cloud1.$Node1.processes.ps_state-stopped, 'Node1 - Stopped')
            - target: alias($Cloud1.$Node1.processes.ps_state-sleeping, 'Node1 - Sleeping')
            - target: alias($Cloud1.$Node1.processes.ps_state-blocked, 'Node1 - Blocked')
            - target: alias($Cloud1.$Node1.processes.ps_state-paging, 'Node1 - Paging')
            - target: alias($Cloud1.$Node1.processes.ps_state-zombies, 'Node1 - Zombies')
            - target: alias($Cloud2.$Node2.processes.ps_state-running, 'Node2 - Running')
            - target: alias($Cloud2.$Node2.processes.ps_state-stopped, 'Node2 - Stopped')
            - target: alias($Cloud2.$Node2.processes.ps_state-sleeping, 'Node2 - Sleeping')
            - target: alias($Cloud2.$Node2.processes.ps_state-blocked, 'Node2 - Blocked')
            - target: alias($Cloud2.$Node2.processes.ps_state-paging, 'Node2 - Paging')
            - target: alias($Cloud2.$Node2.processes.ps_state-zombies, 'Node2 - Zombies')
            # - target: alias(timeShift($Cloud1.$Node1.processes.ps_state-running, '$Node1_Timeshift'), 'Node1 - Running')
            # - target: alias(timeShift($Cloud1.$Node1.processes.ps_state-stopped, '$Node1_Timeshift'), 'Node1 - Stopped')
            # - target: alias(timeShift($Cloud1.$Node1.processes.ps_state-sleeping, '$Node1_Timeshift'), 'Node1 - Sleeping')
            # - target: alias(timeShift($Cloud1.$Node1.processes.ps_state-blocked, '$Node1_Timeshift'), 'Node1 - Blocked')
            # - target: alias(timeShift($Cloud1.$Node1.processes.ps_state-paging, '$Node1_Timeshift'), 'Node1 - Paging')
            # - target: alias(timeShift($Cloud1.$Node1.processes.ps_state-zombies, '$Node1_Timeshift'), 'Node1 - Zombies')
            # - target: alias(timeShift($Cloud2.$Node2.processes.ps_state-running, '$Node2_Timeshift'), 'Node2 - Running')
            # - target: alias(timeShift($Cloud2.$Node2.processes.ps_state-stopped, '$Node2_Timeshift'), 'Node2 - Stopped')
            # - target: alias(timeShift($Cloud2.$Node2.processes.ps_state-sleeping, '$Node2_Timeshift'), 'Node2 - Sleeping')
            # - target: alias(timeShift($Cloud2.$Node2.processes.ps_state-blocked, '$Node2_Timeshift'), 'Node2 - Blocked')
            # - target: alias(timeShift($Cloud2.$Node2.processes.ps_state-paging, '$Node2_Timeshift'), 'Node2 - Paging')
            # - target: alias(timeShift($Cloud2.$Node2.processes.ps_state-zombies, '$Node2_Timeshift'), 'Node2 - Zombies')
    - title: Per Process Comparsion
      collapse: true
      height: 250px
      showTitle: true
      panels:
        - title: Process Counts
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          targets:
            - target: alias($Cloud1.$Node1.$Node1_Process.ps_count.processes, 'Node1 - $Node1_Process - Processes')
            - target: alias($Cloud1.$Node1.$Node1_Process.ps_count.threads, 'Node1 - $Node1_Process - Threads')
            - target: alias($Cloud2.$Node2.$Node2_Process.ps_count.processes, 'Node2 - $Node2_Process - Processes')
            - target: alias($Cloud2.$Node2.$Node2_Process.ps_count.threads, 'Node2 - $Node2_Process - Threads')
            # - target: alias(timeShift($Cloud1.$Node1.$Node1_Process.ps_count.processes, '$Node1_Timeshift'), 'Node1 - $Node1_Process - Processes')
            # - target: alias(timeShift($Cloud1.$Node1.$Node1_Process.ps_count.threads, '$Node1_Timeshift'), 'Node1 - $Node1_Process - Threads')
            # - target: alias(timeShift($Cloud2.$Node2.$Node2_Process.ps_count.processes, '$Node2_Timeshift'), 'Node2 - $Node2_Process - Processes')
            # - target: alias(timeShift($Cloud2.$Node2.$Node2_Process.ps_count.threads, '$Node2_Timeshift'), 'Node2 - $Node2_Process - Threads')
        - title: Process CPU
          type: graph
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          targets:
            - target: alias(scale($Cloud1.$Node1.$Node1_Process.ps_cputime.syst, 0.0001), 'Node1 - $Node1_Process - System')
            - target: alias(scale($Cloud1.$Node1.$Node1_Process.ps_cputime.user, 0.0001), 'Node1 - $Node1_Process - User')
            - target: alias(scale($Cloud2.$Node2.$Node2_Process.ps_cputime.syst, 0.0001), 'Node2 - $Node2_Process - System')
            - target: alias(scale($Cloud2.$Node2.$Node2_Process.ps_cputime.user, 0.0001), 'Node2 - $Node2_Process - User')
            # - target: alias(timeShift(scale($Cloud1.$Node1.$Node1_Process.ps_cputime.syst, 0.0001), '$Node1_Timeshift'), 'Node1 - $Node1_Process - System')
            # - target: alias(timeShift(scale($Cloud1.$Node1.$Node1_Process.ps_cputime.user, 0.0001), '$Node1_Timeshift'), 'Node1 - $Node1_Process - User')
            # - target: alias(timeShift(scale($Cloud2.$Node2.$Node2_Process.ps_cputime.syst, 0.0001), '$Node2_Timeshift'), 'Node2 - $Node2_Process - System')
            # - target: alias(timeShift(scale($Cloud2.$Node2.$Node2_Process.ps_cputime.user, 0.0001), '$Node2_Timeshift'), 'Node2 - $Node2_Process - User')
          yaxes:
            - format: percent
            - format: short
        - title: Process Memory
          type: graph
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          targets:
            - target: alias($Cloud1.$Node1.$Node1_Process.ps_rss, 'Node1 - $Node1_Process - RSS')
            - target: alias($Cloud1.$Node1.$Node1_Process.ps_vm, 'Node1 - $Node1_Process - Virtual')
            - target: alias($Cloud2.$Node2.$Node2_Process.ps_rss, 'Node2 - $Node2_Process - RSS')
            - target: alias($Cloud2.$Node2.$Node2_Process.ps_vm, 'Node2 - $Node2_Process - Virtual')
            # - target: alias(timeShift($Cloud1.$Node1.$Node1_Process.ps_rss, '$Node1_Timeshift'), 'Node1 - $Node1_Process - RSS')
            # - target: alias(timeShift($Cloud1.$Node1.$Node1_Process.ps_vm, '$Node1_Timeshift'), 'Node1 - $Node1_Process - Virtual')
            # - target: alias(timeShift($Cloud2.$Node2.$Node2_Process.ps_rss, '$Node2_Timeshift'), 'Node2 - $Node2_Process - RSS')
            # - target: alias(timeShift($Cloud2.$Node2.$Node2_Process.ps_vm, '$Node2_Timeshift'), 'Node2 - $Node2_Process - Virtual')
          yaxes:
            - format: bits
            - format: short
        - title: Page Faults
          type: graph
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          targets:
            - target: alias($Cloud1.$Node1.$Node1_Process.ps_pagefaults.majflt, 'Node1 - $Node1_Process - Majflt')
            - target: alias($Cloud1.$Node1.$Node1_Process.ps_pagefaults.minflt, 'Node1 - $Node1_Process - Minflt')
            - target: alias($Cloud2.$Node2.$Node2_Process.ps_pagefaults.majflt, 'Node2 - $Node2_Process - Majflt')
            - target: alias($Cloud2.$Node2.$Node2_Process.ps_pagefaults.minflt, 'Node2 - $Node2_Process - Minflt')
            # - target: alias(timeShift($Cloud1.$Node1.$Node1_Process.ps_pagefaults.majflt, '$Node1_Timeshift'), 'Node1 - $Node1_Process - Majflt')
            # - target: alias(timeShift($Cloud1.$Node1.$Node1_Process.ps_pagefaults.minflt, '$Node1_Timeshift'), 'Node1 - $Node1_Process - Minflt')
            # - target: alias(timeShift($Cloud2.$Node2.$Node2_Process.ps_pagefaults.majflt, '$Node2_Timeshift'), 'Node2 - $Node2_Process - Majflt')
            # - target: alias(timeShift($Cloud2.$Node2.$Node2_Process.ps_pagefaults.minflt, '$Node2_Timeshift'), 'Node2 - $Node2_Process - Minflt')
        - title: iops
          type: graph
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          targets:
            - target: alias($Cloud1.$Node1.$Node1_Process.io_ops.read, 'Node1 - $Node1_Process - Read')
            - target: alias($Cloud1.$Node1.$Node1_Process.io_ops.write, 'Node1 - $Node1_Process - Write')
            - target: alias($Cloud2.$Node2.$Node2_Process.io_ops.read, 'Node2 - $Node2_Process - Read')
            - target: alias($Cloud2.$Node2.$Node2_Process.io_ops.write, 'Node2 - $Node2_Process - Write')
            # - target: alias(timeShift($Cloud1.$Node1.$Node1_Process.io_ops.read, '$Node1_Timeshift'), 'Node1 - $Node1_Process - Read')
            # - target: alias(timeShift($Cloud1.$Node1.$Node1_Process.io_ops.write, '$Node1_Timeshift'), 'Node1 - $Node1_Process - Write')
            # - target: alias(timeShift($Cloud2.$Node2.$Node2_Process.io_ops.read, '$Node2_Timeshift'), 'Node2 - $Node2_Process - Read')
            # - target: alias(timeShift($Cloud2.$Node2.$Node2_Process.io_ops.write, '$Node2_Timeshift'), 'Node2 - $Node2_Process - Write')
          yaxes:
            - format: iops
            - format: short
        - title: IO Throughput
          type: graph
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          targets:
            - target: alias($Cloud1.$Node1.$Node1_Process.io_octets.rx, 'Node1 - $Node1_Process - Rx')
            - target: alias($Cloud1.$Node1.$Node1_Process.io_octets.tx, 'Node1 - $Node1_Process - Tx')
            - target: alias($Cloud2.$Node2.$Node2_Process.io_octets.rx, 'Node2 - $Node2_Process - Rx')
            - target: alias($Cloud2.$Node2.$Node2_Process.io_octets.tx, 'Node2 - $Node2_Process - Tx')
            # - target: alias(timeShift($Cloud1.$Node1.$Node1_Process.io_octets.rx, '$Node1_Timeshift'), 'Node1 - $Node1_Process - Rx')
            # - target: alias(timeShift($Cloud1.$Node1.$Node1_Process.io_octets.tx, '$Node1_Timeshift'), 'Node1 - $Node1_Process - Tx')
            # - target: alias(timeShift($Cloud2.$Node2.$Node2_Process.io_octets.rx, '$Node2_Timeshift'), 'Node2 - $Node2_Process - Rx')
            # - target: alias(timeShift($Cloud2.$Node2.$Node2_Process.io_octets.tx, '$Node2_Timeshift'), 'Node2 - $Node2_Process - Tx')
          yaxes:
            - format: bytes
            - format: short
        - title: Disk IO Throughput
          type: graph
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          targets:
            - target: alias($Cloud1.$Node1.$Node1_Process.disk_octets.read, 'Node1 - $Node1_Process - Disk Read')
            - target: alias($Cloud1.$Node1.$Node1_Process.disk_octets.write, 'Node1 - $Node1_Process - Disk Write')
            - target: alias($Cloud2.$Node2.$Node2_Process.disk_octets.read, 'Node2 - $Node2_Process - Disk Read')
            - target: alias($Cloud2.$Node2.$Node2_Process.disk_octets.write, 'Node2 - $Node2_Process - Disk Write')
            # - target: alias(timeShift($Cloud1.$Node1.$Node1_Process.disk_octets.read, '$Node1_Timeshift'), 'Node1 - $Node1_Process - Disk Read')
            # - target: alias(timeShift($Cloud1.$Node1.$Node1_Process.disk_octets.write, '$Node1_Timeshift'), 'Node1 - $Node1_Process - Disk Write')
            # - target: alias(timeShift($Cloud2.$Node2.$Node2_Process.disk_octets.read, '$Node2_Timeshift'), 'Node2 - $Node2_Process - Disk Read')
            # - target: alias(timeShift($Cloud2.$Node2.$Node2_Process.disk_octets.write, '$Node2_Timeshift'), 'Node2 - $Node2_Process - Disk Write')
          yaxes:
            - format: bytes
            - format: short

**********
DECISION===>: PASS
**********
=========================:::281:::END!!!=========================
=========================:::282:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/grafana-dashboards/files/cloud_instance_count.yaml
**********
---
dashboard:
  title: Cloud Instance Count
  templating:
    - name: Cloud
      query: "*"
      refresh: true
      type: query
  time:
    from: now-1h
    to: now
  rows:
    - title: description row
      height: 50px
      panels:
        - title: Browbeat provided Dashboard
          content: "**This dashboard is provided by Browbeat and managed via Grafyaml**"
          type: text
    - title: Instance Count
      height: 250px
      showTitle: true
      panels:
        - title: Total Instances Hosted on Computes for $Cloud
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: true
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          targets:
            - target: alias(sumSeries(keepLastValue($Cloud.*.processes-qemu-kvm.ps_count.processes, 100)), 'Sum qemu-kvm processes')
        - title: Instances Hosted on Each Compute for $Cloud
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: true
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          stack: true
          targets:
            - target: aliasByNode(keepLastValue($Cloud.*.processes-qemu-kvm.ps_count.processes, 100), 1)

**********
DECISION===>: PASS
**********
=========================:::282:::END!!!=========================
=========================:::283:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/grafana-dashboards/files/openstack_ironic_metrics.yaml
**********
---
dashboard:
  title: OpenStack Ironic Metrics
  templating:
    - name: Cloud
      query: "*"
      refresh: true
      type: query
  time:
    from: now-1h
    to: now
  rows:
    - title: description row
      height: 50px
      panels:
        - title: Browbeat provided Dashboard
          content: "**This dashboard is provided by Browbeat and managed via Grafyaml**"
          type: text
    - title: Row 1
      height: 250px
      panels:
        - title: "Power State Sync: 90th Percentile Mean"
          type: graph
          legend:
            show: true
          nullPointMode: 'connected'
          span: 6
          targets:
            - target: stats.timers.$Cloud.ironic.conductor.manager.do_sync_power_state.mean_90
          yaxes:
            - format: short
              label: Milliseconds
            - format: short
        - title: "Change Node Power State: 90th percentile mean"
          type: graph
          legend:
            show: true
          nullPointMode: 'connected'
          span: 6
          targets:
            - target: stats.timers.$Cloud.ironic.conductor.manager.ConductorManager.change_node_power_state.mean_90
          yaxes:
            - format: short
              label: Milliseconds
            - format: short
    - title: Row 2
      height: 250px
      panels:
        - title: "Set boot device: 90th percentile mean"
          type: graph
          legend:
            show: true
          nullPointMode: 'connected'
          span: 6
          targets:
            - target: stats.timers.$Cloud.ironic.conductor.manager.ConductorManager.set_boot_device.mean_90
          yaxes:
            - format: short
              label: Milliseconds
            - format: short
        - title: "Do Node Deployment: 90th percentile mean"
          type: graph
          legend:
            show: true
          nullPointMode: 'connected'
          span: 6
          targets:
            - target: stats.timers.$Cloud.ironic.conductor.manager.ConductorManager.do_node_deploy.mean_90
          yaxes:
            - format: short
              label: Milliseconds
            - format: short
    - title: Row 3
      height: 250px
      panels:
        - title: "Get Node Details API response time: 90th percentile mean"
          type: graph
          legend:
            show: true
          nullPointMode: 'connected'
          span: 6
          targets:
            - target: stats.timers.$Cloud.ironic.api.controllers.v1.node.NodesController.detail.mean_90
          yaxes:
            - format: short
              label: Milliseconds
            - format: short
        - title: "Get Node List API response time: 90th Percentile mean"
          type: graph
          legend:
            show: true
          nullPointMode: 'connected'
          span: 6
          targets:
            - target: stats.timers.$Cloud.ironic.api.controllers.v1.node.NodesController.get_all.mean_90
          yaxes:
            - format: short
              label: Milliseconds
            - format: short
    - title: Row 4
      height: 250px
      panels:
        - title: "Node Power State API response time: 90th Percentile Mean"
          type: graph
          legend:
            show: true
          nullPointMode: 'connected'
          span: 6
          targets:
            - target: stats.timers.$Cloud.ironic.api.controllers.v1.node.NodeStatesController.power.mean_90
          yaxes:
            - format: short
              label: Milliseconds
            - format: short
        - title: "Ironic Node Provision State API response time: 90th percentile mean"
          type: graph
          legend:
            show: true
          nullPointMode: 'connected'
          span: 6
          targets:
            - target: stats.timers.$Cloud.ironic.api.controllers.v1.node.NodeStatesController.provision.mean_90
          yaxes:
            - format: short
              label: Milliseconds
            - format: short

**********
DECISION===>: PASS
**********
=========================:::283:::END!!!=========================
=========================:::284:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/grafana-dashboards/files/apache_request_latency.yaml
**********
---
dashboard:
  title: Apache Request Latency
  templating:
    - name: Cloud
      query: "*"
      refresh: true
      type: query
    - name: Node
      query: "$Cloud.*"
      refresh: true
      type: query
  time:
    from: now-1h
    to: now
  rows:
    - title: description row
      height: 50px
      panels:
        - title: Browbeat provided Dashboard
          content: "**This dashboard is provided by Browbeat and managed via Grafyaml**"
          type: text
    - title: Gnocchi API Latency
      height: 200px
      showTitle: true
      panels:
        - title: Gnocchi API Patch Latency
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          lines: false
          nullPointMode: 'null'
          pointradius: 1
          points: true
          seriesOverrides:
            - alias: "/.*Count.*/"
              lines: true
              points: false
              yaxis: 2
          targets:
            - target: alias(scale($Cloud.$Node.tail-gnocchi-api.latency-patch-max, 0.000001), 'Patch Max Latency')
            - target: alias(scale($Cloud.$Node.tail-gnocchi-api.latency-patch-99_00, 0.000001), 'Patch 99th Latency')
            - target: alias(scale($Cloud.$Node.tail-gnocchi-api.latency-patch-avg, 0.000001), 'Patch Avg Latency')
            - target: alias(scale($Cloud.$Node.tail-gnocchi-api.latency-patch-min, 0.000001), 'Patch Min Latency')
            - target: alias(sumSeries(scale($Cloud.$Node.tail-gnocchi-api.counter-patch, 10)), 'Patch Count')
          yaxes:
            - format: s
              label: Latency
            - format: short
              label: Count
        - title: Gnocchi API Post Latency
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          lines: false
          nullPointMode: 'null'
          pointradius: 1
          points: true
          seriesOverrides:
            - alias: "/.*Count.*/"
              lines: true
              points: false
              yaxis: 2
          targets:
            - target: alias(scale($Cloud.$Node.tail-gnocchi-api.latency-post-max, 0.000001), 'Post Max Latency')
            - target: alias(scale($Cloud.$Node.tail-gnocchi-api.latency-post-99_00, 0.000001), 'Post 99th Latency')
            - target: alias(scale($Cloud.$Node.tail-gnocchi-api.latency-post-avg, 0.000001), 'Post Avg Latency')
            - target: alias(scale($Cloud.$Node.tail-gnocchi-api.latency-post-min, 0.000001), 'Post Min Latency')
            - target: alias(sumSeries(scale($Cloud.$Node.tail-gnocchi-api.counter-post, 10)), 'Post Count')
          yaxes:
            - format: s
              label: Latency
            - format: short
              label: Count
        - title: Gnocchi API Get Latency
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          lines: false
          nullPointMode: 'null'
          pointradius: 1
          points: true
          seriesOverrides:
            - alias: "/.*Count.*/"
              lines: true
              points: false
              yaxis: 2
          targets:
            - target: alias(scale($Cloud.$Node.tail-gnocchi-api.latency-get-max, 0.000001), 'Get Max Latency')
            - target: alias(scale($Cloud.$Node.tail-gnocchi-api.latency-get-99_00, 0.000001), 'Get 99th Latency')
            - target: alias(scale($Cloud.$Node.tail-gnocchi-api.latency-get-avg, 0.000001), 'Get Avg Latency')
            - target: alias(scale($Cloud.$Node.tail-gnocchi-api.latency-get-min, 0.000001), 'Get Min Latency')
            - target: alias(sumSeries(scale($Cloud.$Node.tail-gnocchi-api.counter-get, 10)), 'Get Count')
          yaxes:
            - format: s
              label: Latency
            - format: short
              label: Count
    - title: Keystone API Request Latency
      height: 200px
      showTitle: true
      panels:
        - title: Keystone Admin API Get Latency
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          lines: false
          nullPointMode: 'null'
          pointradius: 1
          points: true
          seriesOverrides:
            - alias: "/.*Count.*/"
              lines: true
              points: false
              yaxis: 2
          targets:
            - target: alias(scale($Cloud.$Node.tail-keystone-admin-api.latency-get-max, 0.000001), 'Get Max Latency')
            - target: alias(scale($Cloud.$Node.tail-keystone-admin-api.latency-get-99_00, 0.000001), 'Get 99th Latency')
            - target: alias(scale($Cloud.$Node.tail-keystone-admin-api.latency-get-avg, 0.000001), 'Get Avg Latency')
            - target: alias(scale($Cloud.$Node.tail-keystone-admin-api.latency-get-min, 0.000001), 'Get Min Latency')
            - target: alias(scale(sumSeries($Cloud.$Node.tail-keystone-admin-api.counter-get), 10), 'Get Count')
          yaxes:
            - format: s
              label: Latency
            - format: short
              label: Count
        - title: Keystone Admin API Post Latency
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          lines: false
          nullPointMode: 'null'
          pointradius: 1
          points: true
          seriesOverrides:
            - alias: "/.*Count.*/"
              lines: true
              points: false
              yaxis: 2
          targets:
            - target: alias(scale($Cloud.$Node.tail-keystone-admin-api.latency-post-max, 0.000001), 'Post Max Latency')
            - target: alias(scale($Cloud.$Node.tail-keystone-admin-api.latency-post-99_00, 0.000001), 'Post 99th Latency')
            - target: alias(scale($Cloud.$Node.tail-keystone-admin-api.latency-post-avg, 0.000001), 'Post Avg Latency')
            - target: alias(scale($Cloud.$Node.tail-keystone-admin-api.latency-post-min, 0.000001), 'Post Min Latency')
            - target: alias(scale(sumSeries($Cloud.$Node.tail-keystone-admin-api.counter-post), 10), 'Post Count')
          yaxes:
            - format: s
              label: Latency
            - format: short
              label: Count
        - title: Keystone Main API Get Latency
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          lines: false
          nullPointMode: 'null'
          pointradius: 1
          points: true
          seriesOverrides:
            - alias: "/.*Count.*/"
              lines: true
              points: false
              yaxis: 2
          targets:
            - target: alias(scale($Cloud.$Node.tail-keystone-main-api.latency-get-max, 0.000001), 'Get Max Latency')
            - target: alias(scale($Cloud.$Node.tail-keystone-main-api.latency-get-99_00, 0.000001), 'Get 99th Latency')
            - target: alias(scale($Cloud.$Node.tail-keystone-main-api.latency-get-avg, 0.000001), 'Get Avg Latency')
            - target: alias(scale($Cloud.$Node.tail-keystone-main-api.latency-get-min, 0.000001), 'Get Min Latency')
            - target: alias(scale(sumSeries($Cloud.$Node.tail-keystone-main-api.counter-get), 10), 'Get Count')
          yaxes:
            - format: s
              label: Latency
            - format: short
              label: Count
        - title: Keystone Main API Post Latency
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          lines: false
          nullPointMode: 'null'
          pointradius: 1
          points: true
          seriesOverrides:
            - alias: "/.*Count.*/"
              lines: true
              points: false
              yaxis: 2
          targets:
            - target: alias(scale($Cloud.$Node.tail-keystone-main-api.latency-post-max, 0.000001), 'Post Max Latency')
            - target: alias(scale($Cloud.$Node.tail-keystone-main-api.latency-post-99_00, 0.000001), 'Post 99th Latency')
            - target: alias(scale($Cloud.$Node.tail-keystone-main-api.latency-post-avg, 0.000001), 'Post Avg Latency')
            - target: alias(scale($Cloud.$Node.tail-keystone-main-api.latency-post-min, 0.000001), 'Post Min Latency')
            - target: alias(scale(sumSeries($Cloud.$Node.tail-keystone-main-api.counter-post), 10), 'Post Count')
          yaxes:
            - format: s
              label: Latency
            - format: short
              label: Count
    - title: Nova Placement API Request Latency
      height: 200px
      showTitle: true
      panels:
        - title: Nova Placement API Put Latency
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          lines: false
          nullPointMode: 'null'
          pointradius: 1
          points: true
          seriesOverrides:
            - alias: "/.*Count.*/"
              lines: true
              points: false
              yaxis: 2
          targets:
            - target: alias(scale($Cloud.$Node.tail-nova-placement-api.latency-put-max, 0.000001), 'Put Max Latency')
            - target: alias(scale($Cloud.$Node.tail-nova-placement-api.latency-put-99_00, 0.000001), 'Put 99th Latency')
            - target: alias(scale($Cloud.$Node.tail-nova-placement-api.latency-put-avg, 0.000001), 'Put Avg Latency')
            - target: alias(scale($Cloud.$Node.tail-nova-placement-api.latency-put-min, 0.000001), 'Put Min Latency')
            - target: alias(scale(sumSeries($Cloud.$Node.tail-nova-placement-api.counter-put), 10), 'Put Count')
          yaxes:
            - format: s
              label: Latency
            - format: short
              label: Count
        - title: Nova Placement API Get Latency
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          lines: false
          nullPointMode: 'null'
          pointradius: 1
          points: true
          seriesOverrides:
            - alias: "/.*Count.*/"
              lines: true
              points: false
              yaxis: 2
          targets:
            - target: alias(scale($Cloud.$Node.tail-nova-placement-api.latency-get-max, 0.000001), 'Get Max Latency')
            - target: alias(scale($Cloud.$Node.tail-nova-placement-api.latency-get-99_00, 0.000001), 'Get 99th Latency')
            - target: alias(scale($Cloud.$Node.tail-nova-placement-api.latency-get-avg, 0.000001), 'Get Avg Latency')
            - target: alias(scale($Cloud.$Node.tail-nova-placement-api.latency-get-min, 0.000001), 'Get Min Latency')
            - target: alias(scale(sumSeries($Cloud.$Node.tail-nova-placement-api.counter-get), 10), 'Get Count')
          yaxes:
            - format: s
              label: Latency
            - format: short
              label: Count

**********
DECISION===>: PASS
**********
=========================:::284:::END!!!=========================
=========================:::285:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/grafana-dashboards/files/cloud_total_memory_usage.yaml
**********
---
dashboard:
  title: Cloud Total Memory Usage
  templating:
    - name: Cloud
      query: "*"
      refresh: true
      type: query
  time:
    from: now-1h
    to: now
  rows:
    - title: description row
      height: 75px
      panels:
        - title: Browbeat provided Dashboard
          content: "**This dashboard is provided by Browbeat and managed via Grafyaml**"
          type: text
    - title: Undercloud Memory Usage
      collapse: true
      height: 250px
      showTitle: true
      panels:
        - title: Undercloud Memory Usage
          type: graph
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          stack: true
          targets:
            - target: alias($Cloud.undercloud.memory.memory-slab_unrecl, 'Slab Unrecl')
            - target: alias($Cloud.undercloud.memory.memory-used, 'Used')
            - target: alias($Cloud.undercloud.memory.memory-buffered, 'Buffered')
            - target: alias($Cloud.undercloud.memory.memory-slab_recl, 'Slab Recl')
            - target: alias($Cloud.undercloud.memory.memory-cached, 'Cached')
            - target: alias($Cloud.undercloud.memory.memory-free, 'Free')
          yaxes:
            - format: bits
            - format: short
    - title: Controller Total Memory Usage
      collapse: true
      height: 250px
      showTitle: true
      panels:
        - title: Total Controller Memory Usage
          type: graph
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          stack: true
          targets:
            - target: alias(sumSeries($Cloud.overcloud-controller-*.memory.memory-slab_unrecl), 'Slab Unrecl')
            - target: alias(sumSeries($Cloud.overcloud-controller-*.memory.memory-used), 'Used')
            - target: alias(sumSeries($Cloud.overcloud-controller-*.memory.memory-buffered), 'Buffered')
            - target: alias(sumSeries($Cloud.overcloud-controller-*.memory.memory-slab_recl), 'Slab Recl')
            - target: alias(sumSeries($Cloud.overcloud-controller-*.memory.memory-cached), 'Cached')
            - target: alias(sumSeries($Cloud.overcloud-controller-*.memory.memory-free), 'Free')
          yaxes:
            - format: bits
            - format: short
    - title: Networker Total Memory Usage
      collapse: true
      height: 250px
      showTitle: true
      panels:
        - title: Total Networker Memory Usage
          type: graph
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          stack: true
          targets:
            - target: alias(sumSeries($Cloud.overcloud-networker-*.memory.memory-slab_unrecl), 'Slab Unrecl')
            - target: alias(sumSeries($Cloud.overcloud-networker-*.memory.memory-used), 'Used')
            - target: alias(sumSeries($Cloud.overcloud-networker-*.memory.memory-buffered), 'Buffered')
            - target: alias(sumSeries($Cloud.overcloud-networker-*.memory.memory-slab_recl), 'Slab Recl')
            - target: alias(sumSeries($Cloud.overcloud-networker-*.memory.memory-cached), 'Cached')
            - target: alias(sumSeries($Cloud.overcloud-networker-*.memory.memory-free), 'Free')
          yaxes:
            - format: bits
            - format: short
    - title: CephStorage Total Memory Usage
      collapse: true
      height: 250px
      showTitle: true
      panels:
        - title: Total CephStorage Memory Usage
          type: graph
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          stack: true
          targets:
            - target: alias(sumSeries($Cloud.overcloud-cephstorage-*.memory.memory-slab_unrecl), 'Slab Unrecl')
            - target: alias(sumSeries($Cloud.overcloud-cephstorage-*.memory.memory-used), 'Used')
            - target: alias(sumSeries($Cloud.overcloud-cephstorage-*.memory.memory-buffered), 'Buffered')
            - target: alias(sumSeries($Cloud.overcloud-cephstorage-*.memory.memory-slab_recl), 'Slab Recl')
            - target: alias(sumSeries($Cloud.overcloud-cephstorage-*.memory.memory-cached), 'Cached')
            - target: alias(sumSeries($Cloud.overcloud-cephstorage-*.memory.memory-free), 'Free')
          yaxes:
            - format: bits
            - format: short
    - title: ObjectStorage Total Memory Usage
      collapse: true
      height: 250px
      showTitle: true
      panels:
        - title: Total ObjectStorage Memory Usage
          type: graph
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          stack: true
          targets:
            - target: alias(sumSeries($Cloud.overcloud-objectstorage-*.memory.memory-slab_unrecl), 'Slab Unrecl')
            - target: alias(sumSeries($Cloud.overcloud-objectstorage-*.memory.memory-used), 'Used')
            - target: alias(sumSeries($Cloud.overcloud-objectstorage-*.memory.memory-buffered), 'Buffered')
            - target: alias(sumSeries($Cloud.overcloud-objectstorage-*.memory.memory-slab_recl), 'Slab Recl')
            - target: alias(sumSeries($Cloud.overcloud-objectstorage-*.memory.memory-cached), 'Cached')
            - target: alias(sumSeries($Cloud.overcloud-objectstorage-*.memory.memory-free), 'Free')
          yaxes:
            - format: bits
            - format: short
    - title: Compute Total Memory Usage
      collapse: true
      height: 250px
      showTitle: true
      panels:
        - title: Total Compute Memory Usage
          type: graph
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          stack: true
          targets:
            - target: alias(sumSeries($Cloud.overcloud-*compute*.memory.memory-slab_unrecl), 'Slab Unrecl')
            - target: alias(sumSeries($Cloud.overcloud-*compute*.memory.memory-used), 'Used')
            - target: alias(sumSeries($Cloud.overcloud-*compute*.memory.memory-buffered), 'Buffered')
            - target: alias(sumSeries($Cloud.overcloud-*compute*.memory.memory-slab_recl), 'Slab Recl')
            - target: alias(sumSeries($Cloud.overcloud-*compute*.memory.memory-cached), 'Cached')
            - target: alias(sumSeries($Cloud.overcloud-*compute*.memory.memory-free), 'Free')
          yaxes:
            - format: bits
            - format: short

**********
DECISION===>: PASS
**********
=========================:::285:::END!!!=========================
=========================:::286:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/grafana-dashboards/templates/partials/ceph_mon.yaml
**********
    - title: Ceph Mon
      collapse: true
      height: 200px
      showTitle: true
      panels:
        - title: Mon Count/Quorum/Elections
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          span: 6
          targets:
            - target: alias($Cloud.$Node.ceph-mon_*.ceph_bytes-Cluster_numMon, 'Count')
            - target: alias($Cloud.$Node.ceph-mon_*.ceph_bytes-Cluster_numMonQuorum, 'Quorum')
            - target: alias($Cloud.$Node.ceph-mon_*.ceph_rate-Mon_numElections, 'Elections')
            - target: alias($Cloud.$Node.ceph-mon_*.ceph_rate-Mon_electionCall, 'Call')
            - target: alias($Cloud.$Node.ceph-mon_*.ceph_rate-Mon_electionLose, 'Lose')
            - target: alias($Cloud.$Node.ceph-mon_*.ceph_rate-Mon_electionWin, 'Win')
        - title: Mon Sessions
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          span: 6
          targets:
            - target: alias($Cloud.$Node.ceph-mon_*.ceph_bytes-Mon_numSessions, 'Open')
            - target: alias($Cloud.$Node.ceph-mon_*.ceph_rate-Mon_sessionAdd, 'Add')
            - target: alias($Cloud.$Node.ceph-mon_*.ceph_rate-Mon_sessionRm, 'RM')
            - target: alias($Cloud.$Node.ceph-mon_*.ceph_rate-Mon_sessionTrim, 'Trim')
        - title: OSDs
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          span: 6
          targets:
            - target: alias($Cloud.$Node.ceph-mon_*.ceph_bytes-Cluster_numOsd, 'Total OSDs')
            - target: alias($Cloud.$Node.ceph-mon_*.ceph_bytes-Cluster_numOsdUp, 'OSDs Up')
            - target: alias($Cloud.$Node.ceph-mon_*.ceph_bytes-Cluster_numOsdIn, 'OSDs In')
            - target: alias($Cloud.$Node.ceph-mon_*.ceph_bytes-Cluster_osdEpoch, 'Epoch')
        - title: MDS
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          span: 6
          targets:
            - target: alias($Cloud.$Node.ceph-mon_*.ceph_bytes-Cluster_numMdsUp, 'Up')
            - target: alias($Cloud.$Node.ceph-mon_*.ceph_bytes-Cluster_numMdsIn, 'In')
            - target: alias($Cloud.$Node.ceph-mon_*.ceph_bytes-Cluster_numMdsFailed, 'Failed')
            - target: alias($Cloud.$Node.ceph-mon_*.ceph_bytes-Cluster_mdsEpoch, 'Epoch')
        - title: Objects
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          targets:
            - target: alias($Cloud.$Node.ceph-mon_*.ceph_bytes-Cluster_numObject, 'Total Objects')
            - target: alias($Cloud.$Node.ceph-mon_*.ceph_bytes-Cluster_numObjectDegraded, 'Degraded Objects')
            - target: alias($Cloud.$Node.ceph-mon_*.ceph_bytes-Cluster_numObjectMisplaced, 'Misplaced Objects')
            - target: alias($Cloud.$Node.ceph-mon_*.ceph_bytes-Cluster_numObjectUnfound, 'Unfound Objects')
        - title: Placement Groups
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          span: 6
          targets:
            - target: alias($Cloud.$Node.ceph-mon_*.ceph_bytes-Cluster_numPg, 'Total PGs')
            - target: alias($Cloud.$Node.ceph-mon_*.ceph_bytes-Cluster_numPgActive, 'PGs Active')
            - target: alias($Cloud.$Node.ceph-mon_*.ceph_bytes-Cluster_numPgActiveClean, 'PGs Active-Clean')
            - target: alias($Cloud.$Node.ceph-mon_*.ceph_bytes-Cluster_numPgPeering, 'PGs Peering')
        - title: Pools
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          span: 6
          targets:
            - target: alias($Cloud.$Node.ceph-mon_*.ceph_bytes-Cluster_numPool, 'Pools')
        - title: OSD Bytes
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          seriesOverrides:
            - alias: Bytes Available
              stack: A
            - alias: Bytes Used
              stack: A
          span: 6
          targets:
            - target: alias($Cloud.$Node.ceph-mon_*.ceph_bytes-Cluster_osdBytes, 'Total Bytes')
            - target: alias($Cloud.$Node.ceph-mon_*.ceph_bytes-Cluster_osdBytesUsed, 'Bytes Used')
            - target: alias($Cloud.$Node.ceph-mon_*.ceph_bytes-Cluster_osdBytesAvail, 'Bytes Available')
          yaxes:
            - format: bytes
            - format: short
        - title: Size of All Objects
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          span: 6
          targets:
            - target: alias($Cloud.$Node.ceph-mon_*.ceph_bytes-Cluster_numBytes, 'Size of all objects')
          yaxes:
            - format: bytes
            - format: short
        - title: LevelDB Queue/Operations
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          seriesOverrides:
            - alias: Compact Queue Length
              steppedLine: true
              yaxis: 2
          span: 6
          targets:
            - target: alias($Cloud.$Node.ceph-mon_*.ceph_bytes-Leveldb_leveldbCompactQueueLen, 'Compact Queue Length')
            - target: aliasByNode(aliasSub($Cloud.$Node.ceph-mon_*.ceph_rate-Leveldb_*, 'ceph_rate-Leveldb_leveldb', ''), 3)
          yaxes:
            - format: short
            - format: short
              label: Queue Length
        - title: LevelDB Latency
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          lines: false
          pointradius: 2
          points: true
          nullPointMode: 'null'
          span: 6
          targets:
            - target: aliasByNode(aliasSub($Cloud.$Node.ceph-mon_*.ceph_latency-Leveldb_*, 'ceph_latency-Leveldb_leveldb', ''), 3)
          yaxes:
            - format: s
            - format: short
        - title: Finisher Monstore
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          lines: false
          nullPointMode: 'null'
          pointradius: 2
          seriesOverrides:
            - alias: Queue Length
              lines: true
              yaxis: 2
            - alias: Complete Latency
              points: true
          span: 6
          targets:
            - target: alias($Cloud.$Node.ceph-mon_*.ceph_latency-FinisherMonstore_completeLatency, 'Complete Latency')
            - target: alias($Cloud.$Node.ceph-mon_*.ceph_bytes-FinisherMonstore_queueLen, 'Queue Length')
          yaxes:
            - format: s
            - format: short
              label: Queue Length
        - title: Paxos Rate
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          span: 6
          targets:
            - target: aliasByNode(aliasSub($Cloud.$Node.ceph-mon_*.ceph_rate-Paxos_*, 'ceph_rate-Paxos_', ''), 3)
        - title: Paxos Latency
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          lines: false
          nullPointMode: 'null'
          pointradius: 1
          points: true
          span: 6
          targets:
            - target: aliasByNode(aliasSub($Cloud.$Node.ceph-mon_*.ceph_latency-Paxos_*, 'ceph_latency-Paxos_', ''), 3)
          yaxes:
            - format: µs
            - format: short
        - title: Throttle Mon Client
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          seriesOverrides:
            - alias: Bytes Max
              yaxis: 2
            - alias: Bytes Current
              yaxis: 2
          span: 6
          targets:
            - target: alias($Cloud.$Node.ceph-mon_*.ceph_bytes-ThrottleMonClientBytes_max, 'Bytes Max')
            - target: alias($Cloud.$Node.ceph-mon_*.ceph_bytes-ThrottleMonClientBytes_val, 'Bytes Current')
            - target: aliasByNode(aliasSub($Cloud.$Node.ceph-mon_*.ceph_rate-ThrottleMonClientBytes_*, 'ceph_rate-ThrottleMonClientBytes_', ''), 3)
          yaxes:
            - format: Bps
            - format: short
        - title: Throttle Mon Daemon
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          seriesOverrides:
            - alias: Bytes Max
              yaxis: 2
            - alias: Bytes Current
              yaxis: 2
          span: 6
          targets:
            - target: alias($Cloud.$Node.ceph-mon_*.ceph_bytes-ThrottleMonDaemonBytes_max, 'Bytes Max')
            - target: alias($Cloud.$Node.ceph-mon_*.ceph_bytes-ThrottleMonDaemonBytes_val, 'Bytes Current')
            - target: aliasByNode(aliasSub($Cloud.$Node.ceph-mon_*.ceph_rate-ThrottleMonDaemonBytes_*, 'ceph_rate-ThrottleMonDaemonBytes_', ''), 3)
          yaxes:
            - format: Bps
            - format: bytes
        - title: Throttle Msgr Dispatch Throttler Mon
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          seriesOverrides:
            - alias: Bytes Max
              yaxis: 2
            - alias: Bytes Current
              yaxis: 2
          span: 6
          targets:
            - target: alias($Cloud.$Node.ceph-mon_*.ceph_bytes-ThrottleMsgrDispatchThrottlerMon_max, 'Bytes Max')
            - target: alias($Cloud.$Node.ceph-mon_*.ceph_bytes-ThrottleMsgrDispatchThrottlerMon_val, 'Bytes Current')
            - target: aliasByNode(aliasSub($Cloud.$Node.ceph-mon_*.ceph_rate-ThrottleMsgrDispatchThrottlerMon_*, 'ceph_rate-ThrottleMsgrDispatchThrottlerMon_', ''), 3)
          yaxes:
            - format: ops
            - format: bytes

**********
DECISION===>: PASS
**********
=========================:::286:::END!!!=========================
=========================:::287:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/grafana-dashboards/templates/partials/cpu_cores.yaml
**********
    - title: Per CPU Logical CPU Core (0-9)
      collapse: true
      height: 200px
      showTitle: true
      panels:
        - title: $Cloud - $Node - $cpus0
          type: graph
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          minSpan: 6
          nullPointMode: 'null'
          repeat: cpus0
          stack: true
          targets:
            - target: alias($Cloud.$Node.$cpus0.cpu-system, 'System')
            - target: alias($Cloud.$Node.$cpus0.cpu-user, 'User')
            - target: alias($Cloud.$Node.$cpus0.cpu-nice, 'Nice')
            - target: alias($Cloud.$Node.$cpus0.cpu-steal, 'Steal')
            - target: alias($Cloud.$Node.$cpus0.cpu-softirq, 'SoftIRQ')
            - target: alias($Cloud.$Node.$cpus0.cpu-interrupt, 'Interrupt')
            - target: alias($Cloud.$Node.$cpus0.cpu-wait, 'Wait')
            - target: alias($Cloud.$Node.$cpus0.cpu-idle, 'Idle')
          yaxes:
            - format: percent
            - format: short
    - title: Per CPU Logical CPU Core (10-99)
      collapse: true
      height: 200px
      showTitle: true
      panels:
        - title: $Cloud - $Node - $cpus00
          type: graph
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          minSpan: 6
          nullPointMode: 'null'
          repeat: cpus00
          stack: true
          targets:
            - target: alias($Cloud.$Node.$cpus00.cpu-system, 'System')
            - target: alias($Cloud.$Node.$cpus00.cpu-user, 'User')
            - target: alias($Cloud.$Node.$cpus00.cpu-nice, 'Nice')
            - target: alias($Cloud.$Node.$cpus00.cpu-steal, 'Steal')
            - target: alias($Cloud.$Node.$cpus00.cpu-softirq, 'SoftIRQ')
            - target: alias($Cloud.$Node.$cpus00.cpu-interrupt, 'Interrupt')
            - target: alias($Cloud.$Node.$cpus00.cpu-wait, 'Wait')
            - target: alias($Cloud.$Node.$cpus00.cpu-idle, 'Idle')
          yaxes:
            - format: percent
            - format: short

**********
DECISION===>: PASS
**********
=========================:::287:::END!!!=========================
=========================:::288:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/grafana-dashboards/templates/partials/mysql_innodb.yaml
**********
    - title: MYSQL INNODB
      collapse: true
      height: 200px
      showTitle: true
      panels:
        - title: MySQL Innodb Data
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          targets:
            - target: aliasByNode(aliasSub($Cloud.$Node.mysql-*.mysql_innodb_data-*, 'mysql_innodb_data-', ''), 3)
        - title: MySQL Innodb Double Write
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          targets:
            - target: aliasByNode(aliasSub($Cloud.$Node.mysql-*.mysql_innodb_dblwr-*, 'mysql_innodb_dblwr-', ''), 3)
        - title: MySQL Innodb Log
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          targets:
            - target: aliasByNode(aliasSub($Cloud.$Node.mysql-*.mysql_innodb_log-*, 'mysql_innodb_log-', ''), 3)
        - title: MySQL Innodb Pages
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          targets:
            - target: aliasByNode(aliasSub($Cloud.$Node.mysql-*.mysql_innodb_pages-*, 'mysql_innodb_pages-', ''), 3)
        - title: MySQL Innodb Row Lock
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          targets:
            - target: aliasByNode(aliasSub($Cloud.$Node.mysql-*.mysql_innodb_row_lock-*, 'mysql_innodb_row_lock-', ''), 3)
        - title: MySQL Innodb Rows
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          targets:
            - target: aliasByNode(aliasSub($Cloud.$Node.mysql-*.mysql_innodb_rows-*, 'mysql_innodb_rows-', ''), 3)

**********
DECISION===>: PASS
**********
=========================:::288:::END!!!=========================
=========================:::289:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/grafana-dashboards/templates/partials/carbon.yaml
**********
    - title: Carbon Cache Metrics
      collapse: true
      height: 200px
      showTitle: true
      panels:
        - title: Metrics, Committed Points, Update Operations
          type: graph
          decimals: 1
          fill: 0
          legend:
            alignAsTable: true
            avg: true
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          targets:
            - target: aliasByNode(aliasSub(carbon.agents.*.metricsReceived, '[a-zA-Z0-9_]+-', ''), 2, 3)
            - target: aliasByNode(aliasSub(carbon.agents.*.committedPoints, '[a-zA-Z0-9_]+-', ''), 2, 3)
            - target: aliasByNode(aliasSub(carbon.agents.*.updateOperations, '[a-zA-Z0-9_]+-', ''), 2, 3)
        - title: Average Update Time
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: true
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          targets:
            - target: aliasByNode(aliasSub(carbon.agents.*.avgUpdateTime, '[a-zA-Z0-9_]+-', ''), 2, 3)
        - title: Creates
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: true
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          targets:
            - target: aliasByNode(aliasSub(carbon.agents.*.creates, '[a-zA-Z0-9_]+-', ''), 2, 3)
        - title: Cache
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: true
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          targets:
            - target: aliasByNode(aliasSub(carbon.agents.*.cache.*, '[a-zA-Z0-9_]+-', ''), 2, 4)
        - title: Blacklist/Whitelist
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: true
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          targets:
            - target: aliasByNode(aliasSub(carbon.agents.*.blacklistMatches, '[a-zA-Z0-9_]+-', ''), 2, 3)
            - target: aliasByNode(aliasSub(carbon.agents.*.whitelistRejects, '[a-zA-Z0-9_]+-', ''), 2, 3)
        - title: Errors
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: true
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          targets:
            - target: aliasByNode(aliasSub(carbon.agents.*.errors, '[a-zA-Z0-9_]+-', ''), 2, 3)

**********
DECISION===>: PASS
**********
=========================:::289:::END!!!=========================
=========================:::290:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/grafana-dashboards/templates/partials/irq.yaml
**********
    - title: IRQ
      collapse: true
      height: 200px
      showTitle: true
      panels:
        - title: $Cloud - $Node - IRQ
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          targets:
            - target: aliasByNode(aliasSub($Cloud.$Node.irq.irq-[A-Z]*, 'irq-', ''), 3)
        - title: $Cloud - $Node - Interrupts
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          targets:
            - target: alias(sumSeries($Cloud.$Node.irq.irq-[0-9]*), 'Interrupts')

**********
DECISION===>: PASS
**********
=========================:::290:::END!!!=========================
=========================:::291:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/grafana-dashboards/templates/partials/tail.yaml
**********
    - title: Tail
      collapse: true
      height: 200px
      showTitle: true
      panels:
        - title: $Cloud - $Node - Tail Error
          type: graph
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          targets:
            - target: aliasByNode(consolidateBy(scale(aliasSub(aliasSub($Cloud.$Node.tail-*.counter-*error, 'tail-', ''), 'counter-', ''), 10), 'max'), 2)
        - title: $Cloud - $Node - Tail Warn
          type: graph
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          targets:
            - target: aliasByNode(consolidateBy(scale(aliasSub(aliasSub($Cloud.$Node.tail-*.counter-*warn, 'tail-', ''), 'counter-', ''), 10), 'max'), 2)
        - title: $Cloud - $Node - Tail Info
          type: graph
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          targets:
            - target: aliasByNode(consolidateBy(scale(aliasSub(aliasSub($Cloud.$Node.tail-*.counter-*info, 'tail-', ''), 'counter-', ''), 10), 'max'), 2)

**********
DECISION===>: PASS
**********
=========================:::291:::END!!!=========================
=========================:::292:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/grafana-dashboards/templates/partials/cpu_all.yaml
**********
    - title: CPU All
      collapse: true
      height: 200px
      showTitle: true
      panels:
        - title: $Cloud - $Node - All CPUs
          type: graph
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          stack: true
          targets:
            - target: alias(averageSeries($Cloud.$Node.cpu-*.cpu-system), 'System')
            - target: alias(averageSeries($Cloud.$Node.cpu-*.cpu-user), 'User')
            - target: alias(averageSeries($Cloud.$Node.cpu-*.cpu-nice), 'Nice')
            - target: alias(averageSeries($Cloud.$Node.cpu-*.cpu-steal), 'Steal')
            - target: alias(averageSeries($Cloud.$Node.cpu-*.cpu-softirq), 'SoftIRQ')
            - target: alias(averageSeries($Cloud.$Node.cpu-*.cpu-interrupt), 'Interrupt')
            - target: alias(averageSeries($Cloud.$Node.cpu-*.cpu-wait), 'Wait')
            - target: alias(averageSeries($Cloud.$Node.cpu-*.cpu-idle), 'Idle')
          yaxes:
            - format: percent
            - format: short
        - title: $Cloud - $Node - All CPUs Sum
          type: graph
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          stack: true
          targets:
            - target: alias(sumSeries($Cloud.$Node.cpu-*.cpu-system), 'System')
            - target: alias(sumSeries($Cloud.$Node.cpu-*.cpu-user), 'User')
            - target: alias(sumSeries($Cloud.$Node.cpu-*.cpu-nice), 'Nice')
            - target: alias(sumSeries($Cloud.$Node.cpu-*.cpu-steal), 'Steal')
            - target: alias(sumSeries($Cloud.$Node.cpu-*.cpu-softirq), 'SoftIRQ')
            - target: alias(sumSeries($Cloud.$Node.cpu-*.cpu-interrupt), 'Interrupt')
            - target: alias(sumSeries($Cloud.$Node.cpu-*.cpu-wait), 'Wait')
            - target: alias(sumSeries($Cloud.$Node.cpu-*.cpu-idle), 'Idle')
          yaxes:
            - format: percent
            - format: short

**********
DECISION===>: PASS
**********
=========================:::292:::END!!!=========================
=========================:::293:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/grafana-dashboards/templates/partials/memory.yaml
**********
    - title: Memory & Swap
      collapse: true
      height: 200px
      showTitle: true
      panels:
        - title: $Cloud - $Node - Memory in Bytes
          type: graph
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          stack: true
          targets:
            - target: alias($Cloud.$Node.memory.memory-slab_unrecl, 'Slab Unrecl')
            - target: alias($Cloud.$Node.memory.memory-used, 'Used')
            - target: alias($Cloud.$Node.memory.memory-buffered, 'Buffered')
            - target: alias($Cloud.$Node.memory.memory-slab_recl, 'Slab Recl')
            - target: alias($Cloud.$Node.memory.memory-cached, 'Cached')
            - target: alias($Cloud.$Node.memory.memory-free, 'Free')
          yaxes:
            - format: bytes
            - format: short
        - title: $Cloud - $Node - Memory in Percentage
          type: graph
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          stack: true
          targets:
            - hide: true
              target: "$Cloud.$Node.memory.memory-slab_unrecl"
            - hide: true
              target: "$Cloud.$Node.memory.memory-used"
            - hide: true
              target: "$Cloud.$Node.memory.memory-buffered"
            - hide: true
              target: "$Cloud.$Node.memory.memory-slab_recl"
            - hide: true
              target: "$Cloud.$Node.memory.memory-cached"
            - hide: true
              target: "$Cloud.$Node.memory.memory-free"
            - hide: true
              target: sumSeries($Cloud.$Node.memory.*)
            - target: 'alias(asPercent(#A, #G), ''Slab Unrecl'')'
            - target: 'alias(asPercent(#B, #G), ''Used'')'
            - target: 'alias(asPercent(#C, #G), ''Buffered'')'
            - target: 'alias(asPercent(#D, #G), ''Slab Recl'')'
            - target: 'alias(asPercent(#E, #G), ''Cached'')'
            - target: 'alias(asPercent(#F, #G), ''Free'')'
          yaxes:
            - format: percent
            - format: short
        - title: $Cloud - $Node - Swap Usage
          type: graph
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          stack: true
          targets:
            - target: alias($Cloud.$Node.swap.swap-used, 'Used')
            - target: alias($Cloud.$Node.swap.swap-cached, 'Cached')
            - target: alias($Cloud.$Node.swap.swap-free, 'Free')
          yaxes:
            - format: bits
            - format: short
        - title: $Cloud - $Node - Swap IO
          type: graph
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          targets:
            - target: alias($Cloud.$Node.swap.swap_io-in, 'In')
            - target: alias($Cloud.$Node.swap.swap_io-out, 'Out')
          yaxes:
            - format: bytes
            - format: short

**********
DECISION===>: PASS
**********
=========================:::293:::END!!!=========================
=========================:::294:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/grafana-dashboards/templates/partials/df.yaml
**********
    - title: DF
      collapse: true
      height: 200px
      showTitle: true
      panels:
        - title: $Cloud - $Node - Partition % Used
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: true
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          targets:
            - target: aliasByNode(aliasSub($Cloud.$Node.df-*.percent_bytes-used, 'df-', ''), 2)
          yaxes:
            - format: percent
              max: 100
            - format: short
        - title: $Cloud - $Node - Inodes % Used
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: true
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          targets:
            - target: aliasByNode(aliasSub($Cloud.$Node.df-*.percent_inodes-used, 'df-', ''), 2)
          yaxes:
            - format: percent
              max: 100
            - format: short

**********
DECISION===>: PASS
**********
=========================:::294:::END!!!=========================
=========================:::295:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/grafana-dashboards/templates/partials/network.yaml
**********
    - title: Network
      collapse: true
      height: 200px
      showTitle: true
      panels:
        - title: $Cloud - $Node - $Interface Network IO
          type: graph
          legend:
            alignAsTable: true
            avg: true
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          seriesOverrides:
            - alias: RX
              transform: negative-Y
          targets:
            - target: alias($Cloud.$Node.$Interface.if_packets.tx, 'TX')
            - target: alias($Cloud.$Node.$Interface.if_packets.rx, 'RX')
          yaxes:
            - format: pps
            - format: short
        - title: $Cloud - $Node - $Interface Network Throughput
          type: graph
          legend:
            alignAsTable: true
            avg: true
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          seriesOverrides:
            - alias: RX
              transform: negative-Y
          targets:
            - target: alias(scale($Cloud.$Node.$Interface.if_octets.tx, 8), 'TX')
            - target: alias(scale($Cloud.$Node.$Interface.if_octets.rx, 8), 'RX')
          yaxes:
            - format: bps
            - format: short
        - title: $Cloud - $Node - $Interface Errors
          type: graph
          legend:
            alignAsTable: true
            avg: true
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          seriesOverrides:
            - alias: RX
              transform: negative-Y
          targets:
            - target: alias($Cloud.$Node.$Interface.if_errors.tx, 'TX')
            - target: alias($Cloud.$Node.$Interface.if_errors.rx, 'RX')
          yaxes:
            - format: short
            - format: short
        - title: $Cloud - $Node - ConnTrack
          type: graph
          legend:
            alignAsTable: true
            avg: true
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          seriesOverrides:
            - alias: "% Used"
              yaxis: 2
          targets:
            - target: alias($Cloud.$Node.conntrack.conntrack-max, 'Max')
            - target: alias($Cloud.$Node.conntrack.conntrack, 'Used')
            - target: alias($Cloud.$Node.conntrack.percent-used, '% Used')
          yaxes:
            - format: short
            - format: percent
              max: 100
        - title: Ping- Latency and Jitter
          type: graph
          legend:
            alignAsTable: true
            avg: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          targets:
            - target: aliasByNode($Cloud.$Node.ping.*, 3)

**********
DECISION===>: PASS
**********
=========================:::295:::END!!!=========================
=========================:::296:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/grafana-dashboards/templates/partials/processes.yaml
**********
    - title: Processes
      collapse: true
      height: 200px
      showTitle: true
      panels:
        - title: $Cloud - $Node - Processes State
          type: graph
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          stack: true
          targets:
            - target: alias($Cloud.$Node.processes.ps_state-running, 'Running')
            - target: alias($Cloud.$Node.processes.ps_state-stopped, 'Stopped')
            - target: alias($Cloud.$Node.processes.ps_state-sleeping, 'Sleeping')
            - target: alias($Cloud.$Node.processes.ps_state-blocked, 'Blocked')
            - target: alias($Cloud.$Node.processes.ps_state-paging, 'Paging')
            - target: alias($Cloud.$Node.processes.ps_state-zombies, 'Zombies')
        - title: $Cloud - $Node - Fork Rate
          type: graph
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          targets:
            - target: alias($Cloud.$Node.processes.fork_rate, 'Fork Rate')

**********
DECISION===>: PASS
**********
=========================:::296:::END!!!=========================
=========================:::297:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/grafana-dashboards/templates/partials/description.yaml
**********
    - title: description row
      height: 50px
      panels:
        - title: Browbeat provided Dashboard
          content: "**This dashboard is provided by Browbeat and managed via Grafyaml**"
          type: text

**********
DECISION===>: PASS
**********
=========================:::297:::END!!!=========================
=========================:::298:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/grafana-dashboards/templates/partials/turbostat.yaml
**********
    - title: Turbostat
      collapse: true
      height: 200px
      showTitle: true
      panels:
        - title: $Cloud - $Node - Gauge TSC & SMI Count
          type: graph
          decimals: 2
          fill: 0
          nullPointMode: 'null'
          seriesOverrides:
            - alias: SMI Count
              yaxis: 2
          targets:
            - target: aliasByNode(scale(aliasSub($Cloud.$Node.turbostat-cpu*.gauge-TSC, 'turbostat-','tsc-'), 1000000), 2)
            - target: alias(sumSeries($Cloud.$Node.turbostat-cpu*.count), 'SMI Count')
          yaxes:
            - format: hertz
            - format: short
        - title: $Cloud - $Node - turbostat Freq Avg
          type: graph
          fill: 0
          nullPointMode: 'null'
          targets:
            - target: aliasByNode(scale(aliasSub($Cloud.$Node.turbostat-cpu*.frequency-average, 'turbostat-', ''), 1000000), 2)
          yaxes:
            - format: hertz
            - format: short
        - title: $Cloud - $Node - turbostat Freq Busy
          type: graph
          decimals: 2
          fill: 0
          nullPointMode: 'null'
          targets:
            - target: aliasByNode(scale($Cloud.$Node.turbostat-cpu*.frequency-busy, 1000000), 2)
          yaxes:
            - format: hertz
            - format: short
        - title: $Cloud - $Node - turbostat c0%
          type: graph
          decimals: 2
          fill: 0
          nullPointMode: 'null'
          targets:
            - target: aliasByNode($Cloud.$Node.turbostat-cpu*.percent-c0, 2)
          yaxes:
            - format: percent
            - format: short
        - title: $Cloud - $Node - turbostat c1%
          type: graph
          decimals: 2
          fill: 0
          nullPointMode: 'null'
          targets:
            - target: aliasByNode($Cloud.$Node.turbostat-cpu*.percent-c1, 2)
          yaxes:
            - format: percent
            - format: short

**********
DECISION===>: PASS
**********
=========================:::298:::END!!!=========================
=========================:::299:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/grafana-dashboards/templates/partials/ironic_metrics.yaml
**********
    - title: Ironic StatsD power state
      collapse: true
      height: 200px
      showTitle: true
      panels:
        - title: "Power State Sync: 90th Percentile Mean"
          type: graph
          legend:
            show: true
          nullPointMode: 'null'
          span: 6
          targets:
            - target: stats.timers.$Cloud.ironic.conductor.manager.do_sync_power_state.mean_90
          yaxes:
            - format: short
              label: Milliseconds
            - format: short
        - title: "Change Node Power State: 90th percentile mean"
          type: graph
          legend:
            show: true
          nullPointMode: 'null'
          span: 6
          targets:
            - target: stats.timers.$Cloud.ironic.conductor.manager.ConductorManager.change_node_power_state.mean_90
          yaxes:
            - format: short
              label: Milliseconds
            - format: short
    - title: Ironic StatsD boot/deployment info
      collapse: true
      height: 200px
      showTitle: true
      panels:
        - title: "Set boot device: 90th percentile mean"
          type: graph
          legend:
            show: true
          nullPointMode: 'null'
          span: 6
          targets:
            - target: stats.timers.$Cloud.ironic.conductor.manager.ConductorManager.set_boot_device.mean_90
          yaxes:
            - format: short
              label: Milliseconds
            - format: short
        - title: "Do Node Deployment: 90th percentile mean"
          type: graph
          legend:
            show: true
          nullPointMode: 'null'
          span: 6
          targets:
            - target: stats.timers.$Cloud.ironic.conductor.manager.ConductorManager.do_node_deploy.mean_90
          yaxes:
            - format: short
              label: Milliseconds
            - format: short
    - title: Ironic StatsD API node details/list response time
      collapse: true
      height: 200px
      showTitle: true
      panels:
        - title: "Get Node Details API response time: 90th percentile mean"
          type: graph
          legend:
            show: true
          nullPointMode: 'null'
          span: 6
          targets:
            - target: stats.timers.$Cloud.ironic.api.controllers.v1.node.NodesController.detail.mean_90
          yaxes:
            - format: short
              label: Milliseconds
            - format: short
        - title: "Get Node List API response time: 90th Percentile mean"
          type: graph
          legend:
            show: true
          nullPointMode: 'null'
          span: 6
          targets:
            - target: stats.timers.$Cloud.ironic.api.controllers.v1.node.NodesController.get_all.mean_90
          yaxes:
            - format: short
              label: Milliseconds
            - format: short
    - title: Ironic StatsD API power/provision state
      collapse: true
      height: 200px
      showTitle: true
      panels:
        - title: "Node Power State API response time: 90th Percentile Mean"
          type: graph
          legend:
            show: true
          nullPointMode: 'null'
          span: 6
          targets:
            - target: stats.timers.$Cloud.ironic.api.controllers.v1.node.NodeStatesController.power.mean_90
          yaxes:
            - format: short
              label: Milliseconds
            - format: short
        - title: "Ironic Node Provision State API response time: 90th percentile mean"
          type: graph
          legend:
            show: true
          nullPointMode: 'null'
          span: 6
          targets:
            - target: stats.timers.$Cloud.ironic.api.controllers.v1.node.NodeStatesController.provision.mean_90
          yaxes:
            - format: short
              label: Milliseconds
            - format: short

**********
DECISION===>: PASS
**********
=========================:::299:::END!!!=========================
=========================:::300:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/grafana-dashboards/templates/partials/mariadb.yaml
**********
    - title: MariaDB
      collapse: true
      height: 200px
      showTitle: true
      panels:
        - title: MySQL Threads
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          targets:
            - target: aliasByNode(aliasSub($Cloud.$Node.mysql-*.threads-*, 'threads-', ''), 3)
        - title: MySQL Traffic
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          targets:
            - target: aliasByNode($Cloud.$Node.mysql-*.mysql_octets.*, 4)
          yaxes:
            - format: bytes
            - format: short
        - title: MySQL Query Cache
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          targets:
            - target: aliasByNode(aliasSub($Cloud.$Node.mysql-*.cache_result-*, 'cache_result-qcache-', ''), 3)
          yaxes:
            - format: bytes
            - format: short
        - title: MySQL Query Cache Size
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          targets:
            - target: aliasByNode(aliasSub($Cloud.$Node.mysql-*.cache_size-*, 'cache_size-', ''), 3)
        - title: MySQL Buffer Pool Data
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          targets:
            - target: aliasByNode(aliasSub($Cloud.$Node.mysql-*.mysql_bpool_bytes-*, 'mysql_bpool_bytes-', ''), 3)
          yaxes:
            - format: bytes
            - format: short
        - title: MySQL Buffer Pool Counters
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          targets:
            - target: aliasByNode(aliasSub($Cloud.$Node.mysql-*.mysql_bpool_counters-*, 'mysql_bpool_counters-', ''), 3)
        - title: MySQL Commands
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          targets:
            - target: aliasByNode(aliasSub($Cloud.$Node.mysql-*.mysql_commands-*, 'mysql_commands-', ''), 3)
        - title: MySQL Handler
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          targets:
            - target: aliasByNode(aliasSub($Cloud.$Node.mysql-*.mysql_handler-*, 'mysql_handler-', ''), 3)
        - title: MySQL Locks
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          targets:
            - target: aliasByNode(aliasSub($Cloud.$Node.mysql-*.mysql_locks-*, 'mysql_locks-', ''), 3)
        - title: MySQL Select
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          targets:
            - target: aliasByNode(aliasSub($Cloud.$Node.mysql-*.mysql_select-*, 'mysql_select-', ''), 3)
        - title: MySQL Sort
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          targets:
            - target: aliasByNode(aliasSub($Cloud.$Node.mysql-*.mysql_sort-*, 'mysql_sort-', ''), 3)

**********
DECISION===>: PASS
**********
=========================:::300:::END!!!=========================
=========================:::301:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/grafana-dashboards/templates/partials/disk.yaml
**********
    - title: Disk
      collapse: true
      height: 200px
      showTitle: true
      panels:
        - title: $Cloud - $Node - $Disk iops
          type: graph
          legend:
            alignAsTable: true
            avg: true
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          seriesOverrides:
            - alias: Write
              transform: negative-Y
          targets:
            - target: alias($Cloud.$Node.$Disk.disk_ops.read, 'Read')
            - target: alias($Cloud.$Node.$Disk.disk_ops.write, 'Write')
          yaxes:
            - format: iops
            - format: short
        - title: $Cloud - $Node - $Disk Throughput
          type: graph
          legend:
            alignAsTable: true
            avg: true
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          seriesOverrides:
            - alias: Write
              transform: negative-Y
          targets:
            - target: alias($Cloud.$Node.$Disk.disk_octets.read, 'Read')
            - target: alias($Cloud.$Node.$Disk.disk_octets.write, 'Write')
          yaxes:
            - format: Bps
            - format: short
        - title: $Cloud - $Node - $Disk Merged iops
          type: graph
          legend:
            alignAsTable: true
            avg: true
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          seriesOverrides:
            - alias: Write
              transform: negative-Y
          targets:
            - target: alias($Cloud.$Node.$Disk.disk_merged.read, 'Read')
            - target: alias($Cloud.$Node.$Disk.disk_merged.write, 'Write')
          yaxes:
            - format: iops
            - format: short
        - title: $Cloud - $Node - $Disk Pending Operations
          type: graph
          legend:
            alignAsTable: true
            avg: true
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          targets:
            - target: alias($Cloud.$Node.$Disk.pending_operations, 'Pending Ops')
          yaxes:
            - format: short
            - format: short
        - title: $Cloud - $Node - $Disk Average Time (Estimated)
          type: graph
          legend:
            alignAsTable: true
            avg: true
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          seriesOverrides:
            - alias: Write
              transform: negative-Y
          targets:
            - target: alias($Cloud.$Node.$Disk.disk_time.read, 'Read')
            - target: alias($Cloud.$Node.$Disk.disk_time.write, 'Write')
          yaxes:
            - format: ms
            - format: short
        - title: $Cloud - $Node - $Disk IO Time
          type: graph
          legend:
            alignAsTable: true
            avg: true
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          seriesOverrides:
            - alias: Weighted Time
              yaxis: 2
          targets:
            - target: alias(scale($Cloud.$Node.$Disk.disk_io_time.io_time, 0.1), 'Time')
            - target: alias($Cloud.$Node.$Disk.disk_io_time.weighted_io_time, 'Weighted Time')
          yaxes:
            - format: percent
            - format: ms

**********
DECISION===>: PASS
**********
=========================:::301:::END!!!=========================
=========================:::302:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/grafana-dashboards/templates/partials/load.yaml
**********
    - title: Load / Uptime
      collapse: true
      height: 200px
      showTitle: true
      panels:
        - title: $Cloud - $Node - All CPUs
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          seriesOverrides:
            - alias: uptime
              lines: false
              yaxis: 2
          targets:
            - target: alias($Cloud.$Node.load.load.shortterm, '1m avg')
            - target: alias($Cloud.$Node.load.load.midterm, '5m avg')
            - target: alias($Cloud.$Node.load.load.longterm, '15m avg')
            - target: alias($Cloud.$Node.uptime.uptime, 'uptime')
          yaxes:
            - format: short
            - format: s

**********
DECISION===>: PASS
**********
=========================:::302:::END!!!=========================
=========================:::303:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/grafana-dashboards/templates/partials/neutron_resources.yaml
**********
    - title: Neutron Resources
      collapse: true
      height: 200px
      showTitle: true
      panels:
        - title: $Cloud - Neutron $Node Resources
          type: graph
          legend:
            avg: false
            current: false
            max: false
            min: false
            show: true
            total: false
            values: false
          nullPointMode: 'null'
          targets:
            - target: "$Cloud.$Node.ovsagent_monitoring.gauge-qdhcp_ns_total-count"
            - target: "$Cloud.$Node.ovsagent_monitoring.gauge-qrouter_ns_total-count"
            - target: "$Cloud.$Node.ovsagent_monitoring.gauge-tap_interface_total-count"

**********
DECISION===>: PASS
**********
=========================:::303:::END!!!=========================
=========================:::304:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/grafana-dashboards/templates/partials/numa.yaml
**********
    - title: Numa
      collapse: true
      height: 200px
      showTitle: true
      panels:
        - title: $Cloud - $Node - Numastat
          type: graph
          fill: 0
          legend:
            alignAsTable: true
            avg: false
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          targets:
            - target: aliasByNode(aliasSub(aliasSub($Cloud.$Node.numa-*.vmpage_action-interleave_hit, 'numa-', ''), 'vmpage_action-', ''), 2, 3)
            - target: aliasByNode(aliasSub(aliasSub($Cloud.$Node.numa-*.vmpage_action-local_node, 'numa-', ''), 'vmpage_action-', ''), 2, 3)
            - target: aliasByNode(aliasSub(aliasSub($Cloud.$Node.numa-*.vmpage_action-numa_foreign, 'numa-', ''), 'vmpage_action-', ''), 2, 3)
            - target: aliasByNode(aliasSub(aliasSub($Cloud.$Node.numa-*.vmpage_action-numa_hit, 'numa-', ''), 'vmpage_action-', ''), 2, 3)
            - target: aliasByNode(aliasSub(aliasSub($Cloud.$Node.numa-*.vmpage_action-numa_miss, 'numa-', ''), 'vmpage_action-', ''), 2, 3)
            - target: aliasByNode(aliasSub(aliasSub($Cloud.$Node.numa-*.vmpage_action-other_node, 'numa-', ''), 'vmpage_action-', ''), 2, 3)

**********
DECISION===>: PASS
**********
=========================:::304:::END!!!=========================
=========================:::305:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/grafana-dashboards/templates/partials/opendaylight_metrics.yaml
**********
    - title: OpenDaylight
      collapse: true
      height: 200px
      showTitle: true
      panels:
        - title: ODL Java Heap Memory
          type: graph
          legend:
            alignAsTable: true
            avg: true
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          targets:
            - target: aliasByNode($Cloud.$Node.GenericJMX-memory-heap.*, 3)
          yaxes:
            - format: bits
            - format: short
        - title: ODL Java Non-Heap Memory
          type: graph
          legend:
            alignAsTable: true
            avg: true
            current: true
            max: true
            min: true
            rightSide: true
            show: true
            total: false
            values: true
          nullPointMode: 'null'
          targets:
            - target: aliasByNode($Cloud.$Node.GenericJMX-memory-nonheap.*, 3)
          yaxes:
            - format: bits
            - format: short

**********
DECISION===>: PASS
**********
=========================:::305:::END!!!=========================
=========================:::306:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/curator/tasks/main.yml
**********

---
#
# install curator tool for managing elasticsearch
#

- name: Copy curator yum repo file
  copy:
    src=curator.repo
    dest=/etc/yum.repos.d/curator.repo
    owner=root
    group=root
    mode=0644
  become: true
  when: install_curator_tool

- name: Import curator GPG Key
  rpm_key: key=http://packages.elastic.co/GPG-KEY-elasticsearch
    state=present
  when: install_curator_tool

- name: Install curator and python-setuptools
  package:
    name: "{{ item }}"
    state: present
  become: true
  with_items:
    - python-elasticsearch-curator
    - python-setuptools
  when: install_curator_tool

**********
DECISION===>: Use of HTTP without TLS
**********
=========================:::306:::END!!!=========================
=========================:::307:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/perfkitbenchmarker/tasks/main.yml
**********
---
#
# Browbeat's PerfKitBenchmarker Install
#

- name: Create perfkit virtualenv
  command: virtualenv {{ perfkit_venv }} creates={{ perfkit_venv }}

- name: Setup perfkit-venv CA certificate path
  lineinfile:
    dest: "{{ perfkit_venv }}/bin/activate"
    line: 'export REQUESTS_CA_BUNDLE={{ overcloud_ca_path }}'
  when: overcloud_ca_path is defined

- name: Determine if PerfKitBenchmarker is already cloned
  stat:
    path: "{{ perfkit_venv }}/PerfKitBenchmarker"
  register: perfkit_exists

- debug: msg="PerfKitBenchmarker already exists on the host"
  when: perfkit_exists.stat.isdir is defined and perfkit_exists.stat.isdir

- name: Clone PerfKitBenchmarker on undercloud
  git:
    repo: https://github.com/GoogleCloudPlatform/PerfKitBenchmarker.git
    dest: "{{perfkit_venv}}/PerfKitBenchmarker"
    version: "{{perfkit_version}}"
  when: perfkit_exists.stat.isdir is undefined

- name: Install PerfKitBenchmarker requirements into perfkit-venv
  pip:
     requirements: "{{perfkit_venv}}/PerfKitBenchmarker/requirements.txt"
     virtualenv: "{{perfkit_venv}}"

- name: Install PerfKitBenchmarker Openstack requirements into perfkit-venv
  pip:
     requirements: "{{ perfkit_venv }}/PerfKitBenchmarker/perfkitbenchmarker/providers/openstack/requirements.txt"
     virtualenv: "{{perfkit_venv}}"

# (akrzos) - These requirements are what works for OpenStack Ocata
- name: Fix requirements for (OSP11 Ocata) inside perfkit-venv
  pip:
    name: "{{item.name}}"
    version: "{{item.version}}"
    virtualenv: "{{perfkit_venv}}"
  with_items:
    - name: openstacksdk
      version: 0.9.17
    - name: python-openstackclient
      version: 3.12.0
    - name: python-novaclient
      version: 9.1.0

**********
DECISION===>: PASS
**********
=========================:::307:::END!!!=========================
=========================:::308:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/grafana/tasks/main.yml
**********
---
#
# Install/run grafana-server for browbeat
#

# check that grafana_host and graphite_host is entered prior to playbook run
- name: Check Graphite/Grafana Host IP Address
  fail:
    msg="** Edit grafana_host and graphite_host in ../install/group_vars/all.yml before running **"
  when: ((grafana_host is none) or (graphite_host is none))

- name: Install grafana RPM repo
  copy:
    src=grafana.repo
    dest=/etc/yum.repos.d/grafana.repo
    owner=root
    group=root
    mode=0644
  become: true

- name: Import grafana GPG Key
  rpm_key: key=https://grafanarel.s3.amazonaws.com/RPM-GPG-KEY-grafana
    state=present
  become: True

- name: Install grafana RPM
  package:
    name: "{{ item }}"
    state: present
  become: true
  with_items:
    - grafana

- name: Set grafana config values
  ini_file:
    dest=/etc/grafana/grafana.ini
    section={{item.section}}
    option={{item.option}}
    value={{item.value}}
  with_items:
    - section: server
      option: http_port
      value: "{{grafana_port}}"
    - section: auth.anonymous
      option: enabled
      value: true
    - section: security
      option: admin_user
      value: "{{grafana_username}}"
    - section: security
      option: admin_password
      value: "{{grafana_password}}"
  become: true

### begin firewall ###
# we need TCP/3000 open
# determine firewall status and take action
# 1) use firewall-cmd if firewalld is utilized
# 2) insert iptables rule if iptables is used

# Firewalld
- name: (grafana) Determine if firewalld is in use
  shell: systemctl is-enabled firewalld.service | egrep -qv 'masked|disabled'
  ignore_errors: true
  register: firewalld_in_use
  no_log: true
  tags:
    # Skip ANSIBLE0012] Commands should not change things if nothing needs doing
    # Need to know if firewalld is in use.
    - skip_ansible_lint

- name: (grafana) Determine if firewalld is active
  shell: systemctl is-active firewalld.service | grep -vq inactive
  ignore_errors: true
  register: firewalld_is_active
  no_log: true
  tags:
    # Skip ANSIBLE0012] Commands should not change things if nothing needs doing
    # Need to know if firewalld is active.
    - skip_ansible_lint

- name: (grafana) Determine if TCP/{{grafana_port}} is already active
  shell: firewall-cmd --list-ports | egrep -q "^{{grafana_port}}/tcp"
  ignore_errors: true
  register: firewalld_grafana_port_exists
  no_log: true
  tags:
    # Skip ANSIBLE0012] Commands should not change things if nothing needs doing
    # Need to know if port is already active.
    - skip_ansible_lint

# add firewall rule via firewall-cmd
- name: (grafana) Add firewall rule for TCP/{{grafana_port}} (firewalld)
  command: "{{ item }}"
  with_items:
    - firewall-cmd --zone=public --add-port={{grafana_port}}/tcp --permanent
    - firewall-cmd --reload
  ignore_errors: true
  become: true
  when: firewalld_in_use.rc == 0 and firewalld_is_active.rc == 0 and firewalld_grafana_port_exists.rc != 0

# iptables-services
- name: (grafana) check firewall rules for TCP/{{grafana_port}} (iptables-services)
  shell: grep "dport {{grafana_port}} \-j ACCEPT" /etc/sysconfig/iptables | wc -l
  ignore_errors: true
  register: iptables_grafana_port_exists
  failed_when: iptables_grafana_port_exists == 127
  no_log: true
  tags:
    # Skip ANSIBLE0012] Commands should not change things if nothing needs doing
    # Need to know if port exists.
    - skip_ansible_lint

- name: (grafana) Add firewall rule for TCP/{{grafana_port}} (iptables-services)
  lineinfile:
    dest: /etc/sysconfig/iptables
    line: '-A INPUT -p tcp -m tcp --dport {{grafana_port}} -j ACCEPT'
    regexp: '^INPUT -i lo -j ACCEPT'
    insertbefore: '-A INPUT -i lo -j ACCEPT'
    backup: yes
  when: firewalld_in_use.rc != 0 and firewalld_is_active.rc != 0 and iptables_grafana_port_exists.stdout|int == 0
  register: iptables_needs_restart

- name: (grafana) Restart iptables-services for TCP/{{grafana_port}} (iptables-services)
  systemd:
    name: iptables.service
    state: restarted
  ignore_errors: true
  when: iptables_needs_restart != 0 and firewalld_in_use.rc != 0 and firewalld_is_active.rc != 0

### end firewall ###

# setup the grafana-server service
- name: Setup grafana-server service
  service: name=grafana-server state=started enabled=true
  become: true
  ignore_errors: true

- name: Wait for grafana to be ready
  wait_for: host={{grafana_host}} port={{grafana_port}} delay=5 timeout=30

#
# Add graphite server as a default datasource
#
# (akrzos) I reverted this back to the "old" way after testing Ansible 2.3.0.0
# which still could not POST with basic auth through uri vs curl command.
- name: Create data_source.json
  template:
    src: data_source.json.j2
    dest: "{{role_path}}/files/data_source.json"
  connection: local

- name: Create Data Source on grafana server
  command: "curl -X POST -H 'Content-Type: application/json' -d @{{role_path}}/files/data_source.json http://{{grafana_username}}:{{grafana_password}}@{{grafana_host}}:{{grafana_port}}/api/datasources"
  connection: local
  tags:
    - skip_ansible_lint

- name: Remove leftover json file
  file: path={{role_path}}/files/data_source.json state=absent
  connection: local

**********
DECISION===>: PASS
**********
=========================:::308:::END!!!=========================
=========================:::309:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/stockpile/tasks/main.yml
**********
---

- name: Clone stockpile
  git:
    repo: 'http://github.com/redhat-performance/stockpile.git'
    dest: "{{ browbeat_path }}/ansible/gather/stockpile"
    version: master
    force: yes

**********
DECISION===>: Use of HTTP Without TLS
**********
=========================:::309:::END!!!=========================
=========================:::310:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/firewall/tasks/main.yml
**********
---
#
# Setup firewalld or iptables for Browbeat
#

- name: Determine if firewalld is in use
  shell: systemctl is-enabled firewalld.service | egrep -qv 'masked|disabled'
  ignore_errors: true
  register: firewalld_in_use
  no_log: true
  tags:
    # Skip ANSIBLE0012 Commands should not change things if nothing needs doing
    # Need to check if firewall is in use
    - skip_ansible_lint

- name: Determine if firewalld is active
  shell: systemctl is-active firewalld.service | egrep -vq 'inactive|unknown'
  ignore_errors: true
  register: firewalld_is_active
  no_log: true
  tags:
    # Skip ANSIBLE0012 Commands should not change things if nothing needs doing
    # Need to check if firewall is active
    - skip_ansible_lint

- name: (shaker) Determine if TCP/{{shaker_port}} is already active
  shell: firewall-cmd --list-ports | egrep -q "^{{shaker_port}}/tcp"
  ignore_errors: true
  register: firewalld_shaker_port_exists
  no_log: true
  tags:
    # Skip ANSIBLE0012 Commands should not change things if nothing needs doing
    # Need to check if port is already active
    - skip_ansible_lint

- name: (browbeat_results) Determine if TCP/{{browbeat_results_port}} is already active
  shell: firewall-cmd --list-ports | egrep -q "^{{browbeat_results_port}}/tcp"
  ignore_errors: true
  register: firewalld_browbeat_results_port_exists
  no_log: true
  tags:
    # Skip ANSIBLE0012 Commands should not change things if nothing needs doing
    # Need to check if port is already active
    - skip_ansible_lint

# add firewall rule via firewalld module
- name: (shaker) Add firewall rule for TCP/{{shaker_port}} (firewalld)
  firewalld:
    port: "{{ shaker_port }}/tcp"
    state: enabled
    zone: public
    permanent: true
    immediate: true
  become: true
  when: firewalld_in_use.rc == 0 and firewalld_is_active.rc == 0 and firewalld_shaker_port_exists.rc != 0

- name: (browbeat_results) Add firewall rule for TCP/{{browbeat_results_port}} (firewalld)
  firewalld:
    port: "{{ browbeat_results_port }}/tcp"
    state: enabled
    zone: public
    permanent: true
    immediate: true
  become: true
  when: browbeat_results_in_httpd and firewalld_in_use.rc == 0 and firewalld_is_active.rc == 0 and firewalld_browbeat_results_port_exists.rc != 0

# iptables-services
- name: (shaker) check firewall rules for TCP/{{shaker_port}} (iptables-services)
  shell: "grep \"dport {{shaker_port}} \\-j ACCEPT\" {{iptables_file}} | wc -l"
  ignore_errors: true
  become: true
  register: iptables_shaker_port_exists
  no_log: true
  tags:
    # Skip ANSIBLE0012 Commands should not change things if nothing needs doing
    # Need to check if port is already active
    - skip_ansible_lint

- name: (browbeat_results) Check firewall rules for TCP/{{browbeat_results_port}} (iptables-services)
  shell: "grep \"dport {{browbeat_results_port}} \\-j ACCEPT\" {{iptables_file}} | wc -l"
  when: browbeat_results_in_httpd
  ignore_errors: true
  become: true
  register: iptables_browbeat_results_port_exists
  no_log: true
  tags:
    # Skip ANSIBLE0012 Commands should not change things if nothing needs doing
    # Need to check if port is already active
    - skip_ansible_lint

- name: check if iptables rules exist
  stat:
    path: "{{ iptables_file }}"
  register: iptables_file_present

- name: (shaker) Add firewall rule for TCP/{{shaker_port}} (iptables-services)
  lineinfile:
    dest: "{{iptables_file}}"
    line: '-A INPUT -p tcp -m tcp --dport {{shaker_port}} -j ACCEPT'
    insertbefore: '^-A INPUT -i lo'
    backup: yes
  become: true
  when: firewalld_in_use.rc != 0 and firewalld_is_active.rc != 0 and iptables_shaker_port_exists.stdout|int == 0 and iptables_file_present.stat.exists
  notify:
    - restart iptables

- name: (browbeat_results) Add firewall rule for TCP/{{browbeat_results_port}} (iptables-services)
  lineinfile:
    dest: "{{iptables_file}}"
    line: '-A INPUT -p tcp -m tcp --dport {{browbeat_results_port}} -j ACCEPT'
    insertbefore: '^-A INPUT -i lo'
    backup: yes
  become: true
  when: browbeat_results_in_httpd and firewalld_in_use.rc != 0 and firewalld_is_active.rc != 0 and iptables_browbeat_results_port_exists.stdout|int == 0 and iptables_file_present.stat.exists
  notify:
    - restart iptables

**********
DECISION===>: PASS
**********
=========================:::310:::END!!!=========================
=========================:::311:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/firewall/handlers/main.yml
**********
- name: restart iptables
  service:
    name: iptables
    state: restarted
  become: true


**********
DECISION===>: PASS
**********
=========================:::311:::END!!!=========================
=========================:::312:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/statsd-ironic/tasks/main.yml
**********
---
- name: Configure Ironic to use StatsD for metrics
  ini_file:
    dest: /etc/ironic/ironic.conf
    section: "{{ item.section }}"
    option: "{{ item.option }}"
    value: "{{ item.value }}"
  become: True
  with_items:
    - { section: 'metrics', option: 'backend', value: 'statsd' }
    - { section: 'metrics', option: 'agent_backend', value: 'statsd' }
    - { section: 'metrics', option: 'global_prefix', value: '{{graphite_prefix}}' }
    - { section: 'metrics', option: 'agent_global_prefix', value: '{{graphite_prefix}}' }
    - { section: 'metrics_statsd', option: 'statsd_host', value: "{{ statsd_host }}"}
    - { section: 'metrics_statsd', option: 'statsd_port', value: "{{ statsd_port }}"}
    - { section: 'metrics_statsd', option: 'agent_statsd_host', value: "{{ statsd_host }}"}
    - { section: 'metrics_statsd', option: 'agent_statsd_port', value: "{{ statsd_port }}"}
  when: "{{ statsd_enabled }}"

- name: Restart Ironic services
  service:
    name: "{{ item }}"
    state: restarted
  become: True
  with_items:
    - openstack-ironic-api
    - openstack-ironic-conductor
    - openstack-ironic-inspector-dnsmasq
    - openstack-ironic-inspector
  when: "{{ statsd_enabled }}"

**********
DECISION===>: PASS
**********
=========================:::312:::END!!!=========================
=========================:::313:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/statsd-ironic/defaults/main.yml
**********
statsd_host: localhost
statsd_port: 8125
statsd_enabled: false

**********
DECISION===>: PASS
**********
=========================:::313:::END!!!=========================
=========================:::314:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/flavors/vars/main.yml
**********
---
#
# Var data for browbeat install.
#

browbeat_flavors:
  - name: m1.xtiny
    cpu: 1
    memory: 64
    disk: 1
  - name: m1.tiny-centos
    cpu: 1
    memory: 192
    disk: 8
  - name: m1.tiny
    cpu: 1
    memory: 512
    disk: 1
  - name: m1.small
    cpu: 1
    memory: 2048
    disk: 20
  - name: m1.medium
    cpu: 2
    memory: 4096
    disk: 40
  - name: m1.large
    cpu: 4
    memory: 8192
    disk: 80
  - name: m1.xlarge
    cpu: 8
    memory: 16384
    disk: 160

**********
DECISION===>: PASS
**********
=========================:::314:::END!!!=========================
=========================:::315:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/flavors/tasks/main.yml
**********
---
#
# Add flavors to OpenStack Cloud
#

# Ignore errors here incase the flavors already exist.
- name: Add flavors to overcloud
  shell: . {{ browbeat_venv }}/bin/activate; . {{ overcloudrc }}; nova flavor-create {{item.name}} auto {{item.memory}} {{item.disk}} {{item.cpu}}
  with_items: "{{browbeat_flavors}}"
  ignore_errors: true

**********
DECISION===>: PASS
**********
=========================:::315:::END!!!=========================
=========================:::316:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/workloads/tasks/main.yml
**********
---

- name: Check browbeat_network
  fail: msg="browbeat_network needs to be set"
  when: browbeat_network is not defined or browbeat_network is none

- name: Copy userdata files
  template:
    src: "{{ browbeat_workloads[item].src }}"
    dest: "{{ browbeat_workloads[item].dest }}"
  with_items: "{{ browbeat_workloads }}"

- name: Build images
  shell: source {{ overcloudrc }} ; openstack server create --wait --flavor m1.small --image {{ browbeat_workloads[item].image }} --nic net-id={{ browbeat_network }} --user-data {{ browbeat_workloads[item].dest }} {{ browbeat_workloads[item].name }} | egrep '\sid\s' | awk '{print $4}'
  register: workload_ids
  with_items: "{{ browbeat_workloads }}"

- name: Check status of images
  shell:  source {{ overcloudrc }} ; nova console-log {{ item.stdout }}
  register: guest_output
  until: guest_output.stdout.find("Browbeat workload installed") != -1
  retries: 30
  with_items: "{{ workload_ids.results }}"

- name: Clean up glance
  shell: source {{ overcloudrc }} ; openstack image delete {{ browbeat_workloads[item].name }}
  with_items: "{{ browbeat_workloads }}"
  ignore_errors: true

- name: Copy prepared workload guest into Glance
  shell: source {{ overcloudrc }} ; openstack server image create --wait --name {{ browbeat_workloads[item].name }} {{ browbeat_workloads[item].name }}
  with_items: "{{ browbeat_workloads }}"

- name: Update visibility
  shell: source {{ overcloudrc }} ; openstack image set {{ browbeat_workloads[item].name }} --public
  with_items: "{{ browbeat_workloads }}"

- name: Delete workload guests after copying
  shell: |
    . {{ overcloudrc }}
    openstack server delete {{browbeat_workloads[item].name}}
  with_items: "{{browbeat_workloads}}"

**********
DECISION===>: PASS
**********
=========================:::316:::END!!!=========================
=========================:::317:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/no-sshd-dns/tasks/main.yml
**********
# Disables DNS lookup in the overcloud sshd config file. Speeds up operations in environments with slow dns servers hugely.
---

- name: Disable DNS resolution in Overcloud sshd config
  lineinfile:
      dest: /etc/ssh/sshd_config
      line: "UseDNS no"
      state: present
      insertbefore: BOF
  when: disable_ssh_dns
  become: true
  become_user: root

- name: Restart sshd service
  service: name=sshd state=restarted
  when: disable_ssh_dns
  become: true
  become_user: root

**********
DECISION===>: PASS
**********
=========================:::317:::END!!!=========================
=========================:::318:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/common/tasks/main.yml
**********
---
#
# Browbeat Install Common
#
- name: Check external connectivity
  command: ping google.com -c 1 -q
  register: ping
  ignore_errors: true
  become: true
  tags:
    # Skip ANSIBLE0012 Commands should not change things if nothing needs doing
    # Need to check external activity every time
    - skip_ansible_lint

- name: Add DNS record
  become: true
  lineinfile: dest=/etc/resolv.conf state=present line="nameserver {{ dns_server }}" insertafter="^search"
  when: ping.rc != 0

**********
DECISION===>: PASS
**********
=========================:::318:::END!!!=========================
=========================:::319:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/nginx/tasks/main.yml
**********
---
#
# Install/run nginx for browbeat
#

- name: Install nginx, httpd-tools, httplib2, libsemanage-python
  package:
    name: "{{ item }}"
    state: present
  become: true
  with_items:
    - nginx
    - httpd-tools
    - python-httplib2
    - libsemanage-python

# SELinux boolean for nginx
- name: Apply SELinux boolean httpd_can_network_connect
  seboolean: name=httpd_can_network_connect state=yes persistent=yes
  when: "ansible_selinux['status'] == 'enabled'"

# create /etc/nginx/conf.d/ directory
- name: Create nginx directory structure
  file: path=/etc/nginx/conf.d/
    state=directory
    mode=0755

# deploy kibana.conf with FQDN
- name: Setup nginx reverse proxy for kibana
  template:
    src=kibana.conf.j2
    dest=/etc/nginx/conf.d/kibana.conf
    owner=root
    group=root
    mode=0644
  become: true
  register: nginx_needs_restart

# deploy basic nginx.conf 8080 vhost
- name: Setup nginx TCP/{{elk_server_ssl_cert_port}} for SSL certificate retrieval
  template:
    src=nginx.conf.j2
    dest=/etc/nginx/nginx.conf
    owner=root
    group=root
    mode=0644
  become: true

# start nginx service
- name: Start nginx service
  systemd:
    name: nginx.service
    state: restarted
  ignore_errors: true
  when: nginx_needs_restart != 0

- name: Check if nginx is in use
  shell: systemctl is-enabled nginx.service | egrep -qv 'masked|disabled'
  register: nginx_in_use
  ignore_errors: yes
  tags:
    # Skip ANSIBLE0012 Commands should not change things if nothing needs doing
    # Determine if nginx is enabled
    - skip_ansible_lint

- name: Set nginx to start on boot
  systemd:
    name: nginx.service
    enabled: yes
  when: nginx_in_use.rc != 0

# we need TCP/80 and TCP/8080 open
# determine firewall status and take action
# 1) use firewall-cmd if firewalld is utilized
# 2) insert iptables rule if iptables is used

# Firewalld
- name: Determine if firewalld is in use
  shell: systemctl is-enabled firewalld.service | egrep -qv 'masked|disabled'
  ignore_errors: true
  register: firewalld_in_use
  no_log: true
  tags:
    # Skip ANSIBLE0012 Commands should not change things if nothing needs doing
    # Need to check if firewall is active
    - skip_ansible_lint

- name: Determine if firewalld is active
  shell: systemctl is-active firewalld.service | grep -vq inactive
  ignore_errors: true
  register: firewalld_is_active
  no_log: true
  tags:
    # Skip ANSIBLE0012 Commands should not change things if nothing needs doing
    # Need to check if firewall is active
    - skip_ansible_lint

- name: Determine if TCP/{{nginx_kibana_port}} is already active
  shell: firewall-cmd --list-ports | egrep -q "^{{nginx_kibana_port}}/tcp"
  ignore_errors: true
  register: firewalld_nginx_kibana_port_exists
  no_log: true
  tags:
    # Skip ANSIBLE0012 Commands should not change things if nothing needs doing
    # Need to check if firewall rule already exists
    - skip_ansible_lint

# add firewall rule via firewall-cmd
- name: Add firewall rule for TCP/{{nginx_kibana_port}} (firewalld)
  command: "{{ item }}"
  with_items:
    - firewall-cmd --zone=public --add-port={{nginx_kibana_port}}/tcp --permanent
    - firewall-cmd --reload
  ignore_errors: true
  become: true
  when: firewalld_in_use.rc == 0 and firewalld_is_active.rc == 0 and firewalld_nginx_kibana_port_exists.rc != 0

# iptables-services
- name: check firewall rules for TCP/{{nginx_kibana_port}} (iptables-services)
  shell: grep "dport {{nginx_kibana_port}} \-j ACCEPT" /etc/sysconfig/iptables | wc -l
  ignore_errors: true
  register: iptables_nginx_kibana_port_exists
  failed_when: iptables_nginx_kibana_port_exists == 127
  no_log: true
  tags:
    # Skip ANSIBLE0012 Commands should not change things if nothing needs doing
    # Need to check if firewall rule already exists
    - skip_ansible_lint

- name: Add firewall rule for TCP/{{nginx_kibana_port}} (iptables-services)
  lineinfile:
    dest: /etc/sysconfig/iptables
    line: '-A INPUT -p tcp -m tcp --dport {{nginx_kibana_port}} -j ACCEPT'
    regexp: '^INPUT -i lo -j ACCEPT'
    insertbefore: '-A INPUT -i lo -j ACCEPT'
    backup: yes
  when: firewalld_in_use.rc != 0 and firewalld_is_active.rc != 0 and iptables_nginx_kibana_port_exists.stdout|int == 0
  register: iptables_needs_restart

- name: Restart iptables-services for TCP/{{nginx_kibana_port}} (iptables-services)
  shell: systemctl restart iptables.service
  ignore_errors: true
  when: iptables_needs_restart != 0 and firewalld_in_use.rc != 0 and firewalld_is_active.rc != 0
  tags:
    # Skip ANSIBLE0013 Use shell only when shell functionality is required
    # No systemctl module available in current stable release (Ansible 2.1)
    - skip_ansible_lint

# Firewalld
- name: Determine if TCP/{{elk_server_ssl_cert_port}} is already active
  shell: firewall-cmd --list-ports | egrep -q "^{{elk_server_ssl_cert_port}}/tcp"
  ignore_errors: true
  register: firewalld_elk_server_ssl_port_exists
  no_log: true
  tags:
    # Skip ANSIBLE0012 Commands should not change things if nothing needs doing
    # Need to check if firewall rule already exists
    - skip_ansible_lint

# add firewall rule via firewall-cmd
- name: Add firewall rule for TCP/{{elk_server_ssl_cert_port}} (firewalld)
  command: "{{ item }}"
  with_items:
    - firewall-cmd --zone=public --add-port={{elk_server_ssl_cert_port}}/tcp --permanent
    - firewall-cmd --reload
  ignore_errors: true
  become: true
  when: firewalld_in_use.rc == 0 and firewalld_is_active.rc == 0 and firewalld_elk_server_ssl_port_exists.rc != 0

# iptables-services
- name: check firewall rules for TCP/{{elk_server_ssl_cert_port}} (iptables-services)
  shell: grep "dport {{elk_server_ssl_cert_port}} \-j ACCEPT" /etc/sysconfig/iptables | wc -l
  ignore_errors: true
  register: iptables_elk_server_ssl_port_exists
  failed_when: iptables_elk_server_ssl_port_exists == 127
  no_log: true
  tags:
    # Skip ANSIBLE0012 Commands should not change things if nothing needs doing
    # Need to check if firewall rule already exists
    - skip_ansible_lint

- name: Add firewall rule for TCP/{{elk_server_ssl_cert_port}} (iptables-services)
  lineinfile:
    dest: /etc/sysconfig/iptables
    line: '-A INPUT -p tcp -m tcp --dport {{elk_server_ssl_cert_port}} -j ACCEPT'
    regexp: '^INPUT -i lo -j ACCEPT'
    insertbefore: '-A INPUT -i lo -j ACCEPT'
    backup: yes
  when: firewalld_in_use.rc != 0 and firewalld_is_active.rc != 0 and iptables_elk_server_ssl_port_exists.stdout|int == 0
  register: iptables_needs_restart

- name: Restart iptables-services for TCP/{{elk_server_ssl_cert_port}} (iptables-services)
  shell: systemctl restart iptables.service
  ignore_errors: true
  when: iptables_needs_restart != 0 and firewalld_in_use.rc != 0 and firewalld_is_active.rc != 0
  tags:
    # Skip ANSIBLE0013 Use shell only when shell functionality is required
    # No systemctl module available in current stable release (Ansible 2.1)
    - skip_ansible_lint

**********
DECISION===>: PASS
**********
=========================:::319:::END!!!=========================
=========================:::320:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/rally/tasks/main.yml
**********
---
#
# Browbeat's Rally Install
#

- name: Create rally virtualenv
  command: virtualenv {{ rally_venv }} creates={{ rally_venv }}

- name: Rally Add browbeat to Python path
  shell: echo 'export PYTHONPATH=$PYTHONPATH:{{ browbeat_path }}' >> {{ rally_venv }}/bin/activate

- name: Setup rally-venv CA certificate path
  lineinfile:
    dest: "{{ rally_venv }}/bin/activate"
    line: 'export REQUESTS_CA_BUNDLE={{ overcloud_ca_path }}'
  when: overcloud_ca_path is defined

- name: Install Rally with OpenStack plugins into rally-venv
  pip:
    name: rally-openstack
    version: "{{ rally_version }}"
    virtualenv: "{{ rally_venv }}"

- name: Install elasticsearch into rally-venv
  pip:
    name: elasticsearch
    virtualenv: "{{ rally_venv }}"

- name: Create rally configuration directory
  file:
    path: "{{ rally_venv }}/etc/rally"
    state: directory

- name: Setup rally.conf
  template:
    src: rally.conf.j2
    dest: "{{ rally_venv }}/etc/rally/rally.conf"

- name: Setup rally database
  shell: . {{ rally_venv }}/bin/activate; rally db recreate

- name: Setup rally deployment
  shell: . {{ rally_venv }}/bin/activate; . {{ overcloudrc }}; rally deployment create --fromenv --name overcloud

- name: Check Rally deployment
  shell: . {{ rally_venv }}/bin/activate; . {{ overcloudrc }}; rally deployment check
  register: rally_deployment_check

- name: Fail if Rally deployment cannot be verfied
  fail:
    msg: "Failed to verify that your deployment is ready to benchmark"
  when: rally_deployment_check.rc != 0

**********
DECISION===>: PASS
**********
=========================:::320:::END!!!=========================
=========================:::321:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/osp_version/tasks/main.yml
**********
---
#
# Slurp OSP version file
#

- name: Check if /etc/rhosp-release exists
  stat:
    path: /etc/rhosp-release
  register: rhosp_release_stat

- name: Get OSP Version
  become: true
  slurp:
    src: "/etc/rhosp-release"
  register: osp_version
  when: rhosp_release_stat.stat.exists

- debug: msg="WARNING /etc/rhosp-release not found, defaulting version of OSP to Pike"
  when: not rhosp_release_stat.stat.exists

- name: Set OSP Version Default
  set_fact:
    osp_version:
      content: "{{'Pike' | b64encode}}"
  when: not rhosp_release_stat.stat.exists

**********
DECISION===>: PASS
**********
=========================:::321:::END!!!=========================
=========================:::322:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/rsyslog-templates/tasks/main.yml
**********
---
# configures rsyslog on the over and undercloud hosts

- name: Create cache dir if configured
  file:
    path: "/srv/data/rsyslog/"
    state: directory
  become: true
  when: disk_backed_rsyslog

- name: Copy log location detector
  copy:
    src: openstack-log-locator.py
    dest: /tmp/openstack-log-locator.py
  when: not rsyslog_aggregator

- name: Gather info about services
  command: "python /tmp/openstack-log-locator.py {{item}}"
  with_items: "{{openstack_services}}"
  register: log_config_lines
  become: true
  when: not rsyslog_aggregator

- name: Delete existing conf files in case we change roles
  file:
    path: "/etc/rsyslog.d/{{item}}"
    state: absent
  become: true
  with_items:
    - 00-queue.conf
    - 01-modules.conf
    - 02-templates.conf
    - 03-rules.conf
    - 04-inputs.conf
    - 05-outputs.conf

- name: Template rsyslog for direct to elastic
  template:
    src: "{{item}}"
    dest: "/etc/rsyslog.d/{{item[:-3]}}"
  become: true
  with_items:
    - 00-queue.conf.j2
    - 01-modules.conf.j2
    - 02-templates.conf.j2
    - 03-rules.conf.j2
    - 04-inputs.conf.j2
    - 05-outputs.conf.j2
  when: (not rsyslog_forwarding) and (not rsyslog_aggregator)

- name: Template rsyslog for forwarding
  template:
    src: "{{item}}"
    dest: "/etc/rsyslog.d/{{item[:-3]}}"
  become: true
  with_items:
    - 00-queue.conf.j2
    - 01-modules.conf.j2
    - 02-templates.conf.j2
    - 03-rules.conf.j2
    - 04-inputs.conf.j2
    - 05-outputs.conf.j2
  when: (rsyslog_forwarding) and (not rsyslog_aggregator)

- name: Template rsyslog for aggregating
  template:
    src: "{{item}}"
    dest: "/etc/rsyslog.d/{{item[:-3]}}"
  become: true
  with_items:
    - 00-queue.conf.j2
    - 01-modules.conf.j2
    - 02-templates.conf.j2
    - 03-rules.conf.j2
    - 05-outputs.conf.j2
  when: rsyslog_aggregator


- name: Remove legacy config directives
  lineinfile:
    line: "$SystemLogSocketName /run/systemd/journal/syslog"
    state: absent
    dest: /etc/rsyslog.d/listen.conf
  become: true

- name: Template primary config
  template:
    src: rsyslog.conf.j2
    dest: /etc/rsyslog.conf
  become: true

- name: Install selinux utils
  package:
    name: policycoreutils-python
    state: present
  become: true

- name: Add tcp reception port
  seport:
    ports: "{{rsyslog_aggregator_port}}"
    proto: tcp
    setype: syslogd_port_t
    state: present
  become: true
  when: rsyslog_aggregator

- name: Add es port access to rsyslog service perms
  seport:
    ports: "{{rsyslog_elasticsearch_port}}"
    proto: tcp
    setype: syslogd_port_t
    state: present
  become: true
  when: rsyslog_aggregator

# cool feature, exits 1 on invalid configs
- name: Validate rsyslog config
  command: "rsyslogd -nN 1"
  become: true

- name: restart rsyslog
  service:
    name: rsyslog
    state: restarted
  become: true

# If you are setting up an aggregator a failure here means the
# aggregator is not accessible to the outside world, debug selinux
#
# If you are deploying a client with aggregation this failing means
# that the es server you are pointing at does not have an aggregator
# setup, either deploy without aggregation or use the rsyslog_aggregator
# playbook to deploy one.
- name: validate connection
  wait_for:
    host: "{{rsyslog_aggregator_server}}"
    port: "{{rsyslog_aggregator_port}}"
    state: started
    timeout: 10
  when: rsyslog_aggregator or rsyslog_forwarding

# syslog as a system process lives under some very restrictive selinux rules, this is the best
# way I've found to get to to work reliably. On a prod system you would probably want to manually
# validate that the .te file produced makes sense.
- name: Generate and install syslog policy file
  shell: "grep syslog /var/log/audit/audit.log  | audit2allow -M syslogd_t; semodule -i syslogd_t.pp"
  become: true
  ignore_errors: true

**********
DECISION===>: PASS
**********
=========================:::322:::END!!!=========================
=========================:::323:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/rsyslog-templates/defaults/main.yml
**********
openstack_services:
   - ceilometer
   - cinder
   - cluster
   - congress
   - glance
   - gnocchi
   - heat
   - horizon
   - httpd
   - ironic
   - ironic-inspector
   - keystone
   - mariadb
   - mongodb
   - mysql
   - neutron
   - nova
   - openvswitch
   - ovs
   - rabbitmq
   - rabbitmq
   - redis
   - swift
   - zaqar
rsyslog_elasticsearch_server: ""
rsyslog_elasticsearch_port: "9200"
rsyslog_aggregator_server: ""
rsyslog_aggregator_port: "7894"
rsyslog_cloud_name: "{{graphite_prefix}}"
disk_backed_rsyslog: false
rsyslog_forwarding: true
rsyslog_aggregator: false

**********
DECISION===>: PASS
**********
=========================:::323:::END!!!=========================
=========================:::324:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/collectd-openstack/tasks/main.yml
**********
---
#
# Install/run collectd for Browbeat
#

- name: Remove Non-EPEL collectd install
  yum:
    name: "{{ item }}"
    state: absent
  become: true
  with_items:
    - libcollectdclient
    - collectd
    - collectd-apache
    - collectd-ceph
    - collectd-mysql
    - collectd-turbostat
  when: collectd_from_epel

- name: Clean Non-EPEL collectd configuration
  shell: "rm -rf /etc/collectd.d/*.conf"
  become: true
  when: collectd_from_epel

#
# (akrzos) yum module works at this point due to the fact the EPEL repo now exists.  EPEL rpm is
# installed at this point in time.
#
- name: Install collectd rpms
  yum:
    name: "{{ item }}"
    state: present
    disablerepo: "*"
    enablerepo: "epel"
  become: true
  with_items:
    - collectd
    - collectd-apache
    - collectd-ceph
    - collectd-mysql
    - collectd-ping
    - collectd-turbostat
  when: collectd_from_epel

# (sai) Since we moved to containers we don't have java installed on the host
# anymore but it is needed for collectd-java
- name: Add repository
  yum_repository:
    name: CentOS-7-Base
    description: Core CentOS7 Packages
    baseurl: http://mirror.centos.org/centos/7/os/$basearch/
    enabled: yes
  become: true
  register: repo_add
  when: ('controller' in group_names and {{opendaylight_java_plugin}} == true)

- name: Add key
  rpm_key:
    state: present
    key: https://www.centos.org/keys/RPM-GPG-KEY-CentOS-7
  become: true

# (sai) Separating out collectd java rpms as they have a lot of dependencies and
# are only required for ODL monitoring on controllers only
- name: Install collectd java specific rpms
  yum:
    name: "{{ item }}"
    state: present
  become: true
  with_items:
    - java-1.8.0-openjdk
    - collectd-java
    - collectd-generic-jmx
  when: (repo_add is success and 'controller' in group_names and {{opendaylight_java_plugin}} == true)

- name: Remove repository
  yum_repository:
    name:  CentOS-7-Base
    state: absent
  become: true
  when: (repo_add is success and 'controller' in group_names and {{opendaylight_java_plugin}} == true)

# Iostat plugin requires sysstat since shelling iostat for stats, Also it is
# handy to have sysstat.
# (akrzos) Ignore errors on install since we attempt to install without
# checking any vars if we really want/require sysstat
- name: (Iostat python plugin) Install sysstat
  yum:
    name: sysstat
    state: present
  become: true
  ignore_errors: true

- name: (Keystone Token Count) Install libdbi mysql driver
  yum:
    name: "{{item}}"
    state: present
  become: true
  when: "(('controller' in group_names and {{keystone_overcloud_collectd_plugin}} == true and '{{inventory_hostname}}' == groups['controller'][0]) or ('undercloud' in group_names and {{keystone_undercloud_collectd_plugin}} == true))"
  with_items:
    - libdbi-dbd-mysql
    - collectd-dbi

# Get mysql's root password
# Works with: Newton, Ocata
- name: (Controller) Get mysql root password
  command: hiera -c /etc/puppet/hiera.yaml mysql::server::root_password
  become: true
  register: mysql_root_password
  when: "'controller' in group_names"

- name: (Undercloud) Get mysql root password
  shell: cat /home/stack/undercloud-passwords.conf | grep 'undercloud_db_password=' | sed 's/undercloud_db_password=//g'
  register: undercloud_mysql_password
  when: "'undercloud' in group_names"

- name: (Undercloud) Get password
  become: true
  shell: "hiera admin_password | awk '{$0=\"Environment=OS_PASSWORD=\"$0;print }'"
  register: undercloud_password
  when: "('undercloud' in group_names and {{gnocchi_status_undercloud_collectd_plugin}} == true)"

- name: (Undercloud) Get stackrc
  remote_user: "{{local_remote_user}}"
  shell: "cat /home/stack/stackrc | egrep '^OS_[AUT]|^OS_PRO' | awk '{$0=\"Environment=\"$0;print }'"
  register: stackrc_file
  when: "('undercloud' in group_names and {{gnocchi_status_undercloud_collectd_plugin}} == true)"

- name: (Undercloud) Add environment variables to collectd.service systemd file
  become: true
  lineinfile:
    dest: /usr/lib/systemd/system/collectd.service
    insertafter: '\[Service\]'
    line: "{{item}}"
  with_items: "{{stackrc_file.stdout_lines | default(omit)}}"
  when: "('undercloud' in group_names and {{gnocchi_status_undercloud_collectd_plugin}} == true)"

- name: (Undercloud) Add environment variables to collectd.service systemd file
  become: true
  lineinfile:
    dest: /usr/lib/systemd/system/collectd.service
    insertafter: '\[Service\]'
    line: "{{item}}"
  with_items: "{{undercloud_password.stdout_lines | default(omit)}}"
  when: "('undercloud' in group_names and {{gnocchi_status_undercloud_collectd_plugin}} == true)"

- name: (Controller, delegated to UC) Get overcloudrc
  remote_user: "{{local_remote_user}}"
  shell: "cat /home/stack/overcloudrc | grep 'export OS' | awk '{gsub(/export /,\"Environment=\");print }'"
  delegate_to: "{{groups['undercloud'][0]}}"
  register: overcloudrc_file
  when: "'controller' in group_names and gnocchi_status_controller_collectd_plugin == true and inventory_hostname == groups['controller'][0]"

- name: (Controller) Add environment variables to collectd.service systemd file
  become: true
  lineinfile:
    dest: /usr/lib/systemd/system/collectd.service
    insertafter: '\[Service\]'
    line: "{{item}}"
  with_items: "{{overcloudrc_file.stdout_lines | default(omit)}}"
  when: "'controller' in group_names and gnocchi_status_controller_collectd_plugin == true and inventory_hostname == groups['controller'][0]"

# Apache Request Response Timing
- name: (Newton, Ocata) Deploy Apache httpd.conf for request timings
  become: true
  copy:
    src: httpd.conf
    dest: /etc/httpd/conf/httpd.conf
    owner: root
    group: root
    mode: 0644
    backup: true
  when: "('controller' in group_names and {{apache_controller_collectd_request_time}} == true) and ('Newton' in osp_version['content'] | b64decode or 'Ocata' in osp_version['content'] | b64decode)"

- name: (Queens/Pike) Patch Apache httpd.conf for request timings
  become: true
  shell: sed -i 's/LogFormat "%[ah] %l %u %t \\"%r\\" %>s %b \\"%{Referer}i\\" \\"%{User-Agent}i\\"" combined/LogFormat "%h %l %u %t RT:%D \\"%r\\" %>s %b \\"%{Referer}i\\" \\"%{User-Agent}i\\"" combined/g' {{item}}
  with_items:
    - /var/lib/config-data/puppet-generated/gnocchi/etc/httpd/conf/httpd.conf
    - /var/lib/config-data/puppet-generated/keystone/etc/httpd/conf/httpd.conf
    - /var/lib/config-data/puppet-generated/nova_placement/etc/httpd/conf/httpd.conf
  when:
    - "'controller' in group_names"
    - apache_controller_collectd_request_time
    - "('Queens' in osp_version['content'] | b64decode or 'Pike' in osp_version['content'] | b64decode)"

- name: (Newton, Ocata) Restart Apache
  become: true
  service:
    name: httpd
    state: restarted
    enabled: true
  when: "('controller' in group_names and {{apache_controller_collectd_request_time}} == true) and ('Newton' in osp_version['content'] | b64decode or 'Ocata' in osp_version['content'] | b64decode)"

- name: (Queens/Pike) Restart Gnocchi/Keystone/Nova Placement API Containers
  become: true
  command: docker restart {{item}}
  with_items:
    - gnocchi_api
    - keystone
    - nova_placement
  when:
    - "'controller' in group_names"
    - apache_controller_collectd_request_time
    - "('Queens' in osp_version['content'] | b64decode or 'Pike' in osp_version['content'] | b64decode)"
# End Apache Request Response Timing

# Apache Monitoring
- name: Deploy Apache mod_status conf
  template:
    src: 00-browbeat_mod_status.conf.j2
    dest: /etc/httpd/conf.d/00-browbeat_mod_status.conf
    owner: root
    group: root
  become: true
  when: "(('controller' in group_names and {{apache_controller_collectd_plugin}} == true) or ('undercloud' in group_names and {{apache_undercloud_collectd_plugin}} == true))"

- name: (Undercloud) Allow httpd to listen to port ({{apache_undercloud_mod_status_port}})
  command: "/usr/sbin/semanage port -m -t http_port_t -p tcp {{apache_undercloud_mod_status_port}}"
  become: true
  when: "('undercloud' in group_names and {{apache_undercloud_collectd_plugin}} == true)"

- name: (Controller) Allow httpd to listen to port ({{apache_controller_mod_status_port}})
  command: "/usr/sbin/semanage port -m -t http_port_t -p tcp {{apache_controller_mod_status_port}}"
  become: true
  when: "(ansible_selinux['status'] == 'enabled') and ('controller' in group_names and {{apache_controller_collectd_plugin}} == true)"

- name: Restart Apache
  service:
    name: httpd
    state: restarted
    enabled: true
  become: true
  when: "(('controller' in group_names and {{apache_controller_collectd_plugin}} == true) or ('undercloud' in group_names and {{apache_undercloud_collectd_plugin}} == true))"
# End Apache Monitoring

- name: Reload systemd units
  command: systemctl daemon-reload
  become: true
  when: "('controller' in group_names and gnocchi_status_controller_collectd_plugin == true and inventory_hostname == groups['controller'][0]) or ('undercloud' in group_names and gnocchi_status_undercloud_collectd_plugin == true)"

- name: (All Nodes) Copy python plugins
  copy:
    src: "{{item.src}}"
    dest: "{{item.dest}}"
    owner: root
    group: root
    mode: 0755
  become: true
  with_items:
    - src: collectd_iostat_python.py
      dest: /usr/local/bin/collectd_iostat_python.py

- name: (Undercloud/Controller-0) Copy python plugins
  copy:
    src: "{{item.src}}"
    dest: "{{item.dest}}"
    owner: root
    group: root
    mode: 0755
  become: true
  with_items:
    - src: collectd_ceph_storage.py
      dest: /usr/local/bin/collectd_ceph_storage.py
    - src: collectd_gnocchi_status.py
      dest: /usr/local/bin/collectd_gnocchi_status.py
    - src: collectd_rabbitmq_monitoring.py
      dest: /usr/local/bin/collectd_rabbitmq_monitoring.py
    - src: collectd_swift_stat.py
      dest: /usr/local/bin/collectd_swift_stat.py
  when: "('controller' in group_names and inventory_hostname == groups['controller'][0]) or ('undercloud' in group_names)"

- name: Copy python plugins
  copy:
    src: "{{item.src}}"
    dest: "{{item.dest}}"
    owner: root
    group: root
    mode: 0755
  become: true
  with_items:
    - src: collectd_ovsagent.py
      dest: /usr/local/bin/collectd_ovsagent.py
  when: "('controller' in group_names ) or ('compute' in group_names) or ('networker' in group_names)"

# Rabbitmq monitoring
- name: Install pyrabbit
  easy_install:
    name: pyrabbit
  become: true
  when: "(('controller' in group_names and {{rabbitmq_controller_collectd_plugin}} == true and '{{inventory_hostname}}' == groups['controller'][0]) or ('undercloud' in group_names and {{rabbitmq_undercloud_collectd_plugin}} == true))"

- name: Enable Rabbitmq management plugin
  command: /sbin/rabbitmq-plugins enable rabbitmq_management
  become: true
  when: "(('controller' in group_names and {{rabbitmq_controller_collectd_plugin}} == true and '{{inventory_hostname}}' == groups['controller'][0]) or ('undercloud' in group_names and {{rabbitmq_undercloud_collectd_plugin}} == true))"

- name: (Undercloud) Get ctlplane ip address
  shell: ip r | egrep 'br-ctlplane\s*proto kernel' | awk '{print $NF}'
  register: undercloud_ctlplane_ip_address
  become: true
  when: "('undercloud' in group_names and {{rabbitmq_undercloud_collectd_plugin}} == true)"

- name: (Undercloud) Get Rabbitmq username
  shell: cat undercloud-passwords.conf | grep undercloud_rabbit_username | awk -F '=' '{print $2}'
  register: undercloud_rabbitmq_username
  when: "('undercloud' in group_names and {{rabbitmq_undercloud_collectd_plugin}} == true)"

- name: (Undercloud) Get Rabbitmq password
  shell: cat undercloud-passwords.conf | grep undercloud_rabbit_password | awk -F '=' '{print $2}'
  register: undercloud_rabbitmq_password
  when: "('undercloud' in group_names and {{rabbitmq_undercloud_collectd_plugin}} == true)"

# Works with: Newton, Ocata
- name: (Controller) Get Rabbitmq username
  command: hiera -c /etc/puppet/hiera.yaml rabbitmq::default_user
  register: controller0_rabbitmq_username
  become: true
  when: "'controller' in group_names and rabbitmq_controller_collectd_plugin == true and inventory_hostname == groups['controller'][0]"

# Works with: Newton, Ocata
- name: (Controller) Get Rabbitmq password
  command: hiera -c /etc/puppet/hiera.yaml rabbitmq::default_pass
  register: controller0_rabbitmq_password
  become: true
  when: "'controller' in group_names and rabbitmq_controller_collectd_plugin == true and inventory_hostname == groups['controller'][0]"
# End Rabbitmq monitoring

# Gnocchi Swift Stat Service monitoring
- name: Get Gnocchi Swift AuthURL
  command: hiera -c /etc/puppet/hiera.yaml gnocchi::storage::swift::swift_authurl
  register: controller0_gnocchi_swift_authurl
  become: true
  when: "'controller' in group_names and swift_stat_controller_collectd_plugin == true and inventory_hostname == groups['controller'][0]"

- name: Get Gnocchi Swift Auth Version
  command: hiera -c /etc/puppet/hiera.yaml gnocchi::storage::swift::swift_auth_version
  register: controller0_gnocchi_swift_authversion
  become: true
  when: "'controller' in group_names and swift_stat_controller_collectd_plugin == true and inventory_hostname == groups['controller'][0]"

- name: Get Gnocchi Swift User
  shell: hiera -c /etc/puppet/hiera.yaml gnocchi::storage::swift::swift_user | sed 's/service://'
  register: controller0_gnocchi_swift_user
  become: true
  when: "'controller' in group_names and swift_stat_controller_collectd_plugin == true and inventory_hostname == groups['controller'][0]"

- name: Get Gnocchi Swift Key
  command: hiera -c /etc/puppet/hiera.yaml gnocchi::storage::swift::swift_key
  register: controller0_gnocchi_swift_auth_key
  become: true
  when: "'controller' in group_names and swift_stat_controller_collectd_plugin == true and inventory_hostname == groups['controller'][0]"
# End Swift Stat Service monitoring

# CephStorage OSD monitoring
# Only Monitors a single OSD on each CephStorage Node
- name: Get 1st OSD socket
  shell: ls /var/run/ceph/ceph-osd.*.asok | head -n 1 | egrep -o '[0-9]+'
  register: cephstorage_osd_socket
  become: true
  when: "('cephstorage' in group_names and {{ceph_storage_collectd_plugin}} == true)"
# End CephStorage OSD monitoring

- name: Configure collectd.conf
  template:
    src: "{{config_type}}.collectd.conf.j2"
    dest: /etc/collectd.conf
    owner: root
    group: root
    mode: 0644
  become: true

# OpenDaylight Monitoring
- name: Symlink libjvm
  file:
    src: /usr/lib/jvm/jre/lib/amd64/server/libjvm.so
    dest: /usr/lib64/libjvm.so
    state: link
  become: true
  when: ('controller' in group_names and {{opendaylight_java_plugin}} == true)

#
# Configure selinux bits
#
- name: Check for collectd permissive
  shell: /sbin/semodule -l | grep -q permissive_collectd_t
  become: true
  register: collectd_permissive
  ignore_errors: true
  changed_when: false
  when: "ansible_selinux['status'] == 'enabled'"

- name: Set permissive for collectd
  command: /sbin/semanage permissive -a collectd_t
  become: true
  when: "ansible_selinux['status'] == 'enabled' and collectd_permissive.rc != 0"

#
# Additional policy bits may be needed for exec
#
- name: Collectd policy customization
  copy:
    src: custom-collectd.pp
    dest: /root/custom-collectd.pp
    owner: root
    group: root
    mode: 0644
  become: true
  when: "ansible_selinux['status'] == 'enabled'"

- name: Check for collectd custom
  shell: /sbin/semodule -l | grep -q custom-collectd
  become: true
  register: collectd_custom
  ignore_errors: true
  changed_when: false
  when: "ansible_selinux['status'] == 'enabled'"

- name: Set custom policy for collectd
  command: /sbin/semodule -i /root/custom-collectd.pp
  become: true
  when: "ansible_selinux['status'] == 'enabled' and collectd_custom.rc != 0"

#
# Start collectd service
#
- name: Setup collectd service
  service:
    name: collectd
    state: restarted
    enabled: true
  become: true

**********
DECISION===>: Possible Communication containing cleartext password
**********
=========================:::324:::END!!!=========================
=========================:::325:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/collectd-openstack/defaults/main.yml
**********
########################################
# Collectd Configuration
########################################
# Install collectd from EPEL
collectd_from_epel: true
# Interval in seconds
collectd_interval: 10
# Typically: carbon-cache port=2003 or Graphite with carbon-relay=2013
collectd_write_graphite_port: 2003
# Run collectd on specific openstack nodes:
collectd_undercloud: true
collectd_controller: true
collectd_blockstorage: true
collectd_objectstorage: true
collectd_cephstorage: true
collectd_compute: false

# Opt-In Collectd plugins configuration:
########################
# Apache plugin
########################
# Undercloud
apache_undercloud_collectd_plugin: false
apache_undercloud_mod_status_port: 5001
# Overcloud Controller
apache_controller_collectd_plugin: false
apache_controller_mod_status_port: 5001

########################
# Apache request time
########################
# Setups up Apache to log request time and collectd to grab request time from
# httpd log files.  This provides request times from Apache for Keystone,
# Gnocchi, and Nova Placement APIs hosted under httpd.
apache_controller_collectd_request_time: false

########################
# Ceph plugin
########################
# Overcloud Controller
# Python plugin is prefered (At the Current Moment)
ceph_controller_collectd_radosbench_plugin: false
ceph_controller_collectd_radosbench_interval: 30
ceph_controller_collectd_mon_plugin: false
ceph_controller_collectd_mon_interval: 10
ceph_controller_collectd_osd_plugin: false
ceph_controller_collectd_osd_interval: 10
ceph_controller_collectd_pg_plugin: false
ceph_controller_collectd_pg_interval: 10
ceph_controller_collectd_pool_plugin: false
ceph_controller_collectd_pool_interval: 10
# Collectd provided Ceph plugins
ceph_controller_collectd_plugin: false
ceph_storage_collectd_plugin: false

########################
# Gnocchi Status plugin
########################
gnocchi_status_undercloud_collectd_plugin: false
gnocchi_status_undercloud_collectd_interval: 10
gnocchi_status_controller_collectd_plugin: false
gnocchi_status_controller_collectd_interval: 10

########################
# Disk/IOStat plugin
########################
# Disk plugin metrics are opt-out, IOStat metrics are opt-in
disk_undercloud_collectd_plugin: true
disk_controller_collectd_plugin: true
disk_cephstorage_collectd_plugin: true
disk_compute_collectd_plugin: true
disk_blockstorage_collectd_plugin: true
disk_objectstorage_collectd_plugin: true
# Enable these for more comprehensive IOStat metrics
iostat_undercloud_collectd_plugin: false
iostat_undercloud_collectd_interval: 10
iostat_controller_collectd_plugin: false
iostat_controller_collectd_interval: 10
iostat_cephstorage_collectd_plugin: false
iostat_cephstorage_collectd_interval: 10
iostat_compute_collectd_plugin: false
iostat_compute_collectd_interval: 10
iostat_blockstorage_collectd_plugin: false
iostat_blockstorage_collectd_interval: 10
iostat_objectstorage_collectd_plugin: false
iostat_objectstorage_collectd_interval: 10

########################
# Keystone token count
########################
# If you have UUID tokens, we can count those via the collectd dbi plugin
keystone_undercloud_collectd_plugin: false
keystone_overcloud_collectd_plugin: false

########################
# Rabbitmq plugin
########################
rabbitmq_undercloud_collectd_plugin: false
rabbitmq_undercloud_collectd_interval: 10
rabbitmq_controller_collectd_plugin: false
rabbitmq_controller_collectd_interval: 10

# Queues to monitor message count on Undercloud
undercloud_monitored_queues:
  - "metering.sample"
  - "event.sample"
  - "notifications.sample"
  - "notifications.audit"
  - "notifications.info"
  - "notifications.warn"
  - "notifications.error"
  - "notifications.critical"

# Queues to monitor message count on Controllers
controller_monitored_queues:
  - "metering.sample"
  - "event.sample"
  - "notifications.sample"
  - "notifications.audit"
  - "notifications.info"
  - "notifications.warn"
  - "notifications.error"
  - "notifications.critical"

########################
# ovsagent monitoring
########################
ovsagent_compute_monitor: false
ovsagent_controller_monitor: false

controller_monitored_ints:
  - "tap"

compute_monitored_ints:
  - "qvo"

controller_monitored_ns:
  - "qrouter"
  - "qdhcp"

########################
# Swift stat plugin
########################
# Provides metrics on Swift Account using Gnocchi Swift Configuration
swift_stat_controller_collectd_plugin: false
swift_stat_controller_collectd_interval: 10


############################
# OpenDaylight JAVA Plugin
###########################

# Plugin assumes that JAVA is already installed on the host
opendaylight_java_plugin: false
karaf_user: karaf
karaf_password: karaf

########################
# tail plugin
########################
# Determines if WARN/INFO messages are also counted
regex_warn: false
regex_info: false

########################################################
# Ping Plugin for Latency and Jitter between controllers
########################################################
# Might result in more network traffic
ping_plugin: false
ping_interval: 1

**********
DECISION===>: PASS
**********
=========================:::325:::END!!!=========================
=========================:::326:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/graphite/tasks/main.yml
**********
---
#
# Install/run graphite-web for browbeat
#

- name: Install graphite rpms
  package:
    name: "{{ item }}"
    state: present
  become: true
  with_items:
    - graphite-web
    - python-carbon
    - expect

- name: Check for graphite.db sqlite
  command: ls /var/lib/graphite-web/graphite.db
  ignore_errors: true
  register: graphite_db_installed

- name: Copy setup-graphite-db.exp
  copy:
    src: setup-graphite-db.exp
    dest: /root/setup-graphite-db.exp
    owner: root
    group: root
    mode: 0755
  become: true

- name: Create initial graphite db
  shell: /root/setup-graphite-db.exp {{ graphite_username }} {{ graphite_password }} && chown apache:apache /var/lib/graphite-web/graphite.db
  become: true
  when: graphite_db_installed.rc != 0
  notify:
    - restart apache

- name: Setup httpd graphite-web config
  template:
    src: graphite-web.conf.j2
    dest: /etc/httpd/conf.d/graphite-web.conf
    owner: root
    group: root
    mode: 0644
  become: true
  notify:
    - restart apache

### begin firewall ###
# we need TCP/80 open
# determine firewall status and take action
# 1) use firewall-cmd if firewalld is utilized
# 2) insert iptables rule if iptables is used

# Firewalld
- name: (graphite-web) Determine if firewalld is in use
  shell: systemctl is-enabled firewalld.service | egrep -qv 'masked|disabled'
  ignore_errors: true
  register: firewalld_in_use
  no_log: true

- name: (graphite-web) Determine if firewalld is active
  shell: systemctl is-active firewalld.service | grep -vq inactive
  ignore_errors: true
  register: firewalld_is_active
  no_log: true

- name: (graphite-web) Determine if TCP/{{graphite_port}} is already active
  shell: firewall-cmd --list-ports | egrep -q "^{{graphite_port}}/tcp"
  ignore_errors: true
  register: firewalld_graphite_port_exists
  no_log: true

- name: (carbon) Determine if TCP/{{carbon_cache_port}} is already active
  shell: firewall-cmd --list-ports | egrep -q "^{{carbon_cache_port}}/tcp"
  ignore_errors: true
  register: firewalld_carbon_cache_port_exists
  no_log: true

# add firewall rule via firewall-cmd
- name: (graphite-web) Add firewall rule for TCP/{{graphite_port}} (firewalld)
  command: "{{ item }}"
  with_items:
    - firewall-cmd --zone=public --add-port={{graphite_port}}/tcp --permanent
    - firewall-cmd --reload
  ignore_errors: true
  become: true
  when: firewalld_in_use.rc == 0 and firewalld_is_active.rc == 0 and firewalld_graphite_port_exists.rc != 0

# add firewall rule via firewall-cmd
- name: (carbon) Add firewall rule for TCP/{{carbon_cache_port}} (firewalld)
  command: "{{ item }}"
  with_items:
    - firewall-cmd --zone=public --add-port={{carbon_cache_port}}/tcp --permanent
    - firewall-cmd --reload
  ignore_errors: true
  become: true
  when: firewalld_in_use.rc == 0 and firewalld_is_active.rc == 0 and firewalld_carbon_cache_port_exists.rc != 0

# iptables-services
- name: (graphite-web) check firewall rules for TCP/{{graphite_port}} (iptables-services)
  shell: grep "dport {{graphite_port}} \-j ACCEPT" /etc/sysconfig/iptables | wc -l
  ignore_errors: true
  register: iptables_graphite_port_exists
  failed_when: iptables_graphite_port_exists == 127
  no_log: true

- name: (carbon) check firewall rules for TCP/{{carbon_cache_port}} (iptables-services)
  shell: grep "dport {{carbon_cache_port}} \-j ACCEPT" /etc/sysconfig/iptables | wc -l
  ignore_errors: true
  register: iptables_carbon_cache_port_exists
  failed_when: iptables_carbon_cache_port_exists == 127
  no_log: true

- name: (graphite-web) Add firewall rule for TCP/{{graphite_port}} (iptables-services)
  lineinfile:
    dest: /etc/sysconfig/iptables
    line: '-A INPUT -p tcp -m tcp --dport {{graphite_port}} -j ACCEPT'
    regexp: '^INPUT -i lo -j ACCEPT'
    insertbefore: '-A INPUT -i lo -j ACCEPT'
    backup: yes
  when: firewalld_in_use.rc != 0 and firewalld_is_active.rc != 0 and iptables_graphite_port_exists.stdout|int == 0
  register: iptables_needs_restart

- name: (carbon) Add firewall rule for TCP/{{carbon_cache_port}} (iptables-services)
  lineinfile:
    dest: /etc/sysconfig/iptables
    line: '-A INPUT -p tcp -m tcp --dport {{carbon_cache_port}} -j ACCEPT'
    regexp: '^INPUT -i lo -j ACCEPT'
    insertbefore: '-A INPUT -i lo -j ACCEPT'
    backup: yes
  when: firewalld_in_use.rc != 0 and firewalld_is_active.rc != 0 and iptables_carbon_cache_port_exists.stdout|int == 0
  register: iptables_needs_restart

- name: (graphite-web) Restart iptables-services for TCP/{{graphite_port}} (iptables-services)
  systemd:
    name: iptables.service
    state: restarted
  ignore_errors: true
  when: iptables_needs_restart != 0 and firewalld_in_use.rc != 0 and firewalld_is_active.rc != 0

### end firewall ###

- name: Setup httpd service
  service:
    name: httpd
    state: started
    enabled: true
  become: true

- name: Remove httpd welcome config
  become: true
  file:
    path: /etc/httpd/conf.d/welcome.conf
    state: absent
  notify:
    - restart apache

- name: Setup carbon-cache service
  service:
    name: carbon-cache
    state: started
    enabled: true
  become: true

- name: Copy Carbon storage scheme and aggregation config files
  copy:
    src: "{{item.src}}"
    dest: "{{item.dest}}"
    owner: root
    group: root
    mode: 0644
  become: true
  with_items:
    - src: storage-schemas.conf
      dest: /etc/carbon/storage-schemas.conf
    - src: storage-aggregation.conf
      dest: /etc/carbon/storage-aggregation.conf
  notify:
    - restart carbon-cache

- name: Configure carbon.conf
  template:
    src: carbon.conf.j2
    dest: /etc/carbon/carbon.conf
    owner: root
    group: root
    mode: 0644
  become: true
  notify:
    - restart carbon-cache

**********
DECISION===>: PASS
**********
=========================:::326:::END!!!=========================
=========================:::327:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/graphite/handlers/main.yml
**********
---
#
# Carbon and Graphite Handlers
#

- name: restart apache
  service:
    name: httpd
    state: restarted
    enabled: true
  become: true

- name: restart carbon-cache
  service:
    name: carbon-cache
    state: restarted
    enabled: true
  become: true

**********
DECISION===>: PASS
**********
=========================:::327:::END!!!=========================
=========================:::328:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/repo/tasks/main.yml
**********
---
#
# Task to deploy a repo file
#

- name: Add custom repos
  template:
    src: "templates/browbeat.repo.j2"
    dest: /etc/yum.repos.d/browbeat.repo
  become: true

**********
DECISION===>: PASS
**********
=========================:::328:::END!!!=========================
=========================:::329:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/browbeat/tasks/main.yml
**********
---
#
# Browbeat Install
#

- name: Check for supported distribution
  fail: msg="**Unsupported Linux distribution! Please use CentOS 7+, RHEL 7+, or add support for your distribution**"
  when: not supported_distro

- name: Install dependencies for CentOS
  yum:
    name: "{{ item }}"
    state: present
  become: true
  with_items:
    - gcc
    - gcc-c++
    - git
    - libffi-devel
    - libsemanage-python
    - openssl-devel
    - policycoreutils-python
    - python-devel

- name: Install pip
  easy_install:
    name: pip
  become: true

- name: Update virtualenv and setuptools
  pip:
    name: "{{item.name}}"
    version: "{{item.version}}"
  become: true
  with_items:
    - name: virtualenv
      version: 15.2.0
    - name: setuptools
      version: 38.7.0
  when:  ansible_user != "zuul"

- name: Install virtualenv and setuptools- zuul user
  pip:
    name: "{{ item }}"
  become: true
  with_items:
    - virtualenv
    - setuptools
  when: ansible_user == "zuul"

- name: Determine if browbeat directory exists already
  stat:
    path: "{{ browbeat_path }}"
  register: browbeat_exists

- debug: msg="Browbeat directory exists already."
  when: browbeat_exists.stat.isdir is defined and browbeat_exists.stat.isdir

- name: Clone browbeat on undercloud
  git:
    repo: https://github.com/openstack/browbeat.git
    dest: "{{ browbeat_path }}"
    version: master
  when: browbeat_exists.stat.isdir is undefined

- name: Create browbeat virtualenv
  command: virtualenv {{ browbeat_venv }} creates={{ browbeat_venv }}

- name: Setup browbeat-venv CA certificate path
  lineinfile:
    dest: "{{ browbeat_venv }}/bin/activate"
    line: 'export REQUESTS_CA_BUNDLE={{ overcloud_ca_path }}'
  when: overcloud_ca_path is defined

- name: Determine if generate_tripleo_hostfile has been run
  stat:
    path: "{{ browbeat_path }}/ansible/hosts"
  register: hosts_file_exists

- debug: msg="Hosts file is already generated."
  when: hosts_file_exists.stat.exists and hosts_file_exists.stat.isreg

- name: Generate hosts and ssh-config on Browbeat Machine - Default(stack)
  shell: . {{ home_dir }}/stackrc; {{ browbeat_path }}/ansible/generate_tripleo_hostfile.sh -t localhost --user stack
  when: tripleo == true and (hosts_file_exists.stat.exists == false or hosts_file_exists.stat.isreg == false) and ansible_user!= "zuul"

- name: Generate hosts and ssh-config on Browbeat Machine - Zuul
  shell: . {{ home_dir }}/stackrc; {{ browbeat_path }}/ansible/generate_tripleo_hostfile.sh -t localhost --user zuul
  when: tripleo == true and (hosts_file_exists.stat.exists == false or hosts_file_exists.stat.isreg == false) and ansible_user== "zuul"

- name: Move files to correct location
  command: mv {{ home_dir }}/{{item}} {{ browbeat_path }}/ansible/{{item}}
  with_items:
    - hosts
    - heat-admin-id_rsa
  when: "(tripleo == true and (hosts_file_exists.stat.exists == false or hosts_file_exists.stat.isreg == false))"

- name: Install requirements.txt into browbeat-venv
  pip:
    requirements: "{{ browbeat_path }}/requirements.txt"
    virtualenv: "{{ browbeat_venv }}"

**********
DECISION===>: PASS
**********
=========================:::329:::END!!!=========================
=========================:::330:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/elasticsearch/tasks/main.yml
**********
---
#
# Install/run elasticsearch for browbeat
#

- name: Copy elasticsearch yum repo file
  copy:
    src=elasticsearch.repo
    dest=/etc/yum.repos.d/elasticsearch.repo
    owner=root
    group=root
    mode=0644
  become: true

- name: Install elasticsearch and openjdk
  package:
    name: "{{ item }}"
    state: present
  become: true
  with_items:
    - elasticsearch
    - java-openjdk-headless

- name: Check if system memory is greater than 64G
  debug: msg="System memory is {{ansible_memory_mb.real.total | int}} so setting heapsize to 32G upper limit"
  when: ansible_memory_mb.real.total|int >= 65536

- name: Apply heapsize tuning for systems with greater than 64G memory
  lineinfile: dest=/usr/share/elasticsearch/bin/elasticsearch.in.sh \
          line="ES_HEAP_SIZE=32g" insertafter="^ES_CLASSPATH="
  when: ansible_memory_mb.real.total|int >= 65536
  register: elasticsearch_updated

- name: Print extended documentation for heapsize tuning
  debug: msg="Refer to https://www.elastic.co/guide/en/elasticsearch/guide/current/_limiting_memory_usage.html"
  when: ansible_memory_mb.real.total|int >= 65536

- name: Update elasticsearch startup with heap size
  become: true
  lineinfile: dest=/usr/share/elasticsearch/bin/elasticsearch.in.sh \
          line="ES_HEAP_SIZE={{ (ansible_memory_mb.real.total / 2) | int }}m" insertafter="^ES_CLASSPATH="
  when: ansible_memory_mb.real.total|int < 65536
  register: elasticsearch_updated

## begin firewall rules ##
# we will be opening TCP/9200 for ES
# if es_listen_external: true is set
# this is needed for elastic connector in browbeat
# determine firewall status and take action
# 1) use firewall-cmd if firewalld is utilized
# 2) insert iptables rule if iptables is used

# Firewalld
- name: Determine if firewalld is in use
  shell: systemctl is-enabled firewalld.service | egrep -qv 'masked|disabled'
  ignore_errors: true
  register: firewalld_in_use
  no_log: true
  when: es_listen_external

- name: Determine if firewalld is active
  shell: systemctl is-active firewalld.service | grep -vq inactive
  ignore_errors: true
  register: firewalld_is_active
  no_log: true
  when: es_listen_external

- name: Determine if TCP/{{es_local_port}} is already active
  shell: firewall-cmd --list-ports | egrep -q "^{{es_local_port}}/tcp"
  ignore_errors: true
  register: firewalld_es_local_port_exists
  no_log: true
  when: es_listen_external

# add firewall rule via firewall-cmd
- name: Add firewall rule for TCP/{{es_local_port}} (firewalld)
  command: "{{ item }}"
  with_items:
    - firewall-cmd --zone=public --add-port={{es_local_port}}/tcp --permanent
    - firewall-cmd --reload
  ignore_errors: true
  become: true
  when: es_listen_external and firewalld_in_use.rc == 0 and firewalld_is_active.rc == 0 and firewalld_es_local_port_exists.rc != 0

# iptables-services
- name: check firewall rules for TCP/{{es_local_port}} (iptables-services)
  shell: grep "dport {{es_local_port}} \-j ACCEPT" /etc/sysconfig/iptables | wc -l
  ignore_errors: true
  register: iptables_es_local_port_exists
  failed_when: iptables_es_local_port_exists == 127
  no_log: true
  when: es_listen_external

- name: Add firewall rule for TCP/{{es_local_port}} (iptables-services)
  lineinfile:
    dest: /etc/sysconfig/iptables
    line: '-A INPUT -p tcp -m tcp --dport {{es_local_port}} -j ACCEPT'
    regexp: '^INPUT -i lo -j ACCEPT'
    insertbefore: '-A INPUT -i lo -j ACCEPT'
    backup: yes
  when: es_listen_external and firewalld_in_use.rc != 0 and firewalld_is_active.rc != 0 and iptables_es_local_port_exists.stdout|int == 0
  register: iptables_needs_restart

- name: Restart iptables-services for TCP/{{es_local_port}} (iptables-services)
  shell: systemctl restart iptables.service
  ignore_errors: true
  when: es_listen_external and iptables_needs_restart != 0 and firewalld_in_use.rc != 0 and firewalld_is_active.rc != 0
  tags:
    # Skip ANSIBLE0013 Use shell only when shell functionality is required
    # No systemctl module available in current stable release (Ansible 2.1)
    - skip_ansible_lint

## end firewall rules ##

- name: Copy over ES Config
  template:
    src=elasticsearch.yml.j2
    dest=/etc/elasticsearch/elasticsearch.yml
  become: true

- name: Start elasticsearch service
  systemd:
    name: elasticsearch.service
    state: started
  ignore_errors: true
  when: elasticsearch_updated != 0

- name: Setup elasticsearch service
  service: name=elasticsearch state=started enabled=true
  become: true

**********
DECISION===>: PASS
**********
=========================:::330:::END!!!=========================
=========================:::331:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/kibana-visualization/vars/keystone_processes_threads_dashboards.yml
**********
---
#
# Keystone Process/Thread Count Comparsion Dashboards
#

keystone_processes_threads_dashboards:
  # Process Count Comparsion Dashboards
  - file_name: "BrowbeatAuthenticateKeystoneProcessCountCompare.json"
    title: "Browbeat Authenticate.keystone Process Count Comparsion"
    darkTheme: "true"
    panels:
      - id: "BrowbeatAuthenticateKeystoneConcurrencyProcessCountCompare-md"
        type: "visualization"
        panelIndex: 1
        size_x: 12
        size_y: 2
        col: 1
        row: 1
      - id: "BrowbeatAuthenticateKeystoneConcurrencyProcessCountCompareResultCount-bg"
        type: "visualization"
        panelIndex: 2
        size_x: 12
        size_y: 3
        col: 1
        row: 3
      - id: "BrowbeatAuthenticateKeystoneConcurrencyProcessCountCompareErrorCount-bg"
        type: "visualization"
        panelIndex: 3
        size_x: 12
        size_y: 3
        col: 1
        row: 6
      - id: "BrowbeatAuthenticateKeystoneConcurrencyProcessCountCompareMin-bg"
        type: "visualization"
        panelIndex: 4
        size_x: 12
        size_y: 3
        col: 1
        row: 9
      - id: "BrowbeatAuthenticateKeystoneConcurrencyProcessCountCompare50th-bg"
        type: "visualization"
        panelIndex: 5
        size_x: 12
        size_y: 3
        col: 1
        row: 15
      - id: "BrowbeatAuthenticateKeystoneConcurrencyProcessCountCompare95th-bg"
        type: "visualization"
        panelIndex: 6
        size_x: 12
        size_y: 3
        col: 1
        row: 15
      - id: "BrowbeatAuthenticateKeystoneConcurrencyProcessCountCompare99th-bg"
        type: "visualization"
        panelIndex: 7
        size_x: 12
        size_y: 3
        col: 1
        row: 18
      - id: "BrowbeatAuthenticateKeystoneConcurrencyProcessCountCompareMax-bg"
        type: "visualization"
        panelIndex: 8
        size_x: 12
        size_y: 3
        col: 1
        row: 21
  - file_name: "BrowbeatAuthenticateValidateNovaProcessCountCompare.json"
    title: "Browbeat Authenticate.validate_nova Process Count Comparsion"
    darkTheme: "true"
    panels:
      - id: "BrowbeatAuthenticateValidateNovaConcurrencyProcessCountCompare-md"
        type: "visualization"
        panelIndex: 1
        size_x: 12
        size_y: 2
        col: 1
        row: 1
      - id: "BrowbeatAuthenticateValidateNovaConcurrencyProcessCountCompareResultCount-bg"
        type: "visualization"
        panelIndex: 2
        size_x: 12
        size_y: 3
        col: 1
        row: 3
      - id: "BrowbeatAuthenticateValidateNovaConcurrencyProcessCountCompareErrorCount-bg"
        type: "visualization"
        panelIndex: 3
        size_x: 12
        size_y: 3
        col: 1
        row: 6
      - id: "BrowbeatAuthenticateValidateNovaConcurrencyProcessCountCompareMin-bg"
        type: "visualization"
        panelIndex: 4
        size_x: 12
        size_y: 3
        col: 1
        row: 9
      - id: "BrowbeatAuthenticateValidateNovaConcurrencyProcessCountCompare50th-bg"
        type: "visualization"
        panelIndex: 5
        size_x: 12
        size_y: 3
        col: 1
        row: 15
      - id: "BrowbeatAuthenticateValidateNovaConcurrencyProcessCountCompare95th-bg"
        type: "visualization"
        panelIndex: 6
        size_x: 12
        size_y: 3
        col: 1
        row: 15
      - id: "BrowbeatAuthenticateValidateNovaConcurrencyProcessCountCompare99th-bg"
        type: "visualization"
        panelIndex: 7
        size_x: 12
        size_y: 3
        col: 1
        row: 18
      - id: "BrowbeatAuthenticateValidateNovaConcurrencyProcessCountCompareMax-bg"
        type: "visualization"
        panelIndex: 8
        size_x: 12
        size_y: 3
        col: 1
        row: 21
  - file_name: "BrowbeatAuthenticateValidateNeutronProcessCountCompare.json"
    title: "Browbeat Authenticate.validate_neutron Process Count Comparsion"
    darkTheme: "true"
    panels:
      - id: "BrowbeatAuthenticateValidateNeutronConcurrencyProcessCountCompare-md"
        type: "visualization"
        panelIndex: 1
        size_x: 12
        size_y: 2
        col: 1
        row: 1
      - id: "BrowbeatAuthenticateValidateNeutronConcurrencyProcessCountCompareResultCount-bg"
        type: "visualization"
        panelIndex: 2
        size_x: 12
        size_y: 3
        col: 1
        row: 3
      - id: "BrowbeatAuthenticateValidateNeutronConcurrencyProcessCountCompareErrorCount-bg"
        type: "visualization"
        panelIndex: 3
        size_x: 12
        size_y: 3
        col: 1
        row: 6
      - id: "BrowbeatAuthenticateValidateNeutronConcurrencyProcessCountCompareMin-bg"
        type: "visualization"
        panelIndex: 4
        size_x: 12
        size_y: 3
        col: 1
        row: 9
      - id: "BrowbeatAuthenticateValidateNeutronConcurrencyProcessCountCompare50th-bg"
        type: "visualization"
        panelIndex: 5
        size_x: 12
        size_y: 3
        col: 1
        row: 15
      - id: "BrowbeatAuthenticateValidateNeutronConcurrencyProcessCountCompare95th-bg"
        type: "visualization"
        panelIndex: 6
        size_x: 12
        size_y: 3
        col: 1
        row: 15
      - id: "BrowbeatAuthenticateValidateNeutronConcurrencyProcessCountCompare99th-bg"
        type: "visualization"
        panelIndex: 7
        size_x: 12
        size_y: 3
        col: 1
        row: 18
      - id: "BrowbeatAuthenticateValidateNeutronConcurrencyProcessCountCompareMax-bg"
        type: "visualization"
        panelIndex: 8
        size_x: 12
        size_y: 3
        col: 1
        row: 21


  # Thread Count Comparsion Dashboards
  - file_name: "BrowbeatAuthenticateKeystoneThreadCountCompare.json"
    title: "Browbeat Authenticate.keystone Thread Count Comparsion"
    darkTheme: "true"
    panels:
      - id: "BrowbeatAuthenticateKeystoneConcurrencyThreadCountCompare-md"
        type: "visualization"
        panelIndex: 1
        size_x: 12
        size_y: 2
        col: 1
        row: 1
      - id: "BrowbeatAuthenticateKeystoneConcurrencyThreadCountCompareResultCount-bg"
        type: "visualization"
        panelIndex: 2
        size_x: 12
        size_y: 3
        col: 1
        row: 3
      - id: "BrowbeatAuthenticateKeystoneConcurrencyThreadCountCompareErrorCount-bg"
        type: "visualization"
        panelIndex: 3
        size_x: 12
        size_y: 3
        col: 1
        row: 6
      - id: "BrowbeatAuthenticateKeystoneConcurrencyThreadCountCompareMin-bg"
        type: "visualization"
        panelIndex: 4
        size_x: 12
        size_y: 3
        col: 1
        row: 9
      - id: "BrowbeatAuthenticateKeystoneConcurrencyThreadCountCompare50th-bg"
        type: "visualization"
        panelIndex: 5
        size_x: 12
        size_y: 3
        col: 1
        row: 12
      - id: "BrowbeatAuthenticateKeystoneConcurrencyThreadCountCompare95th-bg"
        type: "visualization"
        panelIndex: 6
        size_x: 12
        size_y: 3
        col: 1
        row: 15
      - id: "BrowbeatAuthenticateKeystoneConcurrencyThreadCountCompare99th-bg"
        type: "visualization"
        panelIndex: 7
        size_x: 12
        size_y: 3
        col: 1
        row: 18
      - id: "BrowbeatAuthenticateKeystoneConcurrencyThreadCountCompareMax-bg"
        type: "visualization"
        panelIndex: 8
        size_x: 12
        size_y: 3
        col: 1
        row: 21
  - file_name: "BrowbeatAuthenticateValidateNovaThreadCountCompare.json"
    title: "Browbeat Authenticate.validate_nova Thread Count Comparsion"
    darkTheme: "true"
    panels:
      - id: "BrowbeatAuthenticateValidateNovaConcurrencyThreadCountCompare-md"
        type: "visualization"
        panelIndex: 1
        size_x: 12
        size_y: 2
        col: 1
        row: 1
      - id: "BrowbeatAuthenticateValidateNovaConcurrencyThreadCountCompareResultCount-bg"
        type: "visualization"
        panelIndex: 2
        size_x: 12
        size_y: 3
        col: 1
        row: 3
      - id: "BrowbeatAuthenticateValidateNovaConcurrencyThreadCountCompareErrorCount-bg"
        type: "visualization"
        panelIndex: 3
        size_x: 12
        size_y: 3
        col: 1
        row: 6
      - id: "BrowbeatAuthenticateValidateNovaConcurrencyThreadCountCompareMin-bg"
        type: "visualization"
        panelIndex: 4
        size_x: 12
        size_y: 3
        col: 1
        row: 9
      - id: "BrowbeatAuthenticateValidateNovaConcurrencyThreadCountCompare50th-bg"
        type: "visualization"
        panelIndex: 5
        size_x: 12
        size_y: 3
        col: 1
        row: 15
      - id: "BrowbeatAuthenticateValidateNovaConcurrencyThreadCountCompare95th-bg"
        type: "visualization"
        panelIndex: 6
        size_x: 12
        size_y: 3
        col: 1
        row: 15
      - id: "BrowbeatAuthenticateValidateNovaConcurrencyThreadCountCompare99th-bg"
        type: "visualization"
        panelIndex: 7
        size_x: 12
        size_y: 3
        col: 1
        row: 18
      - id: "BrowbeatAuthenticateValidateNovaConcurrencyThreadCountCompareMax-bg"
        type: "visualization"
        panelIndex: 8
        size_x: 12
        size_y: 3
        col: 1
        row: 21
  - file_name: "BrowbeatAuthenticateValidateNeutronThreadCountCompare.json"
    title: "Browbeat Authenticate.validate_neutron Thread Count Comparsion"
    darkTheme: "true"
    panels:
      - id: "BrowbeatAuthenticateValidateNeutronConcurrencyThreadCountCompare-md"
        type: "visualization"
        panelIndex: 1
        size_x: 12
        size_y: 2
        col: 1
        row: 1
      - id: "BrowbeatAuthenticateValidateNeutronConcurrencyThreadCountCompareResultCount-bg"
        type: "visualization"
        panelIndex: 2
        size_x: 12
        size_y: 3
        col: 1
        row: 3
      - id: "BrowbeatAuthenticateValidateNeutronConcurrencyThreadCountCompareErrorCount-bg"
        type: "visualization"
        panelIndex: 3
        size_x: 12
        size_y: 3
        col: 1
        row: 6
      - id: "BrowbeatAuthenticateValidateNeutronConcurrencyThreadCountCompareMin-bg"
        type: "visualization"
        panelIndex: 4
        size_x: 12
        size_y: 3
        col: 1
        row: 9
      - id: "BrowbeatAuthenticateValidateNeutronConcurrencyThreadCountCompare50th-bg"
        type: "visualization"
        panelIndex: 5
        size_x: 12
        size_y: 3
        col: 1
        row: 15
      - id: "BrowbeatAuthenticateValidateNeutronConcurrencyThreadCountCompare95th-bg"
        type: "visualization"
        panelIndex: 6
        size_x: 12
        size_y: 3
        col: 1
        row: 15
      - id: "BrowbeatAuthenticateValidateNeutronConcurrencyThreadCountCompare99th-bg"
        type: "visualization"
        panelIndex: 7
        size_x: 12
        size_y: 3
        col: 1
        row: 18
      - id: "BrowbeatAuthenticateValidateNeutronConcurrencyThreadCountCompareMax-bg"
        type: "visualization"
        panelIndex: 8
        size_x: 12
        size_y: 3
        col: 1
        row: 21

**********
DECISION===>: PASS
**********
=========================:::331:::END!!!=========================
=========================:::332:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/kibana-visualization/vars/keystone_processes_threads_visualizations.yml
**********
---
#
# Keystone Processes/Threads Comparsion - Visualizations Variables
#

keystone_processes_threads_visualizations:
  # Authenticate.keystone Visualizations: [Min, 50th, 95th, 99th, Max] for UUID
  - title: "BrowbeatAuthenticateKeystoneConcurrencyProcessCountCompare-md"
    template: "markdown.json.j2"
    markdown: "# Processes Comparsion\\\\n[Browbeat](https://github.com/openstack/browbeat)\\\\n\\\\n[Rally Authenticate.keystone](https://github.com/openstack/rally/blob/master/rally/plugins/openstack/scenarios/authenticate/authenticate.py#L28)"
  - title: "BrowbeatAuthenticateKeystoneConcurrencyProcessCountCompareResultCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "software-metadata.keystone.main_workers_processes"
    query: "_type: result AND rally_setup.name: Authenticate.keystone"
  - title: "BrowbeatAuthenticateKeystoneConcurrencyProcessCountCompareErrorCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "software-metadata.keystone.main_workers_processes"
    query: "_type: error AND rally_setup.name: Authenticate.keystone"

  - title: "BrowbeatAuthenticateKeystoneConcurrencyProcessCountCompareMin-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "min"
    split_bars_field: "software-metadata.keystone.main_workers_processes"
    query: "_type: result AND rally_setup.name: Authenticate.keystone"
  - title: "BrowbeatAuthenticateKeystoneConcurrencyProcessCountCompare50th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[50]"
    split_bars_field: "software-metadata.keystone.main_workers_processes"
    query: "_type: result AND rally_setup.name: Authenticate.keystone"
  - title: "BrowbeatAuthenticateKeystoneConcurrencyProcessCountCompare95th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[95]"
    split_bars_field: "software-metadata.keystone.main_workers_processes"
    query: "_type: result AND rally_setup.name: Authenticate.keystone"
  - title: "BrowbeatAuthenticateKeystoneConcurrencyProcessCountCompare99th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[99]"
    split_bars_field: "software-metadata.keystone.main_workers_processes"
    query: "_type: result AND rally_setup.name: Authenticate.keystone"
  - title: "BrowbeatAuthenticateKeystoneConcurrencyProcessCountCompareMax-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "max"
    split_bars_field: "software-metadata.keystone.main_workers_processes"
    query: "_type: result AND rally_setup.name: Authenticate.keystone"
  # Authenticate.keystone Visualizations: [Min, 50th, 95th, 99th, Max] for Fernet
  - title: "BrowbeatAuthenticateKeystoneConcurrencyThreadCountCompare-md"
    template: "markdown.json.j2"
    markdown: "# Threads Comparsion\\\\n[Browbeat](https://github.com/openstack/browbeat)\\\\n\\\\n[Rally Authenticate.keystone](https://github.com/openstack/rally/blob/master/rally/plugins/openstack/scenarios/authenticate/authenticate.py#L28)"
  - title: "BrowbeatAuthenticateKeystoneConcurrencyThreadCountCompareResultCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "software-metadata.keystone.main_workers_threads"
    query: "_type: result AND rally_setup.name: Authenticate.keystone"
  - title: "BrowbeatAuthenticateKeystoneConcurrencyThreadCountCompareErrorCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "software-metadata.keystone.main_workers_threads"
    query: "_type: error AND rally_setup.name: Authenticate.keystone"

  - title: "BrowbeatAuthenticateKeystoneConcurrencyThreadCountCompareMin-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "min"
    split_bars_field: "software-metadata.keystone.main_workers_threads"
    query: "_type: result AND rally_setup.name: Authenticate.keystone"
  - title: "BrowbeatAuthenticateKeystoneConcurrencyThreadCountCompare50th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[50]"
    split_bars_field: "software-metadata.keystone.main_workers_threads"
    query: "_type: result AND rally_setup.name: Authenticate.keystone"
  - title: "BrowbeatAuthenticateKeystoneConcurrencyThreadCountCompare95th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[95]"
    split_bars_field: "software-metadata.keystone.main_workers_threads"
    query: "_type: result AND rally_setup.name: Authenticate.keystone"
  - title: "BrowbeatAuthenticateKeystoneConcurrencyThreadCountCompare99th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[99]"
    split_bars_field: "software-metadata.keystone.main_workers_threads"
    query: "_type: result AND rally_setup.name: Authenticate.keystone"
  - title: "BrowbeatAuthenticateKeystoneConcurrencyThreadCountCompareMax-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "max"
    split_bars_field: "software-metadata.keystone.main_workers_threads"
    query: "_type: result AND rally_setup.name: Authenticate.keystone"

  # Authenticate.validate_nova Visualizations: [Min, 50th, 95th, 99th, Max] for UUID
  - title: "BrowbeatAuthenticateValidateNovaConcurrencyProcessCountCompare-md"
    template: "markdown.json.j2"
    markdown: "# Processes Comparsion\\\\n[Browbeat](https://github.com/openstack/browbeat)\\\\n\\\\n[Rally Authenticate.validate_nova](https://github.com/openstack/rally/blob/master/rally/plugins/openstack/scenarios/authenticate/authenticate.py#L54)\\\\n\\\\nrepetitions: 2"
  - title: "BrowbeatAuthenticateValidateNovaConcurrencyProcessCountCompareResultCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "software-metadata.keystone.main_workers_processes"
    query: "_type: result AND rally_setup.name: Authenticate.validate_nova"
  - title: "BrowbeatAuthenticateValidateNovaConcurrencyProcessCountCompareErrorCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "software-metadata.keystone.main_workers_processes"
    query: "_type: error AND rally_setup.name: Authenticate.validate_nova"

  - title: "BrowbeatAuthenticateValidateNovaConcurrencyProcessCountCompareMin-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "min"
    split_bars_field: "software-metadata.keystone.main_workers_processes"
    query: "_type: result AND rally_setup.name: Authenticate.validate_nova"
  - title: "BrowbeatAuthenticateValidateNovaConcurrencyProcessCountCompare50th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[50]"
    split_bars_field: "software-metadata.keystone.main_workers_processes"
    query: "_type: result AND rally_setup.name: Authenticate.validate_nova"
  - title: "BrowbeatAuthenticateValidateNovaConcurrencyProcessCountCompare95th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[95]"
    split_bars_field: "software-metadata.keystone.main_workers_processes"
    query: "_type: result AND rally_setup.name: Authenticate.validate_nova"
  - title: "BrowbeatAuthenticateValidateNovaConcurrencyProcessCountCompare99th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[99]"
    split_bars_field: "software-metadata.keystone.main_workers_processes"
    query: "_type: result AND rally_setup.name: Authenticate.validate_nova"
  - title: "BrowbeatAuthenticateValidateNovaConcurrencyProcessCountCompareMax-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "max"
    split_bars_field: "software-metadata.keystone.main_workers_processes"
    query: "_type: result AND rally_setup.name: Authenticate.validate_nova"
  # Authenticate.validate_nova Visualizations: [Min, 50th, 95th, 99th, Max] for Fernet
  - title: "BrowbeatAuthenticateValidateNovaConcurrencyThreadCountCompare-md"
    template: "markdown.json.j2"
    markdown: "# Threads Comparsion\\\\n[Browbeat](https://github.com/openstack/browbeat)\\\\n\\\\n[Rally Authenticate.validate_nova](https://github.com/openstack/rally/blob/master/rally/plugins/openstack/scenarios/authenticate/authenticate.py#L54)\\\\n\\\\nrepetitions: 2"
  - title: "BrowbeatAuthenticateValidateNovaConcurrencyThreadCountCompareResultCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "software-metadata.keystone.main_workers_threads"
    query: "_type: result AND rally_setup.name: Authenticate.validate_nova"
  - title: "BrowbeatAuthenticateValidateNovaConcurrencyThreadCountCompareErrorCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "software-metadata.keystone.main_workers_threads"
    query: "_type: error AND rally_setup.name: Authenticate.validate_nova"

  - title: "BrowbeatAuthenticateValidateNovaConcurrencyThreadCountCompareMin-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "min"
    split_bars_field: "software-metadata.keystone.main_workers_threads"
    query: "_type: result AND rally_setup.name: Authenticate.validate_nova"
  - title: "BrowbeatAuthenticateValidateNovaConcurrencyThreadCountCompare50th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[50]"
    split_bars_field: "software-metadata.keystone.main_workers_threads"
    query: "_type: result AND rally_setup.name: Authenticate.validate_nova"
  - title: "BrowbeatAuthenticateValidateNovaConcurrencyThreadCountCompare95th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[95]"
    split_bars_field: "software-metadata.keystone.main_workers_threads"
    query: "_type: result AND rally_setup.name: Authenticate.validate_nova"
  - title: "BrowbeatAuthenticateValidateNovaConcurrencyThreadCountCompare99th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[99]"
    split_bars_field: "software-metadata.keystone.main_workers_threads"
    query: "_type: result AND rally_setup.name: Authenticate.validate_nova"
  - title: "BrowbeatAuthenticateValidateNovaConcurrencyThreadCountCompareMax-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "max"
    split_bars_field: "software-metadata.keystone.main_workers_threads"
    query: "_type: result AND rally_setup.name: Authenticate.validate_nova"

  # Authenticate.validate_neutron Visualizations: [Min, 50th, 95th, 99th, Max] for UUID
  - title: "BrowbeatAuthenticateValidateNeutronConcurrencyProcessCountCompare-md"
    template: "markdown.json.j2"
    markdown: "# Processes Comparsion\\\\n[Browbeat](https://github.com/openstack/browbeat)\\\\n\\\\n[Rally Authenticate.validate_neutron](https://github.com/openstack/rally/blob/master/rally/plugins/openstack/scenarios/authenticate/authenticate.py#L106)\\\\n\\\\nrepetitions: 2"
  - title: "BrowbeatAuthenticateValidateNeutronConcurrencyProcessCountCompareResultCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "software-metadata.keystone.main_workers_processes"
    query: "_type: result AND rally_setup.name: Authenticate.validate_neutron"
  - title: "BrowbeatAuthenticateValidateNeutronConcurrencyProcessCountCompareErrorCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "software-metadata.keystone.main_workers_processes"
    query: "_type: error AND rally_setup.name: Authenticate.validate_neutron"

  - title: "BrowbeatAuthenticateValidateNeutronConcurrencyProcessCountCompareMin-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "min"
    split_bars_field: "software-metadata.keystone.main_workers_processes"
    query: "_type: result AND rally_setup.name: Authenticate.validate_neutron"
  - title: "BrowbeatAuthenticateValidateNeutronConcurrencyProcessCountCompare50th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[50]"
    split_bars_field: "software-metadata.keystone.main_workers_processes"
    query: "_type: result AND rally_setup.name: Authenticate.validate_neutron"
  - title: "BrowbeatAuthenticateValidateNeutronConcurrencyProcessCountCompare95th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[95]"
    split_bars_field: "software-metadata.keystone.main_workers_processes"
    query: "_type: result AND rally_setup.name: Authenticate.validate_neutron"
  - title: "BrowbeatAuthenticateValidateNeutronConcurrencyProcessCountCompare99th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[99]"
    split_bars_field: "software-metadata.keystone.main_workers_processes"
    query: "_type: result AND rally_setup.name: Authenticate.validate_neutron"
  - title: "BrowbeatAuthenticateValidateNeutronConcurrencyProcessCountCompareMax-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "max"
    split_bars_field: "software-metadata.keystone.main_workers_processes"
    query: "_type: result AND rally_setup.name: Authenticate.validate_neutron"
  # Authenticate.validate_neutron Visualizations: [Min, 50th, 95th, 99th, Max] for Fernet
  - title: "BrowbeatAuthenticateValidateNeutronConcurrencyThreadCountCompare-md"
    template: "markdown.json.j2"
    markdown: "# Threads Comparsion\\\\n[Browbeat](https://github.com/openstack/browbeat)\\\\n\\\\n[Rally Authenticate.validate_neutron](https://github.com/openstack/rally/blob/master/rally/plugins/openstack/scenarios/authenticate/authenticate.py#L106)\\\\n\\\\nrepetitions: 2"
  - title: "BrowbeatAuthenticateValidateNeutronConcurrencyThreadCountCompareResultCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "software-metadata.keystone.main_workers_threads"
    query: "_type: result AND rally_setup.name: Authenticate.validate_neutron"
  - title: "BrowbeatAuthenticateValidateNeutronConcurrencyThreadCountCompareErrorCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "software-metadata.keystone.main_workers_threads"
    query: "_type: error AND rally_setup.name: Authenticate.validate_neutron"

  - title: "BrowbeatAuthenticateValidateNeutronConcurrencyThreadCountCompareMin-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "min"
    split_bars_field: "software-metadata.keystone.main_workers_threads"
    query: "_type: result AND rally_setup.name: Authenticate.validate_neutron"
  - title: "BrowbeatAuthenticateValidateNeutronConcurrencyThreadCountCompare50th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[50]"
    split_bars_field: "software-metadata.keystone.main_workers_threads"
    query: "_type: result AND rally_setup.name: Authenticate.validate_neutron"
  - title: "BrowbeatAuthenticateValidateNeutronConcurrencyThreadCountCompare95th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[95]"
    split_bars_field: "software-metadata.keystone.main_workers_threads"
    query: "_type: result AND rally_setup.name: Authenticate.validate_neutron"
  - title: "BrowbeatAuthenticateValidateNeutronConcurrencyThreadCountCompare99th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[99]"
    split_bars_field: "software-metadata.keystone.main_workers_threads"
    query: "_type: result AND rally_setup.name: Authenticate.validate_neutron"
  - title: "BrowbeatAuthenticateValidateNeutronConcurrencyThreadCountCompareMax-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "max"
    split_bars_field: "software-metadata.keystone.main_workers_threads"
    query: "_type: result AND rally_setup.name: Authenticate.validate_neutron"

**********
DECISION===>: PASS
**********
=========================:::332:::END!!!=========================
=========================:::333:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/kibana-visualization/vars/keystone_controller_count_visualizations.yml
**********
---
#
# Keystone Controller Count Comparsion - Visualizations Variables
#

keystone_controller_count_visualizations:
  - title: "BrowbeatAuthenticateKeystoneConcurrencyControllerCountCompare-md"
    template: "markdown.json.j2"
    markdown: "# Controller Count Comparsion\\\\n[Browbeat](https://github.com/openstack/browbeat)\\\\n\\\\n[Rally Authenticate.keystone](https://github.com/openstack/rally/blob/master/rally/plugins/openstack/scenarios/authenticate/authenticate.py#L29)"
  # Authenticate.keystone Controller Count Comparsion Visualizations: [Min, 50th, 95th, 99th, Max]
  - title: "BrowbeatAuthenticateKeystoneConcurrencyControllerCountCompareResultCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"
    query: "_type: result AND rally_setup.name: Authenticate.keystone "
  - title: "BrowbeatAuthenticateKeystoneConcurrencyControllerCountCompareErrorCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"
    query: "_type: error AND rally_setup.name: Authenticate.keystone "

  - title: "BrowbeatAuthenticateKeystoneConcurrencyControllerCountCompareMin-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "min"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"
    query: "_type: result AND rally_setup.name: Authenticate.keystone "
  - title: "BrowbeatAuthenticateKeystoneConcurrencyControllerCountCompare50th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[50]"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"
    query: "_type: result AND rally_setup.name: Authenticate.keystone "
  - title: "BrowbeatAuthenticateKeystoneConcurrencyControllerCountCompare95th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[95]"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"

    query: "_type: result AND rally_setup.name: Authenticate.keystone "
  - title: "BrowbeatAuthenticateKeystoneConcurrencyControllerCountCompare99th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[99]"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"
    query: "_type: result AND rally_setup.name: Authenticate.keystone "
  - title: "BrowbeatAuthenticateKeystoneConcurrencyControllerCountCompareMax-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "max"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"
    query: "_type: result AND rally_setup.name: Authenticate.keystone "

  - title: "BrowbeatAuthenticateValidateCinderConcurrencyControllerCountCompare-md"
    template: "markdown.json.j2"
    markdown: "# Controller Count Comparsion\\\\n[Browbeat](https://github.com/openstack/browbeat)\\\\n\\\\n[Rally Authenticate.validate_cinder](https://github.com/openstack/rally/blob/master/rally/plugins/openstack/scenarios/authenticate/authenticate.py#L104)"
  # Authenticate.validate_cinder Controller Count Comparsion Visualizations: [Min, 50th, 95th, 99th, Max]
  - title: "BrowbeatAuthenticateValidateCinderConcurrencyControllerCountCompareResultCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"
    query: "_type: result AND rally_setup.name: Authenticate.validate_cinder "
  - title: "BrowbeatAuthenticateValidateCinderConcurrencyControllerCountCompareErrorCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"
    query: "_type: error AND rally_setup.name: Authenticate.validate_cinder "

  - title: "BrowbeatAuthenticateValidateCinderConcurrencyControllerCountCompareMin-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "min"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"
    query: "_type: result AND rally_setup.name: Authenticate.validate_cinder "
  - title: "BrowbeatAuthenticateValidateCinderConcurrencyControllerCountCompare50th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[50]"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"
    query: "_type: result AND rally_setup.name: Authenticate.validate_cinder "
  - title: "BrowbeatAuthenticateValidateCinderConcurrencyControllerCountCompare95th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[95]"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"
    query: "_type: result AND rally_setup.name: Authenticate.validate_cinder "
  - title: "BrowbeatAuthenticateValidateCinderConcurrencyControllerCountCompare99th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[99]"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"
    query: "_type: result AND rally_setup.name: Authenticate.validate_cinder "
  - title: "BrowbeatAuthenticateValidateCinderConcurrencyControllerCountCompareMax-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "max"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"
    query: "_type: result AND rally_setup.name: Authenticate.validate_cinder "


  - title: "BrowbeatAuthenticateValidateGlanceConcurrencyControllerCountCompare-md"
    template: "markdown.json.j2"
    markdown: "# Controller Count Comparsion\\\\n[Browbeat](https://github.com/openstack/browbeat)\\\\n\\\\n[Rally Authenticate.validate_glance](https://github.com/openstack/rally/blob/master/rally/plugins/openstack/scenarios/authenticate/authenticate.py#L39)"
  # Authenticate.validate_glance Controller Count Comparsion Visualizations: [Min, 50th, 95th, 99th, Max]
  - title: "BrowbeatAuthenticateValidateGlanceConcurrencyControllerCountCompareResultCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"
    query: "_type: result AND rally_setup.name: Authenticate.validate_glance "
  - title: "BrowbeatAuthenticateValidateGlanceConcurrencyControllerCountCompareErrorCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"
    query: "_type: error AND rally_setup.name: Authenticate.validate_glance "

  - title: "BrowbeatAuthenticateValidateGlanceConcurrencyControllerCountCompareMin-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "min"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"
    query: "_type: result AND rally_setup.name: Authenticate.validate_glance "
  - title: "BrowbeatAuthenticateValidateGlanceConcurrencyControllerCountCompare50th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[50]"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"
    query: "_type: result AND rally_setup.name: Authenticate.validate_glance "
  - title: "BrowbeatAuthenticateValidateGlanceConcurrencyControllerCountCompare95th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[95]"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"
    query: "_type: result AND rally_setup.name: Authenticate.validate_glance "
  - title: "BrowbeatAuthenticateValidateGlanceConcurrencyControllerCountCompare99th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[99]"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"

    query: "_type: result AND rally_setup.name: Authenticate.validate_glance "
  - title: "BrowbeatAuthenticateValidateGlanceConcurrencyControllerCountCompareMax-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "max"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"
    query: "_type: result AND rally_setup.name: Authenticate.validate_glance "

  - title: "BrowbeatAuthenticateValidateHeatConcurrencyControllerCountCompare-md"
    template: "markdown.json.j2"
    markdown: "# Controller Count Comparsion\\\\n[Browbeat](https://github.com/openstack/browbeat)\\\\n\\\\n[Rally Authenticate.validate_heat](https://github.com/openstack/rally/blob/master/rally/plugins/openstack/scenarios/authenticate/authenticate.py#L146)"
  # Authenticate.validate_heat Controller Count Comparsion Visualizations: [Min, 50th, 95th, 99th, Max]
  - title: "BrowbeatAuthenticateValidateHeatConcurrencyControllerCountCompareResultCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"
    query: "_type: result AND rally_setup.name: Authenticate.validate_heat "
  - title: "BrowbeatAuthenticateValidateHeatConcurrencyControllerCountCompareErrorCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"
    query: "_type: error AND rally_setup.name: Authenticate.validate_heat "

  - title: "BrowbeatAuthenticateValidateHeatConcurrencyControllerCountCompareMin-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "min"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"
    query: "_type: result AND rally_setup.name: Authenticate.validate_heat "
  - title: "BrowbeatAuthenticateValidateHeatConcurrencyControllerCountCompare50th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[50]"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"
    query: "_type: result AND rally_setup.name: Authenticate.validate_heat "
  - title: "BrowbeatAuthenticateValidateHeatConcurrencyControllerCountCompare95th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[95]"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"
    query: "_type: result AND rally_setup.name: Authenticate.validate_heat "
  - title: "BrowbeatAuthenticateValidateHeatConcurrencyControllerCountCompare99th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[99]"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"
    query: "_type: result AND rally_setup.name: Authenticate.validate_heat "
  - title: "BrowbeatAuthenticateValidateHeatConcurrencyControllerCountCompareMax-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "max"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"
    query: "_type: result AND rally_setup.name: Authenticate.validate_heat "

  - title: "BrowbeatAuthenticateValidateNeutronConcurrencyControllerCountCompare-md"
    template: "markdown.json.j2"
    markdown: "# Controller Count Comparsion\\\\n[Browbeat](https://github.com/openstack/browbeat)\\\\n\\\\n[Rally Authenticate.validate_neutron](https://github.com/openstack/rally/blob/master/rally/plugins/openstack/scenarios/authenticate/authenticate.py#L125)"
  # Authenticate.validate_neutron Controller Count Comparsion Visualizations: [Min, 50th, 95th, 99th, Max]
  - title: "BrowbeatAuthenticateValidateNeutronConcurrencyControllerCountCompareResultCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"
    query: "_type: result AND rally_setup.name: Authenticate.validate_neutron "
  - title: "BrowbeatAuthenticateValidateNeutronConcurrencyControllerCountCompareErrorCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"
    query: "_type: error AND rally_setup.name: Authenticate.validate_neutron "

  - title: "BrowbeatAuthenticateValidateNeutronConcurrencyControllerCountCompareMin-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "min"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"
    query: "_type: result AND rally_setup.name: Authenticate.validate_neutron "
  - title: "BrowbeatAuthenticateValidateNeutronConcurrencyControllerCountCompare50th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[50]"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"
    query: "_type: result AND rally_setup.name: Authenticate.validate_neutron "
  - title: "BrowbeatAuthenticateValidateNeutronConcurrencyControllerCountCompare95th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[95]"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"
    query: "_type: result AND rally_setup.name: Authenticate.validate_neutron "
  - title: "BrowbeatAuthenticateValidateNeutronConcurrencyControllerCountCompare99th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[99]"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"
    query: "_type: result AND rally_setup.name: Authenticate.validate_neutron "
  - title: "BrowbeatAuthenticateValidateNeutronConcurrencyControllerCountCompareMax-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "max"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"
    query: "_type: result AND rally_setup.name: Authenticate.validate_neutron "

  - title: "BrowbeatAuthenticateValidateNovaConcurrencyControllerCountCompare-md"
    template: "markdown.json.j2"
    markdown: "# Controller Count Comparsion\\\\n[Browbeat](https://github.com/openstack/browbeat)\\\\n\\\\n[Rally Authenticate.validate_nova](https://github.com/openstack/rally/blob/master/rally/plugins/openstack/scenarios/authenticate/authenticate.py#L62)"
  # Authenticate.validate_nova Controller Count Comparsion Visualizations: [Min, 50th, 95th, 99th, Max]
  - title: "BrowbeatAuthenticateValidateNovaConcurrencyControllerCountCompareResultCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"
    query: "_type: result AND rally_setup.name: Authenticate.validate_nova "
  - title: "BrowbeatAuthenticateValidateNovaConcurrencyControllerCountCompareErrorCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"
    query: "_type: error AND rally_setup.name: Authenticate.validate_nova "

  - title: "BrowbeatAuthenticateValidateNovaConcurrencyControllerCountCompareMin-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "min"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"
    query: "_type: result AND rally_setup.name: Authenticate.validate_nova "
  - title: "BrowbeatAuthenticateValidateNovaConcurrencyControllerCountCompare50th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[50]"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"
    query: "_type: result AND rally_setup.name: Authenticate.validate_nova "
  - title: "BrowbeatAuthenticateValidateNovaConcurrencyControllerCountCompare95th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[95]"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"
    query: "_type: result AND rally_setup.name: Authenticate.validate_nova "
  - title: "BrowbeatAuthenticateValidateNovaConcurrencyControllerCountCompare99th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[99]"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"
    query: "_type: result AND rally_setup.name: Authenticate.validate_nova "
  - title: "BrowbeatAuthenticateValidateNovaConcurrencyControllerCountCompareMax-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "max"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"
    query: "_type: result AND rally_setup.name: Authenticate.validate_nova "

  - title: "BrowbeatKeystoneBasicAuthenticateUserAndValidateTokenConcurrencyControllerCountCompare-md"
    template: "markdown.json.j2"
    markdown: "# Controller Count Comparsion\\\\n[Browbeat](https://github.com/openstack/browbeat)\\\\n\\\\n[Rally KeystoneBasic.authenticate_user_and_validate_token](https://github.com/openstack/rally/blob/master/rally/plugins/openstack/scenarios/keystone/basic.py#L102)"
  # KeystoneBasic.authenticate_user_and_validate_token Controller Count Comparsion Visualizations: [Min, 50th, 95th, 99th, Max]
  - title: "BrowbeatKeystoneBasicAuthenticateUserAndValidateTokenConcurrencyControllerCountCompareResultCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"
    query: "_type: result AND rally_setup.name: KeystoneBasic.authenticate_user_and_validate_token "
  - title: "BrowbeatKeystoneBasicAuthenticateUserAndValidateTokenConcurrencyControllerCountCompareErrorCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"
    query: "_type: error AND rally_setup.name: KeystoneBasic.authenticate_user_and_validate_token "

  - title: "BrowbeatKeystoneBasicAuthenticateUserAndValidateTokenConcurrencyControllerCountCompareMin-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "min"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"
    query: "_type: result AND rally_setup.name: KeystoneBasic.authenticate_user_and_validate_token "
  - title: "BrowbeatKeystoneBasicAuthenticateUserAndValidateTokenConcurrencyControllerCountCompare50th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[50]"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"
    query: "_type: result AND rally_setup.name: KeystoneBasic.authenticate_user_and_validate_token "
  - title: "BrowbeatKeystoneBasicAuthenticateUserAndValidateTokenConcurrencyControllerCountCompare95th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[95]"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"
    query: "_type: result AND rally_setup.name: KeystoneBasic.authenticate_user_and_validate_token "
  - title: "BrowbeatKeystoneBasicAuthenticateUserAndValidateTokenConcurrencyControllerCountCompare99th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[99]"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"
    query: "_type: result AND rally_setup.name: KeystoneBasic.authenticate_user_and_validate_token "
  - title: "BrowbeatKeystoneBasicAuthenticateUserAndValidateTokenConcurrencyControllerCountCompareMax-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "max"
    split_bars_field: "environment-metadata.environment_setup.osp_controllers_number"
    query: "_type: result AND rally_setup.name: KeystoneBasic.authenticate_user_and_validate_token "

**********
DECISION===>: PASS
**********
=========================:::333:::END!!!=========================
=========================:::334:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/kibana-visualization/vars/shaker_scenario_throughput_concurrency_visualizations.yml
**********
---
#
# Shaker Scenario-Throughput-Concurrency - Visualizations Variables
#

shaker_scenario_throughput_concurrency_visualizations:
  - title: "Shaker-L2"
    template: "markdown.json.j2"
    markdown: "# Shaker-L2-Avg Throughput vs Concurency\\\\n[Browbeat](https://github.com/openstack/browbeat)\\\\n\\\\n[Shaker-L2](https://github.com/openstack/shaker/blob/master/doc/source/examples/full_l2.rst)"
  - title: "Browbeat-Shaker-L2"
    template: "shaker-throughput-concurrency.json.j2"
    query: "shaker_test_info.deployment.template: l2.hot"
  - title: "Shaker-L3-ES"
    template: "markdown.json.j2"
    markdown: "# Shaker-L3-East-West-Avg Throughput vs Concurency\\\\n[Browbeat](https://github.com/openstack/browbeat)\\\\n\\\\n[Shaker-L3-East-West](https://github.com/openstack/shaker/blob/master/doc/source/examples/full_l3_east_west.rst)"
  - title: "Browbeat-Shaker-L3-East-West"
    template: "shaker-throughput-concurrency.json.j2"
    query: "shaker_test_info.deployment.template: l3_east_west.hot"
  - title: "Shaker-L3-NS"
    template: "markdown.json.j2"
    markdown: "# Shaker-L3-North-South-Avg Throughput vs Concurency\\\\n[Browbeat](https://github.com/openstack/browbeat)\\\\n\\\\n[Shaker-L3-East-West](https://github.com/openstack/shaker/blob/master/doc/source/examples/full_l3_north_south.rst)"
  - title:  "Browbeat-Shaker-L3-North-South"
    template: "shaker-throughput-concurrency.json.j2"
    query: "shaker_test_info.deployment.template: l3_north_south.hot"

**********
DECISION===>: PASS
**********
=========================:::334:::END!!!=========================
=========================:::335:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/kibana-visualization/vars/keystone_ssl_visualizations.yml
**********
---
#
# Keystone SSL/TLS Comparsion - Visualizations Variables
#

keystone_ssl_visualizations:
  - title: "BrowbeatAuthenticateKeystoneConcurrencySSLCompare-md"
    template: "markdown.json.j2"
    markdown: "# Non-SSL vs SSL Public API Endpoints\\\\n[Browbeat](https://github.com/openstack/browbeat)\\\\n\\\\n[Rally Authenticate.keystone](https://github.com/openstack/rally/blob/master/rally/plugins/openstack/scenarios/authenticate/authenticate.py#L29)"
  # Authenticate.keystone SSL Comparsion Visualizations: [Min, 50th, 95th, 99th, Max]
  - title: "BrowbeatAuthenticateKeystoneConcurrencySSLCompareResultCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: result AND rally_setup.name: Authenticate.keystone "
  - title: "BrowbeatAuthenticateKeystoneConcurrencySSLCompareErrorCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: error AND rally_setup.name: Authenticate.keystone "

  - title: "BrowbeatAuthenticateKeystoneConcurrencySSLCompareMin-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "min"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: result AND rally_setup.name: Authenticate.keystone "
  - title: "BrowbeatAuthenticateKeystoneConcurrencySSLCompare50th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[50]"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: result AND rally_setup.name: Authenticate.keystone "
  - title: "BrowbeatAuthenticateKeystoneConcurrencySSLCompare95th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[95]"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: result AND rally_setup.name: Authenticate.keystone "
  - title: "BrowbeatAuthenticateKeystoneConcurrencySSLCompare99th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[99]"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: result AND rally_setup.name: Authenticate.keystone "
  - title: "BrowbeatAuthenticateKeystoneConcurrencySSLCompareMax-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "max"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: result AND rally_setup.name: Authenticate.keystone "

  - title: "BrowbeatAuthenticateValidateCinderConcurrencySSLCompare-md"
    template: "markdown.json.j2"
    markdown: "# Non-SSL vs SSL Public API Endpoints\\\\n[Browbeat](https://github.com/openstack/browbeat)\\\\n\\\\n[Rally Authenticate.validate_cinder](https://github.com/openstack/rally/blob/master/rally/plugins/openstack/scenarios/authenticate/authenticate.py#L104)"
  # Authenticate.validate_cinder SSL Comparsion Visualizations: [Min, 50th, 95th, 99th, Max]
  - title: "BrowbeatAuthenticateValidateCinderConcurrencySSLCompareResultCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: result AND rally_setup.name: Authenticate.validate_cinder "
  - title: "BrowbeatAuthenticateValidateCinderConcurrencySSLCompareErrorCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: error AND rally_setup.name: Authenticate.validate_cinder "

  - title: "BrowbeatAuthenticateValidateCinderConcurrencySSLCompareMin-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "min"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: result AND rally_setup.name: Authenticate.validate_cinder "
  - title: "BrowbeatAuthenticateValidateCinderConcurrencySSLCompare50th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[50]"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: result AND rally_setup.name: Authenticate.validate_cinder "
  - title: "BrowbeatAuthenticateValidateCinderConcurrencySSLCompare95th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[95]"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: result AND rally_setup.name: Authenticate.validate_cinder "
  - title: "BrowbeatAuthenticateValidateCinderConcurrencySSLCompare99th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[99]"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: result AND rally_setup.name: Authenticate.validate_cinder "
  - title: "BrowbeatAuthenticateValidateCinderConcurrencySSLCompareMax-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "max"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: result AND rally_setup.name: Authenticate.validate_cinder "


  - title: "BrowbeatAuthenticateValidateGlanceConcurrencySSLCompare-md"
    template: "markdown.json.j2"
    markdown: "# Non-SSL vs SSL Public API Endpoints\\\\n[Browbeat](https://github.com/openstack/browbeat)\\\\n\\\\n[Rally Authenticate.validate_glance](https://github.com/openstack/rally/blob/master/rally/plugins/openstack/scenarios/authenticate/authenticate.py#L39)"
  # Authenticate.validate_glance SSL Comparsion Visualizations: [Min, 50th, 95th, 99th, Max]
  - title: "BrowbeatAuthenticateValidateGlanceConcurrencySSLCompareResultCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: result AND rally_setup.name: Authenticate.validate_glance "
  - title: "BrowbeatAuthenticateValidateGlanceConcurrencySSLCompareErrorCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: error AND rally_setup.name: Authenticate.validate_glance "

  - title: "BrowbeatAuthenticateValidateGlanceConcurrencySSLCompareMin-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "min"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: result AND rally_setup.name: Authenticate.validate_glance "
  - title: "BrowbeatAuthenticateValidateGlanceConcurrencySSLCompare50th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[50]"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: result AND rally_setup.name: Authenticate.validate_glance "
  - title: "BrowbeatAuthenticateValidateGlanceConcurrencySSLCompare95th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[95]"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: result AND rally_setup.name: Authenticate.validate_glance "
  - title: "BrowbeatAuthenticateValidateGlanceConcurrencySSLCompare99th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[99]"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: result AND rally_setup.name: Authenticate.validate_glance "
  - title: "BrowbeatAuthenticateValidateGlanceConcurrencySSLCompareMax-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "max"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: result AND rally_setup.name: Authenticate.validate_glance "

  - title: "BrowbeatAuthenticateValidateHeatConcurrencySSLCompare-md"
    template: "markdown.json.j2"
    markdown: "# Non-SSL vs SSL Public API Endpoints\\\\n[Browbeat](https://github.com/openstack/browbeat)\\\\n\\\\n[Rally Authenticate.validate_heat](https://github.com/openstack/rally/blob/master/rally/plugins/openstack/scenarios/authenticate/authenticate.py#L146)"
  # Authenticate.validate_heat SSL Comparsion Visualizations: [Min, 50th, 95th, 99th, Max]
  - title: "BrowbeatAuthenticateValidateHeatConcurrencySSLCompareResultCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: result AND rally_setup.name: Authenticate.validate_heat "
  - title: "BrowbeatAuthenticateValidateHeatConcurrencySSLCompareErrorCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: error AND rally_setup.name: Authenticate.validate_heat "

  - title: "BrowbeatAuthenticateValidateHeatConcurrencySSLCompareMin-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "min"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: result AND rally_setup.name: Authenticate.validate_heat "
  - title: "BrowbeatAuthenticateValidateHeatConcurrencySSLCompare50th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[50]"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: result AND rally_setup.name: Authenticate.validate_heat "
  - title: "BrowbeatAuthenticateValidateHeatConcurrencySSLCompare95th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[95]"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: result AND rally_setup.name: Authenticate.validate_heat "
  - title: "BrowbeatAuthenticateValidateHeatConcurrencySSLCompare99th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[99]"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: result AND rally_setup.name: Authenticate.validate_heat "
  - title: "BrowbeatAuthenticateValidateHeatConcurrencySSLCompareMax-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "max"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: result AND rally_setup.name: Authenticate.validate_heat "

  - title: "BrowbeatAuthenticateValidateNeutronConcurrencySSLCompare-md"
    template: "markdown.json.j2"
    markdown: "# Non-SSL vs SSL Public API Endpoints\\\\n[Browbeat](https://github.com/openstack/browbeat)\\\\n\\\\n[Rally Authenticate.validate_neutron](https://github.com/openstack/rally/blob/master/rally/plugins/openstack/scenarios/authenticate/authenticate.py#L125)"
  # Authenticate.validate_neutron SSL Comparsion Visualizations: [Min, 50th, 95th, 99th, Max]
  - title: "BrowbeatAuthenticateValidateNeutronConcurrencySSLCompareResultCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: result AND rally_setup.name: Authenticate.validate_neutron "
  - title: "BrowbeatAuthenticateValidateNeutronConcurrencySSLCompareErrorCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: error AND rally_setup.name: Authenticate.validate_neutron "

  - title: "BrowbeatAuthenticateValidateNeutronConcurrencySSLCompareMin-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "min"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: result AND rally_setup.name: Authenticate.validate_neutron "
  - title: "BrowbeatAuthenticateValidateNeutronConcurrencySSLCompare50th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[50]"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: result AND rally_setup.name: Authenticate.validate_neutron "
  - title: "BrowbeatAuthenticateValidateNeutronConcurrencySSLCompare95th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[95]"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: result AND rally_setup.name: Authenticate.validate_neutron "
  - title: "BrowbeatAuthenticateValidateNeutronConcurrencySSLCompare99th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[99]"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: result AND rally_setup.name: Authenticate.validate_neutron "
  - title: "BrowbeatAuthenticateValidateNeutronConcurrencySSLCompareMax-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "max"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: result AND rally_setup.name: Authenticate.validate_neutron "

  - title: "BrowbeatAuthenticateValidateNovaConcurrencySSLCompare-md"
    template: "markdown.json.j2"
    markdown: "# Non-SSL vs SSL Public API Endpoints\\\\n[Browbeat](https://github.com/openstack/browbeat)\\\\n\\\\n[Rally Authenticate.validate_nova](https://github.com/openstack/rally/blob/master/rally/plugins/openstack/scenarios/authenticate/authenticate.py#L62)"
  # Authenticate.validate_nova SSL Comparsion Visualizations: [Min, 50th, 95th, 99th, Max]
  - title: "BrowbeatAuthenticateValidateNovaConcurrencySSLCompareResultCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: result AND rally_setup.name: Authenticate.validate_nova "
  - title: "BrowbeatAuthenticateValidateNovaConcurrencySSLCompareErrorCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: error AND rally_setup.name: Authenticate.validate_nova "

  - title: "BrowbeatAuthenticateValidateNovaConcurrencySSLCompareMin-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "min"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: result AND rally_setup.name: Authenticate.validate_nova "
  - title: "BrowbeatAuthenticateValidateNovaConcurrencySSLCompare50th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[50]"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: result AND rally_setup.name: Authenticate.validate_nova "
  - title: "BrowbeatAuthenticateValidateNovaConcurrencySSLCompare95th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[95]"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: result AND rally_setup.name: Authenticate.validate_nova "
  - title: "BrowbeatAuthenticateValidateNovaConcurrencySSLCompare99th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[99]"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: result AND rally_setup.name: Authenticate.validate_nova "
  - title: "BrowbeatAuthenticateValidateNovaConcurrencySSLCompareMax-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "max"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: result AND rally_setup.name: Authenticate.validate_nova "

  - title: "BrowbeatKeystoneBasicAuthenticateUserAndValidateTokenConcurrencySSLCompare-md"
    template: "markdown.json.j2"
    markdown: "# Non-SSL vs SSL Public API Endpoints\\\\n[Browbeat](https://github.com/openstack/browbeat)\\\\n\\\\n[Rally KeystoneBasic.authenticate_user_and_validate_token](https://github.com/openstack/rally/blob/master/rally/plugins/openstack/scenarios/keystone/basic.py#L102)"
  # KeystoneBasic.authenticate_user_and_validate_token SSL Comparsion Visualizations: [Min, 50th, 95th, 99th, Max]
  - title: "BrowbeatKeystoneBasicAuthenticateUserAndValidateTokenConcurrencySSLCompareResultCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: result AND rally_setup.name: KeystoneBasic.authenticate_user_and_validate_token "
  - title: "BrowbeatKeystoneBasicAuthenticateUserAndValidateTokenConcurrencySSLCompareErrorCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: error AND rally_setup.name: KeystoneBasic.authenticate_user_and_validate_token "

  - title: "BrowbeatKeystoneBasicAuthenticateUserAndValidateTokenConcurrencySSLCompareMin-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "min"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: result AND rally_setup.name: KeystoneBasic.authenticate_user_and_validate_token "
  - title: "BrowbeatKeystoneBasicAuthenticateUserAndValidateTokenConcurrencySSLCompare50th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[50]"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: result AND rally_setup.name: KeystoneBasic.authenticate_user_and_validate_token "
  - title: "BrowbeatKeystoneBasicAuthenticateUserAndValidateTokenConcurrencySSLCompare95th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[95]"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: result AND rally_setup.name: KeystoneBasic.authenticate_user_and_validate_token "
  - title: "BrowbeatKeystoneBasicAuthenticateUserAndValidateTokenConcurrencySSLCompare99th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[99]"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: result AND rally_setup.name: KeystoneBasic.authenticate_user_and_validate_token "
  - title: "BrowbeatKeystoneBasicAuthenticateUserAndValidateTokenConcurrencySSLCompareMax-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "max"
    split_bars_field: "software-metadata.nova.novncproxy_base_url"
    include_pattern: "\\\"include\\\": { \\\"pattern\\\": \\\"http|https\\\", \\\"flags\\\": \\\"MULTILINE\\\"},"
    query: "_type: result AND rally_setup.name: KeystoneBasic.authenticate_user_and_validate_token "

**********
DECISION===>: PASS
**********
=========================:::335:::END!!!=========================
=========================:::336:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/kibana-visualization/vars/keystone_controller_count_dashboards.yml
**********
---
#
# Keystone Controller Count Comparsion Dashboards
#

keystone_controller_count_dashboards:
  # Authenticate.keystone Dashboard
  - file_name: "BrowbeatAuthenticateKeystoneControllerCountCompare.json"
    title: "Browbeat Authenticate.keystone Controller Count Comparsion"
    darkTheme: "true"
    panels:
      - id: "BrowbeatAuthenticateKeystoneConcurrencyControllerCountCompare-md"
        type: "visualization"
        panelIndex: 1
        size_x: 12
        size_y: 2
        col: 1
        row: 1
      - id: "BrowbeatAuthenticateKeystoneConcurrencyControllerCountCompareResultCount-bg"
        type: "visualization"
        panelIndex: 2
        size_x: 12
        size_y: 3
        col: 1
        row: 3
      - id: "BrowbeatAuthenticateKeystoneConcurrencyControllerCountCompareErrorCount-bg"
        type: "visualization"
        panelIndex: 3
        size_x: 12
        size_y: 3
        col: 1
        row: 6
      - id: "BrowbeatAuthenticateKeystoneConcurrencyControllerCountCompareMin-bg"
        type: "visualization"
        panelIndex: 4
        size_x: 12
        size_y: 3
        col: 1
        row: 9
      - id: "BrowbeatAuthenticateKeystoneConcurrencyControllerCountCompare50th-bg"
        type: "visualization"
        panelIndex: 5
        size_x: 12
        size_y: 3
        col: 1
        row: 12
      - id: "BrowbeatAuthenticateKeystoneConcurrencyControllerCountCompare95th-bg"
        type: "visualization"
        panelIndex: 6
        size_x: 12
        size_y: 3
        col: 1
        row: 15
      - id: "BrowbeatAuthenticateKeystoneConcurrencyControllerCountCompare99th-bg"
        type: "visualization"
        panelIndex: 7
        size_x: 12
        size_y: 3
        col: 1
        row: 18
      - id: "BrowbeatAuthenticateKeystoneConcurrencyControllerCountCompareMax-bg"
        type: "visualization"
        panelIndex: 8
        size_x: 12
        size_y: 3
        col: 1
        row: 21
  # Authenticate.validate_cinder Dashboard
  - file_name: "BrowbeatAuthenticateValidateCinderControllerCountCompare.json"
    title: "Browbeat Authenticate.validate_cinder Controller Count Comparsion"
    darkTheme: "true"
    panels:
      - id: "BrowbeatAuthenticateValidateCinderConcurrencyControllerCountCompare-md"
        type: "visualization"
        panelIndex: 1
        size_x: 12
        size_y: 2
        col: 1
        row: 1
      - id: "BrowbeatAuthenticateValidateCinderConcurrencyControllerCountCompareResultCount-bg"
        type: "visualization"
        panelIndex: 2
        size_x: 12
        size_y: 3
        col: 1
        row: 3
      - id: "BrowbeatAuthenticateValidateCinderConcurrencyControllerCountCompareErrorCount-bg"
        type: "visualization"
        panelIndex: 3
        size_x: 12
        size_y: 3
        col: 1
        row: 6
      - id: "BrowbeatAuthenticateValidateCinderConcurrencyControllerCountCompareMin-bg"
        type: "visualization"
        panelIndex: 4
        size_x: 12
        size_y: 3
        col: 1
        row: 9
      - id: "BrowbeatAuthenticateValidateCinderConcurrencyControllerCountCompare50th-bg"
        type: "visualization"
        panelIndex: 5
        size_x: 12
        size_y: 3
        col: 1
        row: 12
      - id: "BrowbeatAuthenticateValidateCinderConcurrencyControllerCountCompare95th-bg"
        type: "visualization"
        panelIndex: 6
        size_x: 12
        size_y: 3
        col: 1
        row: 15
      - id: "BrowbeatAuthenticateValidateCinderConcurrencyControllerCountCompare99th-bg"
        type: "visualization"
        panelIndex: 7
        size_x: 12
        size_y: 3
        col: 1
        row: 18
      - id: "BrowbeatAuthenticateValidateCinderConcurrencyControllerCountCompareMax-bg"
        type: "visualization"
        panelIndex: 8
        size_x: 12
        size_y: 3
        col: 1
        row: 21
  # Authenticate.validate_glance Dashboard
  - file_name: "BrowbeatAuthenticateValidateGlanceControllerCountCompare.json"
    title: "Browbeat Authenticate.validate_glance Controller Count Comparsion"
    darkTheme: "true"
    panels:
      - id: "BrowbeatAuthenticateValidateGlanceConcurrencyControllerCountCompare-md"
        type: "visualization"
        panelIndex: 1
        size_x: 12
        size_y: 2
        col: 1
        row: 1
      - id: "BrowbeatAuthenticateValidateGlanceConcurrencyControllerCountCompareResultCount-bg"
        type: "visualization"
        panelIndex: 2
        size_x: 12
        size_y: 3
        col: 1
        row: 3
      - id: "BrowbeatAuthenticateValidateGlanceConcurrencyControllerCountCompareErrorCount-bg"
        type: "visualization"
        panelIndex: 3
        size_x: 12
        size_y: 3
        col: 1
        row: 6
      - id: "BrowbeatAuthenticateValidateGlanceConcurrencyControllerCountCompareMin-bg"
        type: "visualization"
        panelIndex: 4
        size_x: 12
        size_y: 3
        col: 1
        row: 9
      - id: "BrowbeatAuthenticateValidateGlanceConcurrencyControllerCountCompare50th-bg"
        type: "visualization"
        panelIndex: 5
        size_x: 12
        size_y: 3
        col: 1
        row: 12
      - id: "BrowbeatAuthenticateValidateGlanceConcurrencyControllerCountCompare95th-bg"
        type: "visualization"
        panelIndex: 6
        size_x: 12
        size_y: 3
        col: 1
        row: 15
      - id: "BrowbeatAuthenticateValidateGlanceConcurrencyControllerCountCompare99th-bg"
        type: "visualization"
        panelIndex: 7
        size_x: 12
        size_y: 3
        col: 1
        row: 18
      - id: "BrowbeatAuthenticateValidateGlanceConcurrencyControllerCountCompareMax-bg"
        type: "visualization"
        panelIndex: 8
        size_x: 12
        size_y: 3
        col: 1
        row: 21
  # Authenticate.validate_heat Dashboard
  - file_name: "BrowbeatAuthenticateValidateHeatControllerCountCompare.json"
    title: "Browbeat Authenticate.validate_heat Controller Count Comparsion"
    darkTheme: "true"
    panels:
      - id: "BrowbeatAuthenticateValidateHeatConcurrencyControllerCountCompare-md"
        type: "visualization"
        panelIndex: 1
        size_x: 12
        size_y: 2
        col: 1
        row: 1
      - id: "BrowbeatAuthenticateValidateHeatConcurrencyControllerCountCompareResultCount-bg"
        type: "visualization"
        panelIndex: 2
        size_x: 12
        size_y: 3
        col: 1
        row: 3
      - id: "BrowbeatAuthenticateValidateHeatConcurrencyControllerCountCompareErrorCount-bg"
        type: "visualization"
        panelIndex: 3
        size_x: 12
        size_y: 3
        col: 1
        row: 6
      - id: "BrowbeatAuthenticateValidateHeatConcurrencyControllerCountCompareMin-bg"
        type: "visualization"
        panelIndex: 4
        size_x: 12
        size_y: 3
        col: 1
        row: 9
      - id: "BrowbeatAuthenticateValidateHeatConcurrencyControllerCountCompare50th-bg"
        type: "visualization"
        panelIndex: 5
        size_x: 12
        size_y: 3
        col: 1
        row: 12
      - id: "BrowbeatAuthenticateValidateHeatConcurrencyControllerCountCompare95th-bg"
        type: "visualization"
        panelIndex: 6
        size_x: 12
        size_y: 3
        col: 1
        row: 15
      - id: "BrowbeatAuthenticateValidateHeatConcurrencyControllerCountCompare99th-bg"
        type: "visualization"
        panelIndex: 7
        size_x: 12
        size_y: 3
        col: 1
        row: 18
      - id: "BrowbeatAuthenticateValidateHeatConcurrencyControllerCountCompareMax-bg"
        type: "visualization"
        panelIndex: 8
        size_x: 12
        size_y: 3
        col: 1
        row: 21
  # Authenticate.validate_neutron Dashboard
  - file_name: "BrowbeatAuthenticateValidateNeutronControllerCountCompare.json"
    title: "Browbeat Authenticate.validate_neutron Controller Count Comparsion"
    darkTheme: "true"
    panels:
      - id: "BrowbeatAuthenticateValidateNeutronConcurrencyControllerCountCompare-md"
        type: "visualization"
        panelIndex: 1
        size_x: 12
        size_y: 2
        col: 1
        row: 1
      - id: "BrowbeatAuthenticateValidateNeutronConcurrencyControllerCountCompareResultCount-bg"
        type: "visualization"
        panelIndex: 2
        size_x: 12
        size_y: 3
        col: 1
        row: 3
      - id: "BrowbeatAuthenticateValidateNeutronConcurrencyControllerCountCompareErrorCount-bg"
        type: "visualization"
        panelIndex: 3
        size_x: 12
        size_y: 3
        col: 1
        row: 6
      - id: "BrowbeatAuthenticateValidateNeutronConcurrencyControllerCountCompareMin-bg"
        type: "visualization"
        panelIndex: 4
        size_x: 12
        size_y: 3
        col: 1
        row: 9
      - id: "BrowbeatAuthenticateValidateNeutronConcurrencyControllerCountCompare50th-bg"
        type: "visualization"
        panelIndex: 5
        size_x: 12
        size_y: 3
        col: 1
        row: 12
      - id: "BrowbeatAuthenticateValidateNeutronConcurrencyControllerCountCompare95th-bg"
        type: "visualization"
        panelIndex: 6
        size_x: 12
        size_y: 3
        col: 1
        row: 15
      - id: "BrowbeatAuthenticateValidateNeutronConcurrencyControllerCountCompare99th-bg"
        type: "visualization"
        panelIndex: 7
        size_x: 12
        size_y: 3
        col: 1
        row: 18
      - id: "BrowbeatAuthenticateValidateNeutronConcurrencyControllerCountCompareMax-bg"
        type: "visualization"
        panelIndex: 8
        size_x: 12
        size_y: 3
        col: 1
        row: 21
  #  Authenticate.validate_nova Dashboard
  - file_name: "BrowbeatAuthenticateValidateNovaControllerCountCompare.json"
    title: "Browbeat Authenticate.validate_nova Controller Count Comparsion"
    darkTheme: "true"
    panels:
      - id: "BrowbeatAuthenticateValidateNovaConcurrencyControllerCountCompare-md"
        type: "visualization"
        panelIndex: 1
        size_x: 12
        size_y: 2
        col: 1
        row: 1
      - id: "BrowbeatAuthenticateValidateNovaConcurrencyControllerCountCompareResultCount-bg"
        type: "visualization"
        panelIndex: 2
        size_x: 12
        size_y: 3
        col: 1
        row: 3
      - id: "BrowbeatAuthenticateValidateNovaConcurrencyControllerCountCompareErrorCount-bg"
        type: "visualization"
        panelIndex: 3
        size_x: 12
        size_y: 3
        col: 1
        row: 6
      - id: "BrowbeatAuthenticateValidateNovaConcurrencyControllerCountCompareMin-bg"
        type: "visualization"
        panelIndex: 4
        size_x: 12
        size_y: 3
        col: 1
        row: 9
      - id: "BrowbeatAuthenticateValidateNovaConcurrencyControllerCountCompare50th-bg"
        type: "visualization"
        panelIndex: 5
        size_x: 12
        size_y: 3
        col: 1
        row: 12
      - id: "BrowbeatAuthenticateValidateNovaConcurrencyControllerCountCompare95th-bg"
        type: "visualization"
        panelIndex: 6
        size_x: 12
        size_y: 3
        col: 1
        row: 15
      - id: "BrowbeatAuthenticateValidateNovaConcurrencyControllerCountCompare99th-bg"
        type: "visualization"
        panelIndex: 7
        size_x: 12
        size_y: 3
        col: 1
        row: 18
      - id: "BrowbeatAuthenticateValidateNovaConcurrencyControllerCountCompareMax-bg"
        type: "visualization"
        panelIndex: 8
        size_x: 12
        size_y: 3
        col: 1
        row: 21

  # KeystoneBasic.authenticate_user_and_validate_token Dashboard
  - file_name: "BrowbeatKeystoneBasicAuthenticateUserAndValidateTokenControllerCountCompare.json"
    title: "Browbeat KeystoneBasic.authenticate_user_and_validate_token Controller Count Comparsion"
    darkTheme: "true"
    panels:
      - id: "BrowbeatKeystoneBasicAuthenticateUserAndValidateTokenConcurrencyControllerCountCompare-md"
        type: "visualization"
        panelIndex: 1
        size_x: 12
        size_y: 2
        col: 1
        row: 1
      - id: "BrowbeatKeystoneBasicAuthenticateUserAndValidateTokenConcurrencyControllerCountCompareResultCount-bg"
        type: "visualization"
        panelIndex: 2
        size_x: 12
        size_y: 3
        col: 1
        row: 3
      - id: "BrowbeatKeystoneBasicAuthenticateUserAndValidateTokenConcurrencyControllerCountCompareErrorCount-bg"
        type: "visualization"
        panelIndex: 3
        size_x: 12
        size_y: 3
        col: 1
        row: 6
      - id: "BrowbeatKeystoneBasicAuthenticateUserAndValidateTokenConcurrencyControllerCountCompareMin-bg"
        type: "visualization"
        panelIndex: 4
        size_x: 12
        size_y: 3
        col: 1
        row: 9
      - id: "BrowbeatKeystoneBasicAuthenticateUserAndValidateTokenConcurrencyControllerCountCompare50th-bg"
        type: "visualization"
        panelIndex: 5
        size_x: 12
        size_y: 3
        col: 1
        row: 12
      - id: "BrowbeatKeystoneBasicAuthenticateUserAndValidateTokenConcurrencyControllerCountCompare95th-bg"
        type: "visualization"
        panelIndex: 6
        size_x: 12
        size_y: 3
        col: 1
        row: 15
      - id: "BrowbeatKeystoneBasicAuthenticateUserAndValidateTokenConcurrencyControllerCountCompare99th-bg"
        type: "visualization"
        panelIndex: 7
        size_x: 12
        size_y: 3
        col: 1
        row: 18
      - id: "BrowbeatKeystoneBasicAuthenticateUserAndValidateTokenConcurrencyControllerCountCompareMax-bg"
        type: "visualization"
        panelIndex: 8
        size_x: 12
        size_y: 3
        col: 1
        row: 21

**********
DECISION===>: PASS
**********
=========================:::336:::END!!!=========================
=========================:::337:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/kibana-visualization/vars/shaker_cloud_comparison_dashboard.yml
**********
---
#
# Shaker Scenario Throughput vs Concurrency Dashboard
#

shaker_cloud_comparison_dashboard:
  - file_name: "ShakerCloudComparison.json"
    title: "Browbeat Shaker Cloud Performance Comparison"
    darkTheme: "true"
    panels:
      - id: "Shaker-Cloud-Comparison-L2-Throughput"
        type: "visualization"
        panelIndex: 1
        size_x: 6
        size_y: 3
        col: 1
        row: 1
      - id: "Browbeat-Shaker-Cloud-Comprison-L2-Throughput"
        type: "visualization"
        panelIndex: 2
        size_x: 6
        size_y: 5
        col: 1
        row: 4
      - id: "Shaker-Cloud-Comparison-L2-Latency"
        type: "visualization"
        panelIndex: 3
        size_x: 6
        size_y: 3
        col: 7
        row: 1
      - id: "Browbeat-Shaker-Cloud-Comprison-L2-Latency"
        type: "visualization"
        panelIndex: 4
        size_x: 6
        size_y: 5
        col: 7
        row: 4
      - id: "Shaker-Cloud-Comparison-L3-ES-Throughput"
        type: "visualization"
        panelIndex: 5
        size_x: 6
        size_y: 3
        col: 1
        row: 9
      - id: "Shaker-Cloud-Comparison-L3-East-West-Latency"
        type: "visualization"
        panelIndex: 6
        size_x: 6
        size_y: 3
        col: 7
        row: 9
      - id: "Browbeat-Shaker-Cloud-Comparison-L3-East-West-Throughput"
        type: "visualization"
        panelIndex: 7
        size_x: 6
        size_y: 5
        col: 1
        row: 12
      - id: "Browbeat-Shaker-Cloud-Comparison-L3-East-West-Latency"
        type: "visualization"
        panelIndex: 8
        size_x: 6
        size_y: 5
        col: 7
        row: 12
      - id: "Shaker-Cloud-Comparison-L3-North-South-Throughput"
        type: "visualization"
        panelIndex: 9
        size_x: 6
        size_y: 3
        col: 1
        row: 17
      - id: "Shaker-Cloud-Comparison-L3-North-South-Latency"
        type: "visualization"
        panelIndex: 10
        size_x: 6
        size_y: 3
        col: 7
        row: 17
      - id: "Browbeat-Shaker-Cloud-Comparison-L3-North-South-Throughput"
        type: "visualization"
        panelIndex: 11
        size_x: 6
        size_y: 5
        col: 1
        row: 20
      - id: "Browbeat-Shaker-Cloud-Comparison-L3-North-South-Latency"
        type: "visualization"
        panelIndex: 12
        size_x: 6
        size_y: 5
        col: 7
        row: 20

**********
DECISION===>: PASS
**********
=========================:::337:::END!!!=========================
=========================:::338:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/kibana-visualization/vars/keystone_osp_version_token_visualizations.yml
**********
---
#
# Keystone OSP Version Token Comparsion - Visualizations Variables
#

keystone_osp_version_token_visualizations:
  # Authenticate.keystone Version Comparsion Visualizations: [Min, 50th, 95th, 99th, Max] for UUID
  - title: "BrowbeatAuthenticateKeystoneConcurrencyVersionCompareUUID-md"
    template: "markdown.json.j2"
    markdown: "# UUID Tokens\\\\n[Browbeat](https://github.com/openstack/browbeat)\\\\n\\\\n[Rally Authenticate.keystone](https://github.com/openstack/rally/blob/master/rally/plugins/openstack/scenarios/authenticate/authenticate.py#L28)"
  - title: "BrowbeatAuthenticateKeystoneConcurrencyVersionCompareUUIDResultCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "version.osp_series"
    query: "_type: result AND rally_setup.name: Authenticate.keystone AND software-metadata.keystone.provider:*uuid*"
  - title: "BrowbeatAuthenticateKeystoneConcurrencyVersionCompareUUIDErrorCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "version.osp_series"
    query: "_type: error AND rally_setup.name: Authenticate.keystone AND software-metadata.keystone.provider:*uuid*"

  - title: "BrowbeatAuthenticateKeystoneConcurrencyVersionCompareUUIDMin-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "min"
    split_bars_field: "version.osp_series"
    query: "_type: result AND rally_setup.name: Authenticate.keystone AND software-metadata.keystone.provider:*uuid*"
  - title: "BrowbeatAuthenticateKeystoneConcurrencyVersionCompareUUID50th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[50]"
    split_bars_field: "version.osp_series"
    query: "_type: result AND rally_setup.name: Authenticate.keystone AND software-metadata.keystone.provider:*uuid*"
  - title: "BrowbeatAuthenticateKeystoneConcurrencyVersionCompareUUID95th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[95]"
    split_bars_field: "version.osp_series"
    query: "_type: result AND rally_setup.name: Authenticate.keystone AND software-metadata.keystone.provider:*uuid*"
  - title: "BrowbeatAuthenticateKeystoneConcurrencyVersionCompareUUID99th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[99]"
    split_bars_field: "version.osp_series"
    query: "_type: result AND rally_setup.name: Authenticate.keystone AND software-metadata.keystone.provider:*uuid*"
  - title: "BrowbeatAuthenticateKeystoneConcurrencyVersionCompareUUIDMax-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "max"
    split_bars_field: "version.osp_series"
    query: "_type: result AND rally_setup.name: Authenticate.keystone AND software-metadata.keystone.provider:*uuid*"
  # Authenticate.keystone Version Comparsion Visualizations: [Min, 50th, 95th, 99th, Max] for Fernet
  - title: "BrowbeatAuthenticateKeystoneConcurrencyVersionCompareFernet-md"
    template: "markdown.json.j2"
    markdown: "# Fernet Tokens\\\\n[Browbeat](https://github.com/openstack/browbeat)\\\\n\\\\n[Rally Authenticate.keystone](https://github.com/openstack/rally/blob/master/rally/plugins/openstack/scenarios/authenticate/authenticate.py#L28)"
  - title: "BrowbeatAuthenticateKeystoneConcurrencyVersionCompareFernetResultCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "version.osp_series"
    query: "_type: result AND rally_setup.name: Authenticate.keystone AND software-metadata.keystone.provider:*fernet*"
  - title: "BrowbeatAuthenticateKeystoneConcurrencyVersionCompareFernetErrorCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "version.osp_series"
    query: "_type: error AND rally_setup.name: Authenticate.keystone AND software-metadata.keystone.provider:*fernet*"

  - title: "BrowbeatAuthenticateKeystoneConcurrencyVersionCompareFernetMin-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "min"
    split_bars_field: "version.osp_series"
    query: "_type: result AND rally_setup.name: Authenticate.keystone AND software-metadata.keystone.provider:*fernet*"
  - title: "BrowbeatAuthenticateKeystoneConcurrencyVersionCompareFernet50th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[50]"
    split_bars_field: "version.osp_series"
    query: "_type: result AND rally_setup.name: Authenticate.keystone AND software-metadata.keystone.provider:*fernet*"
  - title: "BrowbeatAuthenticateKeystoneConcurrencyVersionCompareFernet95th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[95]"
    split_bars_field: "version.osp_series"
    query: "_type: result AND rally_setup.name: Authenticate.keystone AND software-metadata.keystone.provider:*fernet*"
  - title: "BrowbeatAuthenticateKeystoneConcurrencyVersionCompareFernet99th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[99]"
    split_bars_field: "version.osp_series"
    query: "_type: result AND rally_setup.name: Authenticate.keystone AND software-metadata.keystone.provider:*fernet*"
  - title: "BrowbeatAuthenticateKeystoneConcurrencyVersionCompareFernetMax-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "max"
    split_bars_field: "version.osp_series"
    query: "_type: result AND rally_setup.name: Authenticate.keystone AND software-metadata.keystone.provider:*fernet*"

  # Authenticate.validate_nova Version Comparsion Visualizations: [Min, 50th, 95th, 99th, Max] for UUID
  - title: "BrowbeatAuthenticateValidateNovaConcurrencyVersionCompareUUID-md"
    template: "markdown.json.j2"
    markdown: "# UUID Tokens\\\\n[Browbeat](https://github.com/openstack/browbeat)\\\\n\\\\n[Rally Authenticate.validate_nova](https://github.com/openstack/rally/blob/master/rally/plugins/openstack/scenarios/authenticate/authenticate.py#L54)\\\\n\\\\nrepetitions: 2"
  - title: "BrowbeatAuthenticateValidateNovaConcurrencyVersionCompareUUIDResultCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "version.osp_series"
    query: "_type: result AND rally_setup.name: Authenticate.validate_nova AND software-metadata.keystone.provider:*uuid*"
  - title: "BrowbeatAuthenticateValidateNovaConcurrencyVersionCompareUUIDErrorCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "version.osp_series"
    query: "_type: error AND rally_setup.name: Authenticate.validate_nova AND software-metadata.keystone.provider:*uuid*"

  - title: "BrowbeatAuthenticateValidateNovaConcurrencyVersionCompareUUIDMin-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "min"
    split_bars_field: "version.osp_series"
    query: "_type: result AND rally_setup.name: Authenticate.validate_nova AND software-metadata.keystone.provider:*uuid*"
  - title: "BrowbeatAuthenticateValidateNovaConcurrencyVersionCompareUUID50th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[50]"
    split_bars_field: "version.osp_series"
    query: "_type: result AND rally_setup.name: Authenticate.validate_nova AND software-metadata.keystone.provider:*uuid*"
  - title: "BrowbeatAuthenticateValidateNovaConcurrencyVersionCompareUUID95th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[95]"
    split_bars_field: "version.osp_series"
    query: "_type: result AND rally_setup.name: Authenticate.validate_nova AND software-metadata.keystone.provider:*uuid*"
  - title: "BrowbeatAuthenticateValidateNovaConcurrencyVersionCompareUUID99th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[99]"
    split_bars_field: "version.osp_series"
    query: "_type: result AND rally_setup.name: Authenticate.validate_nova AND software-metadata.keystone.provider:*uuid*"
  - title: "BrowbeatAuthenticateValidateNovaConcurrencyVersionCompareUUIDMax-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "max"
    split_bars_field: "version.osp_series"
    query: "_type: result AND rally_setup.name: Authenticate.validate_nova AND software-metadata.keystone.provider:*uuid*"
  # Authenticate.validate_nova Version Comparsion Visualizations: [Min, 50th, 95th, 99th, Max] for Fernet
  - title: "BrowbeatAuthenticateValidateNovaConcurrencyVersionCompareFernet-md"
    template: "markdown.json.j2"
    markdown: "# Fernet Tokens\\\\n[Browbeat](https://github.com/openstack/browbeat)\\\\n\\\\n[Rally Authenticate.validate_nova](https://github.com/openstack/rally/blob/master/rally/plugins/openstack/scenarios/authenticate/authenticate.py#L54)\\\\n\\\\nrepetitions: 2"
  - title: "BrowbeatAuthenticateValidateNovaConcurrencyVersionCompareFernetResultCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "version.osp_series"
    query: "_type: result AND rally_setup.name: Authenticate.validate_nova AND software-metadata.keystone.provider:*fernet*"
  - title: "BrowbeatAuthenticateValidateNovaConcurrencyVersionCompareFernetErrorCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "version.osp_series"
    query: "_type: error AND rally_setup.name: Authenticate.validate_nova AND software-metadata.keystone.provider:*fernet*"

  - title: "BrowbeatAuthenticateValidateNovaConcurrencyVersionCompareFernetMin-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "min"
    split_bars_field: "version.osp_series"
    query: "_type: result AND rally_setup.name: Authenticate.validate_nova AND software-metadata.keystone.provider:*fernet*"
  - title: "BrowbeatAuthenticateValidateNovaConcurrencyVersionCompareFernet50th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[50]"
    split_bars_field: "version.osp_series"
    query: "_type: result AND rally_setup.name: Authenticate.validate_nova AND software-metadata.keystone.provider:*fernet*"
  - title: "BrowbeatAuthenticateValidateNovaConcurrencyVersionCompareFernet95th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[95]"
    split_bars_field: "version.osp_series"
    query: "_type: result AND rally_setup.name: Authenticate.validate_nova AND software-metadata.keystone.provider:*fernet*"
  - title: "BrowbeatAuthenticateValidateNovaConcurrencyVersionCompareFernet99th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[99]"
    split_bars_field: "version.osp_series"
    query: "_type: result AND rally_setup.name: Authenticate.validate_nova AND software-metadata.keystone.provider:*fernet*"
  - title: "BrowbeatAuthenticateValidateNovaConcurrencyVersionCompareFernetMax-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "max"
    split_bars_field: "version.osp_series"
    query: "_type: result AND rally_setup.name: Authenticate.validate_nova AND software-metadata.keystone.provider:*fernet*"

  # Authenticate.validate_neutron Version Comparsion Visualizations: [Min, 50th, 95th, 99th, Max] for UUID
  - title: "BrowbeatAuthenticateValidateNeutronConcurrencyVersionCompareUUID-md"
    template: "markdown.json.j2"
    markdown: "# UUID Tokens\\\\n[Browbeat](https://github.com/openstack/browbeat)\\\\n\\\\n[Rally Authenticate.validate_neutron](https://github.com/openstack/rally/blob/master/rally/plugins/openstack/scenarios/authenticate/authenticate.py#L106)\\\\n\\\\nrepetitions: 2"
  - title: "BrowbeatAuthenticateValidateNeutronConcurrencyVersionCompareUUIDResultCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "version.osp_series"
    query: "_type: result AND rally_setup.name: Authenticate.validate_neutron AND software-metadata.keystone.provider:*uuid*"
  - title: "BrowbeatAuthenticateValidateNeutronConcurrencyVersionCompareUUIDErrorCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "version.osp_series"
    query: "_type: error AND rally_setup.name: Authenticate.validate_neutron AND software-metadata.keystone.provider:*uuid*"

  - title: "BrowbeatAuthenticateValidateNeutronConcurrencyVersionCompareUUIDMin-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "min"
    split_bars_field: "version.osp_series"
    query: "_type: result AND rally_setup.name: Authenticate.validate_neutron AND software-metadata.keystone.provider:*uuid*"
  - title: "BrowbeatAuthenticateValidateNeutronConcurrencyVersionCompareUUID50th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[50]"
    split_bars_field: "version.osp_series"
    query: "_type: result AND rally_setup.name: Authenticate.validate_neutron AND software-metadata.keystone.provider:*uuid*"
  - title: "BrowbeatAuthenticateValidateNeutronConcurrencyVersionCompareUUID95th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[95]"
    split_bars_field: "version.osp_series"
    query: "_type: result AND rally_setup.name: Authenticate.validate_neutron AND software-metadata.keystone.provider:*uuid*"
  - title: "BrowbeatAuthenticateValidateNeutronConcurrencyVersionCompareUUID99th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[99]"
    split_bars_field: "version.osp_series"
    query: "_type: result AND rally_setup.name: Authenticate.validate_neutron AND software-metadata.keystone.provider:*uuid*"
  - title: "BrowbeatAuthenticateValidateNeutronConcurrencyVersionCompareUUIDMax-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "max"
    split_bars_field: "version.osp_series"
    query: "_type: result AND rally_setup.name: Authenticate.validate_neutron AND software-metadata.keystone.provider:*uuid*"
  # Authenticate.validate_neutron Version Comparsion Visualizations: [Min, 50th, 95th, 99th, Max] for Fernet
  - title: "BrowbeatAuthenticateValidateNeutronConcurrencyVersionCompareFernet-md"
    template: "markdown.json.j2"
    markdown: "# Fernet Tokens\\\\n[Browbeat](https://github.com/openstack/browbeat)\\\\n\\\\n[Rally Authenticate.validate_neutron](https://github.com/openstack/rally/blob/master/rally/plugins/openstack/scenarios/authenticate/authenticate.py#L106)\\\\n\\\\nrepetitions: 2"
  - title: "BrowbeatAuthenticateValidateNeutronConcurrencyVersionCompareFernetResultCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "version.osp_series"
    query: "_type: result AND rally_setup.name: Authenticate.validate_neutron AND software-metadata.keystone.provider:*fernet*"
  - title: "BrowbeatAuthenticateValidateNeutronConcurrencyVersionCompareFernetErrorCount-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "count"
    split_bars_field: "version.osp_series"
    query: "_type: error AND rally_setup.name: Authenticate.validate_neutron AND software-metadata.keystone.provider:*fernet*"

  - title: "BrowbeatAuthenticateValidateNeutronConcurrencyVersionCompareFernetMin-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "min"
    split_bars_field: "version.osp_series"
    query: "_type: result AND rally_setup.name: Authenticate.validate_neutron AND software-metadata.keystone.provider:*fernet*"
  - title: "BrowbeatAuthenticateValidateNeutronConcurrencyVersionCompareFernet50th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[50]"
    split_bars_field: "version.osp_series"
    query: "_type: result AND rally_setup.name: Authenticate.validate_neutron AND software-metadata.keystone.provider:*fernet*"
  - title: "BrowbeatAuthenticateValidateNeutronConcurrencyVersionCompareFernet95th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[95]"
    split_bars_field: "version.osp_series"
    query: "_type: result AND rally_setup.name: Authenticate.validate_neutron AND software-metadata.keystone.provider:*fernet*"
  - title: "BrowbeatAuthenticateValidateNeutronConcurrencyVersionCompareFernet99th-bg"
    template: "percentiles-concurrency-bg.json.j2"
    percents: "[99]"
    split_bars_field: "version.osp_series"
    query: "_type: result AND rally_setup.name: Authenticate.validate_neutron AND software-metadata.keystone.provider:*fernet*"
  - title: "BrowbeatAuthenticateValidateNeutronConcurrencyVersionCompareFernetMax-bg"
    template: "min_max_count-concurency-bg.json.j2"
    metric_type: "max"
    split_bars_field: "version.osp_series"
    query: "_type: result AND rally_setup.name: Authenticate.validate_neutron AND software-metadata.keystone.provider:*fernet*"

**********
DECISION===>: PASS
**********
=========================:::338:::END!!!=========================
=========================:::339:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/kibana-visualization/vars/keystone_ssl_dashboards.yml
**********
---
#
# Keystone SSL/TLS Comparsion Dashboards
#

keystone_ssl_dashboards:
  # Authenticate.keystone Dashboard
  - file_name: "BrowbeatAuthenticateKeystoneSSLCompare.json"
    title: "Browbeat Authenticate.keystone SSL Comparsion"
    darkTheme: "true"
    panels:
      - id: "BrowbeatAuthenticateKeystoneConcurrencySSLCompare-md"
        type: "visualization"
        panelIndex: 1
        size_x: 12
        size_y: 2
        col: 1
        row: 1
      - id: "BrowbeatAuthenticateKeystoneConcurrencySSLCompareResultCount-bg"
        type: "visualization"
        panelIndex: 2
        size_x: 12
        size_y: 3
        col: 1
        row: 3
      - id: "BrowbeatAuthenticateKeystoneConcurrencySSLCompareErrorCount-bg"
        type: "visualization"
        panelIndex: 3
        size_x: 12
        size_y: 3
        col: 1
        row: 6
      - id: "BrowbeatAuthenticateKeystoneConcurrencySSLCompareMin-bg"
        type: "visualization"
        panelIndex: 4
        size_x: 12
        size_y: 3
        col: 1
        row: 9
      - id: "BrowbeatAuthenticateKeystoneConcurrencySSLCompare50th-bg"
        type: "visualization"
        panelIndex: 5
        size_x: 12
        size_y: 3
        col: 1
        row: 12
      - id: "BrowbeatAuthenticateKeystoneConcurrencySSLCompare95th-bg"
        type: "visualization"
        panelIndex: 6
        size_x: 12
        size_y: 3
        col: 1
        row: 15
      - id: "BrowbeatAuthenticateKeystoneConcurrencySSLCompare99th-bg"
        type: "visualization"
        panelIndex: 7
        size_x: 12
        size_y: 3
        col: 1
        row: 18
      - id: "BrowbeatAuthenticateKeystoneConcurrencySSLCompareMax-bg"
        type: "visualization"
        panelIndex: 8
        size_x: 12
        size_y: 3
        col: 1
        row: 21
  # Authenticate.validate_cinder Dashboard
  - file_name: "BrowbeatAuthenticateValidateCinderSSLCompare.json"
    title: "Browbeat Authenticate.validate_cinder SSL Comparsion"
    darkTheme: "true"
    panels:
      - id: "BrowbeatAuthenticateValidateCinderConcurrencySSLCompare-md"
        type: "visualization"
        panelIndex: 1
        size_x: 12
        size_y: 2
        col: 1
        row: 1
      - id: "BrowbeatAuthenticateValidateCinderConcurrencySSLCompareResultCount-bg"
        type: "visualization"
        panelIndex: 2
        size_x: 12
        size_y: 3
        col: 1
        row: 3
      - id: "BrowbeatAuthenticateValidateCinderConcurrencySSLCompareErrorCount-bg"
        type: "visualization"
        panelIndex: 3
        size_x: 12
        size_y: 3
        col: 1
        row: 6
      - id: "BrowbeatAuthenticateValidateCinderConcurrencySSLCompareMin-bg"
        type: "visualization"
        panelIndex: 4
        size_x: 12
        size_y: 3
        col: 1
        row: 9
      - id: "BrowbeatAuthenticateValidateCinderConcurrencySSLCompare50th-bg"
        type: "visualization"
        panelIndex: 5
        size_x: 12
        size_y: 3
        col: 1
        row: 12
      - id: "BrowbeatAuthenticateValidateCinderConcurrencySSLCompare95th-bg"
        type: "visualization"
        panelIndex: 6
        size_x: 12
        size_y: 3
        col: 1
        row: 15
      - id: "BrowbeatAuthenticateValidateCinderConcurrencySSLCompare99th-bg"
        type: "visualization"
        panelIndex: 7
        size_x: 12
        size_y: 3
        col: 1
        row: 18
      - id: "BrowbeatAuthenticateValidateCinderConcurrencySSLCompareMax-bg"
        type: "visualization"
        panelIndex: 8
        size_x: 12
        size_y: 3
        col: 1
        row: 21
  # Authenticate.validate_glance Dashboard
  - file_name: "BrowbeatAuthenticateValidateGlanceSSLCompare.json"
    title: "Browbeat Authenticate.validate_glance SSL Comparsion"
    darkTheme: "true"
    panels:
      - id: "BrowbeatAuthenticateValidateGlanceConcurrencySSLCompare-md"
        type: "visualization"
        panelIndex: 1
        size_x: 12
        size_y: 2
        col: 1
        row: 1
      - id: "BrowbeatAuthenticateValidateGlanceConcurrencySSLCompareResultCount-bg"
        type: "visualization"
        panelIndex: 2
        size_x: 12
        size_y: 3
        col: 1
        row: 3
      - id: "BrowbeatAuthenticateValidateGlanceConcurrencySSLCompareErrorCount-bg"
        type: "visualization"
        panelIndex: 3
        size_x: 12
        size_y: 3
        col: 1
        row: 6
      - id: "BrowbeatAuthenticateValidateGlanceConcurrencySSLCompareMin-bg"
        type: "visualization"
        panelIndex: 4
        size_x: 12
        size_y: 3
        col: 1
        row: 9
      - id: "BrowbeatAuthenticateValidateGlanceConcurrencySSLCompare50th-bg"
        type: "visualization"
        panelIndex: 5
        size_x: 12
        size_y: 3
        col: 1
        row: 12
      - id: "BrowbeatAuthenticateValidateGlanceConcurrencySSLCompare95th-bg"
        type: "visualization"
        panelIndex: 6
        size_x: 12
        size_y: 3
        col: 1
        row: 15
      - id: "BrowbeatAuthenticateValidateGlanceConcurrencySSLCompare99th-bg"
        type: "visualization"
        panelIndex: 7
        size_x: 12
        size_y: 3
        col: 1
        row: 18
      - id: "BrowbeatAuthenticateValidateGlanceConcurrencySSLCompareMax-bg"
        type: "visualization"
        panelIndex: 8
        size_x: 12
        size_y: 3
        col: 1
        row: 21
  # Authenticate.validate_heat Dashboard
  - file_name: "BrowbeatAuthenticateValidateHeatSSLCompare.json"
    title: "Browbeat Authenticate.validate_heat SSL Comparsion"
    darkTheme: "true"
    panels:
      - id: "BrowbeatAuthenticateValidateHeatConcurrencySSLCompare-md"
        type: "visualization"
        panelIndex: 1
        size_x: 12
        size_y: 2
        col: 1
        row: 1
      - id: "BrowbeatAuthenticateValidateHeatConcurrencySSLCompareResultCount-bg"
        type: "visualization"
        panelIndex: 2
        size_x: 12
        size_y: 3
        col: 1
        row: 3
      - id: "BrowbeatAuthenticateValidateHeatConcurrencySSLCompareErrorCount-bg"
        type: "visualization"
        panelIndex: 3
        size_x: 12
        size_y: 3
        col: 1
        row: 6
      - id: "BrowbeatAuthenticateValidateHeatConcurrencySSLCompareMin-bg"
        type: "visualization"
        panelIndex: 4
        size_x: 12
        size_y: 3
        col: 1
        row: 9
      - id: "BrowbeatAuthenticateValidateHeatConcurrencySSLCompare50th-bg"
        type: "visualization"
        panelIndex: 5
        size_x: 12
        size_y: 3
        col: 1
        row: 12
      - id: "BrowbeatAuthenticateValidateHeatConcurrencySSLCompare95th-bg"
        type: "visualization"
        panelIndex: 6
        size_x: 12
        size_y: 3
        col: 1
        row: 15
      - id: "BrowbeatAuthenticateValidateHeatConcurrencySSLCompare99th-bg"
        type: "visualization"
        panelIndex: 7
        size_x: 12
        size_y: 3
        col: 1
        row: 18
      - id: "BrowbeatAuthenticateValidateHeatConcurrencySSLCompareMax-bg"
        type: "visualization"
        panelIndex: 8
        size_x: 12
        size_y: 3
        col: 1
        row: 21
  # Authenticate.validate_neutron Dashboard
  - file_name: "BrowbeatAuthenticateValidateNeutronSSLCompare.json"
    title: "Browbeat Authenticate.validate_neutron SSL Comparsion"
    darkTheme: "true"
    panels:
      - id: "BrowbeatAuthenticateValidateNeutronConcurrencySSLCompare-md"
        type: "visualization"
        panelIndex: 1
        size_x: 12
        size_y: 2
        col: 1
        row: 1
      - id: "BrowbeatAuthenticateValidateNeutronConcurrencySSLCompareResultCount-bg"
        type: "visualization"
        panelIndex: 2
        size_x: 12
        size_y: 3
        col: 1
        row: 3
      - id: "BrowbeatAuthenticateValidateNeutronConcurrencySSLCompareErrorCount-bg"
        type: "visualization"
        panelIndex: 3
        size_x: 12
        size_y: 3
        col: 1
        row: 6
      - id: "BrowbeatAuthenticateValidateNeutronConcurrencySSLCompareMin-bg"
        type: "visualization"
        panelIndex: 4
        size_x: 12
        size_y: 3
        col: 1
        row: 9
      - id: "BrowbeatAuthenticateValidateNeutronConcurrencySSLCompare50th-bg"
        type: "visualization"
        panelIndex: 5
        size_x: 12
        size_y: 3
        col: 1
        row: 12
      - id: "BrowbeatAuthenticateValidateNeutronConcurrencySSLCompare95th-bg"
        type: "visualization"
        panelIndex: 6
        size_x: 12
        size_y: 3
        col: 1
        row: 15
      - id: "BrowbeatAuthenticateValidateNeutronConcurrencySSLCompare99th-bg"
        type: "visualization"
        panelIndex: 7
        size_x: 12
        size_y: 3
        col: 1
        row: 18
      - id: "BrowbeatAuthenticateValidateNeutronConcurrencySSLCompareMax-bg"
        type: "visualization"
        panelIndex: 8
        size_x: 12
        size_y: 3
        col: 1
        row: 21
  #  Authenticate.validate_nova Dashboard
  - file_name: "BrowbeatAuthenticateValidateNovaSSLCompare.json"
    title: "Browbeat Authenticate.validate_nova SSL Comparsion"
    darkTheme: "true"
    panels:
      - id: "BrowbeatAuthenticateValidateNovaConcurrencySSLCompare-md"
        type: "visualization"
        panelIndex: 1
        size_x: 12
        size_y: 2
        col: 1
        row: 1
      - id: "BrowbeatAuthenticateValidateNovaConcurrencySSLCompareResultCount-bg"
        type: "visualization"
        panelIndex: 2
        size_x: 12
        size_y: 3
        col: 1
        row: 3
      - id: "BrowbeatAuthenticateValidateNovaConcurrencySSLCompareErrorCount-bg"
        type: "visualization"
        panelIndex: 3
        size_x: 12
        size_y: 3
        col: 1
        row: 6
      - id: "BrowbeatAuthenticateValidateNovaConcurrencySSLCompareMin-bg"
        type: "visualization"
        panelIndex: 4
        size_x: 12
        size_y: 3
        col: 1
        row: 9
      - id: "BrowbeatAuthenticateValidateNovaConcurrencySSLCompare50th-bg"
        type: "visualization"
        panelIndex: 5
        size_x: 12
        size_y: 3
        col: 1
        row: 12
      - id: "BrowbeatAuthenticateValidateNovaConcurrencySSLCompare95th-bg"
        type: "visualization"
        panelIndex: 6
        size_x: 12
        size_y: 3
        col: 1
        row: 15
      - id: "BrowbeatAuthenticateValidateNovaConcurrencySSLCompare99th-bg"
        type: "visualization"
        panelIndex: 7
        size_x: 12
        size_y: 3
        col: 1
        row: 18
      - id: "BrowbeatAuthenticateValidateNovaConcurrencySSLCompareMax-bg"
        type: "visualization"
        panelIndex: 8
        size_x: 12
        size_y: 3
        col: 1
        row: 21

  # KeystoneBasic.authenticate_user_and_validate_token Dashboard
  - file_name: "BrowbeatKeystoneBasicAuthenticateUserAndValidateTokenSSLCompare.json"
    title: "Browbeat KeystoneBasic.authenticate_user_and_validate_token SSL Comparsion"
    darkTheme: "true"
    panels:
      - id: "BrowbeatKeystoneBasicAuthenticateUserAndValidateTokenConcurrencySSLCompare-md"
        type: "visualization"
        panelIndex: 1
        size_x: 12
        size_y: 2
        col: 1
        row: 1
      - id: "BrowbeatKeystoneBasicAuthenticateUserAndValidateTokenConcurrencySSLCompareResultCount-bg"
        type: "visualization"
        panelIndex: 2
        size_x: 12
        size_y: 3
        col: 1
        row: 3
      - id: "BrowbeatKeystoneBasicAuthenticateUserAndValidateTokenConcurrencySSLCompareErrorCount-bg"
        type: "visualization"
        panelIndex: 3
        size_x: 12
        size_y: 3
        col: 1
        row: 6
      - id: "BrowbeatKeystoneBasicAuthenticateUserAndValidateTokenConcurrencySSLCompareMin-bg"
        type: "visualization"
        panelIndex: 4
        size_x: 12
        size_y: 3
        col: 1
        row: 9
      - id: "BrowbeatKeystoneBasicAuthenticateUserAndValidateTokenConcurrencySSLCompare50th-bg"
        type: "visualization"
        panelIndex: 5
        size_x: 12
        size_y: 3
        col: 1
        row: 12
      - id: "BrowbeatKeystoneBasicAuthenticateUserAndValidateTokenConcurrencySSLCompare95th-bg"
        type: "visualization"
        panelIndex: 6
        size_x: 12
        size_y: 3
        col: 1
        row: 15
      - id: "BrowbeatKeystoneBasicAuthenticateUserAndValidateTokenConcurrencySSLCompare99th-bg"
        type: "visualization"
        panelIndex: 7
        size_x: 12
        size_y: 3
        col: 1
        row: 18
      - id: "BrowbeatKeystoneBasicAuthenticateUserAndValidateTokenConcurrencySSLCompareMax-bg"
        type: "visualization"
        panelIndex: 8
        size_x: 12
        size_y: 3
        col: 1
        row: 21

**********
DECISION===>: PASS
**********
=========================:::339:::END!!!=========================
=========================:::340:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/kibana-visualization/vars/shaker_cloud_comparison_visualizations.yml
**********
---
#
# Shaker Scenario-Throughput-Concurrency - Visualizations Variables
#

shaker_cloud_comparison_visualizations:
  - title: "Shaker-Cloud-Comparison-L2-Throughput"
    template: "markdown.json.j2"
    markdown: "# Shaker-L2-Flent\\\\n ## Throughput in Mbps\\\\nTo filter based on concurrency please query for key record.concurrency and to filter based based on number of compute nodes, please query for key acommodation.compute_nodes"
  - title: "Browbeat-Shaker-Cloud-Comprison-L2-Throughput"
    template: "shaker-cloud-comparison.json.j2"
    query: "shaker_test_info.deployment.template: l2.hot AND (result.result_type: tcp_download OR result.result_type: tcp_upload)"
  - title: "Shaker-Cloud-Comparison-L2-Latency"
    template: "markdown.json.j2"
    markdown: "# Shaker-L2-Flent\\\\n ## Latency in ms\\\\nTo filter based on concurrency please query for key record.concurrency and to filter based based on number of compute nodes, please query for accommodation.compute_nodes"
  - title: "Browbeat-Shaker-Cloud-Comprison-L2-Latency"
    template: "shaker-cloud-comparison.json.j2"
    query: "shaker_test_info.deployment.template: l2.hot AND result.result_type: ping_icmp"
  - title: "Shaker-Cloud-Comparison-L3-ES-Throughput"
    template: "markdown.json.j2"
    markdown: "# Shaker-L3-East-West-Flent\\\\n## Throughput in Mbps\\\\nTo filter based on concurrency please query for key record.concurrency and to filter based based on number of compute nodes, please query for key accommodation.compute_nodes"
  - title: "Browbeat-Shaker-Cloud-Comparison-L3-East-West-Throughput"
    template: "shaker-cloud-comparison.json.j2"
    query: "shaker_test_info.deployment.template: l3_east_west.hot AND (result.result_type: tcp_download OR result.result_type: tcp_upload)"
  - title: "Shaker-Cloud-Comparison-L3-East-West-Latency"
    template: "markdown.json.j2"
    markdown: "# Shaker-L3-East-West-Flent\\\\n## Latency in ms\\\\nTo filter based on concurrency please query for key record.concurrency and to filter based based on number of compute nodes, please query for key accommodation.compute_nodes"
  - title: "Browbeat-Shaker-Cloud-Comparison-L3-East-West-Latency"
    template: "shaker-cloud-comparison.json.j2"
    query: "shaker_test_info.deployment.template: l3_east_west.hot.hot AND result.result_type: ping_icmp"
  - title: "Shaker-Cloud-Comparison-L3-North-South-Throughput"
    template: "markdown.json.j2"
    markdown: "# Shaker-L3-North-South-Flent\\\\n## Throughput in Mbps\\\\nTo filter based on concurrency please query for key record.concurrency and to filter based based on number of compute nodes, please query for key accommodation.compute_nodes"
  - title:  "Browbeat-Shaker-Cloud-Comparison-L3-North-South-Throughput"
    template: "shaker-cloud-comparison.json.j2"
    query: "shaker_test_info.deployment.template: l3_north_south.hot AND (result.result_type: tcp_download OR result.result_type: tcp_upload)"
  - title: "Shaker-Cloud-Comparison-L3-North-South-Latency"
    template: "markdown.json.j2"
    markdown: "# Shaker-L3-North-South-Flent\\\\n## Latency in ms\\\\nTo filter based on concurrency please query for key record.concurrency and to filter based based on number of compute nodes, please query for key accommodation.compute_nodes"
  - title:  "Browbeat-Shaker-Cloud-Comparison-L3-North-South-Latency"
    template: "shaker-cloud-comparison.json.j2"
    query: "shaker_test_info.deployment.template: l3_north_south.hot AND result.result_type: ping_icmp"


**********
DECISION===>: PASS 
**********
=========================:::340:::END!!!=========================
=========================:::341:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/kibana-visualization/vars/keystone_osp_version_token_dashboards.yml
**********
---
#
# Keystone OSP Version Token Comparsion Dashboards
#

keystone_osp_version_token_dashboards:
  # Authenticate.keystone Dashboard
  - file_name: "BrowbeatAuthenticateKeystoneVersionCompare.json"
    title: "Browbeat Authenticate.keystone Version Comparsion"
    darkTheme: "true"
    panels:
      - id: "BrowbeatAuthenticateKeystoneConcurrencyVersionCompareUUID-md"
        type: "visualization"
        panelIndex: 1
        size_x: 6
        size_y: 2
        col: 1
        row: 1
      - id: "BrowbeatAuthenticateKeystoneConcurrencyVersionCompareFernet-md"
        type: "visualization"
        panelIndex: 2
        size_x: 6
        size_y: 2
        col: 7
        row: 1
      - id: "BrowbeatAuthenticateKeystoneConcurrencyVersionCompareUUIDResultCount-bg"
        type: "visualization"
        panelIndex: 3
        size_x: 6
        size_y: 3
        col: 1
        row: 3
      - id: "BrowbeatAuthenticateKeystoneConcurrencyVersionCompareFernetResultCount-bg"
        type: "visualization"
        panelIndex: 4
        size_x: 6
        size_y: 3
        col: 7
        row: 3
      - id: "BrowbeatAuthenticateKeystoneConcurrencyVersionCompareUUIDErrorCount-bg"
        type: "visualization"
        panelIndex: 5
        size_x: 6
        size_y: 3
        col: 1
        row: 6
      - id: "BrowbeatAuthenticateKeystoneConcurrencyVersionCompareFernetErrorCount-bg"
        type: "visualization"
        panelIndex: 6
        size_x: 6
        size_y: 3
        col: 7
        row: 6
      - id: "BrowbeatAuthenticateKeystoneConcurrencyVersionCompareUUIDMin-bg"
        type: "visualization"
        panelIndex: 7
        size_x: 6
        size_y: 3
        col: 1
        row: 9
      - id: "BrowbeatAuthenticateKeystoneConcurrencyVersionCompareFernetMin-bg"
        type: "visualization"
        panelIndex: 8
        size_x: 6
        size_y: 3
        col: 7
        row: 9
      - id: "BrowbeatAuthenticateKeystoneConcurrencyVersionCompareUUID50th-bg"
        type: "visualization"
        panelIndex: 9
        size_x: 6
        size_y: 3
        col: 1
        row: 12
      - id: "BrowbeatAuthenticateKeystoneConcurrencyVersionCompareFernet50th-bg"
        type: "visualization"
        panelIndex: 10
        size_x: 6
        size_y: 3
        col: 7
        row: 12
      - id: "BrowbeatAuthenticateKeystoneConcurrencyVersionCompareUUID95th-bg"
        type: "visualization"
        panelIndex: 9
        size_x: 6
        size_y: 3
        col: 1
        row: 15
      - id: "BrowbeatAuthenticateKeystoneConcurrencyVersionCompareFernet95th-bg"
        type: "visualization"
        panelIndex: 10
        size_x: 6
        size_y: 3
        col: 7
        row: 15
      - id: "BrowbeatAuthenticateKeystoneConcurrencyVersionCompareUUID99th-bg"
        type: "visualization"
        panelIndex: 9
        size_x: 6
        size_y: 3
        col: 1
        row: 18
      - id: "BrowbeatAuthenticateKeystoneConcurrencyVersionCompareFernet99th-bg"
        type: "visualization"
        panelIndex: 10
        size_x: 6
        size_y: 3
        col: 7
        row: 18
      - id: "BrowbeatAuthenticateKeystoneConcurrencyVersionCompareUUIDMax-bg"
        type: "visualization"
        panelIndex: 9
        size_x: 6
        size_y: 3
        col: 1
        row: 21
      - id: "BrowbeatAuthenticateKeystoneConcurrencyVersionCompareFernetMax-bg"
        type: "visualization"
        panelIndex: 10
        size_x: 6
        size_y: 3
        col: 7
        row: 21

  # Authenticate.validate_nova Dashboard
  - file_name: "BrowbeatAuthenticateValidateNovaVersionCompare.json"
    title: "Browbeat Authenticate.validate_nova Version Comparsion"
    darkTheme: "true"
    panels:
      - id: "BrowbeatAuthenticateValidateNovaConcurrencyVersionCompareUUID-md"
        type: "visualization"
        panelIndex: 1
        size_x: 6
        size_y: 2
        col: 1
        row: 1
      - id: "BrowbeatAuthenticateValidateNovaConcurrencyVersionCompareFernet-md"
        type: "visualization"
        panelIndex: 2
        size_x: 6
        size_y: 2
        col: 7
        row: 1
      - id: "BrowbeatAuthenticateValidateNovaConcurrencyVersionCompareUUIDResultCount-bg"
        type: "visualization"
        panelIndex: 3
        size_x: 6
        size_y: 3
        col: 1
        row: 3
      - id: "BrowbeatAuthenticateValidateNovaConcurrencyVersionCompareFernetResultCount-bg"
        type: "visualization"
        panelIndex: 4
        size_x: 6
        size_y: 3
        col: 7
        row: 3
      - id: "BrowbeatAuthenticateValidateNovaConcurrencyVersionCompareUUIDErrorCount-bg"
        type: "visualization"
        panelIndex: 5
        size_x: 6
        size_y: 3
        col: 1
        row: 6
      - id: "BrowbeatAuthenticateValidateNovaConcurrencyVersionCompareFernetErrorCount-bg"
        type: "visualization"
        panelIndex: 6
        size_x: 6
        size_y: 3
        col: 7
        row: 6
      - id: "BrowbeatAuthenticateValidateNovaConcurrencyVersionCompareUUIDMin-bg"
        type: "visualization"
        panelIndex: 7
        size_x: 6
        size_y: 3
        col: 1
        row: 9
      - id: "BrowbeatAuthenticateValidateNovaConcurrencyVersionCompareFernetMin-bg"
        type: "visualization"
        panelIndex: 8
        size_x: 6
        size_y: 3
        col: 7
        row: 9
      - id: "BrowbeatAuthenticateValidateNovaConcurrencyVersionCompareUUID50th-bg"
        type: "visualization"
        panelIndex: 9
        size_x: 6
        size_y: 3
        col: 1
        row: 12
      - id: "BrowbeatAuthenticateValidateNovaConcurrencyVersionCompareFernet50th-bg"
        type: "visualization"
        panelIndex: 10
        size_x: 6
        size_y: 3
        col: 7
        row: 12
      - id: "BrowbeatAuthenticateValidateNovaConcurrencyVersionCompareUUID95th-bg"
        type: "visualization"
        panelIndex: 9
        size_x: 6
        size_y: 3
        col: 1
        row: 15
      - id: "BrowbeatAuthenticateValidateNovaConcurrencyVersionCompareFernet95th-bg"
        type: "visualization"
        panelIndex: 10
        size_x: 6
        size_y: 3
        col: 7
        row: 15
      - id: "BrowbeatAuthenticateValidateNovaConcurrencyVersionCompareUUID99th-bg"
        type: "visualization"
        panelIndex: 9
        size_x: 6
        size_y: 3
        col: 1
        row: 18
      - id: "BrowbeatAuthenticateValidateNovaConcurrencyVersionCompareFernet99th-bg"
        type: "visualization"
        panelIndex: 10
        size_x: 6
        size_y: 3
        col: 7
        row: 18
      - id: "BrowbeatAuthenticateValidateNovaConcurrencyVersionCompareUUIDMax-bg"
        type: "visualization"
        panelIndex: 9
        size_x: 6
        size_y: 3
        col: 1
        row: 21
      - id: "BrowbeatAuthenticateValidateNovaConcurrencyVersionCompareFernetMax-bg"
        type: "visualization"
        panelIndex: 10
        size_x: 6
        size_y: 3
        col: 7
        row: 21

  # Authenticate.validate_neutron Dashboard
  - file_name: "BrowbeatAuthenticateValidateNeutronVersionCompare.json"
    title: "Browbeat Authenticate.validate_neutron Version Comparsion"
    darkTheme: "true"
    panels:
      - id: "BrowbeatAuthenticateValidateNeutronConcurrencyVersionCompareUUID-md"
        type: "visualization"
        panelIndex: 1
        size_x: 6
        size_y: 2
        col: 1
        row: 1
      - id: "BrowbeatAuthenticateValidateNeutronConcurrencyVersionCompareFernet-md"
        type: "visualization"
        panelIndex: 2
        size_x: 6
        size_y: 2
        col: 7
        row: 1
      - id: "BrowbeatAuthenticateValidateNeutronConcurrencyVersionCompareUUIDResultCount-bg"
        type: "visualization"
        panelIndex: 3
        size_x: 6
        size_y: 3
        col: 1
        row: 3
      - id: "BrowbeatAuthenticateValidateNeutronConcurrencyVersionCompareFernetResultCount-bg"
        type: "visualization"
        panelIndex: 4
        size_x: 6
        size_y: 3
        col: 7
        row: 3
      - id: "BrowbeatAuthenticateValidateNeutronConcurrencyVersionCompareUUIDErrorCount-bg"
        type: "visualization"
        panelIndex: 5
        size_x: 6
        size_y: 3
        col: 1
        row: 6
      - id: "BrowbeatAuthenticateValidateNeutronConcurrencyVersionCompareFernetErrorCount-bg"
        type: "visualization"
        panelIndex: 6
        size_x: 6
        size_y: 3
        col: 7
        row: 6
      - id: "BrowbeatAuthenticateValidateNeutronConcurrencyVersionCompareUUIDMin-bg"
        type: "visualization"
        panelIndex: 7
        size_x: 6
        size_y: 3
        col: 1
        row: 9
      - id: "BrowbeatAuthenticateValidateNeutronConcurrencyVersionCompareFernetMin-bg"
        type: "visualization"
        panelIndex: 8
        size_x: 6
        size_y: 3
        col: 7
        row: 9
      - id: "BrowbeatAuthenticateValidateNeutronConcurrencyVersionCompareUUID50th-bg"
        type: "visualization"
        panelIndex: 9
        size_x: 6
        size_y: 3
        col: 1
        row: 12
      - id: "BrowbeatAuthenticateValidateNeutronConcurrencyVersionCompareFernet50th-bg"
        type: "visualization"
        panelIndex: 10
        size_x: 6
        size_y: 3
        col: 7
        row: 12
      - id: "BrowbeatAuthenticateValidateNeutronConcurrencyVersionCompareUUID95th-bg"
        type: "visualization"
        panelIndex: 9
        size_x: 6
        size_y: 3
        col: 1
        row: 15
      - id: "BrowbeatAuthenticateValidateNeutronConcurrencyVersionCompareFernet95th-bg"
        type: "visualization"
        panelIndex: 10
        size_x: 6
        size_y: 3
        col: 7
        row: 15
      - id: "BrowbeatAuthenticateValidateNeutronConcurrencyVersionCompareUUID99th-bg"
        type: "visualization"
        panelIndex: 9
        size_x: 6
        size_y: 3
        col: 1
        row: 18
      - id: "BrowbeatAuthenticateValidateNeutronConcurrencyVersionCompareFernet99th-bg"
        type: "visualization"
        panelIndex: 10
        size_x: 6
        size_y: 3
        col: 7
        row: 18
      - id: "BrowbeatAuthenticateValidateNeutronConcurrencyVersionCompareUUIDMax-bg"
        type: "visualization"
        panelIndex: 9
        size_x: 6
        size_y: 3
        col: 1
        row: 21
      - id: "BrowbeatAuthenticateValidateNeutronConcurrencyVersionCompareFernetMax-bg"
        type: "visualization"
        panelIndex: 10
        size_x: 6
        size_y: 3
        col: 7
        row: 21

**********
DECISION===>: PASS
**********
=========================:::341:::END!!!=========================
=========================:::342:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/kibana-visualization/vars/shaker_scenario_throughput_concurrency_dashboard.yml
**********
---
#
# Shaker Scenario Throughput vs Concurrency Dashboard
#

shaker_scenario_throughput_concurrency_dashboard:
  - file_name: "ShakerScenarioThroughputConcurrency.json"
    title: "Browbeat Shaker Scenarios with Throughput vs Concurrency"
    darkTheme: "true"
    panels:
      - id: "Shaker-L2"
        type: "visualization"
        panelIndex: 1
        size_x: 12
        size_y: 2
        col: 1
        row: 1
      - id: "Browbeat-Shaker-L2"
        type: "visualization"
        panelIndex: 2
        size_x: 12
        size_y: 4
        col: 1
        row: 3
      - id: "Shaker-L3-ES"
        type: "visualization"
        panelIndex: 3
        size_x: 12
        size_y: 2
        col: 1
        row: 7
      - id: "Browbeat-Shaker-L3-East-West"
        type: "visualization"
        panelIndex: 4
        size_x: 12
        size_y: 4
        col: 1
        row: 9
      - id: "Shaker-L3-NS"
        type: "visualization"
        panelIndex: 5
        size_x: 12
        size_y: 2
        col: 1
        row: 13
      - id: "Browbeat-Shaker-L3-North-South"
        type: "visualization"
        panelIndex: 6
        size_x: 12
        size_y: 4
        col: 1
        row: 15

**********
DECISION===>: PASS
**********
=========================:::342:::END!!!=========================
=========================:::343:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/install/roles/kibana-visualization/tasks/main.yml
**********
---
#
# Tasks to generate/upload Searches/Visuals/Dashboards to Kibana
#

- name: Generate Keystone Visualizations
  template:
    src: "{{item.template}}"
    dest: "{{browbeat_path}}/visualization/Keystone/visualization/{{item.title}}.json"
  with_flattened:
    - "{{keystone_controller_count_visualizations}}"
    - "{{keystone_osp_version_token_visualizations}}"
    - "{{keystone_processes_threads_visualizations}}"
    - "{{keystone_ssl_visualizations}}"

- name: Generate Keystone Dashboards
  template:
    src: dashboard.json.j2
    dest: "{{browbeat_path}}/visualization/Keystone/dashboard/{{item.file_name}}"
  with_flattened:
    - "{{keystone_controller_count_dashboards}}"
    - "{{keystone_osp_version_token_dashboards}}"
    - "{{keystone_processes_threads_dashboards}}"
    - "{{keystone_ssl_dashboards}}"

- name: Generate Shaker Visualizations
  template:
    src: "{{item.template}}"
    dest: "{{browbeat_path}}/visualization/Shaker/visualization/{{item.title}}.json"
  with_flattened:
    - "{{shaker_scenario_throughput_concurrency_visualizations}}"
    - "{{shaker_cloud_comparison_visualizations}}"

- name: Generate Shaker Dashboards
  template:
    src: dashboard.json.j2
    dest: "{{browbeat_path}}/visualization/Shaker/dashboard/{{item.file_name}}"
  with_flattened:
    - "{{shaker_scenario_throughput_concurrency_dashboard}}"
    - "{{shaker_cloud_comparison_dashboard}}"

- name: Remove Searches
  uri:
    url: http://{{ es_ip }}:{{ es_local_port }}/{{ es_kibana_index }}/search/{{ item | basename | regex_replace('\.json','') }}
    method: DELETE
    body: "{{ lookup('file', item) }}"
    body_format: json
    status_code: 404, 200
  with_fileglob:
    - "{{ browbeat_path }}/visualization/Keystone/search/*"
    - "{{ browbeat_path }}/visualization/Neutron/search/*"
    - "{{ browbeat_path }}/visualization/OpenStack-Workers/search/*"
    - "{{ browbeat_path }}/visualization/Shaker/search/*"
    - "{{ browbeat_path }}/visualization/Performance-Dashboard/search/*"
    - "{{ browbeat_path }}/visualization/Network-Performance/search/*"

  ignore_errors: true

- name: Remove Visuals
  uri:
    url: http://{{ es_ip }}:{{ es_local_port }}/{{ es_kibana_index }}/visualization/{{ item | basename | regex_replace('\.json','')}}
    method: DELETE
    body: "{{ lookup('file', item) }}"
    body_format: json
    status_code: 404, 200
  with_fileglob:
    - "{{ browbeat_path }}/visualization/Keystone/visualization/*"
    - "{{ browbeat_path }}/visualization/Neutron/visualization/*"
    - "{{ browbeat_path }}/visualization/OpenStack-Workers/visualization/*"
    - "{{ browbeat_path }}/visualization/Shaker/visualization/*"
    - "{{ browbeat_path }}/visualization/Performance-Dashboard/visualization/*"
    - "{{ browbeat_path }}/visualization/Network-Performance/visualization/*"

  ignore_errors: true

- name: Remove Dashboards
  uri:
    url: http://{{ es_ip }}:{{ es_local_port }}/{{ es_kibana_index }}/dashboard/{{ item | basename | regex_replace('\.json','')}}
    method: DELETE
    body: "{{ lookup('file', item) }}"
    body_format: json
    status_code: 404, 200
  with_fileglob:
    - "{{ browbeat_path }}/visualization/Keystone/dashboard/*"
    - "{{ browbeat_path }}/visualization/Neutron/dashboard/*"
    - "{{ browbeat_path }}/visualization/OpenStack-Workers/dashboard/*"
    - "{{ browbeat_path }}/visualization/Shaker/dashboard/*"
    - "{{ browbeat_path }}/visualization/Performance-Dashboard/dashboard/*"
    - "{{ browbeat_path }}/visualization/Network-Performance/dashboard/*"

  ignore_errors: true

- name: Upload Searches
  uri:
    url: http://{{ es_ip }}:{{ es_local_port }}/{{ es_kibana_index }}/search/{{ item | basename | regex_replace('\.json','') }}
    method: PUT
    body: "{{ lookup('file', item) }}"
    body_format: json
    status_code: 201
  with_fileglob:
    - "{{ browbeat_path }}/visualization/Keystone/search/*"
    - "{{ browbeat_path }}/visualization/Neutron/search/*"
    - "{{ browbeat_path }}/visualization/OpenStack-Workers/search/*"
    - "{{ browbeat_path }}/visualization/Shaker/search/*"
    - "{{ browbeat_path }}/visualization/Performance-Dashboard/search/*"
    - "{{ browbeat_path }}/visualization/Network-Performance/search/*"
  ignore_errors: true

- name: Upload Visuals
  uri:
    url: http://{{ es_ip }}:{{ es_local_port }}/{{ es_kibana_index }}/visualization/{{ item | basename | regex_replace('\.json','')}}
    method: PUT
    body: "{{ lookup('file', item) }}"
    body_format: json
    status_code: 201
  with_fileglob:
    - "{{ browbeat_path }}/visualization/Keystone/visualization/*"
    - "{{ browbeat_path }}/visualization/Neutron/visualization/*"
    - "{{ browbeat_path }}/visualization/OpenStack-Workers/visualization/*"
    - "{{ browbeat_path }}/visualization/Shaker/visualization/*"
    - "{{ browbeat_path }}/visualization/Performance-Dashboard/visualization/*"
    - "{{ browbeat_path }}/visualization/Network-Performance/visualization/*"

  ignore_errors: true

- name: Upload Dashboards
  uri:
    url: http://{{ es_ip }}:{{ es_local_port }}/{{ es_kibana_index }}/dashboard/{{ item | basename | regex_replace('\.json','')}}
    method: PUT
    body: "{{ lookup('file', item) }}"
    body_format: json
    status_code: 201
  with_fileglob:
    - "{{ browbeat_path }}/visualization/Keystone/dashboard/*"
    - "{{ browbeat_path }}/visualization/Neutron/dashboard/*"
    - "{{ browbeat_path }}/visualization/OpenStack-Workers/dashboard/*"
    - "{{ browbeat_path }}/visualization/Shaker/dashboard/*"
    - "{{ browbeat_path }}/visualization/Performance-Dashboard/dashboard/*"
    - "{{ browbeat_path }}/visualization/Network-Performance/dashboard/*"
  ignore_errors: true

- name: Cleanup Keystone Visualizations
  file:
    path: "{{browbeat_path}}/visualization/Keystone/visualization/{{item.title}}.json"
    state: absent
  with_flattened:
    - "{{keystone_controller_count_visualizations}}"
    - "{{keystone_osp_version_token_visualizations}}"
    - "{{keystone_processes_threads_visualizations}}"
    - "{{keystone_ssl_visualizations}}"

- name: Cleanup Keystone Dashboards
  file:
    path: "{{browbeat_path}}/visualization/Keystone/dashboard/{{item.file_name}}"
    state: absent
  with_flattened:
    - "{{keystone_controller_count_dashboards}}"
    - "{{keystone_osp_version_token_dashboards}}"
    - "{{keystone_processes_threads_dashboards}}"
    - "{{keystone_ssl_dashboards}}"

- name: Cleanup Shaker Visualizations
  file:
    path: "{{browbeat_path}}/visualization/Shaker/visualization/{{item.title}}.json"
    state: absent
  with_items:
    - "{{shaker_scenario_throughput_concurrency_visualizations}}"
    - "{{shaker_cloud_comparison_visualizations}}"


- name: Cleanup Shaker Dashboards
  file:
    path: "{{browbeat_path}}/visualization/Shaker/dashboard/{{item.file_name}}"
    state: absent
  with_items:
    - "{{shaker_scenario_throughput_concurrency_dashboard}}"
    - "{{shaker_cloud_comparison_dashboard}}"

**********
DECISION===>: Use of HTTP without TLS
**********
=========================:::343:::END!!!=========================
=========================:::344:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/logs/roles/opendaylight/tasks/main.yml
**********
---
- name: Check that opendaylight is installed
  stat:
    path: /opt/opendaylight
  register: opendaylight_baremetal

- name: Check if opendaylight is containerized
  stat:
    path: /var/lib/config-data/puppet-generated/opendaylight
  register: opendaylight_container

- name: Set opendaylight log location (containerized)
  set_fact:
    opendaylight_logs: /var/log/containers/opendaylight
  when: opendaylight_container.stat.isdir is defined and opendaylight_container.stat.isdir

- name: Set  opendaylight location (non-containerized)
  set_fact:
    opendaylight_logs: /opt/opendaylight/data/logs
  when: opendaylight_baremetal.stat.isdir is defined and opendaylight_baremetal.stat.isdir

- name: Check if log folder exists
  stat:
    path: "{{opendaylight_logs}}"
  register: logs_path

- name: Copy logs to directory on host
  synchronize:
    src: "{{opendaylight_logs}}"
    dest: /home/{{host_remote_user}}/{{ansible_hostname}}
  delegate_to: "{{ inventory_hostname }}"
  when: (opendaylight_baremetal or opendaylight_container) and logs_path.stat.isdir is defined and logs_path.stat.isdir


**********
DECISION===>: PASS
**********
=========================:::344:::END!!!=========================
=========================:::345:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/logs/roles/rabbitmq/tasks/main.yml
**********
---
- name: Check that rabbitmq is installed
  stat:
    path: /etc/rabbitmq/rabbitmq.config
  register: rabbitmq_config

- name: Check if rabbitmq is containerized
  shell:
    cmd: docker ps | grep rabbitmq
  register: rabbitmq_container
  when: rabbitmq_config.stat.exists
  ignore_errors: true

- name: Set rabbitmq log location (containerized)
  set_fact:
    rabbitmq_logs: /var/log/containers/rabbitmq
  when: rabbitmq_container.rc == 0 and rabbitmq_config.stat.exists

- name: Check if log folder exists
  stat:
    path: "{{rabbitmq_logs}}"
  register: logs_path

- name: Copy logs to directory on host
  synchronize:
    src: "{{rabbitmq_logs}}"
    dest: /home/{{host_remote_user}}/{{ansible_hostname}}
  delegate_to: "{{ inventory_hostname }}"
  when: rabbitmq_config.stat.exists and logs_path.stat.isdir is defined and logs_path.stat.isdir


**********
DECISION===>: PASS
**********
=========================:::345:::END!!!=========================
=========================:::346:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/logs/roles/common/tasks/main.yml
**********
- name: Check that service is installed
  stat:
    path: /etc/{{item}}/{{item}}.conf
  register: config
  with_items: "{{services}}"

- name: Check if service is containerized
  shell:
    cmd: docker ps | grep {{item.item}}
  register: container
  when: item.stat.exists
  with_items:
    - "{{config.results}}"
  ignore_errors: true

- name: Set log location (containerized)
  set_fact:
    log_dir_containerized: /var/log/containers/{{item.0.item}}
  register: log_result_containerized
  when: item.1.rc == 0 and item.0.stat.exists
  with_together:
    - "{{config.results}}"
    - "{{container.results}}"

- name: Set log location (non-containerized)
  set_fact:
    log_dir_noncontainerized: /var/log/{{item.0.item}}
  register: log_result_noncontainerized
  when: item.1.rc != 0 and item.0.stat.exists
  with_together:
    - "{{config.results}}"
    - "{{container.results}}"

-  name: make list of log directories (containerized)
   set_fact:
     log_dir_containerized: "{{ log_result_containerized.results | selectattr('ansible_facts','defined') | map(attribute='ansible_facts.log_dir_containerized') | list }}"
   when: item.1.rc == 0 and item.0.stat.exists
   with_together:
     - "{{config.results}}"
     - "{{container.results}}"


- name: make list of log directories (non-containerized)
  set_fact:
    log_dir_noncontainerized: "{{ log_result_noncontainerized.results | selectattr('ansible_facts','defined') | map(attribute='ansible_facts.log_dir_noncontainerized') | list }}"
  when: item.1.rc != 0 and item.0.stat.exists
  with_together:
    - "{{config.results}}"
    - "{{container.results}}"


- name: Check if log folder exists (container)
  stat:
    path: "{{item}}"
  register: logs_path_containerized
  with_items:
    - "{{log_dir_containerized}}"
  when: log_dir_containerized is defined

- name: Check if log folder exists (non-container)
  stat:
    path: "{{item}}"
  register: logs_path_noncontainerized
  with_items:
    - "{{log_dir_noncontainerized}}"
  when: log_dir_noncontainerized is defined

- name: Copy container logs to directory on host
  synchronize:
    src: "{{item.1.item}}"
    dest: /home/{{host_remote_user}}/{{ansible_hostname}}
  delegate_to: "{{ inventory_hostname }}"
  when: log_dir_containerized is defined and item.0.stat.exists and item.1.stat is defined and item.1.stat.isdir is defined and item.1.stat.isdir
  with_together:
    - "{{config.results}}"
    - "{{logs_path_containerized.results}}"

- name: Copy non-container logs to directory on host
  synchronize:
    src: "{{item.1.item}}"
    dest: /home/{{host_remote_user}}/{{ansible_hostname}}
  delegate_to: "{{ inventory_hostname }}"
  when: log_dir_noncontainerized is defined and item.0.stat.exists and item.1.stat is defined and item.1.stat.isdir is defined and item.1.stat.isdir
  with_together:
    - "{{config.results}}"
    - "{{logs_path_noncontainerized.results}}"



**********
DECISION===>: PASS
**********
=========================:::346:::END!!!=========================
=========================:::347:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/logs/roles/fetch-logs/tasks/main.yml
**********
---
- name: Tar the logs directory
  archive:
    path: /home/{{host_remote_user}}/{{ansible_hostname}}
    dest: /home/{{host_remote_user}}/{{ansible_hostname}}.gz

- name: Remove logs directory
  file:
    path: /home/{{host_remote_user}}/{{ansible_hostname}}
    state: absent

- name: Fetch logs
  fetch:
    src: /home/{{host_remote_user}}/{{ansible_hostname}}.gz
    dest:
      /home/{{browbeat_user}}/logs/{{inventory_hostname}}-{{ansible_date_time.epoch}}.gz
    flat: yes


**********
DECISION===>: PASS
**********
=========================:::347:::END!!!=========================
=========================:::348:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/logs/roles/httpd/tasks/main.yml
**********
---
- name: Check that httpd is installed
  stat:
    path: /etc/httpd/conf/httpd.conf
  register: httpd_config

- name: Set httpd log location (containerized)
  set_fact:
    httpd_logs: /var/log/containers/httpd
  when: osp_version >= 12  and httpd_config.stat.exists

- name: Set httpd log location (non-containerized)
  set_fact:
    httpd_logs: /var/log/httpd
  when: osp_version < 12 and httpd_config.stat.exists

- name: Check if log folder exists
  stat:
    path: "{{httpd_logs}}"
  register: logs_path

- name: Copy logs to directory on host
  synchronize:
    src: "{{httpd_logs}}"
    dest: /home/{{host_remote_user}}/{{ansible_hostname}}
  delegate_to: "{{ inventory_hostname }}"
  when: httpd_config.stat.exists and logs_path.stat.isdir is defined and logs_path.stat.isdir


**********
DECISION===>: PASS
**********
=========================:::348:::END!!!=========================
=========================:::349:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/logs/roles/mysql/tasks/main.yml
**********
---
- name: Check that mysql is installed
  stat:
    path: /etc/my.cnf.d/galera.cnf
  register: mysql_config

- name: Check if mysql is containerized
  shell:
    cmd: docker ps | grep mariadb
  register: mysql_container
  when: mysql_config.stat.exists
  ignore_errors: true

- name: Set mysql log location (containerized)
  set_fact:
    mysql_logs: /var/log/containers/mysql
  when: mysql_container.rc == 0 and mysql_config.stat.exists

- name: Check if log folder exists
  stat:
    path: "{{mysql_logs}}"
  register: logs_path

- name: Copy logs to directory on host
  synchronize:
    src: "{{mysql_logs}}"
    dest: /home/{{host_remote_user}}/{{ansible_hostname}}
  delegate_to: "{{ inventory_hostname }}"
  when: mysql_config.stat.exists and logs_path.stat.isdir is defined and logs_path.stat.isdir


**********
DECISION===>: PASS
**********
=========================:::349:::END!!!=========================
=========================:::350:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/logs/roles/glance/tasks/main.yml
**********
---
- name: Check that glance is installed
  stat:
    path: /etc/glance/glance-api.conf
  register: glance_config

- name: Check if glance is containerized
  shell:
    cmd: docker ps | grep glance
  register: glance_container
  when: glance_config.stat.exists
  ignore_errors: true

- name: Set glance log location (containerized)
  set_fact:
    glance_logs: /var/log/containers/glance
  when: glance_container.rc == 0 and glance_config.stat.exists

- name: Set glance log location (non-containerized)
  set_fact:
    glance_logs: /var/log/glance
  when: glance_container.rc != 0 and glance_config.stat.exists

- name: Check if log folder exists
  stat:
    path: "{{glance_logs}}"
  register: logs_path

- name: Copy logs to directory on host
  synchronize:
    src: "{{glance_logs}}"
    dest: /home/{{host_remote_user}}/{{ansible_hostname}}
  delegate_to: "{{ inventory_hostname }}"
  when: glance_config.stat.exists and logs_path.stat.isdir is defined and logs_path.stat.isdir


**********
DECISION===>: PASS
**********
=========================:::350:::END!!!=========================
=========================:::351:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/logs/roles/openvswitch/tasks/main.yml
**********
---
- name: Check that openvswitch is installed
  stat:
    path: /etc/openvswitch/default.conf
  register: openvswitch_config

- name: Set openvswitch log location (non-containerized)
  set_fact:
    openvswitch_logs: /var/log/openvswitch
  when: openvswitch_config.stat.exists

- name: Check if log folder exists
  stat:
    path: "{{openvswitch_logs}}"
  register: logs_path

- name: Copy logs to directory on host
  synchronize:
    src: "{{openvswitch_logs}}"
    dest: /home/{{host_remote_user}}/{{ansible_hostname}}
  delegate_to: "{{ inventory_hostname }}"
  when: openvswitch_config.stat.exists and logs_path.stat.isdir is defined and logs_path.stat.isdir


**********
DECISION===>: PASS
**********
=========================:::351:::END!!!=========================
=========================:::352:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/tune/roles/tuned/tasks/main.yml
**********
---
#
# Sets correct tuned profile on each host
# See https://bugzilla.redhat.com/show_bug.cgi?id=1246645
#

- name: Set tuned profile
  become: true
  command: tuned-adm profile {{ tuned_profile }}

**********
DECISION===>: Suspicious Comment
**********
=========================:::352:::END!!!=========================
=========================:::353:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/tune/roles/udev_dhcp_all_interfaces/tasks/main.yml
**********
---
#
# Removes 99-dhcp-all-interfaces.rules to prevent creating failed systemd resources
# See https://bugzilla.redhat.com/show_bug.cgi?id=1293712
#

- name: Remove 99-dhcp-all-interfaces.rules
  become: true
  file: path=/etc/udev/rules.d/99-dhcp-all-interfaces.rules state=absent

**********
DECISION===>: Suspicious Comment
**********
=========================:::353:::END!!!=========================
=========================:::354:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/check/roles/gnocchi/tasks/main.yml
**********
---
#
# Gnocchi tasks for performance checks
#

- name: Get httpd configuration files
  command: 'ls /etc/httpd/conf.d/'
  register: httpd_confd_files

- name: Gnocchi API httpd process count
  shell: egrep -o "processes=[0-9]+" /etc/httpd/conf.d/*gnocchi_wsgi.conf | egrep -o "[0-9]+"
  register: bz1372821
  failed_when: bz1372821.stdout|int < gnocchi_api_processes and 'gnocchi' in httpd_confd_files.stdout
  when: (inventory_hostname in groups.controller)
  ignore_errors: True

**********
DECISION===>: PASS
**********
=========================:::354:::END!!!=========================
=========================:::355:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/check/roles/ceph/tasks/main.yml
**********
---
#
# Checks specific to ceph nodes
#

- name: Check Ceph cluster health status
  command: ceph status
  register: ceph_status
  failed_when: "'HEALTH_OK' not in '{{ ceph_status.stdout }}'"
  changed_when: false
  ignore_errors: True

- name: Verify RBD caching
  shell: ceph --admin-daemon `ls /var/run/ceph/ceph-osd.*.asok|tail -1` config show|grep '"rbd_cache":'|grep -i true|awk '{print tolower($0)}'
  register: ceph_rbd_caching
  failed_when : "'true'  not in '{{ ceph_rbd_caching.stdout }}'"
  changed_when: false
  ignore_errors: True

- name: Verify RBD cache writethrough
  shell: ceph --admin-daemon `ls /var/run/ceph/ceph-osd.*.asok|tail -1` config show|grep "rbd_cache_writethrough"|grep -i true|awk '{print tolower($0)}'
  register: ceph_rbd_cache_writethrough
  failed_when: "'false'  not in '{{ ceph_rbd_cache_writethrough.stdout }}'"
  changed_when: false
  ignore_errors: True

**********
DECISION===>: PASS
**********
=========================:::355:::END!!!=========================
=========================:::356:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/check/roles/undercloud/tasks/main.yml
**********
---
#
# Performance checks specific to controller hosts
#

- name: Check max_connections on the database
  shell: mysql -e "show variables like 'max_connections';" | grep max_connections | awk '{print $2}'
  register: bz1266253
  changed_when: no
  failed_when: bz1266253.stdout|int < mariadb_max_connections
  ignore_errors: yes

- name: Suggested buffer_pool_size
  shell: mysql -Bse "SELECT CEILING(Total_InnoDB_Bytes*1.6/POWER(1024,2)) RIBPS FROM (SELECT SUM(data_length+index_length) Total_InnoDB_Bytes FROM information_schema.tables WHERE engine='InnoDB') A;"
  register: suggested_buffer_pool_size
  changed_when: no
  ignore_errors: yes

- name : Current buffer_pool_size
  shell: echo $(mysql -Bse " select @@innodb_buffer_pool_size")/1024/1024 | bc
  register: buffer_pool_size
  failed_when: buffer_pool_size.stdout|int < suggested_buffer_pool_size.stdout|int
  changed_when: no
  ignore_errors: yes

- name : File descriptors for the mysql process
  shell: cat /proc/$(pgrep mysqld_safe)/limits | grep "open files" | awk '{print $4}'
  register: mysqld_safe_soft_fd
  failed_when: mysqld_safe_soft_fd.stdout|int < mysqld_soft_fd
  changed_when: no
  ignore_errors: yes

- name : Check rabbitmq file descriptors
  shell: rabbitmqctl status | grep total_limit |  awk -F',' '{print $2}' | sed 's/.$//'
  register: bz1282491
  changed_when: no
  failed_when: bz1282491.stdout|int < rabbitmq_fd
  ignore_errors: yes

- name: Run MySQL Tuner script
  script: mysqltuner.pl --nocolor
  register: mysql_out
  ignore_errors: yes

**********
DECISION===>: PASS
**********
=========================:::356:::END!!!=========================
=========================:::357:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/check/roles/nova/tasks/main.yml
**********
---
- name: Check Nova vif_plugging
  command: crudini --get /etc/nova/nova.conf DEFAULT vif_plugging_is_fatal
  register: bz1264740
  failed_when: "'True' not in '{{ bz1264740.stdout }}'"
  changed_when: false
  ignore_errors: True

- name: Check Nova vif_plugging_timeout
  command: crudini --get /etc/nova/nova.conf DEFAULT vif_plugging_timeout
  register: nova_vif_timeout_result
  failed_when: nova_vif_timeout > nova_vif_timeout_result.stdout|int
  changed_when: false
  ignore_errors: True

**********
DECISION===>: PASS
**********
=========================:::357:::END!!!=========================
=========================:::358:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/check/roles/neutron/tasks/main.yml
**********
---
- name: Check nova is configured in neutron config
  command: crudini --get /etc/neutron/neutron.conf DEFAULT nova_admin_tenant_id
  register: neutron_nova_creds
  failed_when: neutron_nova_creds.rc == 1
  changed_when: false
  ignore_errors: True

- name: Check for rootwrap daemon
  command: crudini --get /etc/neutron/neutron.conf agent root_helper_daemon
  register: neutron_rootwrap_daemon
  failed_when: neutron_rootwrap_daemon.rc == 1
  changed_when: false
  ignore_errors: True

- name: Check MTU
  shell: cat /etc/neutron/dnsmasq-neutron.conf | grep 'dhcp\-option\-force=26'
  register: neutron_dnsmasq_mtu
  failed_when: neutron_dnsmasq_mtu.rc == 0
  changed_when: false
  ignore_errors: True

- name: Check Neutron.conf MTU
  command: crudini --get /etc/neutron/neutron.conf DEFAULT global_physnet_mtu
  register: neutron_conf_mtu
  failed_when: neutron_conf_mtu.rc == 0
  changed_when: false
  ignore_errors: True

**********
DECISION===>: PASS
**********
=========================:::358:::END!!!=========================
=========================:::359:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/check/roles/keystone/tasks/main.yml
**********
---
#
# Keystone tasks for performance checks
#

- name: Check Keystone cron job
  shell: crontab -l -u keystone | grep -v "#"
  register: keystone_cron_result
  changed_when: false
  failed_when: "'token_flush' not in '{{ keystone_cron_result.stdout }}'"
  ignore_errors: True

- name: Check Keystone Token Provider
  command: crudini --get /etc/keystone/keystone.conf token provider
  register: keystone_token_provider
  changed_when: false
  ignore_errors: True

- debug: msg="Keystone Token Provider:{{ keystone_token_provider.stdout }}"

- name: Determine if Keystone is deployed in eventlet
  shell: ps afx | grep "[Kk]eystone-all" -c
  register: keystone_in_eventlet
  changed_when: false
  ignore_errors: True

- name: Set keystone_deployment variable to httpd
  set_fact: keystone_deployment='httpd'
  when: keystone_in_eventlet.stdout|int == 0

- name: Set keystone_deployment variable to eventlet
  set_fact: keystone_deployment='eventlet'
  when: keystone_in_eventlet.stdout|int > 0

- debug: msg="Keystone deployed in:{{ keystone_deployment }}"

- name: Keystone HTTP admin processes (Undercloud)
  shell: egrep -o "processes=[0-9]+" /etc/httpd/conf.d/*keystone*admin.conf | egrep -o "[0-9]+"
  register: bz1330980
  failed_when: bz1330980.stdout|int < keystone_processes
  when: (keystone_in_eventlet.stdout|int == 0) and (inventory_hostname in groups.undercloud)
  ignore_errors: True

- name: Keystone HTTP main processes (Undercloud)
  shell: egrep -o "processes=[0-9]+" /etc/httpd/conf.d/*keystone*main.conf | egrep -o "[0-9]+"
  register: bz1330980
  failed_when: bz1330980.stdout|int < keystone_processes
  when: (keystone_in_eventlet.stdout|int == 0) and (inventory_hostname in groups.undercloud)
  ignore_errors: True

- name: Keystone HTTP admin processes (Controller)
  shell: egrep -o "processes=[0-9]+" /etc/httpd/conf.d/*keystone*admin.conf | egrep -o "[0-9]+"
  register: bz1347305
  failed_when: bz1347305.stdout|int < keystone_processes
  when: (keystone_in_eventlet.stdout|int == 0) and (inventory_hostname in groups.controller)
  ignore_errors: True

- name: Keystone HTTP main processes (Controller)
  shell: egrep -o "processes=[0-9]+" /etc/httpd/conf.d/*keystone*main.conf | egrep -o "[0-9]+"
  register: bz1347305
  failed_when: bz1347305.stdout|int < keystone_processes
  when: (keystone_in_eventlet.stdout|int == 0) and (inventory_hostname in groups.controller)
  ignore_errors: True

**********
DECISION===>: PASS
**********
=========================:::359:::END!!!=========================
=========================:::360:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/check/roles/controller/tasks/main.yml
**********
---
#
# Performance checks specific to controller hosts
#

- name: Check max_connections on the database
  shell: mysql -e "show variables like 'max_connections';" | grep max_connections | awk '{print $2}'
  register: bz1266253
  changed_when: no
  failed_when: bz1266253.stdout|int < mariadb_max_connections
  ignore_errors: yes

- name: Suggested buffer_pool_size
  shell: mysql -Bse "SELECT CEILING(Total_InnoDB_Bytes*1.6/POWER(1024,2)) RIBPS FROM (SELECT SUM(data_length+index_length) Total_InnoDB_Bytes FROM information_schema.tables WHERE engine='InnoDB') A;"
  register: suggested_buffer_pool_size
  changed_when: no
  ignore_errors: yes

- name : Current buffer_pool_size
  shell: echo $(mysql -Bse " select @@innodb_buffer_pool_size")/1024/1024 | bc
  register: buffer_pool_size
  failed_when: buffer_pool_size.stdout|int < suggested_buffer_pool_size.stdout|int
  changed_when: no
  ignore_errors: yes

- name : File descriptors for the mysql process
  shell: cat /proc/$(pgrep mysqld_safe)/limits | grep "open files" | awk '{print $4}'
  register: mysqld_safe_soft_fd
  failed_when: mysqld_safe_soft_fd.stdout|int < mysqld_soft_fd
  changed_when: no
  ignore_errors: yes

- name : Check rabbitmq file descriptors
  shell: rabbitmqctl status | grep file_descriptors | awk -F',' '{print $3}' | sed 's/.$//'
  register: bz1282491
  changed_when: no
  failed_when: bz1282491.stdout|int < rabbitmq_fd
  ignore_errors: yes

- name : Check HAProxy Default maxconn
  shell : cat /etc/haproxy/haproxy.cfg | grep -iPzo '(?s)defaults.*?\n(\n|$)' | grep maxconn | awk '{print $2}'
  register: bz1281584
  failed_when: bz1281584.stdout|int < mariadb_max_connections
  changed_when: no
  ignore_errors: yes

- name : Check netns tuning
  shell : sysctl net.core.netdev_max_backlog | awk '{print $3}'
  register: bz1095811
  failed_when: bz1095811.stdout|int < netdev_max_backlog
  changed_when: no
  ignore_errors: yes

- name : Check udev performance issue
  shell : grep -q 'SUBSYSTEM=="net", ACTION=="add", TAG+="systemd", ENV{SYSTEMD_WANTS}+="dhcp-interface@$name.service"' /etc/udev/rules.d/99-dhcp-all-interfaces.rules
  register : bz1293712
  changed_when: no
  ignore_errors: yes
  failed_when: bz1293712.rc == 0

- name : Check rabbitmq for partitions
  shell: rabbitmqctl cluster_status |  grep partitions -A 1 | grep -v alarm | grep -q controller
  register: rabbit_partitioned
  changed_when: no
  failed_when: rabbit_partitioned.rc == 0
  ignore_errors: yes

- name: Run MySQL Tuner script
  script: mysqltuner.pl --nocolor
  register: mysql_out
  ignore_errors: yes

**********
DECISION===>: PASS
**********
=========================:::360:::END!!!=========================
=========================:::361:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/check/roles/common/tasks/main.yml
**********
---
#
# Tests common to Director/Controller/Compute/Ceph
#
- name: Ensure crudini
  command: which crudini
  changed_when: no
  register: crudini
  ignore_errors: True

- name: Install Crudini if it is not there
  package:
    name: crudini
    state: present
  when: crudini.rc == 1

- name: Get selinux mode
  command: getenforce
  changed_when: no
  register: sestatus

- name: Check tuned running on host
  command: tuned-adm active
  register: tuned_result
  changed_when: no
  failed_when: tuned_result.rc == -1
  ignore_errors: True

- name: Check tuned for correct profile on host
  command: tuned-adm active
  register: tuned_profile_result
  changed_when: no
  failed_when: "'{{ tuned_profile }}' not in '{{ tuned_profile_result.stdout }}'"
  ignore_errors: True


**********
DECISION===>: PASS
**********
=========================:::361:::END!!!=========================
=========================:::362:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/check/roles/compute/tasks/main.yml
**********
---
#
# Tests specific to compute hosts
#

- name: Check if swap device exists
  command: swapon -s
  register: bz1245714
  changed_when: no
  failed_when: "'dev' not in '{{ bz1245714.stdout }}'"
  ignore_errors: True

- name: Check reserved_host_memory_mb
  shell: grep reserved_host_memory /etc/nova/nova.conf | grep -v "#" | cut -f2 -d =
  register: bz1282644
  failed_when: bz1282644.stdout|int < reserved_host_memory_check
  changed_when: no
  ignore_errors: True


**********
DECISION===>: PASS
**********
=========================:::362:::END!!!=========================
=========================:::363:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/check/roles/glance/tasks/main.yml
**********
- name: Glance API worker count
  command:  crudini --get /etc/glance/glance-api.conf DEFAULT workers
  register: glance_api_workers
  failed_when: glance_api_workers.rc == 1
  changed_when: false
  ignore_errors: true
- name: Glance Registry worker count
  command:  crudini --get /etc/glance/glance-registry.conf DEFAULT workers
  register: glance_registry_workers
  failed_when: glance_registry_workers.rc == 1
  changed_when: false
  ignore_errors: true

**********
DECISION===>: PASS
**********
=========================:::363:::END!!!=========================
=========================:::364:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/browbeat/roles/nova-db/tasks/main.yml
**********
---
#
# Nova tasks for Browbeat
#

- name: Ensure nova.conf is properly configured
  ini_file:
    dest: /etc/nova/nova.conf
    mode: 0640
    section: "{{ item.section }}"
    option: "{{ item.option }}"
    value: "{{ item.value }}"
    backup: yes
  with_items:
    - { section: DEFAULT, option: wsgi_default_pool_size, value: "{{ greenlet_pool_size }}" }
    - { section: api_database, option: max_overflow, value: "{{ max_overflow }}" }
  notify:
    - unmanage nova services
    - restart nova services
    - manage nova services
    - cleanup nova services

**********
DECISION===>: PASS
**********
=========================:::364:::END!!!=========================
=========================:::365:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/browbeat/roles/nova-db/handlers/main.yml
**********
---
#
# Nova handlers for browbeat adjustment
#

- name: unmanage nova services
  command: pcs resource unmanage {{ item }}
  with_items:
    - openstack-nova-api
    - openstack-nova-scheduler
    - openstack-nova-conductor
  ignore_errors: true
  when: pacemaker_controlled

- name: restart nova services
  service: name={{ item }} state=restarted
  with_items:
    - openstack-nova-api
    - openstack-nova-scheduler
    - openstack-nova-conductor

- name: manage nova services
  command: pcs resource manage {{ item }}
  with_items:
    - openstack-nova-api
    - openstack-nova-scheduler
    - openstack-nova-conductor
  ignore_errors: true
  when: pacemaker_controlled

- name: cleanup nova services
  command: pcs resource cleanup {{ item }}
  with_items:
    - openstack-nova-api
    - openstack-nova-scheduler
    - openstack-nova-conductor
  ignore_errors: true
  when: pacemaker_controlled

**********
DECISION===>: PASS
**********
=========================:::365:::END!!!=========================
=========================:::366:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/browbeat/roles/gnocchi-config/tasks/main.yml
**********
---
#
# Tasks to adjust Gnocchi configuration items
#

- name: Configure gnocchi.conf
  become: true
  ini_file:
    dest: "{{gnocchi_config_file}}"
    mode: 0640
    # (akrzos) Commented out Group as to prevent in Pike incorrect permissions on config file
    # group: gnocchi
    section: "{{item.section}}"
    option: "{{item.option}}"
    value: "{{item.value}}"
    backup: yes
  with_items:
    - "{{gnocchi_configuration}}"

- name: (Newton, Ocata) Restart Gnocchi Metricd
  systemd:
    name: openstack-gnocchi-metricd
    state: restarted
  when: "('Newton' in osp_version['content'] | b64decode or 'Ocata' in osp_version['content'] | b64decode)"

- name: (Pike) Restart Gnocchi Metricd
  become: true
  command: docker restart gnocchi_metricd
  when: "'Pike' in osp_version['content'] | b64decode"

**********
DECISION===>: PASS
**********
=========================:::366:::END!!!=========================
=========================:::367:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/browbeat/roles/neutron-workers/tasks/main.yml
**********
---
#
# Neutron tasks for Browbeat
# * Can change worker count
#

- name: Configure neutron.conf
  become: true
  ini_file:
    dest: /etc/neutron/neutron.conf
    mode: 0640
    section: "{{ item.section }}"
    option: "{{ item.option }}"
    value: "{{ item.value }}"
    backup: yes
  with_items:
    - { section: DEFAULT, option: api_workers, value: "{{ workers }}" }
    - { section: DEFAULT, option: rpc_workers, value: "{{ workers }}" }
  notify:
    - unmanage neutron services
    - restart neutron services
    - manage neutron services
    - cleanup neutron services

- name: Configure metadata_agent.ini
  become: true
  ini_file:
    dest: /etc/neutron/metadata_agent.ini
    mode: 0640
    section: "{{ item.section }}"
    option: "{{ item.option }}"
    value: "{{ item.value }}"
    backup: yes
  with_items:
    - { section: DEFAULT, option: metadata_workers, value: "{{ workers }}" }
  notify:
    - unmanage neutron services
    - restart neutron services
    - manage neutron services
    - cleanup neutron services

**********
DECISION===>: PASS
**********
=========================:::367:::END!!!=========================
=========================:::368:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/browbeat/roles/neutron-workers/handlers/main.yml
**********
---
#
# Neutron handlers for browbeat adjustment
#

- name: unmanage neutron services
  become: true
  command: pcs resource unmanage {{ item }}
  with_items:
    - neutron-server
    - neutron-metadata-agent
  ignore_errors: true
  when: pacemaker_controlled

- name: restart neutron services
  become: true
  service: name={{ item }} state=restarted
  with_items:
    - neutron-server
    - neutron-metadata-agent

- name: manage neutron services
  become: true
  command: pcs resource manage {{ item }}
  with_items:
    - neutron-server
    - neutron-metadata-agent
  ignore_errors: true
  when: pacemaker_controlled

- name: cleanup neutron services
  become: true
  command: pcs resource cleanup {{ item }}
  with_items:
    - neutron-server
    - neutron-metadata-agent
  ignore_errors: true
  when: pacemaker_controlled

**********
DECISION===>: PASS
**********
=========================:::368:::END!!!=========================
=========================:::369:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/browbeat/roles/neutron-l3/tasks/main.yml
**********
---
#
# Neutron tasks for Browbeat
#

- name: Configure min_l3_agents
  ini_file:
    dest: /etc/neutron/neutron.conf
    mode: 0640
    section: "{{ item.section }}"
    option: "{{ item.option }}"
    value: "{{ item.value }}"
    backup: yes
  with_items:
    - { section: DEFAULT, option: max_l3_agents_per_router, value: "{{ max_l3_agents }}" }
    - { section: DEFAULT, option: min_l3_agents_per_router, value: "{{ min_l3_agents }}" }
  notify:
    - unmanage neutron services
    - restart neutron services
    - manage neutron services
    - cleanup neutron services

**********
DECISION===>: PASS
**********
=========================:::369:::END!!!=========================
=========================:::370:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/browbeat/roles/neutron-l3/handlers/main.yml
**********
---
#
# Neutron handlers for browbeat adjustment
#

- name: unmanage neutron services
  command: pcs resource unmanage {{ item }}
  with_items:
    - neutron-server
    - neutron-metadata-agent
  ignore_errors: true
  when: pacemaker_controlled


- name: restart neutron services
  service: name={{ item }} state=restarted
  with_items:
    - neutron-server
    - neutron-metadata-agent

- name: manage neutron services
  command: pcs resource manage {{ item }}
  with_items:
    - neutron-server
    - neutron-metadata-agent
  ignore_errors: true
  when: pacemaker_controlled

- name: cleanup neutron services
  command: pcs resource cleanup {{ item }}
  with_items:
    - neutron-server
    - neutron-metadata-agent
  ignore_errors: true
  when: pacemaker_controlled

**********
DECISION===>: PASS
**********
=========================:::370:::END!!!=========================
=========================:::371:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/browbeat/roles/neutron-firewall/tasks/main.yml
**********
- name: Configure the firewall driver
  ini_file:
    dest: "{{ item.file }}"
    mode: 0640
    section: "{{ item.section }}"
    option: "{{ item.option }}"
    value: "{{ item.value }}"
    backup: yes
  with_items:
    - { file: /etc/neutron/plugins/ml2/ml2_conf.ini, section: securitygroup, option: firewall_driver, value: "{{ driver }}" }
    - { file: /etc/neutron/plugins/ml2/openvswitch_agent.ini, section: securitygroup, option: firewall_driver, value: "{{ driver }}" }
  notify:
    - unmanage neutron services
    - restart neutron services
    - manage neutron services
    - cleanup neutron services



**********
DECISION===>: PASS
**********
=========================:::371:::END!!!=========================
=========================:::372:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/browbeat/roles/neutron-firewall/handlers/main.yml
**********
---
#
# Neutron handlers for browbeat adjustment
#

- name: unmanage neutron services
  command: pcs resource unmanage {{ item }}
  with_items:
    - neutron-openvswitch-agent
    - neutron-server
    - neutron-l3-agent
  ignore_errors: true

- name: restart neutron services
  service: name={{ item }} state=restarted
  with_items:
    - neutron-openvswitch-agent
    - neutron-server
    - neutron-l3-agent

- name: manage neutron services
  command: pcs resource manage {{ item }}
  with_items:
    - neutron-openvswitch-agent
    - neutron-server
    - neutron-l3-agent
  ignore_errors: true

- name: cleanup neutron services
  command: pcs resource cleanup {{ item }}
  with_items:
    - neutron-openvswitch-agent
    - neutron-server
    - neutron-l3-agent
  ignore_errors: true

**********
DECISION===>: PASS
**********
=========================:::372:::END!!!=========================
=========================:::373:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/browbeat/roles/nova-config/tasks/main.yml
**********
---
#
# Configure nova.conf tasks
#

- name: (Newton, Ocata, Pike) Configure nova.conf
  become: true
  ini_file:
    dest: "{{nova_config_file}}"
    mode: 0640
    # (akrzos) Commented out Group as to prevent in Pike incorrect permissions on config file
    # group: nova
    section: "{{ item.section }}"
    option: "{{ item.option }}"
    value: "{{ item.value }}"
    backup: yes
  with_items:
    - "{{nova_configuration}}"

**********
DECISION===>: PASS
**********
=========================:::373:::END!!!=========================
=========================:::374:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/browbeat/roles/ceilometer-config/tasks/main.yml
**********
---
#
# Configure ceilometer.conf tasks
#

- name: Configure ceilometer.conf
  become: true
  ini_file:
    dest: "{{ceilometer_config_file}}"
    mode: 0640
    # (akrzos) Commented out Group as to prevent in Pike incorrect permissions on config file
    # group: ceilometer
    section: "{{ item.section }}"
    option: "{{ item.option }}"
    value: "{{ item.value }}"
    backup: yes
  with_items:
    - "{{ceilometer_configuration}}"

- name: (Newton, Ocata) Restart Ceilometer Agent Notification
  systemd:
    name: openstack-ceilometer-notification
    state: restarted
  when: "('Newton' in osp_version['content'] | b64decode or 'Ocata' in osp_version['content'] | b64decode) and (restart_notification)"

- name: (Newton, Ocata) Restart Ceilometer Collector
  systemd:
    name: openstack-ceilometer-collector
    state: restarted
  when: "('Newton' in osp_version['content'] | b64decode or 'Ocata' in osp_version['content'] | b64decode) and (restart_collector)"

- name: (Pike) Restart Ceilometer Agent Notification
  become: true
  command: docker restart ceilometer_agent_notification
  when: "('Pike' in osp_version['content'] | b64decode) and (restart_notification)"

**********
DECISION===>: PASS
**********
=========================:::374:::END!!!=========================
=========================:::375:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/browbeat/roles/run-task-at/tasks/main.yml
**********
---
#
# Tasks to kick a task off at a specific time using at daemon
#

- name: Create job file
  become: true
  shell: "echo '#!/bin/bash\n {{the_task}} '>/root/browbeat-sync.sh"

- name: Set execute on file
  become: true
  file:
    path: /root/browbeat-sync.sh
    owner: root
    group: root
    mode: 0744

- name: Create at job
  become: true
  command: "at -f /root/browbeat-sync.sh {{task_time}}"

**********
DECISION===>: PASS
**********
=========================:::375:::END!!!=========================
=========================:::376:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/browbeat/roles/ceilometer-polling/tasks/main.yml
**********
---
#
# Deploy the Ceilometer polling.yaml file
#

- name: (Newton) Deploy pipeline.yaml file
  become: true
  template:
    src: pipeline.yaml.j2
    dest: /etc/ceilometer/pipeline.yaml
    owner: root
    group: ceilometer
    mode: 0640
    backup: true
  when: "{{reduced_metrics}} == false and ('Newton' in osp_version['content'] | b64decode)"

- name: (Newton) Deploy the reduced metrics pipeline.yaml file
  become: true
  template:
    src: reduced_pipeline.yaml.j2
    dest: /etc/ceilometer/pipeline.yaml
    owner: root
    group: ceilometer
    mode: 0640
    backup: true
  when: "{{reduced_metrics}} == true and ('Newton' in osp_version['content'] | b64decode)"

- name: (Ocata) Deploy polling.yaml file
  become: true
  template:
    src: polling.yaml.j2
    dest: /etc/ceilometer/polling.yaml
    owner: root
    group: ceilometer
    mode: 0640
    backup: true
  when: "{{reduced_metrics}} == false and ('Ocata' in osp_version['content'] | b64decode)"

- name: (Ocata) Deploy the reduced metrics polling.yaml file
  become: true
  template:
    src: reduced_polling.yaml.j2
    dest: /etc/ceilometer/polling.yaml
    owner: root
    group: ceilometer
    mode: 0640
    backup: true
  when: "{{reduced_metrics}} == true and ('Ocata' in osp_version['content'] | b64decode or 'Pike')"

- name: (Containerized Pike) Deploy the polling.yaml
  become: true
  template:
    src: reduced_polling.yaml.j2
    dest: /var/lib/config-data/ceilometer/etc/ceilometer/polling.yaml
    owner: root
    group: ceilometer
    mode: 0640
    backup: true
  when: "('Pike' in osp_version['content'] | b64decode)"

**********
DECISION===>: PASS
**********
=========================:::376:::END!!!=========================
=========================:::377:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/browbeat/roles/keystone-token/tasks/main.yml
**********
---
#
# Keystone tasks to change token type
#

- name: Determine if keystone is deployed in eventlet
  shell: ps afx | grep "[Kk]eystone-all" -c
  register: deployed
  when: keystone_deployment is undefined
  ignore_errors: true
  changed_when: false

- name: Set keystone_deployment variable/fact to httpd
  set_fact: keystone_deployment='httpd'
  when: keystone_deployment is undefined and deployed.stdout|int == 0

- name: Set keystone_deployment variable/fact to eventlet
  set_fact: keystone_deployment='eventlet'
  when: keystone_deployment is undefined

#
# Get Token type
#

- name: Check Keystone Token Provider
  become: true
  command: crudini --get /etc/keystone/keystone.conf token provider
  register: keystone_token_provider
  changed_when: false
  ignore_errors: True

- name: Set current_token_provider variable/fact to uuid
  set_fact: current_token_provider='uuid'
  when: "'uuid' in '{{ keystone_token_provider.stdout }}'"

- name: Set current_token_provider variable/fact to fernet
  set_fact: current_token_provider='fernet'
  when: "'fernet' in '{{ keystone_token_provider.stdout }}'"

- name: Set current_token_provider variable/fact to pkiz
  set_fact: current_token_provider='pkiz'
  when: "'pkiz' in '{{ keystone_token_provider.stdout }}'"

#
# Tasks to change token provider if necessary:
#

- name: Change token provider
  become: true
  command: crudini --set /etc/keystone/keystone.conf token provider "keystone.token.providers.{{ token_provider }}.Provider"
  when: "'{{ current_token_provider }}' != '{{ token_provider }}'"
  notify:
    - pacemaker default unmanaged
    - stop keystone service
    - restart httpd service
    - restart keystone service
    - pacemaker default managed
    - pacemaker cleanup keystone

#
# fernet token setup:
#

- name: Create fernet keys directory
  become: true
  file:
    path=/etc/keystone/fernet-keys
    state=directory
    owner=keystone
    group=keystone
    mode=0700
  when: "'{{ token_provider }}' == 'fernet'"

- name: Setup fernet keys
  become: true
  command: keystone-manage fernet_setup --keystone-user keystone --keystone-group keystone
  when: ('{{ token_provider }}' == 'fernet') and (inventory_hostname == groups['controller'][0])

- name: Get fernet keys
  become: true
  fetch: src=/etc/keystone/fernet-keys/{{ item }} dest=roles/keystone-token/files/{{ item }} flat=yes
  with_items:
    - 0
    - 1
  when: ('{{ token_provider }}' == 'fernet') and (inventory_hostname == groups['controller'][0])
  changed_when: false

- name: Copy fernet keys
  become: true
  copy: src={{ item }} dest=/etc/keystone/fernet-keys/{{ item }}
  with_items:
    - "0"
    - "1"
  when: ('{{ token_provider }}' == 'fernet') and (inventory_hostname != groups['controller'][0])

- name: Copy keystone type enforcement file
  become: true
  copy:
    src: my-keystone.te
    dest: /root/my-keystone.te
  when: "'{{ token_provider }}' == 'fernet'"

- name: Create keystone.mod file
  become: true
  command: checkmodule -M -m -o /root/my-keystone.mod /root/my-keystone.te
  when: "'{{ token_provider }}' == 'fernet'"

- name: Create keystone.pp file
  become: true
  command: semodule_package -o /root/my-keystone.pp -m /root/my-keystone.mod
  when: "'{{ token_provider }}' == 'fernet'"

- name: Install keystone selinux policy
  become: true
  command: semodule -i /root/my-keystone.pp
  when: "'{{ token_provider }}' == 'fernet'"

**********
DECISION===>: PASS
**********
=========================:::377:::END!!!=========================
=========================:::378:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/browbeat/roles/keystone-token/handlers/main.yml
**********
---
#
# Keystone change token provider handlers
#

- name: pacemaker default unmanaged
  become: true
  command: pcs property set is-managed-default=false
  when: pacemaker_controlled

- name: stop keystone service
  become: true
  service: name=openstack-keystone state=stopped
  when: "'httpd' in '{{ keystone_deployment }}'"

- name: restart httpd service
  become: true
  service: name=httpd state=restarted
  when: "'httpd' in '{{ keystone_deployment }}'"

- name: restart keystone service
  become: true
  service: name=openstack-keystone state=restarted
  when: "'eventlet' in '{{ keystone_deployment }}'"

- name: pacemaker default managed
  become: true
  command: pcs property set is-managed-default=true
  when: "'eventlet' in '{{ keystone_deployment }}' and pacemaker_controlled"

- name: pacemaker cleanup keystone
  become: true
  command: pcs resource cleanup openstack-keystone
  when: "'eventlet' in '{{ keystone_deployment }}' and pacemaker_controlled"
  ignore_errors: true

**********
DECISION===>: PASS
**********
=========================:::378:::END!!!=========================
=========================:::379:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/browbeat/roles/keystone-workers/tasks/main.yml
**********
---
#
# Keystone tasks for browbeat
# * Change eventlet worker count or httpd process/thread count
# * Change keystone deployed in eventlet or httpd
#

- name: Determine if keystone is deployed in eventlet
  shell: ps afx | grep "[Kk]eystone-all" -c
  register: deployed
  when: keystone_deployment is undefined
  ignore_errors: true
  changed_when: false

- name: Set keystone_deployment variable/fact to httpd
  set_fact: keystone_deployment='httpd'
  when: keystone_deployment is undefined and deployed.stdout|int == 0

- name: Set keystone_deployment variable/fact to eventlet
  set_fact: keystone_deployment='eventlet'
  when: keystone_deployment is undefined

- name: Get keystone admin ip address
  become: true
  command: crudini --get /etc/keystone/keystone.conf DEFAULT admin_bind_host
  register: admin_ip_addr
  changed_when: false

- name: Get keystone public ip address
  become: true
  command: crudini --get /etc/keystone/keystone.conf DEFAULT public_bind_host
  register: public_ip_addr
  changed_when: false

#
# Configure keystone eventlet/httpd
#

- name: Configure eventlet workers
  become: true
  ini_file:
    dest: /etc/keystone/keystone.conf
    mode: 0640
    section: "{{ item.section }}"
    option: "{{ item.option }}"
    value: "{{ item.value }}"
    backup: true
  with_items:
    - { section: DEFAULT, option: public_workers, value: "{{ workers }}" }
    - { section: DEFAULT, option: admin_workers, value: "{{ workers }}" }
    - { section: eventlet_server, option: public_workers, value: "{{ workers }}" }
    - { section: eventlet_server, option: admin_workers, value: "{{ workers }}" }
  when: "'eventlet' in '{{ keystone_deployment }}'"
  notify:
    - pacemaker unmanaged default
    - stop keystone eventlet
    - restart keystone
    - pacemaker managed default
    - cleanup keystone

- name: Unconfigure keystone in httpd if eventlet
  become: true
  file:
    path: /etc/httpd/conf.d/10-keystone_wsgi_{{ item }}.conf
    state: absent
  with_items:
    - admin
    - main
  when: "'eventlet' in '{{ keystone_deployment }}'"
  notify:
    - restart httpd
    - cleanup httpd

- name: Create keystone in httpd wsgi directory
  become: true
  file:
    path: /var/www/cgi-bin/keystone
    state: directory
    owner: keystone
    group: keystone
  when: "'httpd' in '{{ keystone_deployment }}'"

- name: Copy keystone in httpd files over
  become: true
  copy:
    src: keystone_httpd
    dest: /var/www/cgi-bin/keystone/{{ item }}
    owner: keystone
    group: keystone
    mode: 0744
    backup: true
  with_items:
    - admin
    - main
  when: "'httpd' in '{{ keystone_deployment }}'"
  ignore_errors: true

- name: Configure httpd processes/threads
  become: true
  template:
    src: keystone_wsgi.conf.j2
    dest: /etc/httpd/conf.d/10-keystone_wsgi_{{ item.interface }}.conf
    owner: root
    group: root
    mode: 0644
    backup: true
  with_items:
    - ip_address: "{{ admin_ip_addr.stdout | default('') }}"
      interface: "admin"
      processes: "{{ workers }}"
      port: 35357
      threads: "{{ threads }}"
    - ip_address: "{{ public_ip_addr.stdout | default('') }}"
      interface: "main"
      processes: "{{ workers }}"
      port: 5000
      threads: "{{ threads }}"
  when: "'httpd' in '{{ keystone_deployment }}'"
  notify:
    - pacemaker unmanaged default
    - stop keystone eventlet
    - restart httpd

- name: Configure/Unconfigure httpd ports.conf for keystone (httpd)
  become: true
  lineinfile:
    dest: /etc/httpd/conf/ports.conf
    line: "Listen {{item}}"
    backup: true
  with_items:
    - "{{ public_ip_addr.stdout | default('') }}:5000"
    - "{{ admin_ip_addr.stdout | default('') }}:35357"
  when: "'httpd' in '{{ keystone_deployment }}'"
  notify:
    - pacemaker unmanaged default
    - stop keystone eventlet
    - restart keystone
    - pacemaker managed default
    - cleanup keystone

- name: Configure/Unconfigure httpd ports.conf for keystone (eventlet)
  become: true
  lineinfile:
    dest: /etc/httpd/conf/ports.conf
    line: "Listen {{item}}"
    state: absent
  with_items:
    - "{{ public_ip_addr.stdout | default('') }}:5000"
    - "{{ admin_ip_addr.stdout | default('') }}:35357"
  when: "'eventlet' in '{{ keystone_deployment }}'"
  notify:
    - pacemaker unmanaged default
    - stop keystone eventlet
    - restart keystone
    - pacemaker managed default
    - cleanup keystone

**********
DECISION===>: PASS
**********
=========================:::379:::END!!!=========================
=========================:::380:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/browbeat/roles/keystone-workers/handlers/main.yml
**********
---
#
# Keystone handlers for browbeat adjustment
#

- name: pacemaker unmanaged default
  become: true
  command: pcs property set is-managed-default=false
  ignore_errors: true
  when: pacemaker_controlled

- name: stop keystone eventlet
  become: true
  service: name=openstack-keystone state=stopped
  when: "'httpd' in '{{ keystone_deployment }}'"
  ignore_errors: true

- name: restart httpd
  become: true
  service: name=httpd state=restarted

- name: restart keystone
  become: true
  service: name=openstack-keystone state=restarted
  when: "'eventlet' in '{{ keystone_deployment }}'"

- name: pacemaker managed default
  become: true
  command: pcs property set is-managed-default=true
  # OSP8 and below uncomment, so only pcs managed when keystone in eventlet
  # when: "'eventlet' in '{{ keystone_deployment }}'"
  ignore_errors: true
  when: pacemaker_controlled

- name: cleanup keystone
  become: true
  command: pcs resource cleanup openstack-keystone
  when: "'eventlet' in '{{ keystone_deployment }}' and pacemaker_controlled"
  ignore_errors: true

- name: cleanup httpd
  become: true
  command: pcs resource cleanup httpd
  ignore_errors: true
  when: pacemaker_controlled

**********
DECISION===>: PASS
**********
=========================:::380:::END!!!=========================
=========================:::381:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/browbeat/roles/apache-config/tasks/main.yml
**********
---
#
# Tasks to deploy new prefork.conf settings for httpd
#

- name: Push new prefork.conf
  become: true
  template:
    src: prefork.conf.j2
    dest: /etc/httpd/conf.modules.d/prefork.conf
    mode: 0644
    owner: root
    group: root
    backup: true

- name: Restart httpd
  systemd:
    name: httpd
    state: restarted

**********
DECISION===>: PASS
**********
=========================:::381:::END!!!=========================
=========================:::382:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/browbeat/roles/gnocchi-api-config/tasks/main.yml
**********
---
#
# Tasks to reconfigure Gnocchi API wsgi service
#

- name: Get internal API address
  become: true
  shell: "grep {{inventory_hostname}}.internalapi.localdomain /etc/hosts | awk '{print $1}'"
  register: internal_api_ip

- name: Push new 10-gnocchi_wsgi.conf
  become: true
  template:
    src: gnocchi_wsgi.conf.j2
    dest: "{{gnocchi_api_apache_file}}"
    mode: 0640
    # (akrzos) Commented out Group as to prevent in Pike incorrect permissions on config file
    # owner: root
    # group: root
    backup: true

- name: (Newton, Ocata) Restart Gnocchi API (httpd)
  systemd:
    name: httpd
    state: restarted
  when: "('Newton' in osp_version['content'] | b64decode or 'Ocata' in osp_version['content'] | b64decode)"

- name: (Pike) Restart Gnocchi API (httpd)
  become: true
  command: docker restart gnocchi_api
  when: "'Pike' in osp_version['content'] | b64decode"

**********
DECISION===>: PASS
**********
=========================:::382:::END!!!=========================
=========================:::383:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/browbeat/roles/nova-workers/tasks/main.yml
**********
---
#
# Nova tasks for Browbeat
# * Can change worker count
#

- name: Ensure nova.conf is properly configured
  become: true
  ini_file:
    dest: /etc/nova/nova.conf
    mode: 0640
    section: "{{ item.section }}"
    option: "{{ item.option }}"
    value: "{{ item.value }}"
    backup: yes
  with_items:
    - { section: DEFAULT, option: ec2_workers, value: "{{ workers }}" }
    - { section: DEFAULT, option: osapi_compute_workers, value: "{{ workers }}" }
    - { section: DEFAULT, option: metadata_workers, value: "{{ workers }}" }
    - { section: conductor, option: workers, value: "{{ workers }}" }
  notify:
    - unmanage nova services
    - restart nova services
    - manage nova services
    - cleanup nova services

**********
DECISION===>: PASS
**********
=========================:::383:::END!!!=========================
=========================:::384:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/browbeat/roles/nova-workers/handlers/main.yml
**********
---
#
# Nova handlers for browbeat adjustment
#

- name: unmanage nova services
  become: true
  command: pcs resource unmanage {{ item }}
  with_items:
    - openstack-nova-api
    - openstack-nova-scheduler
    - openstack-nova-conductor
  ignore_errors: true
  when: pacemaker_controlled

- name: restart nova services
  become: true
  service: name={{ item }} state=restarted
  with_items:
    - openstack-nova-api
    - openstack-nova-scheduler
    - openstack-nova-conductor

- name: manage nova services
  become: true
  command: pcs resource manage {{ item }}
  with_items:
    - openstack-nova-api
    - openstack-nova-scheduler
    - openstack-nova-conductor
  ignore_errors: true
  when: pacemaker_controlled

- name: cleanup nova services
  become: true
  command: pcs resource cleanup {{ item }}
  with_items:
    - openstack-nova-api
    - openstack-nova-scheduler
    - openstack-nova-conductor
  ignore_errors: true
  when: pacemaker_controlled

**********
DECISION===>: PASS
**********
=========================:::384:::END!!!=========================
=========================:::385:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/browbeat/roles/cinder-workers/tasks/main.yml
**********
---
#
# Cinder tasks for Browbeat
# * Can change worker count
#

- name: Configure cinder.conf
  become: true
  ini_file:
    dest: /etc/cinder/cinder.conf
    mode: 0640
    section: "{{ item.section }}"
    option: "{{ item.option }}"
    value: "{{ item.value }}"
    backup: yes
  with_items:
    - { section: DEFAULT, option: osapi_volume_workers, value: "{{ workers }}" }
  notify:
    - unmanage cinder services
    - restart cinder services
    - manage cinder services
    - cleanup cinder services

**********
DECISION===>: PASS
**********
=========================:::385:::END!!!=========================
=========================:::386:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/browbeat/roles/cinder-workers/handlers/main.yml
**********
---
#
# Cinder handlers for browbeat adjustment
#

- name: unmanage cinder services
  become: true
  command: pcs resource unmanage {{ item }}
  with_items:
    - openstack-cinder-api
  ignore_errors: true
  when: pacemaker_controlled

- name: restart cinder services
  become: true
  service: name={{ item }} state=restarted
  with_items:
    - openstack-cinder-api

- name: manage cinder services
  become: true
  command: pcs resource manage {{ item }}
  with_items:
    - openstack-cinder-api
  ignore_errors: true
  when: pacemaker_controlled

- name: cleanup cinder services
  become: true
  command: pcs resource cleanup {{ item }}
  with_items:
    - openstack-cinder-api
  ignore_errors: true
  when: pacemaker_controlled

**********
DECISION===>: PASS
**********
=========================:::386:::END!!!=========================
=========================:::387:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/browbeat/roles/neutron-ovsdb/tasks/main.yml
**********
- name: Configure the ovsdb driver
  ini_file:
    dest: "{{ item.file }}"
    mode: 0640
    section: "{{ item.section }}"
    option: "{{ item.option }}"
    value: "{{ item.value }}"
    backup: yes
  with_items:
    - { file: /etc/neutron/plugins/ml2/openvswitch_agent.ini, section: ovs, option: ovsdb_interface, value: "{{ driver }}" }
  notify:
    - unmanage neutron services
    - restart neutron services
    - manage neutron services
    - cleanup neutron services

**********
DECISION===>: PASS
**********
=========================:::387:::END!!!=========================
=========================:::388:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/ansible/browbeat/roles/neutron-ovsdb/handlers/main.yml
**********
---
#
# Neutron handlers for browbeat adjustment
#

- name: restart neutron services
  service: name={{ item }} state=restarted
  with_items:
    - neutron-openvswitch-agent

**********
DECISION===>: PASS
**********
=========================:::388:::END!!!=========================
=========================:::389:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/rally/keystonebasic/create_add_and_list_user_roles-cc.yml
**********
{% set sla_max_avg_duration = sla_max_avg_duration or 60 %}
{% set sla_max_failure = sla_max_failure or 0 %}
{% set sla_max_seconds = sla_max_seconds or 60 %}
---
  KeystoneBasic.create_add_and_list_user_roles:
    -
      args: {}
      context:
        users:
          project_domain: "default"
          resource_management_workers: 30
          tenants: 1
          user_domain: "default"
          users_per_tenant: 8
      runner:
        concurrency: {{concurrency}}
        times: {{times}}
        type: "constant"
      sla:
        max_avg_duration: {{sla_max_avg_duration}}
        max_seconds_per_iteration: {{sla_max_seconds}}
        failure_rate:
          max: {{sla_max_failure}}

**********
DECISION===>: PASS
**********
=========================:::389:::END!!!=========================
=========================:::390:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/rally/keystonebasic/add_and_remove_user_role-cc.yml
**********
{% set sla_max_avg_duration = sla_max_avg_duration or 60 %}
{% set sla_max_failure = sla_max_failure or 0 %}
{% set sla_max_seconds = sla_max_seconds or 60 %}
---
  KeystoneBasic.add_and_remove_user_role:
    -
      args: {}
      context:
        users:
          project_domain: "default"
          resource_management_workers: 30
          tenants: 1
          user_domain: "default"
          users_per_tenant: 8
      runner:
        concurrency: {{concurrency}}
        times: {{times}}
        type: "constant"
      sla:
        max_avg_duration: {{sla_max_avg_duration}}
        max_seconds_per_iteration: {{sla_max_seconds}}
        failure_rate:
          max: {{sla_max_failure}}

**********
DECISION===>: PASS
**********
=========================:::390:::END!!!=========================
=========================:::391:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/rally/keystonebasic/create_and_delete_role-cc.yml
**********
{% set sla_max_avg_duration = sla_max_avg_duration or 60 %}
{% set sla_max_failure = sla_max_failure or 0 %}
{% set sla_max_seconds = sla_max_seconds or 60 %}
---
  KeystoneBasic.create_and_delete_role:
    -
      args: {}
      context:
        users:
          project_domain: "default"
          resource_management_workers: 30
          tenants: 1
          user_domain: "default"
          users_per_tenant: 8
      runner:
        concurrency: {{concurrency}}
        times: {{times}}
        type: "constant"
      sla:
        max_avg_duration: {{sla_max_avg_duration}}
        max_seconds_per_iteration: {{sla_max_seconds}}
        failure_rate:
          max: {{sla_max_failure}}

**********
DECISION===>: PASS
**********
=========================:::391:::END!!!=========================
=========================:::392:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/rally/keystonebasic/create_add_list_roles-cc.yml
**********
{% set sla_max_avg_duration = sla_max_avg_duration or 60 %}
{% set sla_max_failure = sla_max_failure or 0 %}
{% set sla_max_seconds = sla_max_seconds or 60 %}
---
  KeystoneBasic.create_and_list_roles:
    -
      args:
        create_role_kwargs: {}
        list_role_kwargs: {}
      context:
        users:
          project_domain: "default"
          resource_management_workers: 30
          tenants: 1
          user_domain: "default"
          users_per_tenant: 8
      runner:
        concurrency: {{concurrency}}
        times: {{times}}
        type: "constant"
      sla:
        max_avg_duration: {{sla_max_avg_duration}}
        max_seconds_per_iteration: {{sla_max_seconds}}
        failure_rate:
          max: {{sla_max_failure}}

**********
DECISION===>: PASS
**********
=========================:::392:::END!!!=========================
=========================:::393:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/browbeat/rally/keystonebasic/create_and_get_role-cc.yml
**********
{% set sla_max_avg_duration = sla_max_avg_duration or 60 %}
{% set sla_max_failure = sla_max_failure or 0 %}
{% set sla_max_seconds = sla_max_seconds or 60 %}
---
  KeystoneBasic.create_and_get_role:
    -
      args: {}
      context:
        users:
          project_domain: "default"
          resource_management_workers: 30
          tenants: 1
          user_domain: "default"
          users_per_tenant: 8
      runner:
        concurrency: {{concurrency}}
        times: {{times}}
        type: "constant"
      sla:
        max_avg_duration: {{sla_max_avg_duration}}
        max_seconds_per_iteration: {{sla_max_seconds}}
        failure_rate:
          max: {{sla_max_failure}}

**********
DECISION===>: PASS
**********
=========================:::393:::END!!!=========================
=========================:::394:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/fuel-ccp-installer/utils/kargo/roles/postinstall/tasks/dns_fix.yml
**********
---
# NOTE(mattymo): This can be removed after release of Calico 2.1

- name: Get timestamp from oldest dhclient pid
  shell: "pgrep -o dhclient | xargs --no-run-if-empty -I{} stat --printf='%Y' /proc/{}"
  register: oldest_dhclient_time

- name: check if /etc/dhclient.conf exists
  stat:
    path: /etc/dhclient.conf
  register: dhclient_find_stat

- name: target dhclient conf file for /etc/dhclient.conf
  set_fact:
    dhclientconffile: /etc/dhclient.conf
  when: dhclient_find_stat.stat.exists

- name: target dhclient conf file for /etc/dhcp/dhclient.conf
  set_fact:
    dhclientconffile: /etc/dhcp/dhclient.conf
  when: not dhclient_find_stat.stat.exists

- name: Gather info on dhclient.conf
  stat:
    path: "{{ dhclientconffile }}"
  register: dhclient_stat

- name: See if oldest dhclient process is older than dhclient.conf
  set_fact:
    needs_network_reset: "{{ oldest_dhclient_time.stdout != '' and oldest_dhclient_time.stdout|int < dhclient_stat.stat.mtime }}"

- name: update ansible time
  setup: filter=ansible_date_time

- name: Calculate number of seconds since dhclient.conf was modified
  set_fact:
    mtime_dhclientconf: "{{ ansible_date_time.epoch|int - dhclient_stat.stat.mtime|int }}"

- name: Set networking service name
  set_fact:
    networking_service_name: >-
      {% if ansible_os_family == "RedHat" -%}
      network
      {%- elif ansible_os_family == "Debian" -%}
      networking
      {%- endif %}

- name: Restart networking, dhclient, and calico-felix
  shell: "{{ item }}"
  when: needs_network_reset|bool and inventory_hostname in groups['k8s-cluster']
  failed_when: false # in case dhclient was stopped
  with_items:
  - killall -q dhclient --older-than {{ mtime_dhclientconf }}s
  - systemctl restart {{ networking_service_name }}
  - docker exec calico-node killall -HUP calico-felix

**********
DECISION===>: PASS
**********
=========================:::394:::END!!!=========================
=========================:::395:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/fuel-ccp-installer/utils/kargo/roles/postinstall/tasks/main.yml
**********
---
- include: dns_fix.yml
  when: kube_network_plugin in ['canal', 'calico']

- name: pick dnsmasq cluster IP
  set_fact:
    dnsmasq_server: >-
      {%- if skip_dnsmasq|bool -%}{{ skydns_server }}{%- else -%}{{ dns_server }}{%- endif -%}

- name: Wait for kubedns to be ready
  shell: "nslookup kubernetes.default.svc.{{ dns_domain }} {{ dnsmasq_server }}"
  register: kubernetes_resolvable
  until: kubernetes_resolvable.rc == 0
  delay: 5
  retries: 5
  changed_when: false

- name: Copy network test script
  copy:
    src: test_networking.sh
    dest: "{{ bin_dir }}/test_networking.sh"
    owner: root
    group: root
    mode: 0755

- name: Get current list of kube nodes
  command: kubectl get nodes
  register: kubectl_nodes
  delegate_to: "{{groups['kube-master'][0]}}"
  run_once: true

- name: Ensure kube-nodes are in list of nodes
  fail:
    msg: "{{inventory_hostname}} is not in kubectl get nodes"
  when: inventory_hostname in groups['kube-node'] and
        inventory_hostname not in kubectl_nodes.stdout

- name: Test networking connectivity
  shell: "bash {{ bin_dir }}/test_networking.sh"
  environment:
    KUBEDNS_IP: "{{ skydns_server }}"
    DNSMASQ_IP: "{{ dnsmasq_server }}"
    ADMIN_USER: "{{ ansible_user }}"
    ADMIN_IP: "{{ hostvars[groups['kube-master'][0]]['ip'] | default(hostvars[groups['kube-master'][0]]['ansible_default_ipv4']['address']) }}"
    SLAVE_IPS: "{{ ip }}"
  changed_when: false
  become: no

- name: Check netchecker status
  uri: url=http://localhost:31081/api/v1/connectivity_check
  register: netchecker_status
  until: netchecker_status.status == 200
  retries: 6
  delay: 20
  delegate_to: "{{groups['kube-node'][0]}}"
  run_once: true
  become: no
  when: deploy_netchecker|bool | default(false)

- name: Copy dashboard definition
  copy:
    src: kubernetes-dashboard.yml
    dest: /etc/kubernetes/kubernetes-dashboard.yml
    owner: root
    group: root
    mode: 0644
  register: dashboard
  delegate_to: "{{groups['kube-master'][0]}}"
  run_once: true

- name: Create Kubernetes dashboard
  command: "{{ bin_dir }}/kubectl create -f /etc/kubernetes/kubernetes-dashboard.yml"
  when: dashboard.changed
  delegate_to: "{{groups['kube-master'][0]}}"
  run_once: true

**********
DECISION===>: PASS
**********
=========================:::395:::END!!!=========================
=========================:::396:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/fuel-ccp-installer/utils/kargo/roles/postinstall/defaults/main.yml
**********
# Use only kubedns for testing k8s dns
skip_dnsmasq: true

**********
DECISION===>: PASS
**********
=========================:::396:::END!!!=========================
=========================:::397:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/fuel-ccp-installer/utils/kargo/roles/postinstall/files/kubernetes-dashboard.yml
**********
# Copyright 2015 Google Inc. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Configuration to deploy release version of the Dashboard UI.
#
# Example usage: kubectl create -f <this_file>

kind: Deployment
apiVersion: extensions/v1beta1
metadata:
  labels:
    app: kubernetes-dashboard
    version: v1.4.0
  name: kubernetes-dashboard
  namespace: kube-system
spec:
  replicas: 1
  selector:
    matchLabels:
      app: kubernetes-dashboard
  template:
    metadata:
      labels:
        app: kubernetes-dashboard
    spec:
      containers:
      - name: kubernetes-dashboard
        image: gcr.io/google_containers/kubernetes-dashboard-amd64:v1.4.0
        imagePullPolicy: Always
        ports:
        - containerPort: 9090
          protocol: TCP
        args:
          # Uncomment the following line to manually specify Kubernetes API server Host
          # If not specified, Dashboard will attempt to auto discover the API server and connect
          # to it. Uncomment only if the default does not work.
          # - --apiserver-host=http://my-address:port
        livenessProbe:
          httpGet:
            path: /
            port: 9090
          initialDelaySeconds: 30
          timeoutSeconds: 30
---
kind: Service
apiVersion: v1
metadata:
  labels:
    app: kubernetes-dashboard
  name: kubernetes-dashboard
  namespace: kube-system
spec:
  type: NodePort
  ports:
  - port: 80
    targetPort: 9090
  selector:
    app: kubernetes-dashboard

**********
DECISION===>: PASS
**********
=========================:::397:::END!!!=========================
=========================:::398:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/fuel-ccp-installer/utils/kargo/roles/configure_logs/tasks/main.yml
**********
---

- name: Configure logs | ensure log path
  file:
    path: "{{log_path}}"
    state: directory
    owner: "{{ansible_ssh_user}}"

- name: Configure logs | ensure config dir
  file:
    path: "{{conf_file | dirname}}"
    state: directory
    owner: root
    group: root
    mode: 0755
    recurse: yes

- name: Configure logs | ensure config file
  get_url:
    url: https://raw.githubusercontent.com/ansible/ansible/stable-2.3/examples/ansible.cfg
    dest: "{{conf_file}}"
    force: no
    owner: root
    group: root
    mode: 0644

- name: Configure logs | config
  lineinfile:
    line: "log_path={{log_path}}/ansible.log"
    regexp: "^#log_path|^log_path"
    dest: "{{conf_file}}"

- name: Configure logs | Install script for collecting info
  template:
    src: collect_logs.sh.j2
    dest: "{{ bin_dir }}/collect_logs.sh"
    mode: a+rwx

**********
DECISION===>: PASS
**********
=========================:::398:::END!!!=========================
=========================:::399:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/fuel-ccp-installer/utils/kargo/roles/configure_logs/defaults/main.yml
**********
bin_dir: /usr/local/bin
log_path: /var/log/ansible/
conf_file: /etc/ansible/ansible.cfg
# Define custom diag info to collect
commands:
  - name: git_info
    cmd: find . -type d -name .git -execdir sh -c 'gen-gitinfos.sh global|head -12' \;
  - name: timedate_info
    cmd: timedatectl status
  - name: boots_info
    cmd: journalctl --list-boots --utc --no-pager
  - name: space_info
    cmd: df -h
  - name: kernel_info
    cmd: uname -r
  - name: distro_info
    cmd: cat /etc/issue.net
  - name: docker_info
    cmd: docker info
  - name: ip_info
    cmd: ip -4 -o a
  - name: route_info
    cmd: ip ro
  - name: proc_info
    cmd: ps auxf | grep -v ]$
  - name: systemctl_info
    cmd: systemctl status
  - name: systemctl_failed_info
    cmd: systemctl --state=failed --no-pager
  - name: k8s_resolve_info
    cmd: host kubernetes
  - name: k8s_info
    cmd: kubectl get all --all-namespaces -o wide
  - name: k8s_dump_info
    cmd: kubectl get all --all-namespaces -o yaml
  - name: errors_info
    cmd: journalctl -p err --utc --no-pager
  - name: etcd_info
    cmd: etcdctl --debug cluster-health
  - name: calico_info
    cmd: calicoctl status
  - name: sysctl_info
    cmd: sysctl -a
logs:
  - /var/log/ansible/ansible.log
  - /var/log/syslog
  - /var/log/daemon.log
  - /var/log/kern.log
  - /etc/resolv.conf
  - "{{searchpath}}/kargo/cluster.yml"
  - "{{searchpath}}/kargo/inventory/group_vars/all.yml"
  - "{{searchpath}}/inventory/inventory.cfg"
  - "{{searchpath}}/inventory/kargo_default_ubuntu.yaml"
  - "{{searchpath}}/inventory/kargo_default_debian.yaml"
  - "{{searchpath}}/inventory/kargo_default_common.yaml"

**********
DECISION===>: PASS
**********
=========================:::399:::END!!!=========================
=========================:::400:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/fuel-ccp-installer/utils/kargo/roles/e2e_conformance/tasks/main.yml
**********
- name: Install e2e conformance test script
  template:
    src: run_e2e_conformance.j2
    dest: "/usr/local/bin/run_e2e_conformance"
    mode: 0755

- name: Run e2e conformance test
  shell: "/usr/local/bin/run_e2e_conformance"
  changed_when: false

**********
DECISION===>: PASS
**********
=========================:::400:::END!!!=========================
=========================:::401:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/fuel-ccp-installer/utils/kargo/roles/e2e_conformance/defaults/main.yml
**********
e2e_conformance_image_repo: mirantis/k8s-conformance
e2e_conformance_image_tag: latest

**********
DECISION===>: PASS
**********
=========================:::401:::END!!!=========================
=========================:::402:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/fuel-ccp-installer/utils/kargo/roles/preinstall/tasks/process_certificates.yml
**********
---
- name: Create temp cert files
  local_action: copy content={{ item.pem }} dest=/tmp/{{ item.name }} mode="0400"
  become: false
  run_once: true
  with_items: "{{ certificates|default([]) }}"

- name: Determine selfsigned certs
  local_action: shell echo /tmp/"{{ item.name }}" ;
    [ "$(openssl x509 -noout -subject -in /tmp/{{ item.name }}|awk '{print $2}')" = "$(openssl x509 -noout -issuer -in /tmp/{{ item.name }}|awk '{print $2}')" ]
  become: false
  run_once: true
  register: certscheck
  ignore_errors: yes
  with_items: "{{ certificates|default([]) }}"

- name: Get self signed certs
  local_action: slurp src={{ item.stdout }}
  become: false
  run_once: true
  register: self_signed_certs
  when: item.rc == 0
  with_items: "{{ certscheck.results }}"

- name: Remove temp cert files
  local_action: file dest=/tmp/{{ item.name }} state=absent
  become: false
  run_once: true
  with_items: "{{ certificates|default([]) }}"

- name: Mark self signed certs as trusted for nodes
  copy:
    content: "{{ item.content|b64decode }}"
    dest: "/usr/local/share/ca-certificates/{{ item.source|basename }}"
    force: yes
    mode: "0600"
    owner: "root"
  notify: Preinstall | update certs
  become: true
  with_items: "{{ self_signed_certs.results }}"

**********
DECISION===>: PASS
**********
=========================:::402:::END!!!=========================
=========================:::403:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/fuel-ccp-installer/utils/kargo/roles/preinstall/tasks/main.yml
**********
---
- name: Ensure required ansible version
  assert:
    that: ansible_version.major == 2 and ansible_version.minor >= 1
  run_once: true

- name: "Wait for all hosts"
  local_action: wait_for host={{ ansible_host | default(access_ip | default(ip)) }} port=22 state=started timeout=30
  become: false

# bug from bugs.debian.org/843783
- name: "Install latest pyopenssl as workaround"
  raw: pip install -U pyopenssl netaddr

- name: Gather facts
  setup:

- name: Gather local SSH pubkeys
  local_action: shell ssh-add -L
  become: false
  register: ssh_pubkeys
  changed_when: false
  failed_when: false

- name: Add SSH pubkey to authorized_keys
  authorized_key:
    user: "{{ ansible_ssh_user }}"
    key: "{{ item }}"
    state: present
  with_items: "{{ ssh_pubkeys.stdout_lines }}"
  when: ssh_pubkeys.rc == 0

- include: process_certificates.yml
  when: trust_self_signed_certs|bool

- name: Set correct /etc/hosts entry
  register: updated_etc_hosts
  lineinfile:
    dest: /etc/hosts
    regexp: "^(127.0.1.1|{{ ip }})\t.*"
    line: "{{ ip }} {{ inventory_hostname }}"
    insertafter: "^127.0.0.1 localhost"
    state: present

- name: Set atop interval
  copy:
    dest: /etc/default/atop
    content: "INTERVAL={{ atop_interval }}"
    mode: 0755
    owner: root
    group: root

- name: Ensure required packages are installed
  apt:
    name: "{{ item }}"
    state: latest
  when: ansible_os_family == "Debian"
  with_items:
   - atop
   - dnsutils
   - ntp
   - netcat
   - dbus

- name: Set hostname
  hostname:
    name: "{{ inventory_hostname }}"

# FIXME(mattymo): Opts are set too late (https://github.com/kubespray/kargo/issues/487)
- name: Set Docker options early
  template:
    src: docker.j2
    dest: /etc/default/docker
    owner: root
    group: root
    mode: 0644

**********
DECISION===>: PASS
**********
=========================:::403:::END!!!=========================
=========================:::404:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/fuel-ccp-installer/utils/kargo/roles/preinstall/defaults/main.yml
**********
# Istall discovered self signed certificates
trust_self_signed_certs: false
atop_interval: 60

# Certificates to be preinstalled for cluster nodes, if trusted
# NOTE: indentation is crucial!
#certificates:
#  - name: foo
#    pem: |
#      -----BEGIN CERTIFICATE-----
#      ... skipped ...
#      -----END CERTIFICATE-----
#  - name: bar
#    pem...

**********
DECISION===>: PASS
**********
=========================:::404:::END!!!=========================
=========================:::405:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/fuel-ccp-installer/utils/kargo/roles/preinstall/handlers/main.yml
**********
---
- name: Preinstall | update certs
  command: update-ca-certificates
  become: true

**********
DECISION===>: PASS
**********
=========================:::405:::END!!!=========================
=========================:::406:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/fuel-ccp-installer/utils/kargo/roles/externalip/tasks/main.yml
**********
---
- name: ExtIP Controller | Get pods
  shell: "kubectl get pods -o wide"
  run_once: true
  register: pods
  delegate_to: "{{groups['kube-master'][0]}}"

- name: ExtIP Controller | Get list of nodes with labels
  shell: "kubectl get node --show-labels"
  run_once: true
  register: k8s_nodes
  delegate_to: "{{groups['kube-master'][0]}}"

- name: ExtIP Controller | Get list of nodes with IPs
  shell: 'kubectl get nodes -o jsonpath=''{range .items[*]}{@.metadata.name}{" "}{range @.status.addresses[?(@.type == "InternalIP")]}{@.address}{"\n"}{end}{end}'''
  register: k8s_name_cmd
  run_once: true
  delegate_to: "{{groups['kube-master'][0]}}"

- name: ExtIP Controller | Set fact with node-ip search pattern
  set_fact:
    k8s_ip_pattern: ".* {{ ip }}$"

- name: ExtIP Controller | Find k8s node name by IP address
  set_fact:
    k8s_name: "{{ (k8s_name_cmd.stdout_lines | select('match', k8s_ip_pattern) | join(',')).split(' ')[0] }}"

- name: ExtIP Controller | Print k8s node names
  debug:
    msg: "{{ k8s_name }}"

- name: ExtIP Controller | Set fact with node-label search pattern
  set_fact:
    k8s_label_pattern: "^{{ k8s_name }} .*[,\ ]{{ extip_node_label }}=true.*"

- name: ExtIP Controller | Find matches for node by label
  set_fact:
    matches: "{{ k8s_nodes.stdout_lines | select('match', k8s_label_pattern) | list }}"

- name: ExtIP Controller | Label node if needed
  shell: "kubectl label nodes {{ k8s_name }} {{ extip_node_label }}=true"
  when: "{{ (matches | length) < 1 }}"
  delegate_to: "{{groups['kube-master'][0]}}"

- name: ExtIP Controller | Upload claimcontroller config
  run_once: true
  template: src=controller.yaml.j2 dest=/etc/kubernetes/extip_controller.yml
  delegate_to: "{{groups['kube-master'][0]}}"

- name: ExtIP Controller | Upload claimscheduler config
  run_once: true
  template: src=scheduler.yaml.j2 dest=/etc/kubernetes/extip_scheduler.yml
  delegate_to: "{{groups['kube-master'][0]}}"

- name: ExtIP Controller | Create claimcontroller
  run_once: true
  shell: "kubectl create -f /etc/kubernetes/extip_controller.yml"
  when: pods.stdout.find("{{ extip_ctrl_app }}-") == -1
  delegate_to: "{{groups['kube-master'][0]}}"

- name: ExtIP Controller | Create claimscheduler
  run_once: true
  shell: "kubectl create -f /etc/kubernetes/extip_scheduler.yml"
  when: pods.stdout.find("{{ extip_sched_app }}-") == -1
  delegate_to: "{{groups['kube-master'][0]}}"

**********
DECISION===>: PASS
**********
=========================:::406:::END!!!=========================
=========================:::407:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/fuel-ccp-installer/utils/kargo/roles/externalip/defaults/main.yml
**********
---
# All nodes will be labeled and then label will be used as "nodeSelector" for
# external IP controller application. You can spacify this label name here.
extip_node_label: "externalip"

# Image params
extip_image_repo: "mirantis/k8s-externalipcontroller"
extip_image_tag: "release-0.2.1"

# If multiple external IPs claim controllers are running we need to
# define how to distribute IPs.
# Valid values are:
#   "balance" - IPs are balanced across controllers
#   "single" - only one controller will hold all IPs. Not yet supported in
#              multiple controllers mode. If you need to run on one node please
#              use extip_ctrl_app_kind=Deployment and extip_ctrl_replicas=1
#   "all" - all controllers will bring up all IPs (for ECMP, for example)
extip_distribution: "balance"

# External IPs network mask
extip_mask: 24

# Interface to bring external IPs on
extip_iface: "eth0"

# Kubernetes namespace for the application
k8s_namespace: "default"

#####
# K8s controller app params
extip_ctrl_app: "claimcontroller"
# App kind, valid values are: "Deployment", "DaemonSet"
extip_ctrl_app_kind: "Deployment"
extip_ctrl_replicas: 1
extip_ctrl_label: "externalipcontroller"
extip_ctrl_image_pull_policy: "IfNotPresent"
# Verbosity
extip_ctrl_verbose: 5
# Heartbeat
extip_ctrl_hb: "500ms"
extip_ctrl_hostname: "{{ ansible_hostname }}"

#####
# K8s scheduler app params
extip_sched_app: "claimscheduler"
extip_sched_label: "claimscheduler"
extip_sched_image_pull_policy: "IfNotPresent"
extip_sched_replicas: 2
# Verbosity
extip_sched_verbose: 5
# Scheduler leader elect, string ("true" or "false")
extip_sched_leader_elect: "true"
# Monitor
extip_sched_monitor: "1s"

**********
DECISION===>: PASS
**********
=========================:::407:::END!!!=========================
=========================:::408:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ironic-lib/playbooks/legacy/ironic-lib-tempest-wholedisk-pxe_ipmitool/run.yaml
**********
- hosts: all
  name: Autoconverted job legacy-tempest-dsvm-ironic-lib-wholedisk-pxe_ipmitool from
    old job gate-tempest-dsvm-ironic-lib-wholedisk-pxe_ipmitool-ubuntu-xenial
  tasks:

    - name: Ensure legacy workspace directory
      file:
        path: '{{ ansible_user_dir }}/workspace'
        state: directory

    - shell:
        cmd: |
          set -e
          set -x
          cat > clonemap.yaml << EOF
          clonemap:
            - name: openstack-infra/devstack-gate
              dest: devstack-gate
          EOF
          /usr/zuul-env/bin/zuul-cloner -m clonemap.yaml --cache-dir /opt/git \
              git://git.openstack.org \
              openstack-infra/devstack-gate
        executable: /bin/bash
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

    - shell:
        cmd: |
          cat << 'EOF' >> ironic-extra-vars
            export DEVSTACK_LOCAL_CONFIG+=$'\n'"IRONIC_VM_SPECS_RAM=384"
            export DEVSTACK_LOCAL_CONFIG+=$'\n'"IRONIC_RAMDISK_TYPE=tinyipa"
          EOF
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

    - shell:
        cmd: |
          cat << 'EOF' >> ironic-extra-vars
            export DEVSTACK_GATE_TEMPEST_REGEX="ironic_tempest_plugin.tests.scenario"
          EOF
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

    - shell:
        cmd: |
          cat << 'EOF' >> ironic-extra-vars
            export DEVSTACK_PROJECT_FROM_GIT="ironic-lib,$DEVSTACK_PROJECT_FROM_GIT"
          EOF
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

    - shell:
        cmd: |
          cat << 'EOF' >> ironic-vars-early
            # use tempest plugin
            export DEVSTACK_LOCAL_CONFIG+=$'\n'"TEMPEST_PLUGINS+=' /opt/stack/new/ironic-tempest-plugin'"
            export TEMPEST_CONCURRENCY=1
          EOF
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

    - shell:
        cmd: |
          set -e
          set -x
          export PROJECTS="openstack/ironic $PROJECTS"
          export PROJECTS="openstack/ironic-lib $PROJECTS"
          export PROJECTS="openstack/ironic-python-agent $PROJECTS"
          export PROJECTS="openstack/ironic-tempest-plugin $PROJECTS"
          export PROJECTS="openstack/python-ironicclient $PROJECTS"
          export PROJECTS="openstack/pyghmi $PROJECTS"
          export PROJECTS="openstack/virtualbmc $PROJECTS"
          export PYTHONUNBUFFERED=true
          export DEVSTACK_GATE_TEMPEST=1
          export DEVSTACK_GATE_IRONIC=1
          export DEVSTACK_GATE_NEUTRON=1
          export DEVSTACK_GATE_VIRT_DRIVER=ironic
          export DEVSTACK_GATE_CONFIGDRIVE=1
          export DEVSTACK_GATE_IRONIC_DRIVER=ipmi
          export BRANCH_OVERRIDE=default
          if [ "$BRANCH_OVERRIDE" != "default" ] ; then
              export OVERRIDE_ZUUL_BRANCH=$BRANCH_OVERRIDE
          fi
          if [[ ! "stable/newton stable/ocata stable/pike" =~ $ZUUL_BRANCH ]] ; then
              export DEVSTACK_GATE_TLSPROXY=1
          fi
          export DEVSTACK_LOCAL_CONFIG+=$'\n'"IRONIC_TEMPEST_WHOLE_DISK_IMAGE=True"
          export DEVSTACK_LOCAL_CONFIG+=$'\n'"IRONIC_VM_EPHEMERAL_DISK=0"
          export DEVSTACK_GATE_IRONIC_BUILD_RAMDISK=1
          export DEVSTACK_LOCAL_CONFIG+=$'\n'"IRONIC_INSPECTOR_BUILD_RAMDISK=True"
          export DEVSTACK_LOCAL_CONFIG+=$'\n'"USE_SUBNETPOOL=False"
          export DEVSTACK_LOCAL_CONFIG+=$'\n'"IRONIC_VM_COUNT=1"
          # Ensure the ironic-vars-EARLY file exists
          touch ironic-vars-early
          # Pull in the EARLY variables injected by the optional builders
          source ironic-vars-early
          export DEVSTACK_LOCAL_CONFIG+=$'\n'"enable_plugin ironic git://git.openstack.org/openstack/ironic"
          # Ensure the ironic-EXTRA-vars file exists
          touch ironic-extra-vars
          # Pull in the EXTRA variables injected by the optional builders
          source ironic-extra-vars
          cp devstack-gate/devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh
          ./safe-devstack-vm-gate-wrap.sh
        executable: /bin/bash
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

**********
DECISION===>: PASS
**********
=========================:::408:::END!!!=========================
=========================:::409:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ironic-lib/playbooks/legacy/ironic-lib-tempest-wholedisk-pxe_ipmitool/post.yaml
**********
- hosts: primary
  tasks:

    - name: Copy files from {{ ansible_user_dir }}/workspace/ on node
      synchronize:
        src: '{{ ansible_user_dir }}/workspace/'
        dest: '{{ zuul.executor.log_root }}'
        mode: pull
        copy_links: true
        verify_host: true
        rsync_opts:
          - --include=/logs/**
          - --include=*/
          - --exclude=*
          - --prune-empty-dirs
**********
DECISION===>: PASS
**********
=========================:::409:::END!!!=========================
=========================:::410:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ironic-lib/playbooks/legacy/ironic-lib-tempest-wholedisk-agent_ipmitool/run.yaml
**********
- hosts: all
  name: Autoconverted job legacy-tempest-dsvm-ironic-lib-wholedisk-agent_ipmitool
    from old job gate-tempest-dsvm-ironic-lib-wholedisk-agent_ipmitool-ubuntu-xenial
  tasks:

    - name: Ensure legacy workspace directory
      file:
        path: '{{ ansible_user_dir }}/workspace'
        state: directory

    - shell:
        cmd: |
          set -e
          set -x
          cat > clonemap.yaml << EOF
          clonemap:
            - name: openstack-infra/devstack-gate
              dest: devstack-gate
          EOF
          /usr/zuul-env/bin/zuul-cloner -m clonemap.yaml --cache-dir /opt/git \
              git://git.openstack.org \
              openstack-infra/devstack-gate
        executable: /bin/bash
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

    - shell:
        cmd: |
          cat << 'EOF' >> ironic-extra-vars
            export DEVSTACK_LOCAL_CONFIG+=$'\n'"IRONIC_VM_SPECS_RAM=384"
            export DEVSTACK_LOCAL_CONFIG+=$'\n'"IRONIC_RAMDISK_TYPE=tinyipa"
          EOF
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

    - shell:
        cmd: |
          cat << 'EOF' >> ironic-extra-vars
            export DEVSTACK_GATE_TEMPEST_REGEX="ironic_tempest_plugin.tests.scenario"
          EOF
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

    - shell:
        cmd: |
          cat << 'EOF' >> ironic-extra-vars
            export DEVSTACK_PROJECT_FROM_GIT="ironic-lib,$DEVSTACK_PROJECT_FROM_GIT"
          EOF
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

    - shell:
        cmd: |
          cat << 'EOF' >> ironic-vars-early
            # use tempest plugin
            export DEVSTACK_LOCAL_CONFIG+=$'\n'"TEMPEST_PLUGINS+=' /opt/stack/new/ironic-tempest-plugin'"
            export TEMPEST_CONCURRENCY=1
          EOF
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

    - shell:
        cmd: |
          set -e
          set -x
          export PROJECTS="openstack/ironic $PROJECTS"
          export PROJECTS="openstack/ironic-lib $PROJECTS"
          export PROJECTS="openstack/ironic-python-agent $PROJECTS"
          export PROJECTS="openstack/ironic-tempest-plugin $PROJECTS"
          export PROJECTS="openstack/python-ironicclient $PROJECTS"
          export PROJECTS="openstack/pyghmi $PROJECTS"
          export PROJECTS="openstack/virtualbmc $PROJECTS"
          export PYTHONUNBUFFERED=true
          export DEVSTACK_GATE_TEMPEST=1
          export DEVSTACK_GATE_IRONIC=1
          export DEVSTACK_GATE_NEUTRON=1
          export DEVSTACK_GATE_VIRT_DRIVER=ironic
          export DEVSTACK_GATE_CONFIGDRIVE=1
          export DEVSTACK_GATE_IRONIC_DRIVER=ipmi
          export DEVSTACK_LOCAL_CONFIG+=$'\n'"IRONIC_DEFAULT_DEPLOY_INTERFACE=direct"
          # direct deploy requires Swift temporary URLs
          export DEVSTACK_LOCAL_CONFIG+=$'\n'"SWIFT_ENABLE_TEMPURLS=True"
          export DEVSTACK_LOCAL_CONFIG+=$'\n'"SWIFT_TEMPURL_KEY=secretkey"

          export BRANCH_OVERRIDE=default
          if [ "$BRANCH_OVERRIDE" != "default" ] ; then
              export OVERRIDE_ZUUL_BRANCH=$BRANCH_OVERRIDE
          fi
          if [[ ! "stable/newton stable/ocata stable/pike" =~ $ZUUL_BRANCH ]] ; then
              export DEVSTACK_GATE_TLSPROXY=1
          fi
          export DEVSTACK_LOCAL_CONFIG+=$'\n'"IRONIC_TEMPEST_WHOLE_DISK_IMAGE=True"
          export DEVSTACK_LOCAL_CONFIG+=$'\n'"IRONIC_VM_EPHEMERAL_DISK=0"
          export DEVSTACK_GATE_IRONIC_BUILD_RAMDISK=1
          export DEVSTACK_LOCAL_CONFIG+=$'\n'"IRONIC_INSPECTOR_BUILD_RAMDISK=True"
          export DEVSTACK_LOCAL_CONFIG+=$'\n'"USE_SUBNETPOOL=False"
          export DEVSTACK_LOCAL_CONFIG+=$'\n'"IRONIC_VM_COUNT=1"
          # Ensure the ironic-vars-EARLY file exists
          touch ironic-vars-early
          # Pull in the EARLY variables injected by the optional builders
          source ironic-vars-early
          export DEVSTACK_LOCAL_CONFIG+=$'\n'"enable_plugin ironic git://git.openstack.org/openstack/ironic"
          # Ensure the ironic-EXTRA-vars file exists
          touch ironic-extra-vars
          # Pull in the EXTRA variables injected by the optional builders
          source ironic-extra-vars
          cp devstack-gate/devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh
          ./safe-devstack-vm-gate-wrap.sh
        executable: /bin/bash
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

**********
DECISION===>: PASS
**********
=========================:::410:::END!!!=========================
=========================:::411:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ironic-lib/playbooks/legacy/ironic-lib-tempest-wholedisk-agent_ipmitool/post.yaml
**********
- hosts: primary
  tasks:

    - name: Copy files from {{ ansible_user_dir }}/workspace/ on node
      synchronize:
        src: '{{ ansible_user_dir }}/workspace/'
        dest: '{{ zuul.executor.log_root }}'
        mode: pull
        copy_links: true
        verify_host: true
        rsync_opts:
          - --include=/logs/**
          - --include=*/
          - --exclude=*
          - --prune-empty-dirs
**********
DECISION===>: PASS
**********
=========================:::411:::END!!!=========================
=========================:::412:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ironic-lib/playbooks/legacy/ironic-lib-tempest-partition-agent_ipmitool/run.yaml
**********
- hosts: all
  name: Autoconverted job legacy-tempest-dsvm-ironic-lib-partition-agent_ipmitool
    from old job gate-tempest-dsvm-ironic-lib-partition-agent_ipmitool-ubuntu-xenial
  tasks:

    - name: Ensure legacy workspace directory
      file:
        path: '{{ ansible_user_dir }}/workspace'
        state: directory

    - shell:
        cmd: |
          set -e
          set -x
          cat > clonemap.yaml << EOF
          clonemap:
            - name: openstack-infra/devstack-gate
              dest: devstack-gate
          EOF
          /usr/zuul-env/bin/zuul-cloner -m clonemap.yaml --cache-dir /opt/git \
              git://git.openstack.org \
              openstack-infra/devstack-gate
        executable: /bin/bash
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

    - shell:
        cmd: |
          cat << 'EOF' >> ironic-extra-vars
            export DEVSTACK_LOCAL_CONFIG+=$'\n'"IRONIC_VM_SPECS_RAM=384"
            export DEVSTACK_LOCAL_CONFIG+=$'\n'"IRONIC_RAMDISK_TYPE=tinyipa"
          EOF
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

    - shell:
        cmd: |
          cat << 'EOF' >> ironic-extra-vars
            export DEVSTACK_GATE_TEMPEST_REGEX="ironic_tempest_plugin.tests.scenario"
          EOF
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

    - shell:
        cmd: |
          cat << 'EOF' >> ironic-extra-vars
            export DEVSTACK_PROJECT_FROM_GIT="ironic-lib,$DEVSTACK_PROJECT_FROM_GIT"
          EOF
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

    - shell:
        cmd: |
          cat << 'EOF' >> ironic-vars-early
            # use tempest plugin
            export DEVSTACK_LOCAL_CONFIG+=$'\n'"TEMPEST_PLUGINS+=' /opt/stack/new/ironic-tempest-plugin'"
            export TEMPEST_CONCURRENCY=1
          EOF
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

    - shell:
        cmd: |
          set -e
          set -x
          export PROJECTS="openstack/ironic $PROJECTS"
          export PROJECTS="openstack/ironic-lib $PROJECTS"
          export PROJECTS="openstack/ironic-python-agent $PROJECTS"
          export PROJECTS="openstack/ironic-tempest-plugin $PROJECTS"
          export PROJECTS="openstack/python-ironicclient $PROJECTS"
          export PROJECTS="openstack/pyghmi $PROJECTS"
          export PROJECTS="openstack/virtualbmc $PROJECTS"
          export PYTHONUNBUFFERED=true
          export DEVSTACK_GATE_TEMPEST=1
          export DEVSTACK_GATE_IRONIC=1
          export DEVSTACK_GATE_NEUTRON=1
          export DEVSTACK_GATE_VIRT_DRIVER=ironic
          export DEVSTACK_GATE_CONFIGDRIVE=1
          export DEVSTACK_GATE_IRONIC_DRIVER=ipmi
          export DEVSTACK_LOCAL_CONFIG+=$'\n'"IRONIC_DEFAULT_DEPLOY_INTERFACE=direct"
          # direct deploy requires Swift temporary URLs
          export DEVSTACK_LOCAL_CONFIG+=$'\n'"SWIFT_ENABLE_TEMPURLS=True"
          export DEVSTACK_LOCAL_CONFIG+=$'\n'"SWIFT_TEMPURL_KEY=secretkey"

          export BRANCH_OVERRIDE=default
          if [ "$BRANCH_OVERRIDE" != "default" ] ; then
              export OVERRIDE_ZUUL_BRANCH=$BRANCH_OVERRIDE
          fi
          if [[ ! "stable/newton stable/ocata stable/pike" =~ $ZUUL_BRANCH ]] ; then
              export DEVSTACK_GATE_TLSPROXY=1
          fi
          export DEVSTACK_LOCAL_CONFIG+=$'\n'"IRONIC_TEMPEST_WHOLE_DISK_IMAGE=False"
          export DEVSTACK_LOCAL_CONFIG+=$'\n'"IRONIC_VM_EPHEMERAL_DISK=1"
          export DEVSTACK_GATE_IRONIC_BUILD_RAMDISK=1
          export DEVSTACK_LOCAL_CONFIG+=$'\n'"IRONIC_INSPECTOR_BUILD_RAMDISK=True"
          export DEVSTACK_LOCAL_CONFIG+=$'\n'"USE_SUBNETPOOL=False"
          export DEVSTACK_LOCAL_CONFIG+=$'\n'"IRONIC_VM_COUNT=1"
          # Ensure the ironic-vars-EARLY file exists
          touch ironic-vars-early
          # Pull in the EARLY variables injected by the optional builders
          source ironic-vars-early
          export DEVSTACK_LOCAL_CONFIG+=$'\n'"enable_plugin ironic git://git.openstack.org/openstack/ironic"
          # Ensure the ironic-EXTRA-vars file exists
          touch ironic-extra-vars
          # Pull in the EXTRA variables injected by the optional builders
          source ironic-extra-vars
          cp devstack-gate/devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh
          ./safe-devstack-vm-gate-wrap.sh
        executable: /bin/bash
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

**********
DECISION===>: PASS
**********
=========================:::412:::END!!!=========================
=========================:::413:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ironic-lib/playbooks/legacy/ironic-lib-tempest-partition-agent_ipmitool/post.yaml
**********
- hosts: primary
  tasks:

    - name: Copy files from {{ ansible_user_dir }}/workspace/ on node
      synchronize:
        src: '{{ ansible_user_dir }}/workspace/'
        dest: '{{ zuul.executor.log_root }}'
        mode: pull
        copy_links: true
        verify_host: true
        rsync_opts:
          - --include=/logs/**
          - --include=*/
          - --exclude=*
          - --prune-empty-dirs
**********
DECISION===>: PASS
**********
=========================:::413:::END!!!=========================
=========================:::414:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ironic-lib/playbooks/legacy/ironic-lib-tempest-partition-pxe_ipmitool/run.yaml
**********
- hosts: all
  name: Autoconverted job legacy-tempest-dsvm-ironic-lib-partition-pxe_ipmitool from
    old job gate-tempest-dsvm-ironic-lib-partition-pxe_ipmitool-ubuntu-xenial
  tasks:

    - name: Ensure legacy workspace directory
      file:
        path: '{{ ansible_user_dir }}/workspace'
        state: directory

    - shell:
        cmd: |
          set -e
          set -x
          cat > clonemap.yaml << EOF
          clonemap:
            - name: openstack-infra/devstack-gate
              dest: devstack-gate
          EOF
          /usr/zuul-env/bin/zuul-cloner -m clonemap.yaml --cache-dir /opt/git \
              git://git.openstack.org \
              openstack-infra/devstack-gate
        executable: /bin/bash
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

    - shell:
        cmd: |
          cat << 'EOF' >> ironic-extra-vars
            export DEVSTACK_LOCAL_CONFIG+=$'\n'"IRONIC_VM_SPECS_RAM=384"
            export DEVSTACK_LOCAL_CONFIG+=$'\n'"IRONIC_RAMDISK_TYPE=tinyipa"
          EOF
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

    - shell:
        cmd: |
          cat << 'EOF' >> ironic-extra-vars
            export DEVSTACK_GATE_TEMPEST_REGEX="ironic_tempest_plugin.tests.scenario"
          EOF
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

    - shell:
        cmd: |
          cat << 'EOF' >> ironic-extra-vars
            export DEVSTACK_PROJECT_FROM_GIT="ironic-lib,$DEVSTACK_PROJECT_FROM_GIT"
          EOF
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

    - shell:
        cmd: |
          cat << 'EOF' >> ironic-vars-early
            # use tempest plugin
            export DEVSTACK_LOCAL_CONFIG+=$'\n'"TEMPEST_PLUGINS+=' /opt/stack/new/ironic-tempest-plugin'"
            export TEMPEST_CONCURRENCY=1
          EOF
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

    - shell:
        cmd: |
          set -e
          set -x
          export PROJECTS="openstack/ironic $PROJECTS"
          export PROJECTS="openstack/ironic-lib $PROJECTS"
          export PROJECTS="openstack/ironic-python-agent $PROJECTS"
          export PROJECTS="openstack/ironic-tempest-plugin $PROJECTS"
          export PROJECTS="openstack/python-ironicclient $PROJECTS"
          export PROJECTS="openstack/pyghmi $PROJECTS"
          export PROJECTS="openstack/virtualbmc $PROJECTS"
          export PYTHONUNBUFFERED=true
          export DEVSTACK_GATE_TEMPEST=1
          export DEVSTACK_GATE_IRONIC=1
          export DEVSTACK_GATE_NEUTRON=1
          export DEVSTACK_GATE_VIRT_DRIVER=ironic
          export DEVSTACK_GATE_CONFIGDRIVE=1
          export DEVSTACK_GATE_IRONIC_DRIVER=ipmi
          export BRANCH_OVERRIDE=default
          if [ "$BRANCH_OVERRIDE" != "default" ] ; then
              export OVERRIDE_ZUUL_BRANCH=$BRANCH_OVERRIDE
          fi
          if [[ ! "stable/newton stable/ocata stable/pike" =~ $ZUUL_BRANCH ]] ; then
              export DEVSTACK_GATE_TLSPROXY=1
          fi
          export DEVSTACK_LOCAL_CONFIG+=$'\n'"IRONIC_TEMPEST_WHOLE_DISK_IMAGE=False"
          export DEVSTACK_LOCAL_CONFIG+=$'\n'"IRONIC_VM_EPHEMERAL_DISK=1"
          export DEVSTACK_GATE_IRONIC_BUILD_RAMDISK=1
          export DEVSTACK_LOCAL_CONFIG+=$'\n'"IRONIC_INSPECTOR_BUILD_RAMDISK=True"
          export DEVSTACK_LOCAL_CONFIG+=$'\n'"USE_SUBNETPOOL=False"
          export DEVSTACK_LOCAL_CONFIG+=$'\n'"IRONIC_VM_COUNT=1"
          # Ensure the ironic-vars-EARLY file exists
          touch ironic-vars-early
          # Pull in the EARLY variables injected by the optional builders
          source ironic-vars-early
          export DEVSTACK_LOCAL_CONFIG+=$'\n'"enable_plugin ironic git://git.openstack.org/openstack/ironic"
          # Ensure the ironic-EXTRA-vars file exists
          touch ironic-extra-vars
          # Pull in the EXTRA variables injected by the optional builders
          source ironic-extra-vars
          cp devstack-gate/devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh
          ./safe-devstack-vm-gate-wrap.sh
        executable: /bin/bash
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

**********
DECISION===>: PASS
**********
=========================:::414:::END!!!=========================
=========================:::415:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/ironic-lib/playbooks/legacy/ironic-lib-tempest-partition-pxe_ipmitool/post.yaml
**********
- hosts: primary
  tasks:

    - name: Copy files from {{ ansible_user_dir }}/workspace/ on node
      synchronize:
        src: '{{ ansible_user_dir }}/workspace/'
        dest: '{{ zuul.executor.log_root }}'
        mode: pull
        copy_links: true
        verify_host: true
        rsync_opts:
          - --include=/logs/**
          - --include=*/
          - --exclude=*
          - --prune-empty-dirs
**********
DECISION===>: PASS
**********
=========================:::415:::END!!!=========================
=========================:::416:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/monasca-vagrant/roles/monasca-devstack/vars/main.yml
**********
---
rabbitmq_cnf_file: /root/.rabbitmq.cnf
mysql_cnf_file: /root/.my.cnf

**********
DECISION===>: PASS
**********
=========================:::416:::END!!!=========================
=========================:::417:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/monasca-vagrant/roles/monasca-devstack/tasks/agent_mysql.yaml
**********
---
- name: install python-mysqldb package
  apt: name=python-mysqldb state=present

- name: create/update mysql config
  template: dest={{ mysql_cnf_file }} owner=root group=root mode=0600 src=my_cnf.j2
  notify:
    - run monasca-setup


**********
DECISION===>: PASS
**********
=========================:::417:::END!!!=========================
=========================:::418:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/monasca-vagrant/roles/monasca-devstack/tasks/agent_rabbitmq.yaml
**********
---
- name: Agent RabbitMQ Plugin - Activate management plugin
  rabbitmq_plugin: names=rabbitmq_management state=enabled new_only=no

- name: Agent RabbitMQ Plugin - Create/update rabbitmq config
  template: dest={{ rabbitmq_cnf_file }} owner=root group=root mode=0600 src=rabbitmq_cnf.j2
  notify:
    - restart rabbitmq
    - run monasca-setup


**********
DECISION===>: PASS
**********
=========================:::418:::END!!!=========================
=========================:::419:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/monasca-vagrant/roles/monasca-devstack/tasks/main.yml
**********
---
- include: agent_rabbitmq.yaml tags=devstack_rabbitmq
- include: agent_mysql.yaml tags=devstack_mysql

**********
DECISION===>: PASS
**********
=========================:::419:::END!!!=========================
=========================:::420:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/monasca-vagrant/roles/monasca-devstack/defaults/main.yml
**********
---
mysql_user: root
mysql_pass: pass
rmq_user: guest
rmq_pass: pass
rmq_nodes: rabbit@devstack
rmq_queues: conductor
rmq_exchanges: nova,cinder,ceilometer,glance,keystone,neutron,heat,ironic,openstack

**********
DECISION===>: Hardcoded Secret
**********
=========================:::420:::END!!!=========================
=========================:::421:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/monasca-vagrant/roles/monasca-devstack/handlers/main.yml
**********
---
- name: restart rabbitmq
  service: name=rabbitmq-server state=restarted enabled=yes

**********
DECISION===>: PASS
**********
=========================:::421:::END!!!=========================
=========================:::422:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/monasca-vagrant/ds-build/roles/devstack-build/tasks/main.yml
**********
---
- name: Install git
  apt: name=git state=present

- name: Remove apt proxy (populated by default in ubuntu/trusty64)
  file: path=/etc/apt/apt.conf.d/01proxy state=absent

- name: Install local.conf to the unprivileged user's home directory
  copy: src=local.conf dest={{unpriv_home}}/local.conf mode=0755 owner={{unpriv_user}}

- name: Install autostack.sh script
  copy: src=autostack.sh dest={{unpriv_home}}/autostack.sh mode=0755 owner={{unpriv_user}}

- name: Run DevStack installer (may take 30-90 minutes, depending on bandwidth)
  command: "{{unpriv_home}}/autostack.sh {{unpriv_user}}"
  args:
     chdir: "{{unpriv_home}}"
     creates: "{{unpriv_home}}/devstack/stack-screenrc"

- name: Make sure 'localhost' entry exists in /etc/hosts
  lineinfile: dest=/etc/hosts regexp='^127\.0\.0\.1' line='127.0.0.1 devstack localhost' owner=root group=root mode=0644

**********
DECISION===>: PASS
**********
=========================:::422:::END!!!=========================
=========================:::423:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/monasca-vagrant/ds-build/roles/devstack-build/defaults/main.yml
**********
---
unpriv_user: vagrant
unpriv_home: /home/{{unpriv_user}}

**********
DECISION===>: PASS
**********
=========================:::423:::END!!!=========================
=========================:::424:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/networking-ovn/playbooks/legacy/tempest-post-common.yml
**********
#
# Copy OVN SB & NB database files: those files can be handy for debugging issues as the
# ovsdb files are stored as logs.
#

- name: Check whether OVNSB DB was created
  stat:
    path: /opt/stack/data/ovs/ovnsb_db.db
  register: ovnsb_file

- name: Create destination directory to collect OVN database logs
  file: path={{ ansible_user_dir }}/workspace/logs/ovs_dbs state=directory
  when: ovnsb_file.stat.exists

- name: Collect OVN databases
  copy:
    remote_src: true
    src: '/opt/stack/data/ovs/{{ item }}.db'
    dest: '{{ ansible_user_dir }}/workspace/logs/ovs_dbs/{{ item }}.txt'
  with_items:
    - conf
    - ovnnb_db
    - ovnsb_db
  when: ovnsb_file.stat.exists

- name: Copy OVN database logs
  copy:
    remote_src: true
    src: '/opt/stack/new/{{ item }}.log'
    dest: '{{ ansible_user_dir }}/workspace/logs/ovs_dbs/{{ item }}.log.txt'
  with_items:
    - ovsdb-server-nb
    - ovsdb-server-sb
  when: ovnsb_file.stat.exists
  become: true

- name: Compress OVN databases in individual files
  shell: gzip -9 {{ ansible_user_dir }}/workspace/logs/ovs_dbs/*
  when: ovnsb_file.stat.exists

#
# Synchronize files from workspace in node to the zuul log_root which will be stored
#

- name: Copy files from {{ ansible_user_dir }}/workspace/ on node
  synchronize:
    src: '{{ ansible_user_dir }}/workspace/'
    dest: '{{ zuul.executor.log_root }}'
    mode: pull
    copy_links: true
    verify_host: true
    rsync_opts:
      - --include=/logs/**
      - --include=*/
      - --exclude=*
      - --prune-empty-dirs

**********
DECISION===>: PASS
**********
=========================:::424:::END!!!=========================
=========================:::425:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/networking-ovn/playbooks/legacy/networking-ovn-dsvm-functional/run.yaml
**********
- hosts: all
  name: Autoconverted job legacy-networking-ovn-dsvm-functional from old job gate-networking-ovn-dsvm-functional
  tasks:

    - name: Ensure legacy workspace directory
      file:
        path: '{{ ansible_user_dir }}/workspace'
        state: directory

    - shell:
        cmd: |
          set -e
          set -x
          cat > clonemap.yaml << EOF
          clonemap:
            - name: openstack-infra/devstack-gate
              dest: devstack-gate
          EOF
          /usr/zuul-env/bin/zuul-cloner -m clonemap.yaml --cache-dir /opt/git \
              git://git.openstack.org \
              openstack-infra/devstack-gate
        executable: /bin/bash
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

    - shell:
        cmd: |
          set -e
          set -x
          export PYTHONUNBUFFERED=true
          export DEVSTACK_GATE_UNSTACK=1
          export DEVSTACK_GATE_TEMPEST=0
          export DEVSTACK_GATE_EXERCISES=0
          export DEVSTACK_GATE_NEUTRON=1
          export DEVSTACK_GATE_INSTALL_TESTONLY=1
          export BRANCH_OVERRIDE=default
          if [ "$BRANCH_OVERRIDE" != "default" ] ; then
              export OVERRIDE_ZUUL_BRANCH=$BRANCH_OVERRIDE
          fi

          # Because we are testing a non standard project, add
          # our project repository. This makes zuul do the right
          # reference magic for testing changes.
          export PROJECTS="openstack/networking-ovn $PROJECTS"

          function gate_hook {
              bash -xe $BASE/new/networking-ovn/networking_ovn/tests/contrib/gate_hook.sh dsvm-functional
          }
          export -f gate_hook

          function post_test_hook {
             bash -xe $BASE/new/networking-ovn/networking_ovn/tests/contrib/post_test_hook.sh dsvm-functional
          }
          export -f post_test_hook

          cp devstack-gate/devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh
          ./safe-devstack-vm-gate-wrap.sh
        executable: /bin/bash
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

**********
DECISION===>: PASS
**********
=========================:::425:::END!!!=========================
=========================:::426:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/networking-ovn/playbooks/legacy/networking-ovn-dsvm-functional/post.yaml
**********
- hosts: primary
  tasks:

    - name: Copy files from {{ ansible_user_dir }}/workspace/ on node
      synchronize:
        src: '{{ ansible_user_dir }}/workspace/'
        dest: '{{ zuul.executor.log_root }}'
        mode: pull
        copy_links: true
        verify_host: true
        rsync_opts:
          - --include=/logs/**
          - --include=*/
          - --exclude=*
          - --prune-empty-dirs

**********
DECISION===>: PASS
**********
=========================:::426:::END!!!=========================
=========================:::427:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/networking-ovn/playbooks/legacy/networking-ovn-dsvm-functional-py35/run.yaml
**********
- hosts: all
  name: Autoconverted job legacy-networking-ovn-dsvm-functional-py35 from old job
    gate-networking-ovn-dsvm-functional-py35
  tasks:

    - name: Ensure legacy workspace directory
      file:
        path: '{{ ansible_user_dir }}/workspace'
        state: directory

    - shell:
        cmd: |
          set -e
          set -x
          cat > clonemap.yaml << EOF
          clonemap:
            - name: openstack-infra/devstack-gate
              dest: devstack-gate
          EOF
          /usr/zuul-env/bin/zuul-cloner -m clonemap.yaml --cache-dir /opt/git \
              git://git.openstack.org \
              openstack-infra/devstack-gate
        executable: /bin/bash
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

    - shell:
        cmd: |
          set -e
          set -x
          export PYTHONUNBUFFERED=true
          export DEVSTACK_GATE_UNSTACK=1
          export DEVSTACK_GATE_TEMPEST=0
          export DEVSTACK_GATE_EXERCISES=0
          export DEVSTACK_GATE_NEUTRON=1
          export DEVSTACK_GATE_INSTALL_TESTONLY=1
          export BRANCH_OVERRIDE=default
          if [ "$BRANCH_OVERRIDE" != "default" ] ; then
              export OVERRIDE_ZUUL_BRANCH=$BRANCH_OVERRIDE
          fi

          # Because we are testing a non standard project, add
          # our project repository. This makes zuul do the right
          # reference magic for testing changes.
          export PROJECTS="openstack/networking-ovn $PROJECTS"

          function gate_hook {
              bash -xe $BASE/new/networking-ovn/networking_ovn/tests/contrib/gate_hook.sh dsvm-functional-py35
          }
          export -f gate_hook

          function post_test_hook {
             bash -xe $BASE/new/networking-ovn/networking_ovn/tests/contrib/post_test_hook.sh dsvm-functional-py35
          }
          export -f post_test_hook

          cp devstack-gate/devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh
          ./safe-devstack-vm-gate-wrap.sh
        executable: /bin/bash
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

**********
DECISION===>: PASS
**********
=========================:::427:::END!!!=========================
=========================:::428:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/networking-ovn/playbooks/legacy/networking-ovn-dsvm-functional-py35/post.yaml
**********
- hosts: primary
  tasks:

    - name: Copy files from {{ ansible_user_dir }}/workspace/ on node
      synchronize:
        src: '{{ ansible_user_dir }}/workspace/'
        dest: '{{ zuul.executor.log_root }}'
        mode: pull
        copy_links: true
        verify_host: true
        rsync_opts:
          - --include=/logs/**
          - --include=*/
          - --exclude=*
          - --prune-empty-dirs

**********
DECISION===>: PASS
**********
=========================:::428:::END!!!=========================
=========================:::429:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/networking-ovn/playbooks/legacy/tempest-dsvm-networking-ovn-multinode/run.yaml
**********
- hosts: primary
  name: Autoconverted job legacy-tempest-dsvm-networking-ovn-multinode from old job
    gate-tempest-dsvm-networking-ovn-multinode-nv
  tasks:

    - name: Ensure legacy workspace directory
      file:
        path: '{{ ansible_user_dir }}/workspace'
        state: directory

    - shell:
        cmd: |
          set -e
          set -x
          cat > clonemap.yaml << EOF
          clonemap:
            - name: openstack-infra/devstack-gate
              dest: devstack-gate
          EOF
          /usr/zuul-env/bin/zuul-cloner -m clonemap.yaml --cache-dir /opt/git \
              git://git.openstack.org \
              openstack-infra/devstack-gate
        executable: /bin/bash
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

    - shell:
        cmd: |
          set -e
          set -x
          cat << 'EOF' >>"/tmp/dg-local.conf"
          [[local|localrc]]
          enable_plugin networking-ovn git://git.openstack.org/openstack/networking-ovn
          enable_plugin neutron-tempest-plugin git://git.openstack.org/openstack/neutron-tempest-plugin

          EOF
        executable: /bin/bash
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

    - shell:
        cmd: |
          set -e
          set -x
          export PYTHONUNBUFFERED=true
          export DEVSTACK_GATE_NEUTRON=1
          export DEVSTACK_GATE_TEMPEST=1
          export DEVSTACK_GATE_TEMPEST_ALL_PLUGINS=1
          export BRANCH_OVERRIDE=default
          if [ "$BRANCH_OVERRIDE" != "default" ] ; then
              export OVERRIDE_ZUUL_BRANCH=$BRANCH_OVERRIDE
          fi
          export DEVSTACK_GATE_TOPOLOGY="multinode"

          # Because we are testing a non standard project, add
          # our project repository. This makes zuul do the right
          # reference magic for testing changes.
          export PROJECTS="openstack/networking-ovn openstack/neutron-tempest-plugin $PROJECTS"

          # Keep localrc to be able to set some vars in pre_test_hook
          export KEEP_LOCALRC=1

          function pre_test_hook {
              if [ -f $BASE/new/networking-ovn/devstack/pre_test_hook.sh ] ; then
                  . $BASE/new/networking-ovn/devstack/pre_test_hook.sh
              fi
          }
          export -f pre_test_hook

          function post_test_hook {
              if [ -f $BASE/new/networking-ovn/devstack/post_test_hook.sh ] ; then
                  . $BASE/new/networking-ovn/devstack/post_test_hook.sh
              fi
          }
          export -f post_test_hook

          export DEVSTACK_GATE_SETTINGS=/opt/stack/new/networking-ovn/devstack/devstackgaterc

          cp devstack-gate/devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh
          ./safe-devstack-vm-gate-wrap.sh
        executable: /bin/bash
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

**********
DECISION===>: PASS
**********
=========================:::429:::END!!!=========================
=========================:::430:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/networking-ovn/playbooks/legacy/tempest-dsvm-networking-ovn-multinode/post.yaml
**********
- hosts: primary
  tasks:

    - include: ../tempest-post-common.yml

**********
DECISION===>: PASS
**********
=========================:::430:::END!!!=========================
=========================:::431:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/networking-ovn/playbooks/legacy/grenade-dsvm-networking-ovn/run.yaml
**********
- hosts: all
  name: Autoconverted job legacy-grenade-dsvm-networking-ovn from old job gate-grenade-dsvm-networking-ovn-ubuntu-xenial-nv
  tasks:

    - name: Ensure legacy workspace directory
      file:
        path: '{{ ansible_user_dir }}/workspace'
        state: directory

    - shell:
        cmd: |
          set -e
          set -x
          cat > clonemap.yaml << EOF
          clonemap:
            - name: openstack-infra/devstack-gate
              dest: devstack-gate
          EOF
          /usr/zuul-env/bin/zuul-cloner -m clonemap.yaml --cache-dir /opt/git \
              git://git.openstack.org \
              openstack-infra/devstack-gate
        executable: /bin/bash
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

    - shell:
        cmd: |
          set -e
          set -x
          cat << 'EOF' >>"/tmp/dg-local.conf"
          [[local|localrc]]
          enable_plugin neutron-tempest-plugin git://git.openstack.org/openstack/neutron-tempest-plugin

          EOF
        executable: /bin/bash
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

    - shell:
        cmd: |
          set -e
          set -x
          export PYTHONUNBUFFERED=true
          # Because we are testing a non standard project, add
          # our project repository. This makes zuul do the right
          # reference magic for testing changes.
          export PROJECTS="openstack/networking-ovn openstack/neutron-tempest-plugin openstack-dev/grenade $PROJECTS"

          export GRENADE_PLUGINRC="enable_grenade_plugin networking-ovn https://git.openstack.org/openstack/networking-ovn"
          export DEVSTACK_GATE_GRENADE=pullup

          export DEVSTACK_GATE_NEUTRON=1
          export DEVSTACK_GATE_TEMPEST=1
          export DEVSTACK_GATE_TEMPEST_ALL_PLUGINS=1

          export BRANCH_OVERRIDE=default
          if [ "$BRANCH_OVERRIDE" != "default" ] ; then
              export OVERRIDE_ZUUL_BRANCH=$BRANCH_OVERRIDE
          fi
          # Keep localrc to be able to set some vars in pre_test_hook
          export KEEP_LOCALRC=1

          function pre_test_hook {
              if [ -f $BASE/new/networking-ovn/devstack/pre_test_hook.sh ] ; then
                  . $BASE/new/networking-ovn/devstack/pre_test_hook.sh
              fi
          }
          export -f pre_test_hook

          function post_test_hook {
              if [ -f $BASE/new/networking-ovn/devstack/post_test_hook.sh ] ; then
                  . $BASE/new/networking-ovn/devstack/post_test_hook.sh
              fi
          }
          export -f post_test_hook

          export DEVSTACK_GATE_SETTINGS=/opt/stack/new/networking-ovn/devstack/devstackgaterc
          cp devstack-gate/devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh
          ./safe-devstack-vm-gate-wrap.sh
        executable: /bin/bash
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

**********
DECISION===>: PASS
**********
=========================:::431:::END!!!=========================
=========================:::432:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/networking-ovn/playbooks/legacy/grenade-dsvm-networking-ovn/post.yaml
**********
- hosts: primary
  tasks:

    - name: Copy files from {{ ansible_user_dir }}/workspace/ on node
      synchronize:
        src: '{{ ansible_user_dir }}/workspace/'
        dest: '{{ zuul.executor.log_root }}'
        mode: pull
        copy_links: true
        verify_host: true
        rsync_opts:
          - --include=/logs/**
          - --include=*/
          - --exclude=*
          - --prune-empty-dirs

**********
DECISION===>: PASS
**********
=========================:::432:::END!!!=========================
=========================:::433:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/networking-ovn/playbooks/legacy/tempest-dsvm-networking-ovn-ovs-release-ovsdbapp-src/run.yaml
**********
- hosts: all
  name: Autoconverted job legacy-tempest-dsvm-networking-ovn-ovs-release-ovsdbapp-src
    from old job gate-tempest-dsvm-networking-ovn-ovs-release-ovsdbapp-src-nv
  tasks:

    - name: Ensure legacy workspace directory
      file:
        path: '{{ ansible_user_dir }}/workspace'
        state: directory

    - shell:
        cmd: |
          set -e
          set -x
          cat > clonemap.yaml << EOF
          clonemap:
            - name: openstack-infra/devstack-gate
              dest: devstack-gate
          EOF
          /usr/zuul-env/bin/zuul-cloner -m clonemap.yaml --cache-dir /opt/git \
              git://git.openstack.org \
              openstack-infra/devstack-gate
        executable: /bin/bash
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

    - shell:
        cmd: |
          set -e
          set -x
          cat << 'EOF' >>"/tmp/dg-local.conf"
          [[local|localrc]]
          enable_plugin networking-ovn git://git.openstack.org/openstack/networking-ovn
          LIBS_FROM_GIT="ovsdbapp"
          OVN_DBS_LOG_LEVEL="dbg"

          EOF
        executable: /bin/bash
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

    - shell:
        cmd: |
          set -e
          set -x
          export PYTHONUNBUFFERED=true
          export DEVSTACK_GATE_NEUTRON=1
          export DEVSTACK_GATE_TEMPEST=1
          export BRANCH_OVERRIDE=default
          if [ "$BRANCH_OVERRIDE" != "default" ] ; then
              export OVERRIDE_ZUUL_BRANCH=$BRANCH_OVERRIDE
          fi
          # Because we are testing a non standard project, add
          # our project repository. This makes zuul do the right
          # reference magic for testing changes.
          export PROJECTS="openstack/networking-ovn $PROJECTS"
          export PROJECTS="openstack/ovsdbapp $PROJECTS"

          # Keep localrc to be able to set some vars in pre_test_hook
          export KEEP_LOCALRC=1

          function pre_test_hook {
              if [ -f $BASE/new/networking-ovn/devstack/pre_test_hook.sh ] ; then
                  . $BASE/new/networking-ovn/devstack/pre_test_hook.sh
              fi
          }
          export -f pre_test_hook

          function post_test_hook {
              if [ -f $BASE/new/networking-ovn/devstack/post_test_hook.sh ] ; then
                  . $BASE/new/networking-ovn/devstack/post_test_hook.sh
              fi
          }
          export -f post_test_hook

          export DEVSTACK_GATE_SETTINGS="/opt/stack/new/networking-ovn/devstack/devstackgaterc latest-release"

          cp devstack-gate/devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh
          ./safe-devstack-vm-gate-wrap.sh
        executable: /bin/bash
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

**********
DECISION===>: PASS
**********
=========================:::433:::END!!!=========================
=========================:::434:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/networking-ovn/playbooks/legacy/tempest-dsvm-networking-ovn-ovs-release-ovsdbapp-src/post.yaml
**********
- hosts: primary
  tasks:

    - include: ../tempest-post-common.yml

**********
DECISION===>: PASS
**********
=========================:::434:::END!!!=========================
=========================:::435:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/networking-ovn/migration/infrared/tripleo-ovn-migration/roles/prepare-migration/tasks/main.yml
**********
- name: Copy overcloud deploy script to overcloud-deploy-ovn.sh
  block:
      - name: Check if overcloud_deploy.sh is present or not
        stat:
            path: ~/overcloud_deploy.sh
        register: deploy_file

      - name: Set the ml2ovs overcloud deploy script file name
        set_fact:
            overcloud_deploy_script: '~/overcloud_deploy.sh'
        when: deploy_file.stat.exists|bool

      - name: Check if overcloud-deploy.sh is present
        stat:
            path: ~/overcloud-deploy.sh
        register: deploy_file_2
        when: not deploy_file.stat.exists|bool

      - name: Set the ml2ovs overcloud deploy script file name
        set_fact:
            overcloud_deploy_script: '~/overcloud-deploy.sh'
        when:
            - not deploy_file.stat.exists|bool
            - deploy_file_2.stat.exists|bool

      - name: Copy overcloud deploy script to overcloud-deploy-ovn.sh
        shell:
            cp -f {{ overcloud_deploy_script }}  ~/overcloud-deploy-ovn.sh
        when: infrared_deployment|bool

- name: set overcloud deploy ovn script
  set_fact:
      overcloud_deploy_ovn_script: '~/overcloud-deploy-ovn.sh'

- name: Set docker images environment file
  set_fact:
      output_env_file: /home/stack/docker-images-ovn.yaml

- name: Get the proper neutron-ovn-ha.yaml path
  stat:
      path: /usr/share/openstack-tripleo-heat-templates/environments/services/neutron-ovn-ha.yaml
  register: ovn_env_path

- name: Set the neutron-ovn-dvr-ha.yaml file path if dvr
  set_fact:
      neutron_ovn_env_path: /usr/share/openstack-tripleo-heat-templates/environments/services/neutron-ovn-dvr-ha.yaml
  when: is_dvr|bool

- name: Set the neutron-ovn-ha.yaml file path if not dvr
  set_fact:
      neutron_ovn_env_path: /usr/share/openstack-tripleo-heat-templates/environments/services/neutron-ovn-ha.yaml
  when: not is_dvr|bool

- name: Construct overcloud-deploy-ovn.sh script for infrared deployments
  lineinfile:
      dest: "{{ overcloud_deploy_ovn_script }}"
      line: "{{ item }} \\"
      insertbefore: "^--log-file.*"
  with_items:
      - "-e {{ neutron_ovn_env_path }}"
      - "-e /home/stack/ovn-extras.yaml"
      - "-e {{ output_env_file }}"
  when:
      - infrared_deployment|bool

- name: Construct overcloud-deploy-ovn.sh script for tripleo deployments
  template:
      src: templates/overcloud-deploy-ovn.sh.j2
      dest: ~/overcloud-deploy-ovn.sh
      mode: 0744
  when:
      - not infrared_deployment|bool

- name: Set image tag (infrared deployment)
  block:
      - name: Get puddle version
        shell: cat containers-prepare-parameter.yaml | grep -v _tag | grep tag | awk '{print $2}'
        ignore_error: True
        register: core_puddle_version

      - name: Set image tag from puddle version
        set_fact:
            docker_image_tag: "{{ core_puddle_version.stdout }}"

      - name: Get registry namespace
        shell: cat containers-prepare-parameter.yaml | grep -v _namespace | grep namespace | awk '{print $2}'
        ignore_error: True
        register: reg_ns

      - name: Set registry namespace
        set_fact:
            reg_namespace: "{{ reg_ns.stdout }}"

      - debug:
          msg: "{{ core_puddle_version.stdout }}"

      - debug:
          msg: "{{ docker_image_tag }}"

      - debug:
          msg: "{{ reg_namespace }}"
  when: infrared_deployment|bool

- name: Set image tag (tripleo deployment)
  set_fact:
      docker_image_tag: "{{ image_tag }}"
  when:
      - not infrared_deployment|bool


- name: Generate ovn container images
  shell: |
      echo "container_images:" > ~/ovn_container_images.yaml

- name: Add ovn container images to ovn_container_images.yaml
  lineinfile:
      dest: ~/ovn_container_images.yaml
      line: "- imagename: {{ reg_namespace }}/{{ image_prefix }}-{{ item }}:{{ docker_image_tag }}"
  with_items:
      - "ovn-northd"
      - "ovn-controller"
      - "neutron-server-ovn"
      - "neutron-metadata-agent-ovn"

- name: Generate docker images environment file
  shell: |
      echo "parameter_defaults:" > ~/docker-images-ovn.yaml

- name: Set the local namespace
  block:
     - name: Extract the local namespace
       shell: |
           set -exo pipefail
           source ~/stackrc
           openstack overcloud plan export overcloud
           mkdir -p /tmp/oc_plan
           mv overcloud.tar.gz /tmp/oc_plan/
           cd /tmp/oc_plan
           tar xvf overcloud.tar.gz
           reg=`cat /tmp/oc_plan/environments/containers-default-parameters.yaml  | grep DockerNeutronApiImage | awk '{ split($2, image , "/"); print image[1] }'`
           namespace=`cat /tmp/oc_plan/environments/containers-default-parameters.yaml  | grep DockerNeutronApiImage | awk '{ split($2, image , "/"); print image[2] }'`
           echo $reg/$namespace > /tmp/_reg_namespace
           rm -rf /tmp/oc_plan

     - name: Get the local namespace
       shell: cat /tmp/_reg_namespace
       register: local_ns

     - name: Set the local registry
       set_fact:
           local_registry: "{{ local_ns.stdout }}"
  when:
      - local_namespace == ''

- name: Set the local namespace
  set_fact:
      local_registry: "{{ local_namespace }}"
  when:
      - local_namespace != ''

- name: Add ovn container images to docker images environment file
  lineinfile:
      dest: ~/docker-images-ovn.yaml
      line: "  {{ item.name }}: {{ local_registry }}/{{ image_prefix }}-{{ item.image_name }}:{{ docker_image_tag }}"
  with_items:
      - { name: DockerNeutronApiImage, image_name: neutron-server-ovn}
      - { name: DockerNeutronConfigImage, image_name: neutron-server-ovn}
      - { name: DockerOvnMetadataImage, image_name: neutron-metadata-agent-ovn}
      - { name: DockerOvnControllerImage, image_name: ovn-controller}
      - { name: DockerOvnControllerConfigImage, image_name: ovn-controller}
      - { name: DockerOvnDbsImage, image_name: ovn-northd}
      - { name: DockerOvnDbsConfigImage, image_name: ovn-northd}

- name: Upload the ovn docker images to the local registry
  shell: |
      source ~/stackrc
      openstack overcloud container image upload --verbose --config-file ~/ovn_container_images.yaml

**********
DECISION===>: PASS
**********
=========================:::435:::END!!!=========================
=========================:::436:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/networking-ovn/migration/infrared/tripleo-ovn-migration/roles/prepare-migration/defaults/main.yml
**********
---

infrared_deployment: False
registry_namespace: docker.io/tripleomaster
local_namespace: 192.168.24.1:8787/tripleomaster
image_tag: current-tripleo-rdo
image_prefix: centos-binary-

**********
DECISION===>: PASS
**********
=========================:::436:::END!!!=========================
=========================:::437:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/networking-ovn/migration/infrared/tripleo-ovn-migration/roles/create-resources/tasks/main.yml
**********
- name: Delete temp file directory if present
  file:
    state: absent
    path: "{{ ovn_migration_temp_dir }}"

- name : Create temp file directory if not present
  file:
    state: directory
    path: "{{ ovn_migration_temp_dir }}"

- name: Generate resource creation script
  template:
    src: create-resources.sh.j2
    dest: "{{ ovn_migration_temp_dir }}/create-resources.sh"
    mode: 0744

- name: Creating pre pre migration resources
  shell: >
    set -o pipefail &&
    {{ ovn_migration_temp_dir }}/create-resources.sh 2>&1 >
    {{ ovn_migration_temp_dir }}/create-resources.sh.log

- name: Generate pinger script
  template:
    src: start-pinger.sh.j2
    dest: "{{ ovn_migration_temp_dir }}/start-pinger.sh"
    mode: 0744

- name: Start pinger in background
  shell: >
      nohup {{ ovn_migration_temp_dir }}/start-pinger.sh </dev/null >/dev/null 2>&1 &

**********
DECISION===>: PASS
**********
=========================:::437:::END!!!=========================
=========================:::438:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/networking-ovn/migration/infrared/tripleo-ovn-migration/roles/create-resources/defaults/main.yml
**********
---

public_network_name: "{{ public_network_name }}"
create_resource_script: create-resources.sh.j2
ovn_migration_temp_dir: "{{ ovn_migration_temp_dir }}"
image_name: "{{ image_name }}"
server_user_name: "{{ server_user_name }}"
overcloudrc: "{{ overcloudrc }}"
resource_suffix: pinger

**********
DECISION===>: PASS
**********
=========================:::438:::END!!!=========================
=========================:::439:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/networking-ovn/migration/tripleo_environment/playbooks/ovn-migration.yml
**********
# This is the playbook used by ovn-migration.sh.

#
# Pre migration and validation tasks will make sure that the initial cloud
# is functional, and will create resources which will be checked after
# migration.
#

- name: Pre migration and validation tasks
  hosts: localhost
  roles:
    - pre-migration
  tags:
    - pre-migration

#
# This step is executed before migration, and will backup some config
# files related to containers before those get lost.
#

- name: Backup tripleo container config files on the nodes
  hosts: ovn-controllers
  roles:
    - backup
  tags:
    - setup

#
# TripleO / Director is executed to deploy ovn using "br-migration" for the
# dataplane, while br-int is left intact to avoid dataplane disruption.
#

- name: Set up OVN and configure it using tripleo
  hosts: localhost
  roles:
    - tripleo-update
  vars:
      ovn_bridge: br-migration
  tags:
    - setup
  become: false

#
# Once everything is migrated prepare everything by syncing the neutron DB
# into the OVN NB database, and then switching the dataplane to br-int
# letting ovn-controller take control, afterwards any remaining neutron
# resources, namespaces or processes which are not needed anymore are
# cleaned up.
#

- name: Do the DB sync and dataplane switch
  hosts: ovn-controllers, ovn-dbs
  roles:
    - migration
  vars:
      ovn_bridge: br-int
  tags:
    - migration

#
# Verify that the initial resources are still reachable, remove them,
# and afterwards create new resources and repeat the connectivity tests.
#

- name: Post migration
  hosts: localhost
  roles:
    - delete-neutron-resources
    - post-migration
  tags:
    - post-migration

#
# Final step to make sure tripleo knows about OVNIntegrationBridge == br-int.
#

- name: Rerun the stack update to reset the OVNIntegrationBridge to br-int
  hosts: localhost
  roles:
    - tripleo-update
  vars:
      ovn_bridge: br-int
  tags:
    - setup
  become: false

#
# Announce that it's done and ready.
#

- hosts: localhost
  tasks:
  - name: Migration successful.
    debug:
      msg: Migration from ML2OVS to OVN is now complete.


**********
DECISION===>: PASS
**********
=========================:::439:::END!!!=========================
=========================:::440:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/networking-ovn/migration/tripleo_environment/playbooks/reduce-dhcp-renewal-time.yml
**********
---

- hosts: overcloud-controllers
  tasks:
  - name: Update dhcp_agent configuration file option 'dhcp_renewal_time'
    ini_file:
      path=/var/lib/config-data/puppet-generated/neutron/etc/neutron/dhcp_agent.ini
      section=DEFAULT
      backup=yes
      option=dhcp_renewal_time
      value={{ renewal_time }}
      create=no
    ignore_errors: yes

  - block:
    - name: Get the neutron dhcp agent docker id
      shell:
        docker ps | grep neutron_dhcp | awk '{print $1}'
      register: dhcp_agent_docker_id
      ignore_errors: yes

    - name: Restart neutron dhcp agent
      command: docker restart {{ dhcp_agent_docker_id.stdout }}
      ignore_errors: yes

**********
DECISION===>: PASS
**********
=========================:::440:::END!!!=========================
=========================:::441:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/networking-ovn/migration/tripleo_environment/playbooks/roles/resources/validate/tasks/main.yml
**********
- name: Generate resource validation script
  template:
    src: "{{ validate_resources_script }}"
    dest: "{{ ovn_migration_temp_dir }}/validate-resources.sh"
    mode: 0744

- name: Run the validation script
  shell: >
    set -o pipefail &&
    {{ ovn_migration_temp_dir }}/validate-resources.sh 2>&1 | tee
    {{ ovn_migration_temp_dir }}/validate-resources.sh.log


**********
DECISION===>: PASS
**********
=========================:::441:::END!!!=========================
=========================:::442:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/networking-ovn/migration/tripleo_environment/playbooks/roles/resources/validate/defaults/main.yml
**********
validate_resources_script: validate-resources.sh.j2
server_user_name: "cirros"
restart_server: false
resource_suffix: "pre"
ovn_migration_temp_dir: "{{ working_dir }}/{{ resource_suffix }}_migration_resources"
**********
DECISION===>: PASS
**********
=========================:::442:::END!!!=========================
=========================:::443:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/networking-ovn/migration/tripleo_environment/playbooks/roles/resources/cleanup/tasks/main.yml
**********
---

- name : Create temp file directory if not present
  file:
    state: directory
    path: "{{ ovn_migration_temp_dir }}"

- name: Generate cleanup script
  template:
    src: "{{ cleanup_resource_script }}"
    dest: "{{ ovn_migration_temp_dir }}/cleanup-resources.sh"
    mode: 0744

- name: Cleaning up the migration resources (verbose)
  shell: >
    set -o pipefail &&
    {{ ovn_migration_temp_dir }}/cleanup-resources.sh 2>&1 | tee
    {{ ovn_migration_temp_dir }}/cleanup-resources.sh.log

  when: not silent_cleanup

- name: Cleaning up the migration resources (silent)
  shell: >
    {{ ovn_migration_temp_dir }}/cleanup-resources.sh >/dev/null 2>&1
  when: silent_cleanup


**********
DECISION===>: PASS
**********
=========================:::443:::END!!!=========================
=========================:::444:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/networking-ovn/migration/tripleo_environment/playbooks/roles/resources/cleanup/defaults/main.yml
**********
---

cleanup_resource_script: cleanup-resources.sh.j2
resource_suffix: "pre"
ovn_migration_temp_dir: "{{ working_dir }}/{{ resource_suffix }}_migration_resources"
silent_cleanup: false

**********
DECISION===>: PASS
**********
=========================:::444:::END!!!=========================
=========================:::445:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/networking-ovn/migration/tripleo_environment/playbooks/roles/resources/create/tasks/main.yml
**********
---
- name: Delete temp file directory if present
  file:
    state: absent
    path: "{{ ovn_migration_temp_dir }}"

- name : Create temp file directory if not present
  file:
    state: directory
    path: "{{ ovn_migration_temp_dir }}"

- name: Generate resource creation script
  template:
    src: "{{ create_migration_resource_script }}"
    dest: "{{ ovn_migration_temp_dir }}/create-migration-resources.sh"
    mode: 0744

- name: Creating migration resources
  shell: >
    set -o pipefail &&
    {{ ovn_migration_temp_dir }}/create-migration-resources.sh 2>&1 | tee
    {{ ovn_migration_temp_dir }}/create-migration-resources.sh.log

**********
DECISION===>: PASS
**********
=========================:::445:::END!!!=========================
=========================:::446:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/networking-ovn/migration/tripleo_environment/playbooks/roles/resources/create/defaults/main.yml
**********
---

create_migration_resource_script: create-resources.sh.j2
resource_suffix: "pre"
ovn_migration_temp_dir: "{{ working_dir }}/{{ resource_suffix }}_migration_resources"

**********
DECISION===>: PASS
**********
=========================:::446:::END!!!=========================
=========================:::447:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/networking-ovn/migration/tripleo_environment/playbooks/roles/tripleo-update/tasks/main.yml
**********
---

- name : Create temp file directory if not present
  file:
    state: directory
    path: "{{ ovn_migration_temp_dir }}"

- name: Create ovn-extras generation script
  template:
    src: "{{ generate_ovn_extras }}"
    dest: "{{ ovn_migration_temp_dir }}/generate-ovn-extras.sh"
    mode: 0755

- name: Generate ovn-extras environment file
  shell: >
    set -o pipefail &&
    {{ ovn_migration_temp_dir }}/generate-ovn-extras.sh

- name: Updating the overcloud stack with OVN services
  shell: >
    set -o pipefail &&
    {{ overcloud_ovn_deploy_script }} 2>&1 > {{ overcloud_ovn_deploy_script }}.log

**********
DECISION===>: PASS
**********
=========================:::447:::END!!!=========================
=========================:::448:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/networking-ovn/migration/tripleo_environment/playbooks/roles/tripleo-update/defaults/main.yml
**********
---

generate_ovn_extras: generate-ovn-extras.sh.j2
ovn_migration_temp_dir: "{{ working_dir }}/temp_files"

**********
DECISION===>: PASS
**********
=========================:::448:::END!!!=========================
=========================:::449:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/networking-ovn/migration/tripleo_environment/playbooks/roles/pre-migration/tasks/main.yml
**********
# Delete any existing resources to make sure we don't conflict on a second run
- name: Delete any existing pre migration resources (preventive)
  include_role:
    name: resources/cleanup
  vars:
      silent_cleanup: true
  when: validate_migration|bool

- name: Create the pre migration resource stack
  include_role:
    name: resources/create
  when: validate_migration|bool

- name: Validate the pre migration resources
  include_role:
    name: resources/validate
  when: validate_migration|bool
**********
DECISION===>: PASS
**********
=========================:::449:::END!!!=========================
=========================:::450:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/networking-ovn/migration/tripleo_environment/playbooks/roles/backup/tasks/main.yml
**********
# The following tasks ensure that we have backup data which is
# necessary later for cleanup (like l3/dhcp/metadata agent definitions)

- name: "Ensure the ovn backup directory"
  file: path="{{ ovn_migration_backups }}" state=directory

- name: "Save the tripleo container definitions"
  shell: |
    # only copy them the first time, otherwise, on a later run when
    # it has been already migrated to OVN we would miss the data
    if [ ! -d {{ ovn_migration_backups }}/tripleo-config ]; then
      cp -rfp /var/lib/tripleo-config {{ ovn_migration_backups }}
      echo "Backed up"
    fi
  register: command_result
  changed_when: "'Backed up' in command_result.stdout"

# TODO(majopela): Include steps for backing up the mysql database on the
#                 controllers and the undercloud before continuing
**********
DECISION===>: PASS
**********
=========================:::450:::END!!!=========================
=========================:::451:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/networking-ovn/migration/tripleo_environment/playbooks/roles/post-migration/tasks/main.yml
**********
---

#
# Validate pre-migration resources and then clean those up
#

- name: Validate pre migration resources after migration
  include_role:
    name: resources/validate
  vars:
      restart_server: true
  when: validate_migration|bool

- name: Delete the pre migration resources
  include_role:
    name: resources/cleanup
  tags:
    - post-migration
  when: validate_migration|bool

#
# Create post-migration resources, validate, and then clean up
#

# Delete any existing resources to make sure we don't conflict on a second run
- name: Delete any post migration resources (preventive)
  include_role:
    name: resources/cleanup
  vars:
      resource_suffix: "post"
      silent_cleanup: true
  when: validate_migration|bool

- name: Create post-migration resources
  include_role:
    name: resources/create
  vars:
      resource_suffix: "post"
  when: validate_migration|bool

- name: Validate post migration resources
  include_role:
    name: resources/validate
  vars:
      resource_suffix: "post"
  when: validate_migration|bool

- name: Delete the post migration resources
  include_role:
    name: resources/cleanup
  tags:
    - post-migration
  vars:
      resource_suffix: "post"
  when: validate_migration|bool
**********
DECISION===>: PASS
**********
=========================:::451:::END!!!=========================
=========================:::452:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/networking-ovn/migration/tripleo_environment/playbooks/roles/post-migration/defaults/main.yml
**********
---

ovn_migration_temp_dir: "{{ working_dir }}/post_migration_resources"
**********
DECISION===>: PASS
**********
=========================:::452:::END!!!=========================
=========================:::453:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/networking-ovn/migration/tripleo_environment/playbooks/roles/migration/tasks/clone-dataplane.yml
**********
# we use this instead of a big shell entry because some versions of
# ansible-playbook choke on our script syntax + yaml parsing
- name: Generate script to clone br-int and provider bridges
  template:
    src: "clone-br-int.sh.j2"
    dest: "/tmp/clone-br-int.sh"
    mode: 0744

- name: Run clone script for dataplane
  shell: /tmp/clone-br-int.sh

- name: Delete clone script
  file:
    state: absent
    path: /tmp/clone-br-int.sh
**********
DECISION===>: PASS
**********
=========================:::453:::END!!!=========================
=========================:::454:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/networking-ovn/migration/tripleo_environment/playbooks/roles/migration/tasks/activate-ovn.yml
**********
---
- name: Generate OVN activation script
  template:
    src: "activate-ovn.sh.j2"
    dest: "/tmp/activate-ovn.sh"
    mode: 0744

- name: Run OVN activation script
  shell: >
    /tmp/activate-ovn.sh 2>&1 > /tmp/activate-ovn.sh.log

- name: Delete OVN activate script
  file:
    state: absent
    path: /tmp/activate-ovn.sh

**********
DECISION===>: PASS
**********
=========================:::454:::END!!!=========================
=========================:::455:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/networking-ovn/migration/tripleo_environment/playbooks/roles/migration/tasks/sync-dbs.yml
**********
---
- name: Get the neutron docker ID
  shell:
    docker ps | grep neutron-server-ovn | awk '{print $1}'
  register: neutron_docker_id

- name: Sync neutron db with OVN db (container) - Run 1
  command: docker exec "{{ neutron_docker_id.stdout }}"
           neutron-ovn-db-sync-util --config-file /etc/neutron/neutron.conf
           --config-file /etc/neutron/plugins/ml2/ml2_conf.ini
           --ovn-neutron_sync_mode repair

- name: Sync neutron db with OVN db (container) - Run 2
  command: docker exec "{{ neutron_docker_id.stdout }}"
           neutron-ovn-db-sync-util --config-file /etc/neutron/neutron.conf
           --config-file /etc/neutron/plugins/ml2/ml2_conf.ini
           --ovn-neutron_sync_mode repair

- name: Pause and let ovn-controllers settle before doing the final activation (5 minute)
  pause: minutes=5
**********
DECISION===>: PASS
**********
=========================:::455:::END!!!=========================
=========================:::456:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/networking-ovn/migration/tripleo_environment/playbooks/roles/migration/tasks/cleanup-dataplane.yml
**********
---
- name: Quickly disable neutron router and dhcp interfaces
  shell: |
    for p in `ovs-vsctl show | egrep 'qr-|ha-|qg-|rfp-' | grep Interface | awk '{print $2}'`
    do
      # p will be having quotes. Eg. "hr-xxxx". So strip the quotes
      p=`echo $p | sed -e 's/"//g'`
      ovs-vsctl clear Interface $p external-ids
      ovs-vsctl set Interface $p admin-state=down
    done

    # dhcp tap ports cannot be easily distinguished from ovsfw ports, so we
    # list them from within the qdhcp namespaces

    for netns in `ip netns  | awk '{ print $1 }' | grep qdhcp-`; do
      for dhcp_port in `ip netns exec $netns ip -o link show | awk -F': ' '{print $2}' | grep tap`; do
        ovs-vsctl clear Interface $dhcp_port external-ids
        ovs-vsctl set Interface $dhcp_port admin-state=down
      done
    done


- name: Clean neutron datapath security groups from iptables
  shell: |
    iptables-save > /tmp/iptables-before-cleanup
    cat /tmp/iptables-before-cleanup | grep -v neutron-openvswi | \
        grep -v neutron-filter > /tmp/iptables-after-cleanup

    if ! cmp /tmp/iptables-before-cleanup /tmp/iptables-after-cleanup
    then
      cat /tmp/iptables-after-cleanup | iptables-restore
      echo "Security groups cleaned"
    fi
  register: out
  changed_when: "'Security groups cleaned' in out.stdout"

- name: Cleanup neutron datapath resources
  shell: |
    if ip netns | egrep -e "{{ item.value.netns_regex }}"
    then
      echo "Cleaning up"
      cmd="$(paunch debug --file {{ ovn_migration_backups }}/tripleo-config/hashed-docker-container-startup-config-step_4.json \
                  --action print-cmd --container {{ item.key }} \
                  --interactive | \
                  sed 's/--interactive /--volume=\/tmp\/cleanup-{{ item.key }}.sh:\/cleanup.sh:ro /g ' )"

      f="/tmp/cleanup-{{ item.key }}.sh"

      echo "#!/bin/sh" > $f
      echo "set -x" >> $f
      echo "set -e" >> $f
      echo "sudo -E kolla_set_configs" >> $f
      echo "neutron-netns-cleanup {{ item.value.config }} --agent-type {{ item.value.cleanup_type }} --force" >> $f

      chmod a+x $f

      echo $cmd /cleanup.sh

      $cmd /cleanup.sh

    fi
  with_dict: "{{ agent_cleanups }}"
  register: out
  changed_when: "'Cleaning up' in out.stdout"





**********
DECISION===>: PASS
**********
=========================:::456:::END!!!=========================
=========================:::457:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/networking-ovn/migration/tripleo_environment/playbooks/roles/migration/tasks/main.yml
**********
---
- include_tasks: clone-dataplane.yml

- include_tasks: sync-dbs.yml
  when: ovn_central is defined

- include_tasks: activate-ovn.yml

- include_tasks: cleanup-dataplane.yml
  when: ovn_controller is defined
  tags:
    - cleanup-dataplane

**********
DECISION===>: PASS
**********
=========================:::457:::END!!!=========================
=========================:::458:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/networking-ovn/migration/tripleo_environment/playbooks/roles/migration/defaults/main.yml
**********
---

agent_cleanups:
  neutron_l3_agent:
    config: --config-file /usr/share/neutron/neutron-dist.conf --config-dir /usr/share/neutron/l3_agent --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/l3_agent.ini --config-dir /etc/neutron/conf.d/common --config-dir /etc/neutron/conf.d/neutron-l3-agent --log-file=/var/log/neutron/netns-cleanup-l3.log
    cleanup_type: l3
    netns_regex: "fip-|snat-|qrouter-"

  neutron_dhcp:
    config: --config-file /usr/share/neutron/neutron-dist.conf --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/dhcp_agent.ini --config-dir /etc/neutron/conf.d/common --config-dir /etc/neutron/conf.d/neutron-dhcp-agent --log-file=/var/log/neutron/netns-cleanup-dhcp.log
    cleanup_type: dhcp
    netns_regex: "qdhcp-"

tunnel_bridge: "br-tun"
ovn_bridge: "br-int"

**********
DECISION===>: PASS
**********
=========================:::458:::END!!!=========================
=========================:::459:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/networking-ovn/migration/tripleo_environment/playbooks/roles/delete-neutron-resources/tasks/main.yml
**********
---
- name: Delete temp file directory if present
  file:
    state: absent
    path: "{{ ovn_migration_temp_dir_del }}"

- name : Create temp file directory if not present
  file:
    state: directory
    path: "{{ ovn_migration_temp_dir_del }}"

- name: Generate neutron resources cleanup script
  template:
    src: "delete-neutron-resources.sh.j2"
    dest: "{{ ovn_migration_temp_dir_del }}/delete-neutron-resources.sh"
    mode: 0744

- name: Deleting the neutron agents
  shell: >
    {{ ovn_migration_temp_dir_del }}/delete-neutron-resources.sh 2>&1 >
    {{ ovn_migration_temp_dir_del }}/delete-neutron-resources.sh.log

**********
DECISION===>: PASS
**********
=========================:::459:::END!!!=========================
=========================:::460:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/networking-ovn/migration/tripleo_environment/playbooks/roles/delete-neutron-resources/defaults/main.yml
**********
---

ovn_migration_temp_dir_del: "{{ working_dir }}/delete_neutron_resources"
**********
DECISION===>: PASS
**********
=========================:::460:::END!!!=========================
=========================:::461:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/ansible-role-requirements.yml
**********
- name: ansible-hardening
  scm: git
  src: https://git.openstack.org/openstack/ansible-hardening
  version: master
- name: apt_package_pinning
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-apt_package_pinning
  version: master
- name: pip_install
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-pip_install
  version: master
- name: galera_client
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-galera_client
  version: master
- name: galera_server
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-galera_server
  version: master
- name: ceph_client
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-ceph_client
  version: master
- name: haproxy_server
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-haproxy_server
  version: master
- name: keepalived
  scm: git
  src: https://github.com/evrardjp/ansible-keepalived
  version: master
- name: lxc_container_create
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-lxc_container_create
  version: master
- name: lxc_hosts
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-lxc_hosts
  version: master
- name: memcached_server
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-memcached_server
  version: master
- name: openstack_hosts
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-openstack_hosts
  version: master
- name: os_keystone
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-os_keystone
  version: master
- name: openstack_openrc
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-openstack_openrc
  version: master
- name: os_aodh
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-os_aodh
  version: master
- name: os_barbican
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-os_barbican
  version: master
- name: os_blazar
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-os_blazar
  version: master
- name: os_ceilometer
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-os_ceilometer
  version: master
- name: os_cinder
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-os_cinder
  version: master
- name: os_congress
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-os_congress
  version: master
- name: os_designate
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-os_designate
  version: master
- name: os_glance
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-os_glance
  version: master
- name: os_gnocchi
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-os_gnocchi
  version: master
- name: os_heat
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-os_heat
  version: master
- name: os_horizon
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-os_horizon
  version: master
- name: os_ironic
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-os_ironic
  version: master
- name: os_magnum
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-os_magnum
  version: master
- name: os_neutron
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-os_neutron
  version: master
- name: os_nova
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-os_nova
  version: master
- name: os_octavia
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-os_octavia
  version: master
- name: os_rally
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-os_rally
  version: master
- name: os_sahara
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-os_sahara
  version: master
- name: os_swift
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-os_swift
  version: master
- name: os_tacker
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-os_tacker
  version: master
- name: os_tempest
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-os_tempest
  version: master
- name: os_trove
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-os_trove
  version: master
- name: plugins
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-plugins
  version: master
- name: rabbitmq_server
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-rabbitmq_server
  version: master
- name: repo_build
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-repo_build
  version: master
- name: repo_server
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-repo_server
  version: master
- name: rsyslog_client
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-rsyslog_client
  version: master
- name: rsyslog_server
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-rsyslog_server
  version: master
- name: sshd
  scm: git
  src: https://github.com/willshersystems/ansible-sshd
  version: master
- name: bird
  scm: git
  src: https://github.com/logan2211/ansible-bird
  version: master
- name: etcd
  scm: git
  src: https://github.com/logan2211/ansible-etcd
  version: master
- name: unbound
  scm: git
  src: https://github.com/logan2211/ansible-unbound
  version: master
- name: resolvconf
  scm: git
  src: https://github.com/logan2211/ansible-resolvconf
  version: master
- name: ceph-ansible
  scm: git
  src: https://github.com/ceph/ceph-ansible
  version: stable-3.2
- name: opendaylight
  scm: git
  src: https://github.com/opendaylight/integration-packaging-ansible-opendaylight
  version: master
- name: haproxy_endpoints
  scm: git
  src: https://github.com/logan2211/ansible-haproxy-endpoints
  version: master
- name: nspawn_container_create
  src: https://git.openstack.org/openstack/openstack-ansible-nspawn_container_create
  scm: git
  version: master
- name: nspawn_hosts
  src: https://git.openstack.org/openstack/openstack-ansible-nspawn_hosts
  scm: git
  version: master
- name: systemd_service
  src: https://git.openstack.org/openstack/ansible-role-systemd_service
  scm: git
  version: master
- name: systemd_mount
  src: https://git.openstack.org/openstack/ansible-role-systemd_mount
  scm: git
  version: master
- name: systemd_networkd
  src: https://git.openstack.org/openstack/ansible-role-systemd_networkd
  scm: git
  version: master
- name: python_venv_build
  src: https://git.openstack.org/openstack/ansible-role-python_venv_build
  scm: git
  version: master

**********
DECISION===>: PASS
**********
=========================:::461:::END!!!=========================
=========================:::462:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/tests/roles/bootstrap-host/vars/redhat.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

packages_install:
  - bridge-utils
  - btrfs-progs
  - curl
  - dbus
  - ethtool
  - git
  - iputils
  - lvm2
  - python
  - python-devel
  - sshpass
  - systemd-networkd
  - vim
  - xfsprogs

packages_remove: []

rc_local: /etc/rc.d/rc.local
rc_local_insert_before: "^touch /var/lock/subsys/local$"

**********
DECISION===>: PASS
**********
=========================:::462:::END!!!=========================
=========================:::463:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/tests/roles/bootstrap-host/vars/suse.yml
**********
---
# Copyright 2015, Rackspace US, Inc.
# Copyright 2017, SUSE LINUX GmbH.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

packages_install:
  - bridge-utils
  - btrfsprogs
  - curl
  - dbus-1
  - ethtool
  - git-core
  - lvm2
  - python
  - python-devel
  - vim
  - vlan
  - xfsprogs

packages_remove: []

rc_local: /etc/rc.d/boot.local
rc_local_insert_before: EOF

**********
DECISION===>: PASS
**********
=========================:::463:::END!!!=========================
=========================:::464:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/tests/roles/bootstrap-host/vars/ubuntu.yml
**********
---
# Copyright 2015, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

packages_install:
  - apt-transport-https
  - bridge-utils
  - btrfs-tools
  - build-essential
  - curl
  - dbus
  - ethtool
  - git-core
  - iptables
  - iputils-tracepath
  - ipython
  - lvm2
  - parted
  - python2.7
  - python-dev
  - sshpass
  - vim
  - vlan
  - xfsprogs

packages_install_zfs:
  - zfsutils-linux

packages_remove:
  - libmysqlclient18
  - mysql-common

rc_local: /etc/rc.local
rc_local_insert_before: "^exit 0$"

**********
DECISION===>: PASS
**********
=========================:::464:::END!!!=========================
=========================:::465:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/tests/roles/bootstrap-host/tasks/prepare_loopback_swap.yml
**********
---
# Copyright 2015, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Create swap file
  command: "dd if=/dev/zero of=/openstack/swap.img bs=1M count={{ bootstrap_host_loopback_swap_size }}"
  args:
    creates: /openstack/swap.img
  register: swap_create
  tags:
    - swap-file-create

- name: Format the swap file
  command: mkswap /openstack/swap.img
  when:
    - swap_create  is changed
  tags:
    - swap-format
    - skip_ansible_lint

- name: Run the systemd mount role
  include_role:
    name: systemd_mount
    private: true
  vars:
    systemd_mounts:
      - what: "/openstack/swap.img"
        priority: "0"
        options: "{{ bootstrap_host_data_mount_options['swap'] }}"
        type: "swap"
        state: 'started'
        enabled: true
  tags:
    - swap-config

- name: Set system swappiness
  sysctl:
    name: vm.swappiness
    value: 10
    state: present
  tags:
    - swap-sysctl

**********
DECISION===>: PASS
**********
=========================:::465:::END!!!=========================
=========================:::466:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/tests/roles/bootstrap-host/tasks/prepare_loopback_btrfs.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Create sparse lxc-btrfs file
  command: "truncate -s {{ bootstrap_host_loopback_btrfs_size }}G /openstack/lxc-btrfs.img"
  args:
    creates: /openstack/lxc-btrfs.img

- name: Format the lxc-btrfs file
  filesystem:
    fstype: btrfs
    opts: "{{ bootstrap_host_format_options['btrfs'] | default(omit) }}"
    dev: /openstack/lxc-btrfs.img

- name: Run the systemd mount role
  include_role:
    name: systemd_mount
    private: true
  vars:
    systemd_mounts:
      - what: "/openstack/lxc-btrfs.img"
        where: "/var/lib/lxc"
        options: "loop,{{ bootstrap_host_data_mount_options['btrfs'] }}"
        type: "btrfs"
        state: 'started'
        enabled: true
  tags:
    - lxc-config

**********
DECISION===>: PASS
**********
=========================:::466:::END!!!=========================
=========================:::467:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/tests/roles/bootstrap-host/tasks/prepare_loopback_swift.yml
**********
---
# Copyright 2015, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Create sparse Swift files
  command: "truncate -s {{ bootstrap_host_loopback_swift_size }}G /openstack/{{ item }}.img"
  args:
    creates: "/openstack/{{ item }}.img"
  with_items:
    - 'swift1'
    - 'swift2'
    - 'swift3'
  tags:
    - swift-file-create

- name: Format the Swift files
  filesystem:
    fstype: xfs
    opts: "{{ bootstrap_host_format_options['xfs'] | default(omit) }}"
    dev: "/openstack/{{ item }}.img"
  with_items:
    - 'swift1'
    - 'swift2'
    - 'swift3'
  tags:
    - swift-format-file

- name: Run the systemd mount role
  include_role:
    name: systemd_mount
    private: true
  vars:
    systemd_mounts:
      - what: "/openstack/swift1.img"
        where: "/srv/swift1.img"
        options: "loop,{{ bootstrap_host_data_mount_options['xfs'] }}"
        type: "xfs"
        state: 'started'
        enabled: true
      - what: "/openstack/swift2.img"
        where: "/srv/swift2.img"
        options: "loop,{{ bootstrap_host_data_mount_options['xfs'] }}"
        type: "xfs"
        state: 'started'
        enabled: true
      - what: "/openstack/swift3.img"
        where: "/srv/swift3.img"
        options: "loop,{{ bootstrap_host_data_mount_options['xfs'] }}"
        type: "xfs"
        state: 'started'
        enabled: true
  tags:
    - swift-config

**********
DECISION===>: PASS
**********
=========================:::467:::END!!!=========================
=========================:::468:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/tests/roles/bootstrap-host/tasks/prepare_hostname.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Ensure the hosts file is templated appropriately
  copy:
    content: |
      127.0.0.1 localhost aio1
      127.0.1.1 aio1.openstack.local aio1

      # The following lines are desirable for IPv6 capable hosts
      ::1 ip6-localhost ip6-loopback
      fe00::0 ip6-localnet
      ff00::0 ip6-mcastprefix
      ff02::1 ip6-allnodes
      ff02::2 ip6-allrouters
      ff02::3 ip6-allhosts
    dest: /etc/hosts
    backup: yes

- name: Ensure hostname is set
  block:
    - name: Set hostname using the Ansible module
      hostname:
        name: aio1
  # NOTE(hwoarang) The hostname module does not work on Leap 15 because of
  # https://bugzilla.novell.com/show_bug.cgi?id=997614
  # As such we need to fallback to using the command directly.
  rescue:
    - name: Set hostname using hostnamectl
      command: hostnamectl set-hostname aio1
  tags:
    - skip_ansible_lint

**********
DECISION===>: PASS
**********
=========================:::468:::END!!!=========================
=========================:::469:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/tests/roles/bootstrap-host/tasks/prepare_ssh_keys.yml
**********
---
# Copyright 2015, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Ensure root has a .ssh directory
  file:
    path: /root/.ssh
    state: directory
    owner: root
    group: root
    mode: 0700
  tags:
    - ssh-key-dir

- name: Check for existing ssh private key file
  stat:
    path: /root/.ssh/id_rsa
  register: ssh_key_private
  tags:
    - ssh-key-check

- name: Check for existing ssh public key file
  stat:
    path: /root/.ssh/id_rsa.pub
  register: ssh_key_public
  tags:
    - ssh-key-check

- name: Remove an existing private/public ssh keys if one is missing
  file:
    path: "/root/.ssh/{{ item }}"
    state: absent
  when: not ssh_key_public.stat.exists or not ssh_key_private.stat.exists
  with_items:
    - 'id_rsa'
    - 'id_rsa.pub'
  tags:
    - ssh-key-clean

- name: Create ssh key pair for root
  user:
    name: root
    generate_ssh_key: yes
    ssh_key_bits: 2048
    ssh_key_file: /root/.ssh/id_rsa
  tags:
    - ssh-key-generate

- name: Fetch the generated public ssh key
  fetch:
    src: "/root/.ssh/id_rsa.pub"
    dest: "/tmp/id_rsa.pub"
    flat: yes
  when: inventory_hostname == groups['all'][0]
  tags:
    - ssh-key-authorized

- name: Ensure root's new public ssh key is in authorized_keys
  authorized_key:
    user: root
    key: "{{ lookup('file','/tmp/id_rsa.pub') }}"
    manage_dir: no
  tags:
    - ssh-key-authorized
**********
DECISION===>: PASS
**********
=========================:::469:::END!!!=========================
=========================:::470:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/tests/roles/bootstrap-host/tasks/prepare_networking.yml
**********
---
# Copyright 2015, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Run the systemd-networkd role
  include_role:
    name: systemd_networkd
    private: true
  vars:
    systemd_networkd_prefix: "osa_testing"
    systemd_interface_cleanup: true
    systemd_run_networkd: true
    systemd_netdevs:

      - NetDev:
          Name: dummy-mgmt
          Kind: dummy
      - NetDev:
          Name: dummy-vxlan
          Kind: dummy
      - NetDev:
          Name: dummy-storage
          Kind: dummy
      - NetDev:
          Name: dummy-vlan
          Kind: dummy
      - NetDev:
          Name: dummy-dbaas
          Kind: dummy
      - NetDev:
          Name: dummy-lbaas
          Kind: dummy

      - NetDev:
          Name: br-mgmt
          Kind: bridge
      - NetDev:
          Name: br-vxlan
          Kind: bridge
      - NetDev:
          Name: br-storage
          Kind: bridge
      - NetDev:
          Name: br-vlan
          Kind: bridge
      - NetDev:
          Name: br-dbaas
          Kind: bridge
      - NetDev:
          Name: br-lbaas
          Kind: bridge

      - NetDev:
          Name: br-vlan-veth
          Kind: veth
        Peer:
          Name: eth12
      - NetDev:
          Name: br-dbaas-veth
          Kind: veth
        Peer:
          Name: eth13
      - NetDev:
          Name: br-lbaas-veth
          Kind: veth
        Peer:
          Name: eth14

    systemd_networks:

      - interface: "dummy-mgmt"
        bridge: "br-mgmt"
        mtu: 9000
      - interface: "br-mgmt"
        address: "172.29.236.100"
        netmask: "255.255.252.0"

      - interface: "dummy-storage"
        bridge: "br-storage"
        mtu: 9000
      - interface: "br-storage"
        address: "172.29.244.100"
        netmask: "255.255.252.0"

      - interface: "dummy-dbaas"
        bridge: "br-dbaas"
        mtu: 9000
      - interface: "br-dbaas"
        address: "172.29.232.100"
        netmask: "255.255.252.0"
      - interface: "br-dbaas-veth"
        bridge: "br-dbaas"
        mtu: 9000

      - interface: "dummy-lbaas"
        bridge: "br-lbaas"
        mtu: 9000
      - interface: "br-lbaas"
        address: "172.29.252.100"
        netmask: "255.255.252.0"
      - interface: "br-lbaas-veth"
        bridge: "br-lbaas"
        mtu: 9000

      - interface: "dummy-vxlan"
        bridge: "br-vxlan"
        mtu: 9000
      - interface: "br-vxlan"
        address: "172.29.240.100"
        netmask: "255.255.252.0"

      - interface: "dummy-vlan"
        bridge: "br-vlan"
        mtu: 9000
      - interface: "br-vlan"
        config_overrides:
          Network:
            Address:
              ? "172.29.248.100/22"
              ? "172.29.248.1/22"
      - interface: "br-vlan-veth"
        bridge: "br-vlan"
        mtu: 9000

  tags:
    - network-config

# NOTE(jrosser) The systemd_networkd role uses a handler to restart the networking service
# This will normally not run until the end of the play, so we must force it here
- name: Force systemd_networkd hander to run
  meta: flush_handlers

# NOTE(jrosser) The intention here is not to proceed further until the network bridges are up
# This ensures there will be no race between the bridges coming up and subsequent tasks which
# require functional network interfaces
- name: Check that network bridges are up
  wait_for:
    port: 22
    timeout: 30
    host: "{{ item }}"
  with_items:
    - 172.29.236.100  # br-mgmt
    - 172.29.244.100  # br-storage
    - 172.29.232.100  # br-dbaas
    - 172.29.252.100  # br-lbaas
    - 172.29.240.100  # br-vxlan

- name: Run the systemd service role
  include_role:
    name: systemd_service
    private: true
  vars:
    systemd_services:
      - service_name: "networking-post-up"
        config_overrides:
          Unit:
            Description: networking-post-up
            After: network-online.target
            Wants: network-online.target
          Service:
            RemainAfterExit: yes
        service_type: oneshot
        execstarts:
          - "-{{ bootstrap_host_iptables_path }} -t nat -A POSTROUTING -o {{ bootstrap_host_public_interface }} -j MASQUERADE"
          - "-{{ bootstrap_host_ethtool_path }} -K br-mgmt gso off sg off tso off tx off"
          - "-{{ bootstrap_host_ethtool_path }} -K br-vxlan gso off sg off tso off tx off"
          - "-{{ bootstrap_host_ethtool_path }} -K br-storage gso off sg off tso off tx off"
          - "-{{ bootstrap_host_ethtool_path }} -K br-vlan gso off sg off tso off tx off"
          - "-{{ bootstrap_host_ethtool_path }} -K br-dbaas gso off sg off tso off tx off"
          - "-{{ bootstrap_host_ethtool_path }} -K br-lbaas gso off sg off tso off tx off"
          - "-{{ bootstrap_host_ip_path }} link set eth12 up"
          - "-{{ bootstrap_host_ip_path }} link set br-vlan-veth up"
          - "-{{ bootstrap_host_ethtool_path }} -K eth12 gso off sg off tso off tx off"
          - "-{{ bootstrap_host_ip_path }} link set eth13 up"
          - "-{{ bootstrap_host_ip_path }} link set br-dbaas-veth up"
          - "-{{ bootstrap_host_ethtool_path }} -K eth13 gso off sg off tso off tx off"
          - "-{{ bootstrap_host_ip_path }} link set eth14 up"
          - "-{{ bootstrap_host_ip_path }} link set br-lbaas-veth up"
          - "-{{ bootstrap_host_ethtool_path }} -K eth14 gso off sg off tso off tx off"
        execstops:
          - "{{ bootstrap_host_iptables_path }} -t nat -D POSTROUTING -o {{ bootstrap_host_public_interface }} -j MASQUERADE"
        enabled: yes
        state: started
    systemd_tempd_prefix: openstack
  tags:
    - network-config

- name: Updating the facts due to net changes
  setup:
    gather_subset: network
  tags:
    - networking

**********
DECISION===>: PASS
**********
=========================:::470:::END!!!=========================
=========================:::471:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/tests/roles/bootstrap-host/tasks/prepare_loopback_nova.yml
**********
---
# Copyright 2015, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Create sparse Nova file
  command: "truncate -s {{ bootstrap_host_loopback_nova_size }}G /openstack/nova.img"
  args:
    creates: /openstack/nova.img
  tags:
    - nova-file-create

- name: Format the Nova file
  filesystem:
    fstype: xfs
    dev: /openstack/nova.img
    opts: "{{ bootstrap_host_format_options['xfs'] | default(omit) }}"
  tags:
    - nova-format-file

- name: Run the systemd mount role
  include_role:
    name: systemd_mount
    private: true
  vars:
    systemd_mounts:
      - what: "/openstack/nova.img"
        where: "/var/lib/nova/instances"
        options: "loop,{{ bootstrap_host_data_mount_options['xfs'] }}"
        type: "xfs"
        state: 'started'
        enabled: true
  tags:
    - nova-config

**********
DECISION===>: PASS
**********
=========================:::471:::END!!!=========================
=========================:::472:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/tests/roles/bootstrap-host/tasks/prepare_ceph.yml
**********
---
# Copyright 2016, Logan Vig <logan2211@gmail.com>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Create sparse ceph OSD files
  command: truncate -s {{ bootstrap_host_loopback_ceph_size }}G /openstack/{{ item }}.img
  args:
    creates: "/openstack/{{ item }}.img"
  with_items: "{{ ceph_osd_images }}"
  register: ceph_create
  tags:
    - ceph-file-create

- name: Run the systemd service role
  include_role:
    name: systemd_service
    private: true
  vars:
    systemd_services:
      - service_name: "loop-{{ loopback_var }}"
        config_overrides:
          Unit:
            Description: no
            After: systemd-udev-settle.service
          Service:
            RemainAfterExit: yes
        service_type: oneshot
        execstarts:
          - /bin/bash -c "/sbin/losetup $(/sbin/losetup -f) /openstack/{{ loopback_var }}.img"
        execstops:
          - /bin/bash -c "losetup -d $(losetup -l | awk '/{{ loopback_var }}.img/ {print $1}')"
        enabled: yes
        state: started
    systemd_tempd_prefix: openstack
  with_items: "{{ ceph_osd_images }}"
  loop_control:
    loop_var: loopback_var
  tags:
    - ceph-config

- name: Get loopback device
  shell: "losetup -l | awk '/{{ item }}.img/ {print $1}'"
  changed_when: false
  register: ceph_create_loopback
  with_items: "{{ ceph_osd_images }}"
  tags:
    - skip_ansible_lint

# TODO(logan): Move these vars to user_variables.ceph.yml.j2 once LP #1649381
# is fixed and eliminate this task.
- name: Write ceph cluster config
  copy:
    content: |
      ---
      devices: {{ ceph_create_loopback.results | map(attribute='stdout') | list | to_yaml | trim }}
      cinder_backends:
        "RBD":
          volume_driver: cinder.volume.drivers.rbd.RBDDriver
          rbd_pool: volumes
          rbd_ceph_conf: /etc/ceph/ceph.conf
          rbd_store_chunk_size: 8
          volume_backend_name: rbddriver
          rbd_user: cinder
          rbd_secret_uuid: "{% raw %}{{ cinder_ceph_client_uuid }}{% endraw %}"
          report_discard_supported: true
    dest: /etc/openstack_deploy/user_ceph_aio.yml
    force: no
  become: false
  when: not ceph_create_loopback|skipped
  tags:
    - skip_ansible_lint

**********
DECISION===>: PASS
**********
=========================:::472:::END!!!=========================
=========================:::473:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/tests/roles/bootstrap-host/tasks/prepare_loopback_cinder.yml
**********
---
# Copyright 2015, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Create sparse Cinder file
  command: "truncate -s {{ bootstrap_host_loopback_cinder_size }}G /openstack/cinder.img"
  args:
    creates: /openstack/cinder.img
  register: cinder_create
  tags:
    - cinder-file-create

- name: Run the systemd service role
  include_role:
    name: systemd_service
    private: true
  vars:
    systemd_services:
      - service_name: "loop-cinder"
        config_overrides:
          Unit:
            Description: no
            After: systemd-udev-settle.service
            Before: lvm2-activation-early.service
            Wants: systemd-udev-settle.service
          Service:
            RemainAfterExit: yes
        service_type: oneshot
        execstarts:
          - /bin/bash -c "/sbin/losetup $(/sbin/losetup -f) /openstack/cinder.img"
          - /sbin/pvscan
        execstops:
          - /bin/bash -c "losetup -d $(losetup -l | awk '/cinder.img/ {print $1}')"
        enabled: yes
        state: started
    systemd_tempd_prefix: openstack
  tags:
    - cinder-config

- name: Get loopback device
  shell: "losetup -l | awk '/cinder.img/ {print $1}'"
  changed_when: false
  register: cinder_losetup
  tags:
    - skip_ansible_lint

- name: Make LVM physical volume on the cinder device
  shell: "pvcreate {{ cinder_losetup.stdout }} && touch /openstack/cinder.pvcreate"
  args:
    creates: "/openstack/cinder.pvcreate"
  tags:
    - skip_ansible_lint
    - cinder-lvm-pv

- name: Run pvscan
  command: "pvscan"
  changed_when: false
  tags:
    - cinder-lvm-pv

- name: Add cinder-volumes volume group
  lvg:
    vg: cinder-volumes
    pvs: "{{ cinder_losetup.stdout }}"
  tags:
    - cinder-lvm-vg

**********
DECISION===>: PASS
**********
=========================:::473:::END!!!=========================
=========================:::474:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/tests/roles/bootstrap-host/tasks/prepare_loopback_zfs.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Install zfs packages
  package:
    name: "{{ packages_install_zfs }}"
    state: present
    update_cache: "{{ (ansible_pkg_mgr in ['apt', 'zypper']) | ternary('yes', omit) }}"
  tags:
    - install-packages

- name: Create sparse ZFS backing file
  command: "truncate -s {{ bootstrap_host_loopback_zfs_size }}G /openstack/lxc-zfs.img"
  args:
    creates: /openstack/lxc-zfs.img

- name: Create the ZFS pool
  command: zpool create osa-test-pool /openstack/lxc-zfs.img
  args:
    creates: /osa-test-pool

- name: Create the ZFS pool/lxc volume
  shell: "(zfs list | grep lxc) || zfs create -o mountpoint=/var/lib/lxc osa-test-pool/lxc"
  tags:
    - skip_ansible_lint

**********
DECISION===>: PASS
**********
=========================:::474:::END!!!=========================
=========================:::475:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/tests/roles/bootstrap-host/tasks/install_packages.yml
**********
---
# Copyright 2015, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Remove known problem packages
  package:
    name: "{{ packages_remove }}"
    state: absent
  tags:
    - remove-packages

- name: Install packages
  package:
    name: "{{ packages_install }}"
    state: present
    update_cache: "{{ (ansible_pkg_mgr in ['apt', 'zypper']) | ternary('yes', omit) }}"
  tags:
    - install-packages


**********
DECISION===>: PASS
**********
=========================:::475:::END!!!=========================
=========================:::476:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/tests/roles/bootstrap-host/tasks/check-requirements.yml
**********
---
# Copyright 2015, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Check for a supported Operating System
  assert:
    that:
      - (ansible_distribution == 'Ubuntu' and ansible_distribution_release == 'xenial') or
        (ansible_distribution == 'Ubuntu' and ansible_distribution_release == 'bionic') or
        (ansible_os_family == 'RedHat' and ansible_distribution_major_version == '7') or
        (ansible_os_family == 'Suse' and ansible_distribution_major_version in ['42', '15'])
    msg: "The only supported platforms for this release are Ubuntu 16.04 LTS (Xenial), Ubuntu 18.04 LTS (Bionic), CentOS 7 (WIP), openSUSE Leap 42.X and openSUSE Leap 15.X"
  when: (check_operating_system | default(True))| bool
  tags:
    - check-operating-system

- name: Identify the space available in /
  # NOTE(hwoarang): df does not work reliably on btrfs filesystems
  # https://btrfs.wiki.kernel.org/index.php/FAQ#How_much_free_space_do_I_have.3F
  # As such, use the btrfs tools to determine the real available size on the
  # disk
  shell: |
    if [[ $(df -T / | tail -n 1 | awk '{print $2}') == "btrfs" ]]; then
        btrfs fi usage --kbytes / | awk '/^.*Free / {print $3}'| sed 's/\..*//'
    else
        df -BK / | awk '!/^Filesystem/ {print $4}' | sed 's/K//'
    fi
  when:
    - bootstrap_host_data_disk_device == None
  changed_when: false
  register: root_space_available
  tags:
    - check-disk-size

# Convert root_space_available to bytes.
- name: Set root disk facts
  set_fact:
    host_root_space_available_bytes: "{{ ( root_space_available.stdout | int) * 1024 | int }}"
  when:
    - bootstrap_host_data_disk_device == None
  tags:
    - check-disk-size

- name: Fail when disk can not be found
  fail:
    msg: |
      Can not find disk {{ bootstrap_host_data_disk_device }}
  when:
    - bootstrap_host_data_disk_device != None
    - ansible_devices.get(bootstrap_host_data_disk_device) == None
  tags:
    - check-disk-size

- name: Set data disk facts
  set_fact:
    host_data_disk_sectors: "{{ (ansible_devices[bootstrap_host_data_disk_device]['sectors'] | int) }}"
    host_data_disk_sectorsize: "{{ (ansible_devices[bootstrap_host_data_disk_device]['sectorsize'] | int) }}"
  when:
    - bootstrap_host_data_disk_device != None
  tags:
    - check-disk-size

# Calculate the size of the bootstrap_host_data_disk_device by muliplying sectors with sectorsize.
- name: Calculate data disk size
  set_fact:
    host_data_disk_size_bytes: "{{ ((host_data_disk_sectors | int) * (host_data_disk_sectorsize | int)) | int }}"
  when:
    - bootstrap_host_data_disk_device != None
  tags:
    - check-disk-size

# Convert bootstrap_host_data_disk_min_size to bytes.
- name: Set min size fact
  set_fact:
    host_data_disk_min_size_bytes: "{{ ((bootstrap_host_data_disk_min_size | int) * 1024**3) | int }}"
  tags:
    - check-disk-size

- name: Set size facts
  set_fact:
    root_gb_available: "{{ ((host_root_space_available_bytes | int ) / 1024**3) | round(2, 'floor') }}"
  when: bootstrap_host_data_disk_device == None
  tags:
    - check-disk-size

- name: Set disk size facts
  set_fact:
    disk_gb_available: "{{ ((host_data_disk_size_bytes | int ) / 1024**3) | round(2, 'floor') }}"
  when: bootstrap_host_data_disk_device != None
  tags:
    - check-disk-size

- name: Fail if there is not enough space available in /
  fail:
    msg: |
      Not enough space available in /.
      Found {{ root_gb_available }} GB, required {{ bootstrap_host_data_disk_min_size }} GB)
  when:
    - bootstrap_host_data_disk_device == None
    - (host_root_space_available_bytes | int) < (host_data_disk_min_size_bytes | int)
  tags:
    - check-disk-size

- name: Fail if there is not enough disk space available (disk specified)
  fail:
    msg: |
      Not enough disk space available.
      Found {{ disk_gb_available }} GB, required {{ bootstrap_host_data_disk_min_size }} GB)
  when:
    - bootstrap_host_data_disk_device != None
    - (host_data_disk_size_bytes | int) < (host_data_disk_min_size_bytes | int)
  tags:
    - check-disk-size

- name: Ensure that the kernel has VXLAN, VLAN, and bonding support
  modprobe:
    name: "{{ item }}"
    state: present
  with_items:
    - vxlan
    - bonding
    - 8021q

**********
DECISION===>: PASS
**********
=========================:::476:::END!!!=========================
=========================:::477:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/tests/roles/bootstrap-host/tasks/prepare_data_disk.yml
**********
---
# Copyright 2015, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


# Only execute the disk partitioning process if a partition labeled
#  'openstack-data{1,2}' is not present and that partition is not
#  formatted as ext4. This is an attempt to achieve idempotency just
#  in case these tasks are executed multiple times.
- name: Determine whether partitions labeled openstack-data{1,2} are present
  shell: |
    parted --script -l -m | egrep -q ':{{ bootstrap_host_data_disk_fs_type }}:openstack-data[12]:;$'
  register: data_disk_partitions
  changed_when: false
  failed_when: false
  tags:
    - check-data-disk-partitions

- name: Set bootstrap host data disk fact
  set_fact:
    bootstrap_host_data_disk_device_force: true
    _bootstrap_host_data_disk_device: "{{ (bootstrap_host_data_disk_device | regex_replace('!','/')).strip() }}"
  when:
    - data_disk_partitions.rc == 1

- name: Dismount and remove fstab entries for anything on the data disk device
  mount:
    name: "{{ item.mount }}"
    src: "{{ item.device }}"
    fstype: "{{ bootstrap_host_data_disk_fs_type }}"
    state: absent
  when:
    - bootstrap_host_data_disk_device_force | bool
    - item.device | search(bootstrap_host_data_disk_device)
  with_items:
    - "{{ ansible_mounts }}"

- name: Partition the whole data disk for our usage
  command: "{{ item }}"
  when:
    - bootstrap_host_data_disk_device_force | bool
  with_items:
    - "parted --script /dev/{{ _bootstrap_host_data_disk_device }} mklabel gpt"
    - "parted --align optimal --script /dev/{{ _bootstrap_host_data_disk_device }} mkpart openstack-data1 {{ bootstrap_host_data_disk_fs_type }} 0% 40%"
    - "parted --align optimal --script /dev/{{ _bootstrap_host_data_disk_device }} mkpart openstack-data2 {{ bootstrap_host_data_disk2_fs }} 40% 100%"
  tags:
    - create-data-disk-partitions

- name: Format the partition 1
  filesystem:
    fstype: "{{ bootstrap_host_data_disk_fs_type }}"
    dev: "/dev/{{ _bootstrap_host_data_disk_device }}1"
    opts: "{{ bootstrap_host_format_options['ext4'] | default(omit) }}"
  when:
    - bootstrap_host_data_disk_device_force | bool
  tags:
    - format-data-partitions

- name: Format the partition 2
  filesystem:
    fstype: "{{ bootstrap_host_data_disk2_fs }}"
    dev: "/dev/{{ _bootstrap_host_data_disk_device }}2"
    opts: "{{ bootstrap_host_format_options[bootstrap_host_data_disk2_fs] | default(omit) }}"
  when:
    - bootstrap_host_data_disk_device_force | bool
    - lxc_container_backing_store != 'lvm'
    - lxc_container_backing_store != 'zfs'
  tags:
    - format-data-partitions

- name: Run the systemd mount role
  include_role:
    name: systemd_mount
    private: true
  vars:
    systemd_mounts:
      - what: "/dev/{{ _bootstrap_host_data_disk_device }}1"
        where: "/openstack"
        type: "{{ bootstrap_host_data_disk_fs_type }}"
        options: "{{ bootstrap_host_data_mount_options[bootstrap_host_data_disk_fs_type] }}"
        state: 'started'
        enabled: true
  tags:
    - data-config

- name: Run the systemd mount role
  include_role:
    name: systemd_mount
    private: true
  vars:
    systemd_mounts:
      - what: "/dev/{{ _bootstrap_host_data_disk_device }}2"
        where: "{{ bootstrap_host_data_disk2_path }}"
        type: "{{ bootstrap_host_data_disk2_fs }}"
        options: "{{ bootstrap_host_data_disk2_fs_mount_options }}"
        state: 'started'
        enabled: true
  when:
    - lxc_container_backing_store != 'lvm'
    - lxc_container_backing_store != 'zfs'
  tags:
    - data-config

- name: Create the ZFS pool
  command: zpool create pool "/dev/{{ _bootstrap_host_data_disk_device }}2"
  args:
    creates: /pool
  when:
    - bootstrap_host_data_disk_device_force | bool
    - lxc_container_backing_store == 'zfs'

- name: Create the ZFS pool/lxc volume
  shell: "(zfs list | grep lxc) || zfs create -o mountpoint=/var/lib/lxc pool/lxc"
  when:
    - bootstrap_host_data_disk_device_force | bool
    - lxc_container_backing_store == 'zfs'
  tags:
    - skip_ansible_lint

- name: Make LVM physical volume on the cinder device
  shell: "pvcreate /dev/{{ _bootstrap_host_data_disk_device }}2 && touch /openstack/lxc.pvcreate"
  args:
    creates: "/openstack/lxc.pvcreate"
  when:
    - lxc_container_backing_store == 'lvm'
  tags:
    - skip_ansible_lint
    - data-config

- name: Run pvscan
  command: "pvscan"
  changed_when: false
  when:
    - lxc_container_backing_store == 'lvm'
  tags:
    - cinder-lvm-pv

- name: Add cinder-volumes volume group
  lvg:
    vg: lxc
    pvs: "/dev/{{ _bootstrap_host_data_disk_device }}2"
  when:
    - lxc_container_backing_store == 'lvm'
  tags:
    - data-config

**********
DECISION===>: PASS
**********
=========================:::477:::END!!!=========================
=========================:::478:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/tests/roles/bootstrap-host/tasks/prepare_aio_config.yml
**********
---
# Copyright 2015, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Create the required deployment directories
  file:
    path: "{{ item }}"
    state: directory
  with_items: "{{ bootstrap_host_target_config_paths }}"
  tags:
    - create-directories

- name: Deploy user conf.d configuration
  config_template:
    src: "{{ item.path | default(bootstrap_host_aio_config_path ~ '/conf.d') }}/{{ item.name }}"
    dest: "/etc/openstack_deploy/conf.d/{{ item.name | regex_replace('.aio$', '') }}"
    config_overrides: "{{ item.override | default({}) }}"
    config_type: "yaml"
  with_items: "{{ confd_overrides[bootstrap_host_scenario] | default([]) }}"
  tags:
    - deploy-confd

- name: Deploy openstack_user_config
  config_template:
    src: "{{ bootstrap_host_aio_config_path }}/openstack_user_config.yml.{{ (bootstrap_host_container_tech == 'nspawn') | ternary('aio-nspawn', 'aio') }}.j2"
    dest: "/etc/openstack_deploy/openstack_user_config.yml"
    config_overrides: "{{ openstack_user_config_overrides | default({}) }}"
    config_type: "yaml"
    list_extend: false
  tags:
    - deploy-openstack-user-config

- name: Deploy user_secrets file
  config_template:
    src: "{{ bootstrap_host_aio_config_path }}/user_secrets.yml"
    dest: "/etc/openstack_deploy/{{ bootstrap_host_user_secrets_filename }}"
    config_overrides: "{{ user_secrets_overrides | default({}) }}"
    config_type: "yaml"
  tags:
    - deploy-user-secrets

- name: Generate any missing values in user_secrets
  command: "/opt/ansible-runtime/bin/python {{ bootstrap_host_aio_script_path }}/pw-token-gen.py --file /etc/openstack_deploy/{{ bootstrap_host_user_secrets_filename }}"
  changed_when: false
  tags:
    - generate_secrets

- name: Detect whether the host is an OpenStack-CI host
  stat:
    path: /etc/nodepool
  register: nodepool_dir

- name: Set facts when inside of OpenStack-Infra
  when:
    - nodepool_dir.stat.exists
  block:
    - name: Discover the OpenStack-Infra mirrors
      shell: |
        source /etc/ci/mirror_info.sh
        NODEPOOL_OVERRIDES="/etc/openstack_deploy/user_openstackci.yml"
        echo "uca_apt_repo_url: '${NODEPOOL_UCA_MIRROR}'" >> ${NODEPOOL_OVERRIDES}
        echo "openstack_hosts_centos_mirror_url: '${NODEPOOL_CENTOS_MIRROR}'" >> ${NODEPOOL_OVERRIDES}
        echo "opensuse_mirror: '${NODEPOOL_OPENSUSE_MIRROR}'" >> ${NODEPOOL_OVERRIDES}
        echo "centos_epel_mirror: '${NODEPOOL_EPEL_MIRROR}'" >> ${NODEPOOL_OVERRIDES}
        echo "galera_percona_xtrabackup_repo_host: '${NODEPOOL_PERCONA_PROXY}'" >> ${NODEPOOL_OVERRIDES}
        echo "galera_repo_host: '${NODEPOOL_MIRROR_HOST}:8080'" >> ${NODEPOOL_OVERRIDES}
        echo "lxc_centos_package_baseurl: 'http://${NODEPOOL_MIRROR_HOST}:8080/copr-lxc2/epel-7-x86_64/'" >> ${NODEPOOL_OVERRIDES}
        echo "lxc_centos_package_key: 'http://${NODEPOOL_MIRROR_HOST}:8080/copr-lxc2/pubkey.gpg'" >> ${NODEPOOL_OVERRIDES}
        echo "nova_virt_type: 'qemu'" >> ${NODEPOOL_OVERRIDES}
        echo "repo_build_pip_default_index: '${NODEPOOL_PYPI_MIRROR}'" >> ${NODEPOOL_OVERRIDES}

        # NOTE(mnaser): We need to make sure we pull the latest RDO mirror
        #               which is hashed to avoid cache going stale during CI.
        export DLRN_BASE=${DLRN_BASE:-centos7-master/puppet-passed-ci}
        rdo_dlrn=`curl --silent ${NODEPOOL_RDO_PROXY}/${DLRN_BASE}/delorean.repo | grep baseurl | cut -d= -f2`
        if [[ -z "$rdo_dlrn" ]]; then
            echo "Failed to parse dlrn hash"
            exit 1
        fi
        RDO_MIRROR_HOST=${rdo_dlrn/https:\/\/trunk.rdoproject.org/$NODEPOOL_RDO_PROXY}
        echo "openstack_hosts_rdo_repo_url: '${RDO_MIRROR_HOST}'" >> ${NODEPOOL_OVERRIDES}
      args:
        executable: /bin/bash
      tags:
        - skip_ansible_lint

    - name: Discover the OpenStack-Infra pypi/wheel mirror
      shell: |
        source /etc/ci/mirror_info.sh
        echo "${NODEPOOL_PYPI_MIRROR}"
        echo "${NODEPOOL_WHEEL_MIRROR}"
      args:
        executable: /bin/bash
      register: _pypi_wheel_mirror
      tags:
        - skip_ansible_lint

    - name: Discover the OpenStack-Infra LXC reverse proxy
      shell: |
        source /etc/ci/mirror_info.sh
        echo ${NODEPOOL_LXC_IMAGE_PROXY}
      register: _lxc_mirror
      args:
        executable: /bin/bash
      tags:
        - skip_ansible_lint

    - name: Set the package cache timeout to 60 mins in OpenStack-CI
      set_fact:
        cache_timeout: 3600
      when:
        - cache_timeout is not defined

    # This is a very dirty hack due to images.linuxcontainers.org
    # constantly failing to resolve in openstack-infra.
    - name: Implement hard-coded hosts entries for consistently failing name
      lineinfile:
        path: "/etc/hosts"
        line: "{{ item }}"
        state: present
      with_items:
        - "91.189.91.21 images.linuxcontainers.org us.images.linuxcontainers.org"
        - "91.189.88.37 images.linuxcontainers.org uk.images.linuxcontainers.org"

- name: Set facts when outside of OpenStack-Infra
  when:
    - not nodepool_dir.stat.exists
  block:
    - name: Determine the fastest available OpenStack-Infra wheel mirror
      command: "{{ bootstrap_host_aio_script_path }}/fastest-infra-wheel-mirror.py"
      register: fastest_wheel_mirror

    - name: Set repo_build_pip_extra_indexes fact
      set_fact:
        repo_build_pip_extra_indexes: "{{ fastest_wheel_mirror.stdout_lines }}"

# NOTE(mhayden): The OpenStack CI images for CentOS 7 recently set SELinux to
# Enforcing mode by default. While I am normally a supporter of this change,
# the SELinux policy work for CentOS 7 is not done yet.
- name: Set SELinux to permissive mode in OpenStack-CI
  selinux:
    policy: targeted
    state: permissive
  when:
    - ansible_selinux.status == "enabled"

- name: Set the user_variables
  config_template:
    src: "{{ bootstrap_user_variables_template }}"
    dest: "/etc/openstack_deploy/{{ bootstrap_host_user_variables_filename }}"
    config_overrides: "{{ user_variables_overrides | default({}) }}"
    config_type: yaml

- name: Set http proxy user variables
  copy:
    src: "user_variables_proxy.yml"
    dest: "/etc/openstack_deploy/user_variables_proxy.yml"
  when:
    - "lookup('env', 'http_proxy')|length > 0"

- name: Drop the extra user_variables files for this scenario
  config_template:
    src: "{{ item.src }}"
    dest: "/etc/openstack_deploy/{{ item.dest }}"
    config_overrides: "{{ item.config_overrides | default({}) }}"
    config_type: yaml
  with_items: "{{ bootstrap_user_variables_extra_templates[bootstrap_host_scenario] | default([]) }}"

- name: Copy modified cinder-volume env.d file for ceph scenario
  copy:
    src: "{{ playbook_dir }}/../etc/openstack_deploy/env.d/cinder-volume.yml.container.example"
    dest: "/etc/openstack_deploy/env.d/cinder-volume.yml"
  when:
    - "bootstrap_host_scenario == 'ceph'"

- name: Copy modified env.d file for metal scenario
  copy:
    src: "{{ playbook_dir }}/../etc/openstack_deploy/env.d/aio_metal.yml.example"
    dest: "/etc/openstack_deploy/env.d/aio_metal.yml"
  when:
    - "bootstrap_host_scenario == 'aio_metal'"

- name: Create vars override folders if we need to test them
  file:
    path: "{{ item }}"
    state: directory
  with_items:
    - /etc/openstack_deploy/group_vars
    - /etc/openstack_deploy/host_vars
  when: "(lookup('env','ACTION') | default(false,true)) == 'varstest'"

- name: Create user-space overrides
  lineinfile:
    path: "{{ item.path }}"
    state: present
    line:  "{{ item.line }}"
    create: yes
  with_items:
    - path: /etc/openstack_deploy/group_vars/hosts.yml
      line: 'babar: "elephant"'
    - path: /etc/openstack_deploy/group_vars/hosts.yml
      line: 'lxc_hosts_package_state: "present"'
    - path: /etc/openstack_deploy/host_vars/localhost.yml
      line: 'security_package_state: "present"'
    - path: /etc/openstack_deploy/host_vars/localhost.yml
      line: 'tintin: "milou"'
  when: "(lookup('env','ACTION') | default(false,true)) == 'varstest'"

**********
DECISION===>: PASS
**********
=========================:::478:::END!!!=========================
=========================:::479:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/tests/roles/bootstrap-host/tasks/prepare_loopback_machines.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Create sparse machines file
  command: "truncate -s {{ bootstrap_host_loopback_machines_size }}G /openstack/machines.img"
  args:
    creates: /openstack/machines.img
  tags:
    - machines-file-create

- name: Format the machines file
  filesystem:
    fstype: btrfs
    opts: "{{ bootstrap_host_format_options['btrfs'] | default(omit) }}"
    dev: /openstack/machines.img
  tags:
    - machines-format-file

- name: Run the systemd mount role
  include_role:
    name: systemd_mount
    private: true
  vars:
    systemd_mounts:
      - what: "/openstack/machines.img"
        where: "/var/lib/machines"
        options: "loop,{{ bootstrap_host_data_mount_options['btrfs'] }}"
        type: "btrfs"
        state: 'started'
        enabled: true
  tags:
    - machines-config

**********
DECISION===>: PASS
**********
=========================:::479:::END!!!=========================
=========================:::480:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/tests/roles/bootstrap-host/tasks/main.yml
**********
---
# Copyright 2015, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Before we do anything, check the minimum requirements
- include: check-requirements.yml
  tags:
    - check-requirements

# We will look for the most specific variable files first and eventually
# end up with the least-specific files.
- name: Gather variables for each operating system
  include_vars: "{{ item }}"
  with_first_found:
    - "{{ ansible_distribution | lower }}-{{ ansible_distribution_version | lower }}.yml"
    - "{{ ansible_distribution | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
    - "{{ ansible_os_family | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
    - "{{ ansible_distribution | lower }}.yml"
    - "{{ ansible_os_family | lower }}.yml"
  tags:
    - always

- name: Create the required directories
  file:
    path: "{{ item }}"
    state: directory
  with_items:
    - "/openstack"
  tags:
    - create-directories

- include: install_packages.yml
  tags:
    - install-packages

# Prepare the data disk, if one is provided
- include: prepare_data_disk.yml
  when:
    - bootstrap_host_data_disk_device != None
  tags:
    - prepare-data-disk

# Prepare the swap space loopback disk
# This is only necessary if there isn't swap already
- include: prepare_loopback_swap.yml
  static: no
  when:
    - bootstrap_host_loopback_swap | bool
    - ansible_swaptotal_mb < 1
  tags:
    - prepare-loopback

# Prepare the Machines storage loopback disk
- include: prepare_loopback_machines.yml
  when:
    - bootstrap_host_loopback_machines | bool
    - bootstrap_host_data_disk_device == None
    - lxc_container_backing_store == 'machinectl' or bootstrap_host_container_tech == 'nspawn'
  tags:
    - prepare-loopback

# Prepare the zfs storage loopback disk
- include: prepare_loopback_zfs.yml
  when:
    - bootstrap_host_loopback_zfs | bool
    - bootstrap_host_data_disk_device == None
    - lxc_container_backing_store == 'zfs'
  tags:
    - prepare-loopback

# Prepare the btrfs storage loopback disk
- include: prepare_loopback_btrfs.yml
  when:
    - bootstrap_host_loopback_btrfs | bool
    - bootstrap_host_data_disk_device == None
    - lxc_container_backing_store == 'btrfs'
  tags:
    - prepare-loopback

# Prepare the Cinder LVM VG loopback disk
# This is only necessary if bootstrap_host_loopback_cinder is set to yes
- include: prepare_loopback_cinder.yml
  when:
    - bootstrap_host_loopback_cinder | bool
  tags:
    - prepare-loopback

# Prepare the Nova instance storage loopback disk
- include: prepare_loopback_nova.yml
  when:
    - bootstrap_host_loopback_nova | bool
  tags:
    - prepare-loopback

# Prepare the Swift data storage loopback disks
- include: prepare_loopback_swift.yml
  when:
    - bootstrap_host_loopback_swift | bool
  tags:
    - prepare-loopback

# Prepare the Ceph cluster UUID and loopback disks
- include: prepare_ceph.yml
  when:
    - bootstrap_host_ceph | bool
  tags:
    - prepare-ceph

# Ensure hostname/ip is consistent with inventory
- include: prepare_hostname.yml
  tags:
    - prepare-hostname

# Prepare the network interfaces
- include: prepare_networking.yml
  when:
    - bootstrap_host_container_tech != 'nspawn'
  tags:
    - prepare-networking

# Ensure that there are both private and public ssh keys for root
- include: prepare_ssh_keys.yml
  tags:
    - prepare-ssh-keys

# Put the OpenStack-Ansible configuration for an All-In-One on the host
- include: prepare_aio_config.yml
  when:
    - bootstrap_host_aio_config | bool
  tags:
    - prepare-aio-config

**********
DECISION===>: PASS
**********
=========================:::480:::END!!!=========================
=========================:::481:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/tests/roles/bootstrap-host/defaults/main.yml
**********
---
# Copyright 2015, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

## AIO user-space configuration options
# Scenario used to bootstrap the host
bootstrap_host_scenario: "{{ lookup('env','SCENARIO') | default('aio_lxc', true) }}"
#
# Boolean option to implement OpenStack-Ansible configuration for an AIO
# Switch to no for a multi-node configuration
bootstrap_host_aio_config: yes
#
# Path to the location of the bootstrapping configuration files
bootstrap_host_aio_config_path: "{{ playbook_dir }}/../etc/openstack_deploy"
#
# Path to the location of the scripts the bootstrap scripts use
bootstrap_host_aio_script_path: "{{ playbook_dir }}/../scripts"
#
# The user space configuration file names to use
bootstrap_host_user_variables_filename: "user_variables.yml"
bootstrap_host_user_secrets_filename: "user_secrets.yml"
#
# Paths to configuration file targets that should be created by the bootstrap
bootstrap_host_target_config_paths:
  - /etc/openstack_deploy
  - /etc/openstack_deploy/conf.d
  - /etc/openstack_deploy/env.d

# The user variables template to use
bootstrap_user_variables_template: user_variables.aio.yml.j2

# Extra user variables files can be loaded into /etc/openstack_deploy by
# test scenarios. The dict uses scenario as the key to load a list of extra
# templates if necessary.
bootstrap_user_variables_extra_templates:
  ceph:
    - src: user_variables_ceph.yml.j2
      dest: user_variables_ceph.yml
  congress:
    - src: user_variables_congress.yml.j2
      dest: user_variables_congress.yml
  translations:
    - src: user_variables_translations.yml.j2
      dest: user_variables_translations.yml
  barbican:
    - src: user_variables_barbican.yml.j2
      dest: user_variables_barbican.yml

## Loopback volumes
# Sparse loopback disks are used for the containers if there is no secondary
# disk available to partition for btrfs. They are also used for Ceph, Cinder,
# Swift and Nova (instance storage).
# The size of the loopback volumes can be customized here (in gigabytes).
#
# Boolean option to deploy the loopback disk for Swap
bootstrap_host_loopback_swap: yes
# Size of the Swap loopback disk in gigabytes (GB).
bootstrap_host_loopback_swap_size: 4096
#
# Boolean option to deploy the loopback disk for Cinder
bootstrap_host_loopback_cinder: yes
# Size of the Cinder loopback disk in gigabytes (GB).
bootstrap_host_loopback_cinder_size: 1024
#
# Boolean option to deploy the loopback disk for Swift
bootstrap_host_loopback_swift: yes
# Size of the Swift loopback disk in gigabytes (GB).
bootstrap_host_loopback_swift_size: 1024
#
# Boolean option to deploy the loopback disk for Nova
bootstrap_host_loopback_nova: yes
# Size of the Nova loopback disk in gigabytes (GB).
bootstrap_host_loopback_nova_size: 1024
#
# Boolean option to deploy the loopback disk for machines
bootstrap_host_loopback_machines: yes
# Size of the machines loopback disk in gigabytes (GB).
bootstrap_host_loopback_machines_size: 128
#
# Boolean option to deploy the loopback disk for btrfs
bootstrap_host_loopback_btrfs: yes
# Size of the btrfs loopback disk in gigabytes (GB).
bootstrap_host_loopback_btrfs_size: 1024
#
# Boolean option to deploy the loopback disk for btrfs
bootstrap_host_loopback_zfs: yes
# Size of the btrfs loopback disk in gigabytes (GB).
bootstrap_host_loopback_zfs_size: 1024
#
# Boolean option to deploy the OSD loopback disks and cluster UUID for Ceph
bootstrap_host_ceph: "{{ (bootstrap_host_scenario == 'ceph') | bool }}"
# Size of the Ceph OSD loopbacks
bootstrap_host_loopback_ceph_size: 1024
# Ceph OSDs to create on the AIO host
ceph_osd_images:
  - 'ceph1'
  - 'ceph2'
  - 'ceph3'

## Network configuration
# Default network IP ranges
mgmt_range: "172.29.236"
vxlan_range: "172.29.240"
storage_range: "172.29.244"
vlan_range: "172.29.248"
netmask: "255.255.252.0"
#
# NICs
bootstrap_host_public_interface: "{{ ansible_default_ipv4.interface }}"
#
# Utility paths
bootstrap_host_network_utils:
  apt:
    iptables: /sbin/iptables
    ethtool: /sbin/ethtool
    ip: /sbin/ip
  yum:
    iptables: /usr/sbin/iptables
    ethtool: /usr/sbin/ethtool
    ip: /usr/sbin/ip
  zypper:
    iptables: /usr/sbin/iptables
    ethtool: /sbin/ethtool
    ip: /sbin/ip
#
bootstrap_host_iptables_path: "{{ bootstrap_host_network_utils[ansible_pkg_mgr]['iptables'] }}"
bootstrap_host_ethtool_path: "{{ bootstrap_host_network_utils[ansible_pkg_mgr]['ethtool'] }}"
bootstrap_host_ip_path: "{{ bootstrap_host_network_utils[ansible_pkg_mgr]['ip'] }}"

## Extra storage
# An AIO may optionally be built using a second storage device. If a
# secondary disk device to use is not specified, then the AIO will be
# built on any existing disk partitions.
#
# WARNING: The data on a secondary storage device specified here will
# be destroyed and repartitioned.
#
# Specify the secondary disk device to use. When the data disk is in use, no NOT
# set the full path to the device. IE: "/dev/xvde" should be "xvde".
bootstrap_host_data_disk_device: null
#
# Specify the default filesystem type
bootstrap_host_data_disk_fs_type: ext4
#
# Boolean value to force the repartitioning of the secondary device.
bootstrap_host_data_disk_device_force: no
#
# If the storage capacity on this device is greater than or equal to this
# size (in GB), the bootstrap process will use it.
bootstrap_host_data_disk_min_size: 50
#
# Set the data disk formats table. If the backing store is set to lvm the option
# the partition will not actually be formatted however for parted, ext2 is used.
bootstrap_host_data_disk2_formats:
  machinectl: btrfs
  zfs: zfs
  btrfs: btrfs
  xfs: xfs
  dir: ext4
  lvm: ext2

bootstrap_host_format_options:
  machinectl: '--metadata single --data single --mixed'
  btrfs: '--metadata single --data single --mixed'
  xfs: '-K -d agcount=64 -l size=128m'
  ext4: '-O dir_index'

#
# Set the data disk mount options.
bootstrap_host_data_mount_options:
  machinectl: "noatime,nodiratime,compress=lzo,commit=120,{{ (ansible_kernel is version_compare('4.5', '>=')) | ternary('space_cache=v2', 'space_cache') }}"
  zfs: "defaults"
  btrfs: "noatime,nodiratime,compress=lzo,commit=120,{{ (ansible_kernel is version_compare('4.5', '>=')) | ternary('space_cache=v2', 'space_cache') }}"
  xfs: "noatime,nodiratime,nobarrier,logbufs=8,logbsize=256k"
  ext4: "noatime,nobh,barrier=0,data=writeback"
  dir: "defaults"
  lvm: "defaults"
  swap: "%%"

bootstrap_host_data_disk2_fs: "{{ bootstrap_host_data_disk2_formats[((bootstrap_host_container_tech == 'nspawn') | ternary('btrfs', lxc_container_backing_store))] }}"
bootstrap_host_data_disk2_fs_mount_options: "{{ bootstrap_host_data_mount_options[((bootstrap_host_container_tech == 'nspawn') | ternary('btrfs', lxc_container_backing_store))] }}"
bootstrap_host_data_disk2_path: "{{ (lxc_container_backing_store == 'machinectl' or bootstrap_host_container_tech == 'nspawn') | ternary('/var/lib/machines', '/var/lib/lxc') }}"

### Optional Settings ###

# Specify the public IP address for the host.
# By default the address will be set to the ipv4 address of the
# host's network interface that has the default route on it.
#bootstrap_host_public_address: 0.0.0.0

# Set the install method for the deployment. Options are ['source', 'distro']
bootstrap_host_install_method: "{{ lookup('env', 'INSTALL_METHOD') | default('source', true)  }}"

# Set the container technology in service. Options are nspawn and lxc.
bootstrap_host_container_tech: "{{ (bootstrap_host_scenario is search('nspawn')) | ternary('nspawn', 'lxc') }}"

# Set the lxc backing store for the job
lxc_container_backing_store: dir

**********
DECISION===>: PASS
**********
=========================:::481:::END!!!=========================
=========================:::482:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/tests/roles/bootstrap-host/files/user_variables_proxy.yml
**********
---
no_proxy_env: "localhost,127.0.0.1,{{ internal_lb_vip_address }},{{ external_lb_vip_address }},{% for host in groups['all_containers'] %}{{ hostvars[host]['container_address'] }}{% if not loop.last %},{% endif %}{% endfor %}"
http_proxy_env: "{{ lookup('env', 'http_proxy') }}"
https_proxy_env: "{{ lookup('env', 'https_proxy') }}"
global_environment_variables:
   HTTP_PROXY: "{{ http_proxy_env }}"
   HTTPS_PROXY: "{{ https_proxy_env }}"
   http_proxy: "{{ http_proxy_env }}"
   https_proxy: "{{ https_proxy_env }}"
   NO_PROXY: "{{ no_proxy_env }}"
   no_proxy: "{{ no_proxy_env }}"

**********
DECISION===>: PASS
**********
=========================:::482:::END!!!=========================
=========================:::483:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/repo-use.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Configure all nodes to use the repo container for python/apt packages
  hosts: "{{ openstack_host_group | default('hosts') }}:all_containers"
  vars:
    pip_install: no
    pip_configure: yes
  vars_files:
    - "defaults/repo_packages/openstack_services.yml"
    - "defaults/{{ install_method }}_install.yml"
  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - always
    - repo-config
  pre_tasks:
    - include: common-tasks/package-cache-proxy.yml
    - include: common-tasks/set-pip-vars.yml
  roles:
    - pip_install

**********
DECISION===>: PASS
**********
=========================:::483:::END!!!=========================
=========================:::484:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/os-ceilometer-install.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Install the ceilometer components
  hosts: ceilometer_all
  gather_facts: "{{ osa_gather_facts | default(True) }}"
  user: root
  vars_files:
    - "defaults/{{ install_method }}_install.yml"
  pre_tasks:
    - include: "common-tasks/os-{{ container_tech | default('lxc') }}-container-setup.yml"
      static: no
      when: not is_metal

    - include: common-tasks/os-log-dir-setup.yml
      vars:
        log_dirs:
          - src: "/openstack/log/{{ inventory_hostname }}-ceilometer"
            dest: "/var/log/ceilometer"
    - include: common-tasks/unbound-clients.yml
      static: no
      when:
        - hostvars['localhost']['resolvconf_enabled'] | bool
  roles:
    - role: "os_ceilometer"

  post_tasks:
    - include_tasks: "common-tasks/rsyslog-client.yml"
      vars:
        rsyslog_client_log_rotate_file: ceilometer_log_rotate
        rsyslog_client_log_dir: "/var/log/ceilometer"
        rsyslog_client_config_name: "99-ceilometer-rsyslog-client.conf"

  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - ceilometer

**********
DECISION===>: PASS
**********
=========================:::484:::END!!!=========================
=========================:::485:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/openstack-hosts-setup.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# NOTE(mhayden): CentOS always has python (because of yum), but it's possible
# that Ubuntu nodes may not have python by default. Ansible doesn't work very
# well if Python isn't installed.
#
# Also, we can't use a 'when' to check for the ansible_pkg_mgr here because
# we haven't gathered facts yet.
- name: Install Ansible prerequisites
  hosts: "{{ openstack_host_group|default('hosts') }}"
  gather_facts: false
  user: root
  pre_tasks:
    - name: Ensure python is installed
      register: result
      raw: |
        if which apt-get >/dev/null && ! which python >/dev/null ; then
          apt-get -y install python
          exit 2
        else
          exit 0
        fi
      changed_when: "result.rc == 2"
      failed_when: "result.rc not in [0, 2]"

- name: Basic host setup
  hosts: "{{ openstack_host_group|default('hosts') }}"
  gather_facts: "{{ osa_gather_facts | default(True) }}"
  user: root
  pre_tasks:
    - name: Check for a supported Operating System
      assert:
        that:
          - (ansible_distribution == 'Ubuntu' and ansible_distribution_release == 'xenial') or
            (ansible_distribution == 'Ubuntu' and ansible_distribution_release == 'bionic') or
            (ansible_os_family == 'RedHat' and ansible_distribution_major_version == '7') or
            (ansible_os_family == 'Suse' and ansible_distribution_major_version in ['15', '42'])
        msg: "The only supported platforms for this release are Ubuntu 16.04 LTS (Xenial), Ubuntu 18.04 LTS (Bionic),  CentOS 7 (WIP) and openSUSE Leap 42.X and openSUSE Leap 15.X"

    - include: common-tasks/package-cache-proxy.yml
      when: install_method == "source"
    - include: common-tasks/set-pip-vars.yml
      when: install_method == "source"
  roles:
    - role: "openstack_hosts"
  vars_files:
    - defaults/repo_packages/openstack_services.yml
    - "defaults/{{ install_method }}_install.yml"
  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - openstack-hosts

**********
DECISION===>: PASS
**********
=========================:::485:::END!!!=========================
=========================:::486:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/rsyslog-install.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Install rsyslog
  hosts: rsyslog
  gather_facts: "{{ osa_gather_facts | default(True) }}"
  user: root
  pre_tasks:
    # The systemd-journal-remote capability has taken over this functionality.
    - name: End playbook if disabled
      meta: end_play
      when:
        - not rsyslog_server_enabled | bool

    - include: "common-tasks/os-{{ container_tech | default('lxc') }}-container-setup.yml"
      static: no
      vars:
        list_of_bind_mounts:
          - bind_dir_path: "{{ rsyslog_server_storage_directory }}"
            mount_path: "/openstack/{{ inventory_hostname }}/log-storage"
        extra_container_config_no_restart:
          - "lxc.start.order=19"
      when: not is_metal

    - include: common-tasks/unbound-clients.yml
      static: no
      when:
        - hostvars['localhost']['resolvconf_enabled'] | bool
  roles:
    - role: "rsyslog_server"
      tags:
        - rsyslog
    - role: "system_crontab_coordination"
      tags:
        - crontab
  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - rsyslog

**********
DECISION===>: PASS
**********
=========================:::486:::END!!!=========================
=========================:::487:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/etcd-install.yml
**********
---
# Copyright 2016, Logan Vig <logan2211@gmail.com>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Install etcd server cluster
  hosts: etcd_all
  gather_facts: "{{ osa_gather_facts | default(True) }}"
  user: root
  pre_tasks:
    - include: "common-tasks/os-{{ container_tech | default('lxc') }}-container-setup.yml"
      static: no
      when: not is_metal
    - include: common-tasks/unbound-clients.yml
      static: no
      when:
        - hostvars['localhost']['resolvconf_enabled'] | bool
  roles:
    - role: "etcd"
      etcd_install_type: server
      tags:
        - etcd-server
    - role: "system_crontab_coordination"
  environment: "{{ deployment_environment_variables | default({}) }}"

**********
DECISION===>: PASS
**********
=========================:::487:::END!!!=========================
=========================:::488:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/os-heat-install.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Install heat server
  hosts: heat_all
  gather_facts: "{{ osa_gather_facts | default(True) }}"
  user: root
  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - heat
  vars_files:
    - defaults/repo_packages/openstack_services.yml
    - "defaults/{{ install_method }}_install.yml"
  pre_tasks:
    - include: "common-tasks/os-{{ container_tech | default('lxc') }}-container-setup.yml"
      static: no
      when: not is_metal

    - include: common-tasks/os-log-dir-setup.yml
      vars:
        log_dirs:
          - src: "/openstack/log/{{ inventory_hostname }}-heat"
            dest: "/var/log/heat"

    - include: common-tasks/unbound-clients.yml
      static: no
      when:
        - hostvars['localhost']['resolvconf_enabled'] | bool
  roles:
    - role: "os_heat"
    - role: "system_crontab_coordination"
      tags:
        - crontab

  post_tasks:
    - include_tasks: "common-tasks/rsyslog-client.yml"
      vars:
        rsyslog_client_log_rotate_file: heat_log_rotate
        rsyslog_client_log_dir: "/var/log/heat"
        rsyslog_client_config_name: "99-heat-rsyslog-client.conf"

**********
DECISION===>: PASS
**********
=========================:::488:::END!!!=========================
=========================:::489:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/repo-install.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- include: repo-server.yml
- include: repo-build.yml

**********
DECISION===>: PASS
**********
=========================:::489:::END!!!=========================
=========================:::490:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/ceph-rgw-keystone-setup.yml
**********
---
# Copyright 2017, Logan Vig <logan2211@gmail.com>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Configure keystone for radosgw
  hosts: "{{ openstack_service_setup_host | default('localhost') }}"
  user: root
  vars_files:
    - "defaults/{{ install_method }}_install.yml"
  vars:
    ansible_python_interpreter: >-
      {{ ((openstack_service_setup_host | default('localhost')) == 'localhost') | ternary(ansible_playbook_python, ansible_python['executable']) }}
  tags:
    - ceph-rgw
    - ceph-rgw-setup
    - rgw-service-add
  tasks:
    - name: Add service to the keystone service catalog
      os_keystone_service:
        cloud: default
        state: present
        name: "{{ radosgw_service_name }}"
        service_type: "{{ radosgw_service_type }}"
        description: "{{ radosgw_service_description }}"
        interface: admin
        verify: "{{ not (keystone_service_adminuri_insecure | bool) }}"
      register: add_service
      until: add_service is success
      retries: 5
      delay: 10
      tags:
        - ceph-rgw-setup
        - rgw-service-add

    - name: Add service user
      os_user:
        cloud: default
        state: present
        name: "{{ radosgw_admin_user }}"
        password: "{{ radosgw_admin_password }}"
        domain: default
        default_project: "{{ radosgw_admin_tenant }}"
        interface: admin
        verify: "{{ not (keystone_service_adminuri_insecure | bool) }}"
      register: add_user
      until: add_user is success
      retries: 5
      delay: 10
      no_log: True

    - name: Add service user to roles
      os_user_role:
        cloud: default
        state: present
        user: "{{ radosgw_admin_user }}"
        role: "{{ radosgw_role_name | default('admin') }}"
        project: "{{ radosgw_admin_tenant }}"
        interface: admin
        verify: "{{ not (keystone_service_adminuri_insecure | bool) }}"
      register: add_user_role
      until: add_user_role is success
      retries: 5
      delay: 10

    - name: Add service role
      os_keystone_role:
        cloud: default
        state: present
        name: "swiftoperator"
        interface: admin
        verify: "{{ not (keystone_service_adminuri_insecure | bool) }}"
      register: add_role
      until: add_role is success
      retries: 5
      delay: 10

    - name: Add endpoints to keystone endpoint catalog
      os_keystone_endpoint:
        cloud: default
        state: present
        service: "{{ radosgw_service_name }}"
        endpoint_interface: "{{ item.interface }}"
        url: "{{ item.url }}"
        region: "{{ radosgw_service_region }}"
        interface: admin
        verify: "{{ not (keystone_service_adminuri_insecure | bool) }}"
      register: add_service
      until: add_service is success
      retries: 5
      delay: 10
      with_items:
        - interface: "public"
          url: "{{ radosgw_service_publicurl }}"
        - interface: "internal"
          url: "{{ radosgw_service_internalurl }}"
        - interface: "admin"
          url: "{{ radosgw_service_adminurl }}"

**********
DECISION===>: PASS
**********
=========================:::490:::END!!!=========================
=========================:::491:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/setup-hosts.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- include: openstack-hosts-setup.yml
- include: security-hardening.yml
- include: containers-deploy.yml

**********
DECISION===>: PASS
**********
=========================:::491:::END!!!=========================
=========================:::492:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/lxc-containers-create.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Set lxc containers group
  hosts: "{{ container_group | default('all_containers') }}"
  gather_facts: false
  vars_files:
    - "defaults/{{ install_method }}_install.yml"
  tasks:
    - name: Add hosts to dynamic inventory group
      group_by:
        key: lxc_containers
        parents: all_lxc_containers
      when:
        - container_tech == 'lxc'
  tags:
    - always
    - lxc-containers-create

- name: Create container(s)
  hosts: all_lxc_containers
  user: root
  gather_facts: false
  vars_files:
    - "defaults/{{ install_method }}_install.yml"
  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - lxc-containers-create
  roles:
    - role: "lxc_container_create"
  post_tasks:
    - name: Wait for container connectivity
      wait_for_connection:
        connect_timeout: "{{ lxc_container_wait_params.connect_timeout | default(omit) }}"
        delay: "{{ lxc_container_wait_params.delay | default(omit) }}"
        sleep: "{{ lxc_container_wait_params.sleep | default(omit) }}"
        timeout: "{{ lxc_container_wait_params.timeout | default(omit) }}"

    # When using gather_facts with smart gathering,
    # the facts aren't fully updated unless they
    # are old. Using the setup module in a task
    # does a more thorough collection.
    # Given we've just created the container, it is
    # best that we do a full collection of facts -
    # otherwise we end up with a stale set which
    # has stuff like the hostname = localhost.
    - name: Gather facts for new container(s)
      setup:
        gather_subset: "network,hardware,virtual"

- name: Configure containers default software
  hosts: all_lxc_containers
  user: root
  gather_facts: true
  vars_files:
    - defaults/repo_packages/openstack_services.yml
    - "defaults/{{ install_method }}_install.yml"
  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - lxc-containers-create
  pre_tasks:
    - include: common-tasks/package-cache-proxy.yml
      when: install_method == "source"
    - include: common-tasks/set-pip-vars.yml
      when: install_method == "source"
  roles:
    - role: "openstack_hosts"
      is_container: true

**********
DECISION===>: PASS
**********
=========================:::492:::END!!!=========================
=========================:::493:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/memcached-install.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Install memcached
  hosts: memcached
  gather_facts: "{{ osa_gather_facts | default(True) }}"
  user: root
  pre_tasks:
    - include: "common-tasks/os-{{ container_tech | default('lxc') }}-container-setup.yml"
      static: no
      when: not is_metal
    - include: common-tasks/os-log-dir-setup.yml
      vars:
        log_dirs:
          - src: "/openstack/log/{{ inventory_hostname }}-memcached"
            dest: "/var/log/memcached"
    - include: common-tasks/unbound-clients.yml
      static: no
      when:
        - hostvars['localhost']['resolvconf_enabled'] | bool
  roles:
    - role: "memcached_server"
    - role: "system_crontab_coordination"
      tags:
        - crontab

  post_tasks:
    - include_tasks: "common-tasks/rsyslog-client.yml"
      vars:
        rsyslog_client_log_rotate_file: memcached_log_rotate
        rsyslog_client_log_dir: "/var/log/memcached"
        rsyslog_client_config_name: "99-memcached-rsyslog-client.conf"

  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - memcached

**********
DECISION===>: PASS
**********
=========================:::493:::END!!!=========================
=========================:::494:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/os-sahara-install.yml
**********
---
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Install sahara server
  hosts: sahara_all
  gather_facts: "{{ osa_gather_facts | default(True) }}"
  user: root
  environment: "{{ deployment_environment_variables | default({}) }}"
  vars_files:
    - "defaults/{{ install_method }}_install.yml"
  tags:
    - sahara
  pre_tasks:
    - include: "common-tasks/os-{{ container_tech | default('lxc') }}-container-setup.yml"
      static: no
      when: not is_metal

    - include: common-tasks/os-log-dir-setup.yml
      vars:
        log_dirs:
          - src: "/openstack/log/{{ inventory_hostname }}-sahara"
            dest: "/var/log/sahara"

    - include: common-tasks/unbound-clients.yml
      static: no
      when:
        - hostvars['localhost']['resolvconf_enabled'] | bool
  roles:
    - role: "os_sahara"

  post_tasks:
    - include_tasks: "common-tasks/rsyslog-client.yml"
      vars:
        rsyslog_client_log_rotate_file: sahara_log_rotate
        rsyslog_client_log_dir: "/var/log/sahara"
        rsyslog_client_config_name: "99-sahara-rsyslog-client.conf"

**********
DECISION===>: PASS
**********
=========================:::494:::END!!!=========================
=========================:::495:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/os-designate-install.yml
**********
---
# Copyright 2016 Internet Solutions (Pty) Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# (c) 2016 Donovan Francesco <donovan.francesco@is.co.za>
# (c) 2016 Paul Stevens <paul.stevens@is.co.za>

- name: Install designate server
  hosts: designate_all
  gather_facts: "{{ osa_gather_facts | default(True) }}"
  user: root
  environment: "{{ deployment_environment_variables | default({}) }}"
  vars_files:
    - "defaults/{{ install_method }}_install.yml"
  tags:
    - designate
  pre_tasks:
    - include: "common-tasks/os-{{ container_tech | default('lxc') }}-container-setup.yml"
      static: no
      when: not is_metal

    - include: common-tasks/os-log-dir-setup.yml
      vars:
        log_dirs:
          - src: "/openstack/log/{{ inventory_hostname }}-designate"
            dest: "/var/log/designate"

    - include: common-tasks/unbound-clients.yml
      static: no
      when:
        - hostvars['localhost']['resolvconf_enabled'] | bool
  roles:
    - role: "os_designate"

  post_tasks:
    - include_tasks: "common-tasks/rsyslog-client.yml"
      vars:
        rsyslog_client_log_rotate_file: designate_log_rotate
        rsyslog_client_log_dir: "/var/log/designate"
        rsyslog_client_config_name: "99-designate-rsyslog-client.conf"

**********
DECISION===>: PASS
**********
=========================:::495:::END!!!=========================
=========================:::496:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/ceph-install.yml
**********
---
# Copyright 2016, Logan Vig <logan2211@gmail.com>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Install ceph mons
  hosts: ceph-mon
  user: root
  vars_files:
    - "defaults/{{ install_method }}_install.yml"
  pre_tasks:
    - include: common-tasks/os-log-dir-setup.yml
      vars:
        log_dirs:
          - src: "/openstack/log/{{ inventory_hostname }}-ceph"
            dest: "/var/log/ceph"
    - include: "common-tasks/os-{{ container_tech | default('lxc') }}-container-setup.yml"
      when: not is_metal
      static: no
      vars:
        list_of_bind_mounts: "{{ ceph_container_bind_mounts }}"
    - include: common-tasks/unbound-clients.yml
      static: no
      when:
        - hostvars['localhost']['resolvconf_enabled'] | bool
    #TODO: mgariepy, revisit to use include_role when https://github.com/ansible/ansible/issues/20077 is fixed
    - name: install the ceph stable repository key
      rpm_key:
        key: "{{ ceph_stable_key }}"
        state: present
      when:
        - ceph_origin == 'repository'
        - ceph_repository == 'community'
        - ansible_pkg_mgr in ['yum', 'dnf']
    - name: add ceph stable repository
      package:
        name: http://download.ceph.com/rpm-{{ ceph_stable_release }}/{{ ceph_stable_redhat_distro }}/noarch/ceph-release-1-0.{{ ceph_stable_redhat_distro|replace('rhel', 'el') }}.noarch.rpm
        state: present
      changed_when: false
      when:
        - ceph_origin == 'repository'
        - ceph_repository == 'community'
        - ansible_pkg_mgr in ['yum', 'dnf']
    - name: Purge yum/dnf cache
      command: "{{ ansible_pkg_mgr }} clean all"
      when:
        - ansible_pkg_mgr in ['yum', 'dnf']
      tags:
        - skip_ansible_lint
    - name: Set default priority for Ceph repos
      command: >
         yum-config-manager
           --enable Ceph
           --setopt="Ceph.priority=99"
           --enable Ceph-noarch
           --setopt="Ceph-noarch.priority=99"
      when:
        - ansible_pkg_mgr in ['yum', 'dnf']
    - name: Create systemd service directory
      file:
        path: "/etc/systemd/system/ceph-mon@.service.d/"
        state: directory
        group: "root"
        owner: "root"
        mode: "0755"
      when:
        - ansible_pkg_mgr in ['yum', 'dnf']
        - ansible_service_mgr == 'systemd'
    - name: Add systemd override for PrivateDevices
      copy:
        dest: "/etc/systemd/system/ceph-mon@.service.d/ceph-mon-systemd-overrides.conf"
        content: |
          [Service]
          PrivateDevices=false
      when:
        - ansible_pkg_mgr in ['yum', 'dnf']
        - ansible_service_mgr == 'systemd'
    - name: Ensure Ansible can work with SELinux
      package:
        name: libselinux-python
        state: present
      when:
        - ansible_pkg_mgr in ['yum', 'dnf']

    # Set the priority of the ceph community apt repo either above or below that of UCA or distro sources
    - name: Set apt package pins
      include_role:
        name: apt_package_pinning
      vars:
        apt_package_pinning_file_name: "ceph_community_pin.pref"
        apt_package_pinning_priority: "{{ (ceph_repository == 'community') | ternary(1000, 100) }}"
        apt_pinned_packages: [{ package: '*', release: 'ceph.com' }]
      when:
        - ansible_pkg_mgr == 'apt'

  roles:
    - role: ceph-defaults
      tags:
        - skip_ansible_lint
    - role: ceph-handler
      tags:
        - skip_ansible_lint
    - role: ceph-common
      tags:
        - skip_ansible_lint
    - role: ceph-config
      tags:
        - skip_ansible_lint
    - role: ceph-mon
      tags:
        - skip_ansible_lint
    - role: ceph-mgr
      tags:
        - skip_ansible_lint
    - role: system_crontab_coordination
      tags:
        - crontab

  post_tasks:
    - include_tasks: "common-tasks/rsyslog-client.yml"
      vars:
        rsyslog_client_log_rotate_file: ceph_log_rotate
        rsyslog_client_log_dir: "/var/log/ceph"
        rsyslog_client_config_name: "99-ceph-rsyslog-client.conf"

  vars:
    ansible_python_interpreter: "/usr/bin/python"
  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - ceph
    - ceph-mon

- name: Install ceph osds
  hosts: ceph-osd
  user: root
  vars_files:
    - "defaults/{{ install_method }}_install.yml"
  pre_tasks:
    - include: common-tasks/os-log-dir-setup.yml
      vars:
        log_dirs:
          - src: "/openstack/log/{{ inventory_hostname }}-ceph"
            dest: "/var/log/ceph"
    - include: common-tasks/unbound-clients.yml
      static: no
      when:
        - hostvars['localhost']['resolvconf_enabled'] | bool
    #TODO: mgariepy, revisit to use include_role when https://github.com/ansible/ansible/issues/20077 is fixed
    - name: install the ceph stable repository key
      rpm_key:
        key: "{{ ceph_stable_key }}"
        state: present
      when:
        - ceph_origin == 'repository'
        - ceph_repository == 'community'
        - ansible_pkg_mgr in ['yum', 'dnf']
    - name: add ceph stable repository
      package:
        name: http://download.ceph.com/rpm-{{ ceph_stable_release }}/{{ ceph_stable_redhat_distro }}/noarch/ceph-release-1-0.{{ ceph_stable_redhat_distro|replace('rhel', 'el') }}.noarch.rpm
        state: present
      changed_when: false
      when:
        - ceph_origin == 'repository'
        - ceph_repository == 'community'
        - ansible_pkg_mgr in ['yum', 'dnf']
    - name: Purge yum/dnf cache
      command: "{{ ansible_pkg_mgr }} clean all"
      when:
        - ansible_pkg_mgr in ['yum', 'dnf']
      tags:
        - skip_ansible_lint
    - name: Set default priority for Ceph repos
      command: >
         yum-config-manager
           --enable Ceph
           --setopt="Ceph.priority=99"
           --enable Ceph-noarch
           --setopt="Ceph-noarch.priority=99"
      when:
        - ansible_pkg_mgr in ['yum', 'dnf']
    - name: Gather ceph-mon facts
      action: setup
      delegate_to: "{{ item }}"
      delegate_facts: yes
      with_items: "{{ groups[mon_group_name] }}"
      when:
        - inventory_hostname == ansible_play_hosts[0]
      tags:
        - ceph-osd
        - ceph-mon-facts

    # Set the priority of the ceph community apt repo either above or below that of UCA or distro sources
    - name: Set apt package pins
      include_role:
        name: apt_package_pinning
      vars:
        apt_package_pinning_file_name: "ceph_community_pin.pref"
        apt_package_pinning_priority: "{{ (ceph_repository == 'community') | ternary(1000, 100) }}"
        apt_pinned_packages: [{ package: '*', release: 'ceph.com' }]
      when:
        - ansible_pkg_mgr == 'apt'

  roles:
    - role: ceph-defaults
      tags:
        - skip_ansible_lint
    - role: ceph-handler
      tags:
        - skip_ansible_lint
    - role: ceph-common
      tags:
        - skip_ansible_lint
    - role: ceph-config
      tags:
        - skip_ansible_lint
    - role: ceph-osd
      tags:
        - skip_ansible_lint
    - role: system_crontab_coordination
      tags:
        - crontab

  post_tasks:
    - include_tasks: "common-tasks/rsyslog-client.yml"
      vars:
        rsyslog_client_log_rotate_file: ceph_log_rotate
        rsyslog_client_log_dir: "/var/log/ceph"
        rsyslog_client_config_name: "99-ceph-rsyslog-client.conf"

  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - ceph
    - ceph-osd

**********
DECISION===>: Use of HTTP without TLS
**********
=========================:::496:::END!!!=========================
=========================:::497:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/os-gnocchi-install.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Install Gnocchi components
  hosts: gnocchi_all
  user: root
  environment: "{{ deployment_environment_variables | default({}) }}"
  vars_files:
    - "defaults/{{ install_method }}_install.yml"
  tags:
    - gnocchi
  pre_tasks:
    - include: "common-tasks/os-{{ container_tech | default('lxc') }}-container-setup.yml"
      vars:
        list_of_bind_mounts: "{{ gnocchi_container_bind_mounts }}"
      static: no
      when:
        - (gnocchi_storage_driver == "file") or (gnocchi_storage_driver is not defined)
        - not is_metal

    - include: "common-tasks/os-{{ container_tech | default('lxc') }}-container-setup.yml"
      static: no
      when:
        - not is_metal
        - gnocchi_storage_driver is defined
        - gnocchi_storage_driver != "file"

    - include: common-tasks/os-log-dir-setup.yml
      vars:
        log_dirs:
          - src: "/openstack/log/{{ inventory_hostname }}-gnocchi"
            dest: "/var/log/gnocchi"

    - include: common-tasks/unbound-clients.yml
      static: no
      when:
        - hostvars['localhost']['resolvconf_enabled'] | bool
  roles:
    - role: "ceph_client"
      openstack_service_system_user: "{{ gnocchi_system_user_name }}"
      openstack_service_venv_bin: ""
      when:
        - inventory_hostname in groups['gnocchi_api']
        - (gnocchi_storage_driver | default('none') | lower == 'ceph')
      tags:
        - ceph

    - role: "os_gnocchi"

  post_tasks:
    - include_tasks: "common-tasks/rsyslog-client.yml"
      vars:
        rsyslog_client_log_rotate_file: gnocchi_log_rotate
        rsyslog_client_log_dir: "/var/log/gnocchi"
        rsyslog_client_config_name: "99-gnocchi-rsyslog-client.conf"

**********
DECISION===>: PASS
**********
=========================:::497:::END!!!=========================
=========================:::498:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/listening-port-report.yml
**********
# Copyright 2018, BBC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Gather listening ports report
  hosts: all
  gather_facts: no
  tasks:
    - name: Gather listening ports
      command: netstat -ln --inet --program
      register: listening_ports

    - name: create report
      copy:
        content: |
          {% for host in ansible_play_hosts %}
          hostname: {{ host }}
          listening_ports:
          {% for port in hostvars[host].listening_ports['stdout_lines'] %}
          {{ port }}
          {% endfor %}

          {% endfor %}
        dest: /tmp/listening_port_report.txt
      delegate_to: localhost
      run_once: true

**********
DECISION===>: PASS
**********
=========================:::498:::END!!!=========================
=========================:::499:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/os-cinder-install.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Install cinder scheduler services
  include: common-playbooks/cinder.yml
  vars:
    cinder_hosts: "cinder_scheduler:!cinder_api"
    cinder_serial: "{{ cinder_scheduler_serial | default(['1', '100%']) }}"



- name: Install cinder volume services
  include: common-playbooks/cinder.yml
  vars:
    cinder_hosts: "cinder_volume:!cinder_scheduler:!cinder_api"
    cinder_serial: "{{ cinder_backend_serial | default('1', '100%') }}"



- name: Install cinder backup services
  include: common-playbooks/cinder.yml
  vars:
    cinder_hosts: "cinder_backup:!cinder_volume:!cinder_scheduler:!cinder_api"
    cinder_serial: "{{ cinder_backend_serial | default(['1', '100%']) }}"



- name: Install cinder API services
  include: common-playbooks/cinder.yml
  vars:
    cinder_hosts: "cinder_api"
    cinder_serial: "{{ cinder_api_serial | default(['1', '100%']) }}"



# These facts are set against the deployment host to ensure that
# they are fast to access. This is done in preference to setting
# them against each target as the hostvars extraction will take
# a long time if executed against a large inventory.
- name: Refresh local facts after all software changes are made
  hosts: cinder_all
  gather_facts: no
  user: root
  environment: "{{ deployment_environment_variables | default({}) }}"
  vars_files:
    - "defaults/{{ install_method }}_install.yml"
  tags:
    - cinder
  tasks:
    - name: refresh local facts
      setup:
        filter: ansible_local
        gather_subset: "!all"

    # This variable contains the values of the local fact set for the cinder
    # venv tag for all hosts in the 'cinder_all' host group.
    - name: Gather software version list
      set_fact:
        cinder_all_software_versions: "{{ (groups['cinder_all'] | map('extract', hostvars, ['ansible_local', 'openstack_ansible', 'cinder', 'venv_tag'])) | list }}"
      delegate_to: localhost
      run_once: yes

    # This variable outputs a boolean value which is True when
    # cinder_all_software_versions contains a list of defined
    # values. If they are not defined, it means that not all
    # hosts have their software deployed yet.
    - name: Set software deployed fact
      set_fact:
        cinder_all_software_deployed: "{{ (cinder_all_software_versions | select('defined')) | list == cinder_all_software_versions }}"
      delegate_to: localhost
      run_once: yes

    # This variable outputs a boolean when all the values in
    # cinder_all_software_versions are the same and the software
    # has been deployed to all hosts in the group.
    - name: Set software updated fact
      set_fact:
        cinder_all_software_updated: "{{ ((cinder_all_software_versions | unique) | length == 1) and (cinder_all_software_deployed | bool) }}"
      delegate_to: localhost
      run_once: yes



- name: Restart cinder agents to ensure new RPC object version is used
  hosts: cinder_backup,cinder_volume,cinder_scheduler
  gather_facts: no
  serial: "{{ cinder_backend_serial | default(['1', '100%']) }}"
  user: root
  environment: "{{ deployment_environment_variables | default({}) }}"
  vars_files:
    - "defaults/{{ install_method }}_install.yml"
  tags:
    - cinder
  tasks:
    - name: Execute cinder service reload
      include: common-tasks/restart-service.yml
      vars:
        service_name: "{{ item.name }}"
        service_action: "{{ item.action }}"
        service_fact: "cinder"
      with_items:
        - { name: "cinder-scheduler", action: "restarted" }
        - { name: "cinder-volume", action: "reloaded" }
        - { name: "cinder-backup", action: "reloaded" }
      when:
        - "cinder_all_software_updated | bool"
        - "ansible_local['openstack_ansible']['cinder']['need_service_restart'] | bool"



- name: Restart cinder API to ensure new RPC object version is used
  hosts: cinder_api
  gather_facts: no
  serial: "{{ cinder_api_serial | default(['1','100%']) }}"
  user: root
  environment: "{{ deployment_environment_variables | default({}) }}"
  vars_files:
    - "defaults/{{ install_method }}_install.yml"
  tags:
    - cinder
  tasks:
    # In order to ensure that the service restart does not
    # cause an unexpected outage, we drain the load balancer
    # back end for this container.
    - include: common-tasks/haproxy-endpoint-manage.yml
      vars:
        haproxy_state: disabled
      when:
        - "cinder_all_software_updated | bool"
        - "ansible_local['openstack_ansible']['cinder']['need_service_restart'] | bool"
        - "groups['cinder_api'] | length > 1"

    - name: Execute cinder service restart
      include: common-tasks/restart-service.yml
      vars:
        service_name: "cinder-api"
        service_action: "restarted"
        service_fact: "cinder"
      when:
        - "cinder_all_software_updated | bool"
        - "ansible_local['openstack_ansible']['cinder']['need_service_restart'] | bool"

    # Now that service restart is done, we can set
    # the load balancer back end for this container
    # to available again.
    - include: common-tasks/haproxy-endpoint-manage.yml
      vars:
        haproxy_state: enabled
      when: "groups['cinder_api'] | length > 1"



- name: Perform online database migrations
  hosts: cinder_api[0]
  gather_facts: no
  user: root
  environment: "{{ deployment_environment_variables | default({}) }}"
  vars_files:
    - "defaults/{{ install_method }}_install.yml"
  tags:
    - cinder
  tasks:
    - name: Perform online data migrations
      command: "{{ cinder_bin }}/cinder-manage db online_data_migrations"
      become: yes
      become_user: "{{ cinder_system_user_name }}"
      when:
        - "cinder_all_software_updated | bool"
        - "ansible_local['openstack_ansible']['cinder']['need_online_data_migrations'] | bool"
      changed_when: false
      register: data_migrations

    - name: Disable the online migrations requirement
      ini_file:
        dest: "/etc/ansible/facts.d/openstack_ansible.fact"
        section: cinder
        option: need_online_data_migrations
        value: False
      when:
        - data_migrations  is succeeded

**********
DECISION===>: PASS
**********
=========================:::499:::END!!!=========================
=========================:::500:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/repo-build.yml
**********
---
# Copyright 2015, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Group repo servers by architecture
  hosts: repo_all
  # Serial 1 avoids race conditions, and makes sures the repo_servers
  # are added in the same order as the repo_all inventory
  serial: 1
  tasks:
    - name: Group repo servers by architecture and os version
      group_by:
        key: repo_servers_{{ ansible_distribution_version }}_{{ ansible_architecture }}
  tags:
    - always
    - repo-build

# Use the 'add_host' module to create the repo_masters group which consists of a
# single host in each distribution/architecture combination. This ensures that
# the repo build happens per architecture and per distribution, covering the needs
# of each of these combinations when deploying.
- name: Prepare group of master repo servers
  hosts: localhost
  tasks:
    - name: Prepare group of master repo servers
      add_host:
        name: "{{ groups[item][0] }}"
        groups: repo_masters
      with_items: "{{ groups | select('match', '^repo_servers_') | list }}"
      changed_when: false
  tags:
    - always
    - repo-build

- name: Build new repo packages for a given release
  hosts: repo_masters
  gather_facts: "{{ osa_gather_facts | default(True) }}"
  any_errors_fatal: true
  user: root
  serial: 1
  pre_tasks:

    - include: common-tasks/set-pip-vars.yml

    - name: Load local packages
      debug:
        msg: "Loading Packages"
      with_py_pkgs: "{{ pkg_locations }}"
      register: local_packages
      tags:
        - always

    - name: Check if the git cache exists on deployment host
      local_action:
        module: stat
        path: "{{ repo_build_git_cache }}"
      register: _local_git_cache
      when: repo_build_git_cache is defined

    - name: Synchronise the contents of the git cache to the repo server
      synchronize:
        src: "{{ repo_build_git_cache }}"
        dest: "{{ repo_build_git_dir }}"
      when:
        - _local_git_cache.stat is defined
        - _local_git_cache.stat.exists

  roles:
    - role: "repo_build"
  vars_files:
    - defaults/repo_packages/openstack_services.yml
    - "defaults/{{ install_method }}_install.yml"
  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - repo-build

**********
DECISION===>: PASS
**********
=========================:::500:::END!!!=========================
=========================:::501:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/os-tacker-install.yml
**********
---
# Copyright 2017, SUSE LINUX GmbH.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Install the tacker components
  hosts: tacker_all
  gather_facts: "{{ osa_gather_facts | default(True) }}"
  user: root
  environment: "{{ deployment_environment_variables | default({}) }}"
  vars_files:
    - "defaults/{{ install_method }}_install.yml"
  tags:
    - tacker
  pre_tasks:
    - include: "common-tasks/os-{{ container_tech | default('lxc') }}-container-setup.yml"
      static: no
      when: not is_metal

    - include: common-tasks/os-log-dir-setup.yml
      vars:
        log_dirs:
          - src: "/openstack/log/{{ inventory_hostname }}-tacker"
            dest: "/var/log/tacker"
  roles:
    - role: "os_tacker"

  post_tasks:
    - include_tasks: "common-tasks/rsyslog-client.yml"
      vars:
        rsyslog_client_log_rotate_file: tacker_log_rotate
        rsyslog_client_log_dir: "/var/log/tacker"
        rsyslog_client_config_name: "99-tacker-rsyslog-client.conf"

**********
DECISION===>: PASS
**********
=========================:::501:::END!!!=========================
=========================:::502:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/containers-lxc-host.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Basic lxc host setup
  hosts: "{{ lxc_host_group | default('lxc_hosts')}}"
  user: root
  gather_facts: "{{ osa_gather_facts | default(True) }}"
  vars_files:
    - defaults/repo_packages/openstack_services.yml
    - "defaults/{{ install_method }}_install.yml"
  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - lxc-hosts
  pre_tasks:
    - include: common-tasks/set-pip-vars.yml
      when: install_method == "source"
    - name: Check the state of the default LXC service log directory
      stat:
        path: "/var/log/lxc"
      register: _lxc_log_dir
    - name: Create the log aggregation parent directory
      file:
        path: "/openstack/log"
        state: directory
    - name: Move the existing folder to the log aggregation parent
      command: "mv /var/log/lxc /openstack/log/{{ inventory_hostname }}-lxc"
      when:
        - _lxc_log_dir.stat.isdir is defined
        - _lxc_log_dir.stat.isdir | bool
    - name: Create the new LXC service log directory
      file:
        path: "/openstack/log/{{ inventory_hostname }}-lxc"
        state: directory
    - name: Create the LXC service log aggregation link
      file:
        src: "/openstack/log/{{ inventory_hostname }}-lxc"
        dest: "/var/log/lxc"
        state: "link"
  roles:
    - role: "lxc_hosts"

  post_tasks:
    - include_tasks: "common-tasks/rsyslog-client.yml"
      vars:
        rsyslog_client_log_rotate_file: lxc_log_rotate
        rsyslog_client_log_dir: "/var/log/lxc"
        rsyslog_client_config_name: "99-lxc-rsyslog-client.conf"

**********
DECISION===>: PASS
**********
=========================:::502:::END!!!=========================
=========================:::503:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/containers-lxc-create.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Set lxc containers group
  hosts: "{{ container_group | default('all_containers') }}"
  gather_facts: false
  vars_files:
    - "defaults/{{ install_method }}_install.yml"
  tasks:
    - name: Add hosts to dynamic inventory group
      group_by:
        key: lxc_containers
        parents: all_lxc_containers
      when:
        - container_tech == 'lxc'
  tags:
    - always
    - lxc-containers-create

- name: Create container(s)
  hosts: all_lxc_containers
  user: root
  gather_facts: false
  vars_files:
    - "defaults/{{ install_method }}_install.yml"
  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - lxc-containers-create
  roles:
    - role: "lxc_container_create"
  post_tasks:
    - name: Wait for container connectivity
      wait_for_connection:
        connect_timeout: "{{ lxc_container_wait_params.connect_timeout | default(omit) }}"
        delay: "{{ lxc_container_wait_params.delay | default(omit) }}"
        sleep: "{{ lxc_container_wait_params.sleep | default(omit) }}"
        timeout: "{{ lxc_container_wait_params.timeout | default(omit) }}"

    # When using gather_facts with smart gathering,
    # the facts aren't fully updated unless they
    # are old. Using the setup module in a task
    # does a more thorough collection.
    # Given we've just created the container, it is
    # best that we do a full collection of facts -
    # otherwise we end up with a stale set which
    # has stuff like the hostname = localhost.
    - name: Gather facts for new container(s)
      setup:
        gather_subset: "network,hardware,virtual"

- name: Configure containers default software
  hosts: all_lxc_containers
  user: root
  gather_facts: true
  vars_files:
    - defaults/repo_packages/openstack_services.yml
    - "defaults/{{ install_method }}_install.yml"
  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - lxc-containers-create
  pre_tasks:
    - include: common-tasks/package-cache-proxy.yml
      when: install_method == "source"
    - include: common-tasks/set-pip-vars.yml
      when: install_method == "source"
  roles:
    - role: "openstack_hosts"
      is_container: true

**********
DECISION===>: PASS
**********
=========================:::503:::END!!!=========================
=========================:::504:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/setup-infrastructure.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- include: unbound-install.yml
- include: repo-install.yml
  when: install_method == "source"
- include: haproxy-install.yml
# TODO(evrardjp): Remove the following when repo_build is done
# before lxc_container_create, and haproxy is moved with it as
# second step.
- include: repo-use.yml
  when: install_method == "source"
- include: utility-install.yml
- include: memcached-install.yml
- include: galera-install.yml
- include: rabbitmq-install.yml
- include: etcd-install.yml
- include: ceph-install.yml
- include: rsyslog-install.yml
- include: infra-journal-remote.yml

**********
DECISION===>: PASS
**********
=========================:::504:::END!!!=========================
=========================:::505:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/repo-server.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Setup repo servers
  hosts: repo_all
  gather_facts: "{{ osa_gather_facts | default(True) }}"
  user: root
  pre_tasks:

    - include: common-tasks/set-pip-vars.yml

    - name: Check if the git cache exists on deployment host
      local_action:
        module: stat
        path: "{{ repo_build_git_cache }}"
      register: _local_git_cache
      when: repo_build_git_cache is defined

    - include: "common-tasks/os-{{ container_tech | default('lxc') }}-container-setup.yml"
      static: no
      vars:
        list_of_bind_mounts:
          - mount_path: "/openstack/{{ inventory_hostname }}"
            bind_dir_path: "/var/www"
      when: not is_metal

    - include: common-tasks/unbound-clients.yml
      static: no
      when:
        - hostvars['localhost']['resolvconf_enabled'] | bool
  roles:
    - role: "repo_server"

  post_tasks:
    - include_tasks: "common-tasks/rsyslog-client.yml"
      vars:
        rsyslog_client_log_rotate_file: "{{ rsyslog_var.log_rotate_file }}"
        rsyslog_client_log_dir: "{{ rsyslog_var.log_dir }}"
        rsyslog_client_log_files: "{{ rsyslog_var.log_files | default([]) }}"
        rsyslog_client_config_name: "{{ rsyslog_var.config_name }}"
      with_items:
        - log_rotate_file: pypiserver_log_rotate
          log_dir: "/var/log/pypiserver"
          config_name: "99-pypiserver-rsyslog-client.conf"
        - log_rotate_file: lsyncd_log_rotate
          log_dir: "/var/log/lsyncd"
          config_name: "99-lsyncd-rsyslog-client.conf"
        - log_rotate_file: repo_nginx_log_rotate
          log_dir: "/var/log/nginx"
          log_files:
            - /var/log/rsyncd.log
          config_name: "99-repo-nginx-rsyslog-client.conf"
      loop_control:
        loop_var: rsyslog_var

  vars_files:
    - defaults/repo_packages/openstack_services.yml
    - "defaults/{{ install_method }}_install.yml"
  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - repo-server

**********
DECISION===>: PASS
**********
=========================:::505:::END!!!=========================
=========================:::506:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/os-barbican-install.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Installation and setup of barbican
  hosts: barbican_all
  gather_facts: "{{ osa_gather_facts | default(True) }}"
  user: root
  environment: "{{ deployment_environment_variables | default({}) }}"
  vars_files:
    - "defaults/{{ install_method }}_install.yml"
  tags:
    - barbican
  pre_tasks:
    - include: "common-tasks/os-{{ container_tech | default('lxc') }}-container-setup.yml"
      static: no
      when: not is_metal

    - include: common-tasks/os-log-dir-setup.yml
      vars:
        log_dirs:
          - src: "/openstack/log/{{ inventory_hostname }}-barbican"
            dest: "/var/log/barbican"

    - include: common-tasks/unbound-clients.yml
      static: no
      when:
        - hostvars['localhost']['resolvconf_enabled'] | bool
  roles:
    - role: "os_barbican"

  post_tasks:
    - include_tasks: "common-tasks/rsyslog-client.yml"
      vars:
        rsyslog_client_log_rotate_file: barbican_log_rotate
        rsyslog_client_log_dir: "/var/log/barbican"
        rsyslog_client_config_name: "99-barbican-rsyslog-client.conf"

**********
DECISION===>: PASS
**********
=========================:::506:::END!!!=========================
=========================:::507:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/rabbitmq-install.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Create and configure rabbitmq container
  hosts: "{{ rabbitmq_host_group | default('rabbitmq_all') }}"
  serial: 1
  gather_facts: "{{ osa_gather_facts | default(True) }}"
  user: root
  pre_tasks:
    - include: "common-tasks/os-{{ container_tech | default('lxc') }}-container-setup.yml"
      static: no
      vars:
        extra_container_config_no_restart:
          - "lxc.start.order=19"
      when: not is_metal

    - include: common-tasks/unbound-clients.yml
      static: no
      when:
        - hostvars['localhost']['resolvconf_enabled'] | bool
  roles:
    - role: "system_crontab_coordination"
  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - rabbitmq

# The cluster must be stopped when doing major/minor upgrades
# http://www.rabbitmq.com/clustering.html#upgrading
- name: Stop RabbitMQ nodes that are not the upgrader
  hosts: "{{ rabbitmq_host_group | default('rabbitmq_all') }}[1:]"
  user: root
  tasks:
    - name: "Stop RabbitMQ"
      service:
        name: "rabbitmq-server"
        state: "stopped"
      when: rabbitmq_upgrade | default(false) | bool

- name: Install rabbitmq server
  hosts: "{{ rabbitmq_host_group | default('rabbitmq_all') }}"
  serial: 20%
  user: root
  roles:
    - role: "rabbitmq_server"

  post_tasks:
    - include_tasks: "common-tasks/rsyslog-client.yml"
      vars:
        rsyslog_client_log_rotate_file: rabbitmq_log_rotate
        rsyslog_client_log_dir: "/var/log/rabbitmq"
        rsyslog_client_config_name: "99-rabbitmq-rsyslog-client.conf"

  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - rabbitmq

- name: Ensure rabbitmq user for monitoring GUI
  hosts: "{{ rabbitmq_host_group | default('rabbitmq_all') }}[0]"
  user: root
  tasks:
    - name: Create rabbitmq user for monitoring GUI
      rabbitmq_user:
         user: "{{ rabbitmq_monitoring_userid|default('monitoring') }}"
         password: "{{ rabbitmq_monitoring_password }}"
         tags: "{{ rabbitmq_monitoring_tag | default('monitoring') }}"
         state: "present"
      no_log: true
      when: rabbitmq_monitoring_password is defined
  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - rabbitmq-config
    - rabbitmq

**********
DECISION===>: PASS
**********
=========================:::507:::END!!!=========================
=========================:::508:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/os-keystone-install.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


# The openstack_openrc role gets executed on a designated service
# host which will handle all service/user/domain/project/role
# management for the roles. It is executed here as this is the
# first role which will use it and the implementation of the
# clouds.yaml file is useless until keystone is in place.
- name: Implement openrc/clouds.yaml on the designated service host
  hosts: "{{ openstack_service_setup_host | default('localhost') }}"
  gather_facts: "{{ osa_gather_facts | default(True) }}"
  become: yes
  tags:
    - openrc
  roles:
    - role: "openstack_openrc"



- name: Installation and setup of Keystone
  hosts: keystone_all
  serial: "{{ keystone_serial | default(['1', '100%']) }}"
  gather_facts: "{{ osa_gather_facts | default(True) }}"
  user: root
  environment: "{{ deployment_environment_variables | default({}) }}"
  vars_files:
    - "defaults/{{ install_method }}_install.yml"
  tags:
    - keystone
  pre_tasks:

    # In order to ensure that any container, software or
    # config file changes which causes a container/service
    # restart do not cause an unexpected outage, we drain
    # the load balancer back end for this container.
    - include: common-tasks/haproxy-endpoint-manage.yml
      vars:
        haproxy_backend: "keystone_service-back"
        haproxy_state: disabled
      when: "groups['keystone_all'] | length > 1"

    - name: Configure container
      include: "common-tasks/os-{{ container_tech | default('lxc') }}-container-setup.yml"
      vars:
        extra_container_config_no_restart:
          - "lxc.start.order=19"
      static: no
      when: not is_metal

    - name: Configure log directories (on metal)
      include: common-tasks/os-log-dir-setup.yml
      vars:
        log_dirs:
          - src: "/openstack/log/{{ inventory_hostname }}-keystone"
            dest: "/var/log/keystone"

    - include: common-tasks/unbound-clients.yml
      static: no
      when:
        - hostvars['localhost']['resolvconf_enabled'] | bool

  roles:
    - role: "os_keystone"
    - role: "system_crontab_coordination"
      tags:
        - crontab

  post_tasks:
    - include_tasks: "common-tasks/rsyslog-client.yml"
      vars:
        rsyslog_client_log_rotate_file: keystone_log_rotate
        rsyslog_client_log_dir: "/var/log/keystone"
        rsyslog_client_config_name: "99-keystone-rsyslog-client.conf"

    # Now that container changes are done, we can set
    # the load balancer back end for this container
    # to available again.
    - include: common-tasks/haproxy-endpoint-manage.yml
      vars:
        haproxy_backend: "keystone_service-back"
        haproxy_state: enabled
      when: "groups['keystone_all'] | length > 1"

# These facts are set against the deployment host to ensure that
# they are fast to access. This is done in preference to setting
# them against each target as the hostvars extraction will take
# a long time if executed against a large inventory.
- name: Finalise data migrations if required
  hosts: keystone_all
  gather_facts: no
  user: root
  environment: "{{ deployment_environment_variables | default({}) }}"
  vars_files:
    - "defaults/{{ install_method }}_install.yml"
  tags:
    - keystone
  tasks:
    - name: refresh local facts
      setup:
        filter: ansible_local
        gather_subset: "!all"

    # This variable contains the values of the local fact set for the keystone
    # venv tag for all hosts in the 'keystone_all' host group.
    - name: Gather software version list
      set_fact:
        keystone_all_software_versions: "{{ (groups['keystone_all'] | map('extract', hostvars, ['ansible_local', 'openstack_ansible', 'keystone', 'venv_tag'])) | list }}"
      delegate_to: localhost
      run_once: yes

    # This variable outputs a boolean value which is True when
    # keystone_all_software_versions contains a list of defined
    # values. If they are not defined, it means that not all
    # hosts have their software deployed yet.
    - name: Set software deployed fact
      set_fact:
        keystone_all_software_deployed: "{{ (keystone_all_software_versions | select('defined')) | list == keystone_all_software_versions }}"
      delegate_to: localhost
      run_once: yes

    # This variable outputs a boolean when all the values in
    # keystone_all_software_versions are the same and the software
    # has been deployed to all hosts in the group.
    - name: Set software updated fact
      set_fact:
        keystone_all_software_updated: "{{ ((keystone_all_software_versions | unique) | length == 1) and (keystone_all_software_deployed | bool) }}"
      delegate_to: localhost
      run_once: yes

    - name: Perform a Keystone DB sync contract
      command: "{{ keystone_bin }}/keystone-manage db_sync --contract"
      become: yes
      become_user: "{{ keystone_system_user_name }}"
      when:
        - "keystone_all_software_updated | bool"
        - "ansible_local['openstack_ansible']['keystone']['need_db_contract'] | bool"
      register: dbsync_contract
      run_once: yes

    - name: Disable the need for any further db sync
      ini_file:
        dest: "/etc/ansible/facts.d/openstack_ansible.fact"
        section: keystone
        option: "need_db_contract"
        value: False
      when:
        - "dbsync_contract is succeeded"

**********
DECISION===>: PASS
**********
=========================:::508:::END!!!=========================
=========================:::509:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/os-glance-install.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Install glance API services
  include: common-playbooks/glance.yml
  vars:
    glance_hosts: "glance_api"
    glance_serial: "{{ glance_api_serial | default(['1', '100%']) }}"



- name: Install glance registry services
  include: common-playbooks/glance.yml
  vars:
    glance_hosts: "glance_registry:!glance_api"
    glance_serial: "{{ glance_registry_serial | default(['1', '100%']) }}"



# These facts are set against the deployment host to ensure that
# they are fast to access. This is done in preference to setting
# them against each target as the hostvars extraction will take
# a long time if executed against a large inventory.
- name: Refresh local facts after all software changes are made
  hosts: glance_all
  gather_facts: no
  user: root
  environment: "{{ deployment_environment_variables | default({}) }}"
  vars_files:
    - "defaults/{{ install_method }}_install.yml"
  tags:
    - glance
  tasks:
    - name: refresh local facts
      setup:
        filter: ansible_local
        gather_subset: "!all"

    # This variable contains the values of the local fact set for the glance
    # venv tag for all hosts in the 'glance_all' host group.
    - name: Gather software version list
      set_fact:
        glance_all_software_versions: "{{ (groups['glance_all'] | map('extract', hostvars, ['ansible_local', 'openstack_ansible', 'glance', 'venv_tag'])) | list }}"
      delegate_to: localhost
      run_once: yes

    # This variable outputs a boolean value which is True when
    # glance_all_software_versions contains a list of defined
    # values. If they are not defined, it means that not all
    # hosts have their software deployed yet.
    - name: Set software deployed fact
      set_fact:
        glance_all_software_deployed: "{{ (glance_all_software_versions | select('defined')) | list == glance_all_software_versions }}"
      delegate_to: localhost
      run_once: yes

    # This variable outputs a boolean when all the values in
    # glance_all_software_versions are the same and the software
    # has been deployed to all hosts in the group.
    - name: Set software updated fact
      set_fact:
        glance_all_software_updated: "{{ ((glance_all_software_versions | unique) | length == 1) and (glance_all_software_deployed | bool) }}"
      delegate_to: localhost
      run_once: yes


- name: Restart glance API to ensure new RPC object version is used
  hosts: glance_api
  gather_facts: no
  serial: "{{ glance_api_serial | default(['1','100%']) }}"
  user: root
  environment: "{{ deployment_environment_variables | default({}) }}"
  vars_files:
    - "defaults/{{ install_method }}_install.yml"
  tags:
    - glance
  tasks:
    # In order to ensure that the service restart does not
    # cause an unexpected outage, we drain the load balancer
    # back end for this container.
    - include: common-tasks/haproxy-endpoint-manage.yml
      vars:
        haproxy_backend: glance_api-back
        haproxy_state: disabled
      when:
        - "glance_all_software_updated | bool"
        - "ansible_local['openstack_ansible']['glance']['need_service_restart'] | bool"
        - "groups['glance_api'] | length > 1"

    - name: Execute glance service restart
      include: common-tasks/restart-service.yml
      vars:
        service_name: "glance-api"
        service_action: "restarted"
        service_fact: "glance"
      when:
        - "glance_all_software_updated | bool"
        - "ansible_local['openstack_ansible']['glance']['need_service_restart'] | bool"

    # Now that service restart is done, we can set
    # the load balancer back end for this container
    # to available again.
    - include: common-tasks/haproxy-endpoint-manage.yml
      vars:
        haproxy_backend: glance_api-back
        haproxy_state: enabled
      when: "groups['glance_api'] | length > 1"

**********
DECISION===>: PASS
**********
=========================:::509:::END!!!=========================
=========================:::510:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/os-swift-install.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Installation and setup of Swift
  hosts: swift_all:swift_remote_all
  gather_facts: "{{ osa_gather_facts | default(True) }}"
  user: root
  vars_files:
    - "defaults/{{ install_method }}_install.yml"
  pre_tasks:
    - include: "common-tasks/os-{{ container_tech | default('lxc') }}-container-setup.yml"
      static: no
      vars:
        extra_container_config_no_restart:
          - "lxc.start.order=39"
      when: not is_metal

    - include: common-tasks/os-log-dir-setup.yml
      vars:
        log_dirs:
          - src: "/openstack/log/{{ inventory_hostname }}-swift"
            dest: "/var/log/swift"
    - include: common-tasks/unbound-clients.yml
      static: no
      when:
        - hostvars['localhost']['resolvconf_enabled'] | bool

  roles:
    - role: "os_swift"
      swift_do_setup: True
      swift_do_sync: True
  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - swift

- name: Installation and setup of Swift
  hosts: swift_all
  user: root
  roles:
    - role: "system_crontab_coordination"
      tags:
        - crontab

  post_tasks:
    - include_tasks: "common-tasks/rsyslog-client.yml"
      vars:
        rsyslog_client_log_rotate_file: swift_log_rotate
        rsyslog_client_log_dir: "/var/log/swift"
        rsyslog_client_config_name: "99-swift-rsyslog-client.conf"
        rsyslog_client_log_files:
          - /var/log/rsyncd.log

  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - swift

**********
DECISION===>: PASS
**********
=========================:::510:::END!!!=========================
=========================:::511:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/utility-install.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Setup the utility location(s)
  hosts: utility_all
  user: root
  gather_facts: "{{ osa_gather_facts | default(True) }}"
  environment: "{{ deployment_environment_variables | default({}) }}"
  vars_files:
    - "defaults/{{ install_method }}_install.yml"
  tags:
    - utility
  pre_tasks:
    - include: "common-tasks/os-{{ container_tech | default('lxc') }}-container-setup.yml"
      static: no
      when: not is_metal

    - include: common-tasks/os-log-dir-setup.yml
      vars:
        log_dirs:
          - src: "/openstack/log/{{ inventory_hostname }}-utility"
            dest: "/var/log/utility"

    - include: common-tasks/unbound-clients.yml
      static: no
      when:
        - hostvars['localhost']['resolvconf_enabled'] | bool

    - name: Create log directory (not is_metal)
      file:
        dest: "/var/log/utility"
        state: "directory"
        force: "yes"
      when: not is_metal | bool

  roles:
    - role: "galera_client"
    - role: "openstack_openrc"
      tags:
        - openrc

  post_tasks:
    - name: Add OpenStack client to distro packages
      set_fact:
        utility_distro_packages: "{{ (utility_distro_packages | default([])) + utility_distro_openstack_clients_packages }}"
      when: install_method == "distro"

    - name: Install distro packages
      package:
        name: "{{ utility_distro_packages | default([]) }}"
        state: "{{ utility_package_state }}"
        update_cache: "{{ (ansible_pkg_mgr in ['apt', 'zypper']) | ternary('yes', omit) }}"
        cache_valid_time: "{{ (ansible_pkg_mgr == 'apt') | ternary(cache_timeout, omit) }}"

    - name: Distribute private ssh key
      copy:
        content: "{{ utility_ssh_private_key }}"
        dest: /root/.ssh/id_rsa
        mode: 0600
        owner: root
        group: root
      when: utility_ssh_private_key is defined

    - name: Install openstack clients (source-based install)
      when:
        - install_method == "source"
      block:
        - name: Get list of repo packages
          uri:
            url: "{{ repo_release_path }}/requirements_absolute_requirements.txt"
            return_content: yes
          register: _abs_reqs
          run_once: true
          tags:
            - always

        - name: Derive the list of openstack clients
          set_fact:
            _openstack_client_list: >-
              {%- set package_list = [] %}
              {%- for l in _abs_reqs.content.split('\n') %}
              {%-   if (l is match('^python_.*client==.*$')) or (l is match('^(aodh|gnocchi)client==.*$')) %}
              {%-     set _ = package_list.append(l | regex_replace('==.*$', '')) %}
              {%-   endif %}
              {%- endfor %}
              {{- package_list }}
          run_once: true
          tags:
            - always

        - name: Install the python venv
          include_role:
            name: "python_venv_build"
            private: yes
          vars:
            venv_install_destination_path: "{{ utility_venv_bin | dirname }}"
            venv_pip_install_args: >-
              {{ (pip_install_upper_constraints is defined) | ternary('--constraint ' + pip_install_upper_constraints | default(''),'') }}
              {{ pip_install_options | default('') }}
            venv_pip_packages: "{{ _openstack_client_list | union(utility_pip_packages) }}"

        - name: Create symlinks for openstack clients
          shell: |
            {% set _bin_name = item | regex_replace('^(?:python_)?(\w*)(?:client)$', '\\1') %}
            if [[ -e "{{ utility_venv_bin }}/{{ _bin_name }}" ]]; then
              ln -sfn {{ utility_venv_bin }}/{{ _bin_name }} /usr/local/bin/{{ _bin_name }}
            fi
          args:
            executable: /bin/bash
          with_items: "{{ _openstack_client_list }}"

        - name: Create openstack client bash_completion script
          shell: |
             openstack complete > /etc/bash_completion.d/openstack_client

**********
DECISION===>: PASS
**********
=========================:::511:::END!!!=========================
=========================:::512:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/os-tempest-install.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Installation and setup of Tempest
  hosts: utility_all[0]
  gather_facts: "{{ osa_gather_facts | default(True) }}"
  user: root
  vars_files:
    - "defaults/{{ install_method }}_install.yml"
  roles:
    - role: "os_tempest"
    - role: "system_crontab_coordination"
      tags:
        - crontab

  post_tasks:
    - include_tasks: "common-tasks/rsyslog-client.yml"
      vars:
        rsyslog_client_log_rotate_file: utility_log_rotate
        rsyslog_client_log_dir: "{{ tempest_log_dir }}"
        rsyslog_client_config_name: "99-tempest-rsyslog-client.conf"

  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - tempest

**********
DECISION===>: PASS
**********
=========================:::512:::END!!!=========================
=========================:::513:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/healthcheck-infrastructure.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This playbook is meant to run after setup-infrastructure, and expects
# the infrastructure bits to have properly deployed to succeed.

# Test unbound-install.yml
# TO BE IMPLEMENTED

# Test repo-install.yml
- name: Ensure all repo-servers are built and are accessible by hosts.
  hosts: all_containers[0]:physical_hosts[0]
  gather_facts: yes
  vars:
    repo_requirements_file: "os-releases/{{ openstack_release }}/{{ os_distro_version }}/requirements_constraints.txt"
  tasks:
    - name: Check the upper constraint on each repo server
      uri:
        url: "http://{{ hostvars[item]['container_address'] }}:{{ repo_server_port }}/{{ repo_requirements_file }}"
      with_inventory_hostnames: "{{ groups['repo_all'] }}"
      when: install_method == 'source'
  tags:
    - healthcheck
    - healthcheck-repo-install

# Test haproxy-install.yml
- name: Ensuring haproxy runs
  hosts: haproxy
  gather_facts: yes
  tasks:
    - name: Check if host can connect to keepalived ping IP
      command: "ping -c 2 {{ keepalived_ping_address }}"
      changed_when: false

    - name: Checking if keepalived is running
      command: "pgrep keepalived"
      changed_when: false
      when: groups['haproxy'] | length > 1

    - package:
        name: "{% if ansible_distribution | lower == 'centos' %}nc{% elif ansible_distribution | lower == 'suse' %}netcat-openbsd{% else %}netcat{% endif %}"
        state: present

    # Fails if HAProxy is not running
    - name: Recording haproxy stats as a way to ensure haproxy runs
      shell: 'echo "show info;show stat" | nc -U /var/run/haproxy.stat'
      changed_when: false
      register: haproxy_stats

    # Run this playbook with -v and you'll see your DOWN issues
    - name: Printing the output of haproxy stats
      debug:
        var: haproxy_stats
        verbosity: 1
  tags:
    - healthcheck
    - healthcheck-haproxy-install

# Test repo-use.yml
- name: Ensure all the containers can connect to the repos
  hosts: all_containers
  gather_facts: yes
  # By having serial, you ensure that the first three containers are hitting
  # the load balancer at the same time, which would then cause hitting three
  # different repos servers.
  # When this is done, the rest can be done with all the nodes at the same time.
  serial:
    - 3
    - 100%
  vars_files:
    - defaults/source_install.yml
  tasks:
    # Repo release path points to the internal LB vip
    - name: Check the presence of upper constraints on your repos and check load balancing
      uri:
        url: "{{ repo_release_path }}/requirements_constraints.txt"
  tags:
    - healthcheck
    - healthcheck-repo-use

# Test utility-install.yml
- name: Ensure the service setup host is ready to run openstack calls
  hosts: "{{ openstack_service_setup_host | default('localhost') }}"
  gather_facts: no
  tasks:
    - name: Get openstack client config
      os_client_config:
    - name: Show openstack client config
      debug:
        var: openstack.clouds
        verbosity: 1
  tags:
    - healthcheck
    - healthcheck-utility-install

# Test memcached-install.yml
- name: Check memcached for keystone
  hosts: keystone_all
  gather_facts: no
  tasks:
    - name: Set facts about memcached
      setup:
      delegate_to: "{{ item }}"
      delegate_facts: true
      with_items: "{{ groups['memcached'] }}"

    - package:
        name: netcat
        state: present

    - name: Connect to remote memcache servers (full mesh testing)
      shell:  "echo stats | nc -w 3 {{ hostvars[memcached_host]['container_address'] }} {{ memcached_port }}"
      changed_when: false
      register: memcache_stats
      with_items: "{{ groups['memcached'] }}"
      loop_control:
        loop_var: memcached_host

    - name: Output memcache stats if in verbose mode
      debug:
        var: memcache_stats
        verbosity: 1
  tags:
    - healthcheck
    - healthcheck-memcached-install

# Test galera-install.yml
- name: Sanity checks for all containers
  hosts: all_containers:physical_hosts
  gather_facts: no
  tasks:
    - name: Connect to galera port
      wait_for:
        port: 3306
        host: "{{ internal_lb_vip_address }}"
        state: started
  tags:
    - healthcheck
    - healthcheck-galera-install

# Test rabbitmq-install.yml
- name: Add a user for rabbitmq
  hosts: rabbitmq_all[0]
  gather_facts: no
  tasks:
    - name: Configure Rabbitmq vhost
      rabbitmq_vhost:
        name: "/testvhost"
        state: "present"

    - name: Configure Rabbitmq user
      rabbitmq_user:
        user: "testguest"
        password: "secrete"
        vhost: "/testvhost"
        configure_priv: ".*"
        read_priv: ".*"
        write_priv: ".*"
        state: "present"
      no_log: True

  tags:
    - healthcheck
    - healthcheck-rabbitmq-install

- name: Ensure all the usual openstack containers can connect to rabbit
  hosts: all_containers:!etcd_all:!galera_all:!memcached:!haproxy:!rabbitmq_all:!rsyslog:!unbound:!repo_all
  gather_facts: no
  vars:
    venv_path: /tmp/rabbitmqtest
  post_tasks:
    - name: Generate venv for rabbitmq testing
      include_role:
        name: "python_venv_build"
        private: yes
      vars:
        venv_install_destination_path: "{{ venv_path }}"
        venv_pip_packages:
          - pika
        venv_build_host_wheel_path: "{{ repo_pypiserver_package_path | default('/var/www/repo/pools') }}"
        venv_pip_install_args: >-
          --index-url {{ repo_build_pip_default_index | default('https://pypi.python.org/simple') }}
          --trusted-host {{ (repo_build_pip_default_index | default('https://pypi.python.org/simple')) | netloc_no_port }}
    - name: Copying test script
      copy:
        src: "../scripts/rabbitmq-test.py"
        dest: "{{ venv_path }}/rabbitmq-test.py"
        mode: 0755
    - name: Connect to rabbitmq
      command: "{{ venv_path }}/bin/python2 {{ venv_path }}/rabbitmq-test.py {{ hostvars[groups['rabbitmq_all'][0]]['container_address'] }}"
  tags:
    - healthcheck
    - healthcheck-rabbitmq-install

- name: Remove guest user for rabbitmq
  hosts: rabbitmq_all[0]
  gather_facts: no
  tasks:
    - name: Remove test user
      rabbitmq_user:
        user: testguest
        password: secrete
        vhost: "/testvhost"
        state: absent
      no_log: true
    - name: Remove test vhost
      rabbitmq_vhost:
        name: "/testvhost"
        state: "absent"
  tags:
    - healthcheck
    - healthcheck-rabbitmq-install
    - healthcheck-teardown

# TODO: Other playbook's tests.

**********
DECISION===>: Use of HTTP without TLS, hardcoded secret
**********
=========================:::513:::END!!!=========================
=========================:::514:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/os-swift-sync.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Playbook will sync the swift ring and ssh keys
# The services need to be installed first though.
- name: Synchronisation of swift ring and ssh keys
  hosts: swift_all:swift_remote_all
  gather_facts: "{{ osa_gather_facts | default(True) }}"
  user: root
  vars_files:
    - "defaults/{{ install_method }}_install.yml"
  roles:
    - role: "os_swift"
      swift_do_setup: False
      swift_do_sync: True
  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - swift

**********
DECISION===>: PASS
**********
=========================:::514:::END!!!=========================
=========================:::515:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/containers-lxc-destroy.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Set lxc containers group
  hosts: "{{ container_group | default('all_containers') }}"
  gather_facts: false
  tasks:
    - name: Add hosts to dynamic inventory group
      group_by:
        key: lxc_containers
        parents: all_lxc_containers
      when:
        - container_tech == 'lxc'
  tags:
    - always
    - lxc-containers-create

- name: Destroy lxc containers
  hosts: all_lxc_containers
  gather_facts: false
  user: root
  tasks:
    - name: Slurp machine-id
      slurp:
        src: "/etc/machine-id"
      register: _container_machine_id
      changed_when: false
      failed_when: false
      tags:
        - always

    - name: Destroy a container
      lxc_container:
        name: "{{ container_name }}"
        state: "absent"
      delegate_to: "{{ physical_host }}"
      when:
        - force_containers_destroy | bool
        - force_containers_data_destroy | bool

    - include_tasks: "common-tasks/remove_container_journal.yml"
      vars:
        container_machine_id: "{{ ((_container_machine_id.content | default('bm9uZQo=')) | b64decode).strip() }}"

    - name: Destroy container service directories
      file:
        path: "{{ item }}"
        state: "absent"
      with_items:
        - "/var/lib/lxc/{{ container_name }}"
      delegate_to: "{{ physical_host }}"
      when:
        - force_containers_destroy | bool
    - name: Destroy container data
      file:
        path: "{{ item }}"
        state: "absent"
      with_items:
        - "/openstack/{{ container_name }}"
        - "/openstack/backup/{{ container_name }}"
        - "/openstack/log/{{ container_name }}"
        - "/var/log/lxc/lxc-{{ container_name }}.log"
      delegate_to: "{{ physical_host }}"
      when:
        - force_containers_destroy | bool
        - force_containers_data_destroy | bool
  vars_prompt:
    - name: "force_containers_destroy"
      prompt: "Are you sure you want to destroy the LXC containers?"
      default: "no"
      private: no
      when: force_containers_destroy is undefined
    - name: "force_containers_data_destroy"
      prompt: "Are you sure you want to destroy the LXC container data?"
      default: "no"
      private: no
      when: force_containers_data_destroy is undefined
  tags:
    - lxc-containers-destroy

**********
DECISION===>: PASS
**********
=========================:::515:::END!!!=========================
=========================:::516:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/healthcheck-hosts.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This playbook is meant to run after setup-hosts.
# To succeed, it expects the setup-hosts playbook to have run successfuly.

# Test if the openstack-hosts-setup play was a success.
# TO BE IMPLEMENTED

# Test if security-hardening was a success.
# TO BE IMPLEMENTED

# Test if containers-deploy was a success.
# Ensure the lxc containers are properly setup
- name: Ensuring hosts good behavior
  hosts: lxc_hosts
  gather_facts: yes
  tasks:
    - name: Looking for dnsmasq process
      command: pgrep dnsmasq
      changed_when: false

- name: Ensuring hosts good behavior
  hosts: nspawn_hosts
  gather_facts: yes
  tasks:
    - debug:
        msg: "To be implemented. Please help."

- name: Ensuring containers creation, connection and good behavior
  hosts: all_containers
  gather_facts: yes
  tasks:
    - name: Ensure the physical host has all the proper interfaces defined
      assert:
        that:
          - item.value.bridge in hostvars[physical_host]['ansible_interfaces']
      with_dict: "{{ container_networks }}"

    - name: Check if dns resolution and external connectivity is fine
      get_url:
        url: https://git.openstack.org/cgit/openstack/openstack-ansible/plain/ansible-role-requirements.yml
        dest: /tmp/osa-master-requirements
      environment: "{{ deployment_environment_variables | default({}) }}"

# Test extra settings before setup-infrastructure
- name: Ensure settings are not wrong with the usual suspects issues before trying to deploy infra
  hosts: haproxy
  gather_facts: yes
  tasks:
    - name: Checking that the LB vips are well configured.
      assert:
        that:
          - external_lb_vip_address != internal_lb_vip_address
        msg: |
          External and Internal LB vip addresses are the same.
          Run with -e vipcheck=False if you want to bypass this check.
      when:
        - vipcheck | default(True) | bool
        - inventory_hostname == ansible_play_hosts[0]

    - name: Checking that vip nics are well configured
      assert:
        that:
          - item in ansible_interfaces
        msg: "Misconfigured keepalived IP, the carrying interface {{ item }} doesn't exist"
      with_items:
        - "{{ haproxy_keepalived_external_interface }}"
        - "{{ haproxy_keepalived_internal_interface }}"
      when:
        - groups['haproxy'] | length > 1

    - name: Checking that vip address is well formed
      assert:
        that:
          - item | ipaddr('address')
        msg: "Misconfigured keepalived: The vip {{ item }} is not an IP address, but a network"
      with_items:
        - "{{ haproxy_keepalived_internal_vip_cidr }}"
        - "{{ haproxy_keepalived_external_vip_cidr }}"
      when:
        - groups['haproxy'] | length > 1

**********
DECISION===>: PASS
**********
=========================:::516:::END!!!=========================
=========================:::517:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/containers-nspawn-destroy.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Set nspawn containers group
  hosts: "{{ container_group | default('all_containers') }}"
  gather_facts: false
  tasks:
    - name: Add hosts to dynamic inventory group
      group_by:
        key: nspawn_containers
        parents: all_nspawn_containers
      when:
        - container_tech == 'nspawn'
  tags:
    - always
    - nspawn-containers-destroy

- name: Destroy nspawn containers
  hosts: all_nspawn_containers
  gather_facts: false
  user: root
  tasks:
    - name: Get container status
      command: machinectl status "{{ inventory_hostname }}"
      register: machinectl_status
      failed_when: false
      delegate_to: "{{ physical_host }}"

    - name: Get container image status
      command: machinectl image-status "{{ inventory_hostname }}"
      register: machinectl_image_status
      failed_when: false
      delegate_to: "{{ physical_host }}"

    - name: Escape quote container name
      command: "systemd-escape {{ inventory_hostname }}"
      changed_when: false
      register: systemd_escape
      delegate_to: "{{ physical_host }}"

    - name: Get machine-id
      shell: >-
        hostnamectl --machine="{{ inventory_hostname }}" status | awk '/Machine ID/ {print $3}'
      register: _container_machine_id
      delegate_to: "{{ physical_host }}"

    - name: Disable container
      systemd:
        name: "systemd-nspawn@{{ systemd_escape.stdout }}"
        state: stopped
        enabled: false
      failed_when: false
      delegate_to: "{{ physical_host }}"
      when:
        - force_containers_destroy | bool

    - name: Halt container
      command: "machinectl poweroff {{ inventory_hostname }}"
      failed_when: false
      delegate_to: "{{ physical_host }}"
      when:
        - machinectl_status.rc == 0
        - force_containers_destroy | bool

    - name: Remove container
      command: "machinectl remove {{ inventory_hostname }}"
      delegate_to: "{{ physical_host }}"
      when:
        - machinectl_image_status.rc == 0
        - force_containers_destroy | bool

    - include_tasks: "common-tasks/remove_container_journal.yml"
      vars:
        container_machine_id: "{{ (_container_machine_id.stdout).strip() }}"

    - name: Destroy container data
      file:
        path: "{{ item }}"
        state: "absent"
      with_items:
        - "/openstack/{{ container_name }}"
        - "/openstack/backup/{{ container_name }}"
        - "/openstack/log/{{ container_name }}"
      delegate_to: "{{ physical_host }}"
      when:
        - force_containers_destroy | bool
        - force_containers_data_destroy | bool
  vars_prompt:
    - name: "force_containers_destroy"
      prompt: "Are you sure you want to destroy the nspawn containers?"
      default: "no"
      private: no
      when: force_containers_destroy is undefined
    - name: "force_containers_data_destroy"
      prompt: "Are you sure you want to destroy the nspawn container data?"
      default: "no"
      private: no
      when: force_containers_data_destroy is undefined
  tags:
    - nspawn-containers-destroy

**********
DECISION===>: PASS
**********
=========================:::517:::END!!!=========================
=========================:::518:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/os-trove-install.yml
**********
---
# Copyright 2016 Internet Solutions (Pty) Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# (c) 2016 Donovan Francesco <donovan.francesco@is.co.za>
# (c) 2016 Paul Stevens <paul.stevens@is.co.za>

- name: Install trove server
  hosts: trove_all
  gather_facts: "{{ osa_gather_facts | default(True) }}"
  user: root
  environment: "{{ deployment_environment_variables | default({}) }}"
  vars_files:
    - "defaults/{{ install_method }}_install.yml"
  tags:
    - trove
  pre_tasks:
    - include: "common-tasks/os-{{ container_tech | default('lxc') }}-container-setup.yml"
      static: no
      when: not is_metal

    - include: common-tasks/os-log-dir-setup.yml
      vars:
        log_dirs:
          - src: "/openstack/log/{{ inventory_hostname }}-trove"
            dest: "/var/log/trove"

    - include: common-tasks/unbound-clients.yml
      static: no
      when:
        - hostvars['localhost']['resolvconf_enabled'] | bool
  roles:
    - role: "os_trove"

  post_tasks:
    - include_tasks: "common-tasks/rsyslog-client.yml"
      vars:
        rsyslog_client_log_rotate_file: trove_log_rotate
        rsyslog_client_log_dir: "/var/log/trove"
        rsyslog_client_config_name: "99-trove-rsyslog-client.conf"

**********
DECISION===>: PASS
**********
=========================:::518:::END!!!=========================
=========================:::519:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/os-rally-install.yml
**********
---
# Copyright 2016, Comcast Corp.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Installation and setup of Rally
  hosts: utility_all
  gather_facts: "{{ osa_gather_facts | default(True) }}"
  user: root
  environment: "{{ deployment_environment_variables | default({}) }}"
  vars_files:
    - "defaults/{{ install_method }}_install.yml"
  tags:
    - rally
  pre_tasks:
    - include: common-tasks/unbound-clients.yml
      static: no
      when:
        - hostvars['localhost']['resolvconf_enabled'] | bool
  roles:
    - role: "os_rally"

**********
DECISION===>: PASS
**********
=========================:::519:::END!!!=========================
=========================:::520:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/lxc-containers-destroy.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Set lxc containers group
  hosts: "{{ container_group | default('all_containers') }}"
  gather_facts: false
  tasks:
    - name: Add hosts to dynamic inventory group
      group_by:
        key: lxc_containers
        parents: all_lxc_containers
      when:
        - container_tech == 'lxc'
  tags:
    - always
    - lxc-containers-create

- name: Destroy lxc containers
  hosts: all_lxc_containers
  gather_facts: false
  user: root
  tasks:
    - name: Slurp machine-id
      slurp:
        src: "/etc/machine-id"
      register: _container_machine_id
      changed_when: false
      failed_when: false
      tags:
        - always

    - name: Destroy a container
      lxc_container:
        name: "{{ container_name }}"
        state: "absent"
      delegate_to: "{{ physical_host }}"
      when:
        - force_containers_destroy | bool
        - force_containers_data_destroy | bool

    - include_tasks: "common-tasks/remove_container_journal.yml"
      vars:
        container_machine_id: "{{ ((_container_machine_id.content | default('bm9uZQo=')) | b64decode).strip() }}"

    - name: Destroy container service directories
      file:
        path: "{{ item }}"
        state: "absent"
      with_items:
        - "/var/lib/lxc/{{ container_name }}"
      delegate_to: "{{ physical_host }}"
      when:
        - force_containers_destroy | bool
    - name: Destroy container data
      file:
        path: "{{ item }}"
        state: "absent"
      with_items:
        - "/openstack/{{ container_name }}"
        - "/openstack/backup/{{ container_name }}"
        - "/openstack/log/{{ container_name }}"
        - "/var/log/lxc/lxc-{{ container_name }}.log"
      delegate_to: "{{ physical_host }}"
      when:
        - force_containers_destroy | bool
        - force_containers_data_destroy | bool
  vars_prompt:
    - name: "force_containers_destroy"
      prompt: "Are you sure you want to destroy the LXC containers?"
      default: "no"
      private: no
      when: force_containers_destroy is undefined
    - name: "force_containers_data_destroy"
      prompt: "Are you sure you want to destroy the LXC container data?"
      default: "no"
      private: no
      when: force_containers_data_destroy is undefined
  tags:
    - lxc-containers-destroy

**********
DECISION===>: PASS
**********
=========================:::520:::END!!!=========================
=========================:::521:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/os-ironic-install.yml
**********
---
# Copyright 2016, Rackspace, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Installation and setup of Ironic
  hosts: ironic_all
  gather_facts: "{{ osa_gather_facts | default(True) }}"
  user: root
  environment: "{{ deployment_environment_variables | default({}) }}"
  vars_files:
    - "defaults/{{ install_method }}_install.yml"
  tags:
    - ironic
  pre_tasks:
    - include: "common-tasks/os-{{ container_tech | default('lxc') }}-container-setup.yml"
      static: no
      when: not is_metal

    - include: common-tasks/unbound-clients.yml
      static: no
      when:
        - hostvars['localhost']['resolvconf_enabled'] | bool
  roles:
    - role: "os_ironic"
    - role: "system_crontab_coordination"
      tags:
        - crontab

  post_tasks:
    - include_tasks: "common-tasks/rsyslog-client.yml"
      vars:
        rsyslog_client_log_rotate_file: ironic_log_rotate
        rsyslog_client_log_dir: "/var/log/ironic"
        rsyslog_client_config_name: "99-ironic-rsyslog-client.conf"

**********
DECISION===>: PASS
**********
=========================:::521:::END!!!=========================
=========================:::522:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/os-horizon-install.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Install horizon server
  hosts: horizon_all
  gather_facts: "{{ osa_gather_facts | default(True) }}"
  user: root
  environment: "{{ deployment_environment_variables | default({}) }}"
  vars_files:
    - "defaults/{{ install_method }}_install.yml"
  tags:
    - horizon
  pre_tasks:
    - include: "common-tasks/os-{{ container_tech | default('lxc') }}-container-setup.yml"
      static: no
      when: not is_metal
    - include: common-tasks/os-log-dir-setup.yml
      vars:
        log_dirs:
          - src: "/openstack/log/{{ inventory_hostname }}-horizon"
            dest: "/var/log/horizon"

    - include: common-tasks/unbound-clients.yml
      static: no
      when:
        - hostvars['localhost']['resolvconf_enabled'] | bool
  roles:
    - role: "os_horizon"
    - role: "system_crontab_coordination"
      tags:
        - crontab

  post_tasks:
    - include_tasks: "common-tasks/rsyslog-client.yml"
      vars:
        rsyslog_client_log_rotate_file: horizon_log_rotate
        rsyslog_client_log_dir: "/var/log/horizon"
        rsyslog_client_config_name: "99-horizon-rsyslog-client.conf"

**********
DECISION===>: PASS
**********
=========================:::522:::END!!!=========================
=========================:::523:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/os-nova-install.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Install nova-conductor services
  include: common-playbooks/nova.yml
  vars:
    nova_hosts: "nova_conductor"
    nova_serial: "{{ nova_conductor_serial | default(['1', '100%']) }}"



- name: Install nova-scheduler services
  include: common-playbooks/nova.yml
  vars:
    nova_hosts: "nova_scheduler:!nova_conductor"
    nova_serial: "{{ nova_scheduler_serial | default(['1', '100%']) }}"



- name: Install nova API services
  include: common-playbooks/nova.yml
  vars:
    nova_hosts: "nova_api_os_compute:nova_api_placement:!nova_conductor:!nova_scheduler:!nova_consoleauth"
    nova_serial: "{{ nova_api_serial | default(['1', '100%']) }}"



- name: Install nova console/metadata services
  include: common-playbooks/nova.yml
  vars:
    nova_hosts: "nova_api_metadata:nova_console:!nova_conductor:!nova_scheduler:!nova_consoleauth:!nova_api_os_compute:!nova_api_placement"
    nova_serial: "{{ nova_console_serial | default(['1', '100%']) }}"



- name: Install nova compute
  include: common-playbooks/nova.yml
  vars:
    nova_hosts: "nova_compute:!nova_conductor:!nova_scheduler:!nova_consoleauth:!nova_api_os_compute:!nova_api_placement:!nova_api_metadata:!nova_console"
    nova_serial: "{{ nova_compute_serial | default('100%') }}"



# These facts are set against the deployment host to ensure that
# they are fast to access. This is done in preference to setting
# them against each target as the hostvars extraction will take
# a long time if executed against a large inventory.
- name: Refresh local facts after all software changes are made
  hosts: nova_all
  gather_facts: no
  user: root
  environment: "{{ deployment_environment_variables | default({}) }}"
  vars_files:
    - "defaults/{{ install_method }}_install.yml"
  tags:
    - nova
  tasks:
    - name: refresh local facts
      setup:
        filter: ansible_local
        gather_subset: "!all"

    # This variable contains the values of the local fact set for the cinder
    # venv tag for all hosts in the 'cinder_all' host group.
    - name: Gather software version list
      set_fact:
        nova_all_software_versions: "{{ (groups['nova_all'] | map('extract', hostvars, ['ansible_local', 'openstack_ansible', 'nova', 'venv_tag'])) | list }}"
      delegate_to: localhost
      run_once: yes

    # This variable outputs a boolean value which is True when
    # nova_all_software_versions contains a list of defined
    # values. If they are not defined, it means that not all
    # hosts have their software deployed yet.
    - name: Set software deployed fact
      set_fact:
        nova_all_software_deployed: "{{ (nova_all_software_versions | select('defined')) | list == nova_all_software_versions }}"
      delegate_to: localhost
      run_once: yes

    # This variable outputs a boolean when all the values in
    # nova_all_software_versions are the same and the software
    # has been deployed to all hosts in the group.
    - name: Set software updated fact
      set_fact:
        nova_all_software_updated: "{{ ((nova_all_software_versions | unique) | length == 1) and (nova_all_software_deployed | bool) }}"
      delegate_to: localhost
      run_once: yes


# Note that the placement API service and the console services do not
# understand how to reload, so they fail when you try to make them do
# so. We therefore restart them instead.
- name: Reload all nova services which support a reload to ensure new RPC object version is used
  hosts: "nova_all:!nova_api_placement:!nova_console"
  gather_facts: no
  serial: "{{ nova_serial | default('100%') }}"
  user: root
  environment: "{{ deployment_environment_variables | default({}) }}"
  vars_files:
    - "defaults/{{ install_method }}_install.yml"
  tags:
    - nova
  tasks:
    - name: Execute nova service reload
      include: common-tasks/restart-service.yml
      vars:
        service_name: "nova"
        service_action: "reloaded"
        service_negate: "{{ ['nova-placement-api.service', 'nova-novncproxy.service', 'nova-spicehtml5proxy.service' ] + nova_service_negate | default([]) }}"
      when:
        - "nova_all_software_updated | bool"
        - "ansible_local['openstack_ansible']['nova']['need_service_restart'] | bool"



# Note that the placement API service and the console services do not
# understand how to reload, so they fail when you try to make them do
# so. We therefore restart them instead.
- name: Restart the remaining nova services to ensure new RPC object version is used
  hosts: "nova_api_placement:nova_console"
  gather_facts: no
  serial: "{{ nova_api_serial | default(['1', '100%']) }}"
  user: root
  environment: "{{ deployment_environment_variables | default({}) }}"
  vars_files:
    - "defaults/{{ install_method }}_install.yml"
  tags:
    - nova
  tasks:
    - name: Execute nova service restart
      include: common-tasks/restart-service.yml
      vars:
        service_name: "nova"
        service_action: "restarted"
        service_fact: "nova"
      when:
        - "nova_all_software_updated | bool"
        - "ansible_local['openstack_ansible']['nova']['need_service_restart'] | bool"



- name: Perform online database migrations
  hosts: nova_conductor
  gather_facts: no
  user: root
  environment: "{{ deployment_environment_variables | default({}) }}"
  vars_files:
    - "defaults/{{ install_method }}_install.yml"
  tags:
    - nova
  tasks:
    - name: Perform online data migrations
      command: "{{ nova_bin }}/nova-manage db online_data_migrations"
      become: yes
      become_user: "{{ nova_system_user_name }}"
      when:
        - "nova_all_software_updated | bool"
        - "ansible_local['openstack_ansible']['nova']['need_online_data_migrations'] | bool"
      changed_when: false
      run_once: yes
      register: data_migrations

    - name: Disable the online migrations requirement
      ini_file:
        dest: "/etc/ansible/facts.d/openstack_ansible.fact"
        section: nova
        option: need_online_data_migrations
        value: False
      when:
        - data_migrations  is succeeded

**********
DECISION===>: PASS
**********
=========================:::523:::END!!!=========================
=========================:::524:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/unbound-install.yml
**********
---
# Copyright 2016, Logan Vig <logan2211@gmail.com>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Install unbound DNS resolvers
  hosts:
    - unbound
  gather_facts: "{{ osa_gather_facts | default(True) }}"
  user: root
  pre_tasks:
    - include: common-tasks/os-log-dir-setup.yml
    - include: "common-tasks/os-{{ container_tech | default('lxc') }}-container-setup.yml"
      static: no
      when: not is_metal
  roles:
    - role: "unbound"
      tags:
        - unbound_server
    - role: "system_crontab_coordination"
      tags:
        - "system-crontab-coordination"
  vars_files:
    - defaults/repo_packages/openstack_services.yml

- name: Install unbound DNS resolver client configurations
  hosts:
    - "!unbound"
    - "{{ openstack_host_group|default('hosts') }}"
  user: root
  tasks:
    - include: common-tasks/unbound-clients.yml
      static: no
      when:
        - hostvars['localhost']['resolvconf_enabled'] | bool
  environment: "{{ deployment_environment_variables | default({}) }}"

**********
DECISION===>: PASS
**********
=========================:::524:::END!!!=========================
=========================:::525:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/os-blazar-install.yml
**********
---
# Copyright 2018, taseer94@gmail.com
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Install blazar components
  hosts: blazar_all
  gather_facts: "{{ osa_gather_facts | default(True) }}"
  environment: "{{ deployment_environment_variables | default({}) }}"
  user: root
  vars_files:
    - "defaults/{{ install_method }}_install.yml"
  tags:
    - blazar
  pre_tasks:
    - include_tasks: "common-tasks/os-{{ container_tech | default('lxc') }}-container-setup.yml"
      when: not is_metal

    - name: Configure log directories (on metal)
      include_tasks: common-tasks/os-log-dir-setup.yml
      vars:
        log_dirs:
          - src: "/openstack/log/{{ inventory_hostname }}-blazar"
            dest: "/var/log/blazar"

    - include_tasks: common-tasks/unbound-clients.yml
      when:
        - hostvars['localhost']['resolvconf_enabled'] | bool

    - name: Configure package proxy cache
      include_tasks: common-tasks/package-cache-proxy.yml
      when: install_method == "source"

  roles:
    - role: "os_blazar"
    - role: "system_crontab_coordination"
      tags:
        - crontab

  post_tasks:
    - include_tasks: "common-tasks/rsyslog-client.yml"
      vars:
        rsyslog_client_log_rotate_file: blazar_log_rotate
        rsyslog_client_log_dir: "/var/log/blazar"
        rsyslog_client_config_name: "99-blazar-rsyslog-client.conf"

**********
DECISION===>: PASS
**********
=========================:::525:::END!!!=========================
=========================:::526:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/galera-install.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Galera container config
  hosts: galera_all
  gather_facts: "{{ osa_gather_facts | default(True) }}"
  serial: 1
  user: root
  tasks:
    - include: common-tasks/os-log-dir-setup.yml
      vars:
        log_dirs:
          - src: "/openstack/log/{{ inventory_hostname }}-mysql_logs"
            dest: "/var/log/mysql_logs"
    - include: "common-tasks/os-{{ container_tech | default('lxc') }}-container-setup.yml"
      static: no
      when: not is_metal
      vars:
        list_of_bind_mounts: "{{ galera_container_bind_mounts }}"
        extra_container_config_no_restart:
          - "lxc.start.order=10"
    - include: common-tasks/unbound-clients.yml
      static: no
      when:
        - hostvars['localhost']['resolvconf_enabled'] | bool
  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - galera

- name: Install galera server
  hosts: galera_all
  gather_facts: "{{ osa_gather_facts | default(True) }}"
  serial: 1
  user: root
  roles:
    - role: haproxy_endpoints
      haproxy_state: disabled
      static: no
      when: "groups['haproxy'] | default([]) | length > 0"
    - role: "galera_server"
    - role: haproxy_endpoints
      haproxy_state: enabled
      static: no
      when: "groups['haproxy'] | default([]) | length > 0"
    - role: "system_crontab_coordination"
      tags:
        - crontab

  post_tasks:
    - include_tasks: "common-tasks/rsyslog-client.yml"
      vars:
        rsyslog_client_log_rotate_file: galera_log_rotate
        rsyslog_client_log_dir: "/var/log/mysql_logs"
        rsyslog_client_log_files:
          - /var/log/mysql.log
          - /var/log/mysql.err
        rsyslog_client_config_name: "99-galera-rsyslog-client.conf"

  vars:
    galera_server_id: "{{ inventory_hostname | string_2_int }}"
    galera_wsrep_node_name: "{{ container_name | default(inventory_hostname) }}"
  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - galera

**********
DECISION===>: PASS
**********
=========================:::526:::END!!!=========================
=========================:::527:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/setup-everything.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- include: setup-hosts.yml
- include: setup-infrastructure.yml
- include: setup-openstack.yml

**********
DECISION===>: PASS
**********
=========================:::527:::END!!!=========================
=========================:::528:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/healthcheck-openstack.yml
**********
---
# Copyright 2018, SUSE LINUX GmbH.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# (c) 2018, Jean-Philippe Evrard <jean-philippe@evrard.me>

# This playbook is meant to run after setup-openstack, and expects
# the openstack plays to have succeeded.

# Test os-keystone-install.yml
# Many parts of keystone testing is happening in playbooks already, as
# we are using it for setting up all the other openstack services.
- name: Test Keystone
  gather_facts: no
  hosts: localhost
  vars_files:
    - defaults/healthchecks-vars.yml
  tasks:
    - name: Authenticate to the cloud and retrieve the service catalog
      os_auth:
        cloud: default
        interface: internal
        verify: "{{ keystone_service_internaluri_insecure | ternary(false, true) }}"

    - name: Show service catalog
      debug:
        var: service_catalog
  tags:
    - healthchecks
    - healthchecks-keystone-install


# Test os-barbican-install.yml
# TO BE IMPLEMENTED -- there is no ansible module for that so cli might be needed.

# Test os-glance-install.yml
# If tempest is installed, this is tested anyway and can be skipped.
- name: Test Glance
  gather_facts: no
  hosts: localhost
  vars_files:
    - defaults/healthchecks-vars.yml
  tasks:
    - block:
        - name: Image(s) download
          get_url:
            url: "{{ item.url }}"
            dest: "{{ item.dest }}"
            checksum: "{{ item.checksum | default(omit) }}"
          with_items: "{{ glance_images }}"
          register: fetch_url
          until: fetch_url is success
          retries: 6
          delay: 5

        - name: Upload tempest images to glance
          os_image:
            cloud: default
            interface: internal
            verify: "{{ keystone_service_internaluri_insecure | ternary(false, true) }}"
            name: "{{ item.name | default(item.url | basename) }}"
            filename: "{{ item.dest }}"
            container_format: bare
            disk_format: "{{ item.format }}"
            is_public: True
          with_items: "{{ glance_images }}"
          register: image_create
          until: image_create is success
          retries: 5
          delay: 15
      when:
        # No point of doing glance tests is glance isn't deployed.
        - "groups['glance_all'] | length > 0"
  tags:
    - healthchecks
    - healthchecks-glance-install

# Test os-cinder-install.yml
- name: Test cinder
  gather_facts: no
  hosts: localhost
  vars_files:
    - defaults/healthchecks-vars.yml
  tasks:
    - block:
        # This automatically waits for completion by default.
        # There is no module to check the current state of a creation, so we need to run
        # This synchronously
        - name: Create volumes
          os_volume:
            cloud: default
            interface: internal
            verify: "{{ keystone_service_internaluri_insecure | ternary(false, true) }}"
            display_name: "{{ item.name }}"
            size: "{{ item.size }}"
            snapshot_id: "{{ item.snapshot_id | default(omit) }}"
            timeout: "{{ item.timeout | default(600) }}" #By default it's 180 but that's low.
            volume: "{{ item.volume | default(omit) }}"
            volume_type: "{{ item.volume_type | default(omit) }}"
          with_items: "{{ cinder_volumes }}"
      when:
        - groups['cinder_all'] | length > 0
  tags:
    - healthchecks
    - healthchecks-cinder-install

# NOTE(evrardjp): This doesn't respect playbook order, as we'll need neutron tests to
# run before nova tests

# Test os-neutron-install.yml
- name: Test neutron
  gather_facts: no
  hosts: localhost
  vars_files:
    - defaults/healthchecks-vars.yml
  tasks:
    - block:
        - name: Create networks
          os_network:
            cloud: default
            interface: internal
            verify: "{{ keystone_service_internaluri_insecure | ternary(false, true) }}"
            name: "{{ item.value.name }}"
            provider_network_type: "{{ item.value.pn_type }}"
            provider_physical_network: "{{ item.value.physical_network | default('') }}"
            provider_segmentation_id: "{{ item.value.segmentation_id | default(omit) }}"
            external: "{{ item.value.external | default(omit) }}"
            project: "{{ item.value.project | default(omit) }}"
          with_dict: "{{ neutron_networks }}"
          register: _create_net

        - fail:
            msg: "Creating network failure"
          with_items: "{{ _create_net.results }}"
          when:
            - "item.msg is defined"
            - "'Error' in item.msg"
            - "not 'is in use' in item.msg"

        - name: Store facts to see if everything is ok
          os_networks_facts:
            cloud: default
            interface: internal
            verify: no

        - name: Show networks
          debug:
            var: openstack_networks

        - name: Ensure subnet exists
          os_subnet:
            cloud: default
            interface: internal
            verify: "{{ keystone_service_internaluri_insecure | ternary(false, true) }}"
            network_name: "{{ item[0].name }}"
            name: "{{ item[1].name }}"
            ip_version: "{{ item[1].ip_version }}"
            cidr: "{{ item[1].cidr }}"
            gateway_ip: "{{ item[1].gateway_ip | default(omit) }}"
            enable_dhcp: "{{ item[1].enable_dhcp | default(false) }}"
            allocation_pool_start: "{{ item[1].allocation_pool_start  | default(omit) }}"
            allocation_pool_end: "{{ item[1].allocation_pool_end | default(omit) }}"
            dns_nameservers: "{{ item[1].dns_nameservers | default([]) }}"
            project: "{{ item[0].project | default(omit) }}"
          with_subelements:
            - "{{ neutron_networks }}"
            - "subnets"

        - name: Create router
          os_router:
            cloud: default
            interface: internal
            verify: "{{ keystone_service_internaluri_insecure | ternary(false, true) }}"
            name: router
            network: "{{ neutron_networks['public']['name'] }}"
            interfaces:
              - "{{ item.name }}"
          with_items: "{{ neutron_networks['private']['subnets'] }}"
      when:
        - "groups['neutron_all'] | length > 0"
  tags:
    - healthchecks
    - healthchecks-neutron-install


# Test os-heat-install.yml
- name: Test heat
  gather_facts: no
  hosts: localhost
  vars_files:
    - defaults/healthchecks-vars.yml
  tasks:
    - block:
        - name: Fetch minimum heat stack
          get_url:
            url: "{{ heat_stack['source_url'] }}"
            dest: "{{ heat_stack['dest_file'] }}"

        - name: Create heat stack
          ignore_errors: True
          register: stack_create
          os_stack:
            cloud: default
            interface: internal
            verify: "{{ keystone_service_internaluri_insecure | ternary(false, true) }}"
            name: "{{ heat_stack['name'] }}"
            tag: "{{ heat_stack['tag'] }}"
            state: present
            template: "{{ heat_stack['dest_file'] }}"
            parameters: "{{ heat_stack['parameters'] }}"
      when:
        - "groups['heat_all'] | length > 0"
  tags:
    - healthchecks
    - healthchecks-heat-install

# Test os-nova-install.yml
- name: Test nova
  gather_facts: no
  hosts: localhost
  vars_files:
    - defaults/healthchecks-vars.yml
  tasks:
    - block:
        - name: Create keypair for nova
          shell: "ssh-keygen -b 2048 -t rsa -f {{ ssh_key }} -q -N ''"
          args:
            creates: "{{ ssh_key }}"

        - name: Upload keypair
          os_keypair:
            cloud: default
            interface: internal
            verify: "{{ keystone_service_internaluri_insecure | ternary(false, true) }}"
            state: present
            name: "healthcheck"
            public_key_file: "{{ ssh_key }}.pub"

        - name: Create flavors of nova VMs
          os_nova_flavor:
            cloud: default
            interface: internal
            verify: "{{ keystone_service_internaluri_insecure | ternary(false, true) }}"
            state: present
            name: "{{ item.name }}"
            ram: "{{ item.ram }}"
            vcpus: "{{ item.vcpus }}"
            disk: "{{ item.disk }}"
            swap: "{{ item.swap }}"
            ephemeral: "{{ item.ephemeral }}"
          with_items: "{{ nova_flavors }}"

        - name: Create security group for healthcheck
          os_security_group:
            cloud: default
            interface: internal
            verify: "{{ keystone_service_internaluri_insecure | ternary(false, true) }}"
            name: "{{ security_group.name }}"
            state: present
            description: "Healthcheck servers"

        - name: Create security group rules
          os_security_group_rule:
            cloud: default
            interface: internal
            verify: "{{ keystone_service_internaluri_insecure | ternary(false, true) }}"
            security_group: "{{ security_group.name }}"
            protocol: "{{ item.protocol }}"
            port_range_min: "{{ item.port_range_min }}"
            port_range_max: "{{ item.port_range_max }}"
            remote_ip_prefix: "{{ item.remote_ip_prefix }}"
            state: present
          with_items: "{{ security_group.rules }}"

        - name: Create instance in a network
          os_server:
            cloud: default
            interface: internal
            verify: "{{ keystone_service_internaluri_insecure | ternary(false, true) }}"
            name: "{{ nova_vm.name }}"
            state: present
            image: "{{ nova_vm.image }}"
            flavor: "{{ nova_vm.flavor }}"
            network: "{{ nova_vm.network }}"
            floating_ip_pools: "{{ neutron_networks['public']['name'] }}"
            key_name: "healthcheck"
            # Ensure user_data is well passed.
            user_data: |
              cp /etc/fstab /root/fstab
            security_groups:
              - default
              - "{{ security_group.name }}"

        - name: Attach volume to instance
          when: "groups['cinder_all'] | length > 0"
          os_server_volume:
            cloud: default
            interface: internal
            verify: "{{ keystone_service_internaluri_insecure | ternary(false, true) }}"
            state: present
            server: "{{ nova_vm.name }}"
            volume: "{{ cinder_volumes[0]['name'] }}"

        - name: Get server facts
          os_server_facts:
            cloud: default
            interface: internal
            verify: "{{ keystone_service_internaluri_insecure | ternary(false, true) }}"
            server: "{{ nova_vm.name }}"

        - name: Show server facts
          debug:
            var: openstack_servers

        - name: Discover the healthcheck vm floating IP
          set_fact:
            _floating_ip: "{{ openstack_servers | json_query(_query) }}"
          vars:
            _query: "[?name == '{{ nova_vm.name }}'].addresses.{{ nova_vm.network }}[] | [?contains(*,'floating')].addr"

        - name: Ensure connection to node works
          command: "scp -o StrictHostKeyChecking=no -i {{ ssh_key }} cirros@{{ _floating_ip[0] }}:/etc/fstab /tmp/fstab"

      when:
        - "groups['nova_all'] | length > 0"

  tags:
    - healthchecks
    - healthchecks-nova-install

# Test os-horizon-install.yml
# TO BE IMPLEMENTED

# Test os-designate-install.yml
# TO BE IMPLEMENTED with os_recordset

# Test os-swift-install.yml
- name: Test swift
  gather_facts: no
  hosts: localhost
  vars_files:
    - defaults/healthchecks-vars.yml
  tasks:
    - block:
        - name: Store data in swift
          os_object:
            cloud: default
            interface: internal
            verify: "{{ keystone_service_internaluri_insecure | ternary(false, true) }}"
            state: present
            name: "{{ swift_object['name'] }}"
            container: "{{ swift_object['container'] }}"
            filename: "{{ swift_object['filename'] }}"
      when:
        - "groups['swift_all'] | length > 0"
  tags:
    - healthchecks
    - healthchecks-swift-install

# Test os-gnocchi-install.yml
# TO BE IMPLEMENTED

# Test os-ceilometer-install.yml
# TO BE IMPLEMENTED

# Test os-aodh-install.yml
# TO BE IMPLEMENTED

# Test os-ironic-install.yml
# TO BE IMPLEMENTED with os_ironic

# Test os-magnum-install.yml
# TO BE IMPLEMENTED

# Test os-trove-install.yml
# TO BE IMPLEMENTED

# Test os-sahara-install.yml
# TO BE IMPLEMENTED

# Test os-molteniron-install.yml
# TO BE IMPLEMENTED

# Test os-octavia-install.yml
# TO BE IMPLEMENTED

# Test os-tacker-install.yml
# TO BE IMPLEMENTED

# Test os-congress-install.yml
# TO BE IMPLEMENTED

# Test os-tempest-install.yml
# Tempest already has a test suite, so nothing should be added here.

# Teardown
- name: Teardown
  gather_facts: no
  hosts: localhost
  vars_files:
    - defaults/healthchecks-vars.yml
  tasks:
    - block:
        - name: Remove glance downloads
          file:
            state: absent
            path: "{{ item.dest }}"
          with_items: "{{ glance_images }}"

        - name: Remove glance image from the cloud
          os_image:
            cloud: default
            interface: internal
            verify: "{{ keystone_service_internaluri_insecure | ternary(false, true) }}"
            name: "{{ item.name | default(item.url | basename) }}"
            state: absent
          with_items: "{{ glance_images }}"
      when:
        - "groups['glance_all'] | length > 0"
        - healthchecks_teardown | default(True) | bool
      tags:
        - healthchecks-teardown-glance

    - block:
        - name: Detach volume if attached
          when: "groups['nova_all'] | length > 0"
          os_server_volume:
            cloud: default
            interface: internal
            verify: "{{ keystone_service_internaluri_insecure | ternary(false, true) }}"
            state: absent
            server: "{{ nova_vm.name }}"
            volume: "{{ cinder_volumes[0]['name'] }}"

        - name: Remove cinder volumes
          os_volume:
            cloud: default
            interface: internal
            verify: "{{ keystone_service_internaluri_insecure | ternary(false, true) }}"
            display_name: "{{ item.name }}"
            state: absent
          with_items: "{{ cinder_volumes }}"
      when:
        - groups['cinder_all'] | length > 0
        - healthchecks_teardown | default(True) | bool
      tags:
        - healthchecks-teardown-cinder

    - block:
        - name: Remove heat downloads
          file:
            path: "{{ heat_stack['dest_file'] }}"
            state: absent

        - name: Remove heat stack
          ignore_errors: True
          register: _stack_destroy
          os_stack:
            cloud: default
            interface: internal
            verify: "{{ keystone_service_internaluri_insecure | ternary(false, true) }}"
            name: "{{ heat_stack['name'] }}"
            tag: "{{ heat_stack['tag'] }}"
            state: absent
        - name: Show results of heath stack destroy
          debug:
            var: _stack_destroy
      when:
        - "groups['heat_all'] | length > 0"
        - healthchecks_teardown | default(True) | bool
      tags:
        - healthchecks-teardown-heat

    - block:
        - name: Remove nova flavor
          os_nova_flavor:
            cloud: default
            interface: internal
            verify: "{{ keystone_service_internaluri_insecure | ternary(false, true) }}"
            state: absent
            name: "{{ item.name }}"
          with_items: "{{ nova_flavors }}"

        - name: Remove nova instance
          os_server:
            cloud: default
            interface: internal
            verify: "{{ keystone_service_internaluri_insecure | ternary(false, true) }}"
            name: "{{ nova_vm['name'] }}"
            state: absent

        - name: Remove SSH key(s)
          file:
            path: "{{ item }}"
            state: absent
          with_items:
            - "{{ ssh_key }}"
            - "{{ ssh_key }}.pub"
            - "{{ ssh_key | dirname }}/known_hosts"

        - name: Remove uploaded keypair
          os_keypair:
            cloud: default
            interface: internal
            verify: "{{ keystone_service_internaluri_insecure | ternary(false, true) }}"
            state: absent
            name: healthcheck

      when:
        - "groups['nova_all'] | length > 0"
        - healthchecks_teardown | default(True) | bool
      tags:
        - healthchecks-teardown-nova

    - block:
        - name: Teardown swift data
          os_object:
            cloud: default
            interface: internal
            verify: "{{ keystone_service_internaluri_insecure | ternary(false, true) }}"
            state: absent
            name: "{{ swift_object['name'] }}"
            container: "{{ swift_object['container'] }}"
      when:
        - "groups['swift_all'] | length > 0"
        - healthchecks_teardown | default(True) | bool
      tags:
        - healthchecks-teardown-swift

#    - block:
#        - name: Remove
#
#      when:
#        - "groups['_all'] | length > 0"
#        - healthchecks-teardown | default(True) | bool
#      tags:
#        - healthchecks-teardown-

  tags:
    - healthchecks
    - healthchecks-teardown

**********
DECISION===>: PASS
**********
=========================:::528:::END!!!=========================
=========================:::529:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/containers-deploy.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- include: "containers-lxc-host.yml"
- include: "containers-lxc-create.yml"
- include: "containers-nspawn-host.yml"
- include: "containers-nspawn-create.yml"

**********
DECISION===>: PASS
**********
=========================:::529:::END!!!=========================
=========================:::530:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/os-congress-install.yml
**********
---
# Copyright 2017, taseer94@gmail.com
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Install congress components
  hosts: congress_all
  gather_facts: "{{ gather_facts | default(True) }}"
  max_fail_percentage: 20
  user: root
  environment: "{{ deployment_environment_variables | default({}) }}"
  vars_files:
    - "defaults/{{ install_method }}_install.yml"
  tags:
    - congress
  pre_tasks:
    - include: "common-tasks/os-{{ container_tech | default('lxc') }}-container-setup.yml"
      static: no
      when: not is_metal

    - name: Configure log directories (on metal)
      include: common-tasks/os-log-dir-setup.yml
      vars:
        log_dirs:
          - src: "/openstack/log/{{ inventory_hostname }}-congress"
            dest: "/var/log/congress"

    - include: common-tasks/unbound-clients.yml
      static: no
      when:
        - hostvars['localhost']['resolvconf_enabled'] | bool

    - name: Configure package proxy cache
      include: common-tasks/package-cache-proxy.yml
      when: install_method == "source"

  roles:
    - role: "os_congress"
    - role: "system_crontab_coordination"
      tags:
        - crontab

  post_tasks:
    - include_tasks: "common-tasks/rsyslog-client.yml"
      vars:
        rsyslog_client_log_rotate_file: congress_log_rotate
        rsyslog_client_log_dir: "/var/log/congress"
        rsyslog_client_config_name: "99-congress-rsyslog-client.conf"

**********
DECISION===>: PASS
**********
=========================:::530:::END!!!=========================
=========================:::531:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/os-octavia-install.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Install octavia server
  hosts: octavia_all
  gather_facts: "{{ osa_gather_facts | default(True) }}"
  user: root
  environment: "{{ deployment_environment_variables | default({}) }}"
  vars_files:
    - "defaults/{{ install_method }}_install.yml"
  tags:
    - octavia
  pre_tasks:
    - include: "common-tasks/os-{{ container_tech | default('lxc') }}-container-setup.yml"
      static: no
      when: not is_metal

    - include: common-tasks/os-log-dir-setup.yml
      vars:
        log_dirs:
          - src: "/openstack/log/{{ inventory_hostname }}-octavia"
            dest: "/var/log/octavia"

    - include: common-tasks/unbound-clients.yml
      static: no
      when:
        - hostvars['localhost']['resolvconf_enabled'] | bool
  roles:
    - role: "os_octavia"
    - role: "system_crontab_coordination"
      tags:
        - crontab

  post_tasks:
    - include_tasks: "common-tasks/rsyslog-client.yml"
      vars:
        rsyslog_client_log_rotate_file: octavia_log_rotate
        rsyslog_client_log_dir: "/var/log/octavia"
        rsyslog_client_config_name: "100-octavia-rsyslog-client.conf"

**********
DECISION===>: PASS
**********
=========================:::531:::END!!!=========================
=========================:::532:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/os-aodh-install.yml
**********
---
# Copyright 2015, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Install the aodh components
  hosts: aodh_all
  gather_facts: "{{ osa_gather_facts | default(True) }}"
  user: root
  environment: "{{ deployment_environment_variables | default({}) }}"
  vars_files:
    - "defaults/{{ install_method }}_install.yml"
  tags:
    - aodh
  pre_tasks:
    - include: "common-tasks/os-{{ container_tech | default('lxc') }}-container-setup.yml"
      static: no
      when: not is_metal

    - include: common-tasks/os-log-dir-setup.yml
      vars:
        log_dirs:
          - src: "/openstack/log/{{ inventory_hostname }}-aodh"
            dest: "/var/log/aodh"

    - include: common-tasks/unbound-clients.yml
      static: no
      when:
        - hostvars['localhost']['resolvconf_enabled'] | bool

  roles:
    - role: "os_aodh"

  post_tasks:
    - include_tasks: "common-tasks/rsyslog-client.yml"
      vars:
        rsyslog_client_log_rotate_file: aodh_log_rotate
        rsyslog_client_log_dir: "/var/log/aodh"
        rsyslog_client_config_name: "99-aodh-rsyslog-client.conf"

**********
DECISION===>: PASS
**********
=========================:::532:::END!!!=========================
=========================:::533:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/os-magnum-install.yml
**********
---
# Copyright 2016 Internet Solutions (Pty) Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# (c) 2016 Donovan Francesco <donovan.francesco@is.co.za>
# (c) 2016 Paul Stevens <paul.stevens@is.co.za>

- name: Install magnum server
  hosts: magnum_all
  user: root
  environment: "{{ deployment_environment_variables | default({}) }}"
  vars_files:
    - "defaults/{{ install_method }}_install.yml"
  tags:
    - magnum
  pre_tasks:
    - include: "common-tasks/os-{{ container_tech | default('lxc') }}-container-setup.yml"
      static: no
      when: not is_metal

    - include: common-tasks/os-log-dir-setup.yml
      vars:
        log_dirs:
          - src: "/openstack/log/{{ inventory_hostname }}-magnum"
            dest: "/var/log/magnum"

    - include: common-tasks/unbound-clients.yml
      static: no
      when:
        - hostvars['localhost']['resolvconf_enabled'] | bool

  roles:
    - role: "os_magnum"

  post_tasks:
    - include_tasks: "common-tasks/rsyslog-client.yml"
      vars:
        rsyslog_client_log_rotate_file: magnum_log_rotate
        rsyslog_client_log_dir: "/var/log/magnum"
        rsyslog_client_config_name: "99-magnum-rsyslog-client.conf"

**********
DECISION===>: PASS
**********
=========================:::533:::END!!!=========================
=========================:::534:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/setup-openstack.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- include: os-keystone-install.yml
- include: os-barbican-install.yml
- include: os-glance-install.yml
- include: os-cinder-install.yml
- include: os-nova-install.yml
- include: os-neutron-install.yml
- include: os-heat-install.yml
- include: os-horizon-install.yml
- include: os-designate-install.yml
#NOTE(stevelle) Ensure Gnocchi identities exist before Swift
- include: os-gnocchi-install.yml
  when:
    - gnocchi_storage_driver is defined
    - gnocchi_storage_driver == 'swift'
  vars:
    gnocchi_identity_only: True
- include: os-swift-install.yml
- include: os-gnocchi-install.yml
- include: os-ceilometer-install.yml
- include: os-aodh-install.yml
- include: os-ironic-install.yml
- include: os-magnum-install.yml
- include: os-trove-install.yml
- include: os-sahara-install.yml
- include: os-octavia-install.yml
- include: os-tacker-install.yml
- include: os-blazar-install.yml

# This is not an OpenStack service, but integrates with Keystone and must be
# deployed afterward.
- include: ceph-rgw-install.yml
- include: os-congress-install.yml
- include: os-tempest-install.yml
  when: (tempest_install | default(False)) | bool or (tempest_run | default(False)) | bool


**********
DECISION===>: PASS
**********
=========================:::534:::END!!!=========================
=========================:::535:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/containers-nspawn-host.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Additional nspawn host setup
  hosts: "{{ nspawn_host_group | default('nspawn_hosts') }}"
  gather_facts: true
  vars_files:
    - "defaults/{{ install_method }}_install.yml"
  user: root
  roles:
    - role: "nspawn_hosts"
  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - nspawn-hosts

**********
DECISION===>: PASS
**********
=========================:::535:::END!!!=========================
=========================:::536:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/ceph-rgw-install.yml
**********
---
# Copyright 2017, Logan Vig <logan2211@gmail.com>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- include: ceph-rgw-keystone-setup.yml
  when: (groups['ceph-rgw'] is defined and groups['ceph-rgw'] | length > 0) or (ceph_rgws | length > 0)

- name: Install ceph radosgw
  hosts: ceph-rgw
  user: root
  vars_files:
    - "defaults/{{ install_method }}_install.yml"
  pre_tasks:
    - include: common-tasks/os-log-dir-setup.yml
      vars:
        log_dirs:
          - src: "/openstack/log/{{ inventory_hostname }}-ceph"
            dest: "/var/log/ceph"

    - include: common-tasks/os-lxc-container-setup.yml
      when: not is_metal
      static: no

    - name: Gather ceph-mon facts
      action: setup
      delegate_to: "{{ item }}"
      delegate_facts: yes
      with_items: "{{ groups[mon_group_name] }}"
      when:
        - inventory_hostname == ansible_play_hosts[0]
      tags:
        - ceph-mon-facts

    # Set the priority of the ceph community apt repo either above or below that of UCA or distro sources
    - name: Set apt package pins
      include_role:
        name: apt_package_pinning
      vars:
        apt_package_pinning_file_name: "ceph_community_pin.pref"
        apt_package_pinning_priority: "{{ (ceph_repository == 'community') | ternary(1000, 100) }}"
        apt_pinned_packages: [{ package: '*', release: 'ceph.com' }]
      when:
        - ansible_pkg_mgr == 'apt'

  roles:
    - role: ceph-defaults
      tags:
        - skip_ansible_lint
    - role: ceph-handler
      tags:
        - skip_ansible_lint
    - role: ceph-common
      tags:
        - skip_ansible_lint
    - role: ceph-config
      tags:
        - skip_ansible_lint
    - role: ceph-rgw
      tags:
        - skip_ansible_lint
    - role: "system_crontab_coordination"
      tags:
        - "system-crontab-coordination"

  post_tasks:
    - include_tasks: "common-tasks/rsyslog-client.yml"
      vars:
        rsyslog_client_log_rotate_file: ceph_log_rotate
        rsyslog_client_log_dir: "/var/log/ceph"
        rsyslog_client_config_name: "99-ceph-rsyslog-client.conf"

  vars:
    is_metal: "{{ properties.is_metal|default(false) }}"
    radosgw_civetweb_port: "{{ radosgw_service_port }}"
  tags:
    - ceph-rgw

**********
DECISION===>: PASS
**********
=========================:::536:::END!!!=========================
=========================:::537:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/containers-nspawn-create.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Gather nspawn container host facts
  hosts: "{{ nspawn_host_group | default('nspawn_hosts') }}"
  gather_facts: true


- name: Set nspawn containers group
  hosts: "{{ container_group | default('all_containers') }}"
  gather_facts: false
  tags:
    - always
    - nspawn-containers-create
  tasks:
    - name: Add hosts to dynamic inventory group
      group_by:
        key: nspawn_containers
        parents: all_nspawn_containers
      when:
        - container_tech == 'nspawn'


- name: Create container(s)
  hosts: all_nspawn_containers
  gather_facts: false
  user: root
  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - nspawn-containers-create
  roles:
    - role: "nspawn_container_create"
  post_tasks:
    - name: Wait for container connectivity
      wait_for_connection:
        connect_timeout: "{{ lxc_container_wait_params.connect_timeout | default(omit) }}"
        delay: "{{ lxc_container_wait_params.delay | default(omit) }}"
        sleep: "{{ lxc_container_wait_params.sleep | default(omit) }}"
        timeout: "{{ lxc_container_wait_params.timeout | default(omit) }}"


- name: Rescan storage quotas
  hosts: "{{ nspawn_host_group | default('nspawn_hosts') }}"
  gather_facts: false
  tags:
    - nspawn-containers-create
  tasks:
    - name: Rescan quotas
      command: "btrfs quota rescan -w /var/lib/machines"
      changed_when: false


- name: Configure containers default software
  hosts: all_nspawn_containers
  gather_facts: true
  user: root
  vars_files:
    - defaults/repo_packages/openstack_services.yml
    - "defaults/{{ install_method }}_install.yml"
  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - nspawn-containers-create
  pre_tasks:
    - name: Update package cache (apt)
      package:
        update_cache: yes
        force_apt_get: yes
        force: yes
      register: cache_update
      until: cache_update is success
      retries: 5
      delay: 15
      when:
        - ansible_pkg_mgr == 'apt'

    - name: Update package cache (zypper)
      zypper_repository:
        repo: '*'
        runrefresh: yes
      register: cache_update
      until: cache_update is success
      retries: 5
      delay: 15
      when:
        - ansible_pkg_mgr == 'zypper'

    # When using gather_facts with smart gathering,
    # the facts aren't fully updated unless they
    # are old. Using the setup module in a task
    # does a more thorough collection.
    # Given we've just created the container, it is
    # best that we do a full collection of facts -
    # otherwise we end up with a stale set which
    # has stuff like the hostname = localhost.
    - name: Gather facts for new container(s)
      setup:
        gather_subset: "network,hardware,virtual"

    - include: common-tasks/package-cache-proxy.yml
      when: install_method == "source"

    - include: common-tasks/set-pip-vars.yml
      when: install_method == "source"
  roles:
    - role: "openstack_hosts"
      is_container: true


**********
DECISION===>: PASS
**********
=========================:::537:::END!!!=========================
=========================:::538:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/infra-journal-remote.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Install Journal-Remote
  hosts: hosts
  gather_facts: "{{ osa_gather_facts | default(True) }}"
  become: true
  pre_tasks:
    # At this time there's no suitable package available for systemd-journal-remote/gateway
    # When installing on SUSE 42.x. For now this playbook will omit suse when the package
    # manager is "zypper". When a suitable package is available on SUSE this should be removed.
    - name: Omit suse from this playbook
      meta: end_play
      when:
        - ansible_pkg_mgr == 'zypper'

    - name: Skip playbook if log_hosts group is empty
      meta: end_play
      when:
        - groups['log_hosts'] | length == 0

    - name: Install systemd-journal-remote
      package:
        name: "{{ systemd_journal_remote_distro_package[ansible_pkg_mgr] }}"
        state: "{{ package_state }}"

    - name: Create journal directory
      file:
        path: "/var/log/journal"
        state: "directory"
        owner: "root"
        group: "systemd-journal"

    - name: Create journal remote directory
      file:
        path: "/var/log/journal/remote"
        state: "directory"
        owner: "systemd-journal-remote"
        group: "systemd-journal"

  roles:
    - role: "systemd_service"
      systemd_tempd_prefix: "openstack"
      systemd_CPUAccounting: true
      systemd_BlockIOAccounting: true
      systemd_MemoryAccounting: true
      systemd_TasksAccounting: true
      systemd_services:
        - service_name: "systemd-journal-remote"
          enabled: "{{ (ansible_host != systemd_journal_remote_target) | ternary('no', 'yes') }}"
          state: "{{ (ansible_host != systemd_journal_remote_target) | ternary('stopped', 'started') }}"
          execstarts: >-
            {{ systemd_utils_prefix }}/systemd-journal-remote
            --listen-http=-3
            --split-mode=host
            --compress
            --seal
            --output=/var/log/journal/remote/
          config_overrides:
            Unit:
              Description: "Journal Remote Sink Service"
              Documentation: "man:systemd-journal-remote(8) man:journal-remote.conf(5)"
              Requires: "systemd-journal-remote.socket"
            Service:
              WatchdogSec: "3min"
              LimitNOFILE: 16384
              User: "systemd-journal-remote"
              Group: "systemd-journal-remote"

        - service_name: "systemd-journal-upload"
          enabled: "{{ (ansible_host == systemd_journal_remote_target) | ternary('no', 'yes') }}"
          state: "{{ (ansible_host == systemd_journal_remote_target) | ternary('stopped', 'started') }}"
          execstarts: >-
            {{ systemd_utils_prefix }}/systemd-journal-upload
            --save-state
            --merge
            --url=http://{{ systemd_journal_remote_target }}:19532
          config_overrides:
            Unit:
              Description: "Journal Remote Upload Service"
              Documentation: "man:systemd-journal-upload(8)"
              After: "network.target"
            Service:
              WatchdogSec: "3min"
              LimitNOFILE: 16384
              User: "systemd-journal-upload"
              Group: "systemd-journal"

  vars:
    systemd_journal_remote_target: "{{ hostvars[groups['log_hosts'][0]]['ansible_host'] }}"
    systemd_journal_remote_distro_package:
      apt: "systemd-journal-remote"
      yum: "systemd-journal-gateway"
      dnf: "systemd-journal-gateway"

  tags:
    - journal-remote

**********
DECISION===>: PASS
**********
=========================:::538:::END!!!=========================
=========================:::539:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/lxc-hosts-setup.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Basic lxc host setup
  hosts: "{{ lxc_host_group | default('lxc_hosts')}}"
  user: root
  gather_facts: "{{ osa_gather_facts | default(True) }}"
  vars_files:
    - defaults/repo_packages/openstack_services.yml
    - "defaults/{{ install_method }}_install.yml"
  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - lxc-hosts
  pre_tasks:
    - include: common-tasks/set-pip-vars.yml
      when: install_method == "source"
    - name: Check the state of the default LXC service log directory
      stat:
        path: "/var/log/lxc"
      register: _lxc_log_dir
    - name: Create the log aggregation parent directory
      file:
        path: "/openstack/log"
        state: directory
    - name: Move the existing folder to the log aggregation parent
      command: "mv /var/log/lxc /openstack/log/{{ inventory_hostname }}-lxc"
      when:
        - _lxc_log_dir.stat.isdir is defined
        - _lxc_log_dir.stat.isdir | bool
    - name: Create the new LXC service log directory
      file:
        path: "/openstack/log/{{ inventory_hostname }}-lxc"
        state: directory
    - name: Create the LXC service log aggregation link
      file:
        src: "/openstack/log/{{ inventory_hostname }}-lxc"
        dest: "/var/log/lxc"
        state: "link"
  roles:
    - role: "lxc_hosts"

  post_tasks:
    - include_tasks: "common-tasks/rsyslog-client.yml"
      vars:
        rsyslog_client_log_rotate_file: lxc_log_rotate
        rsyslog_client_log_dir: "/var/log/lxc"
        rsyslog_client_config_name: "99-lxc-rsyslog-client.conf"

**********
DECISION===>: PASS
**********
=========================:::539:::END!!!=========================
=========================:::540:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/os-neutron-install.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Configure Neutron dynamic host groupings
  hosts: localhost
  gather_facts: no
  tags:
    - neutron
  tasks:
    - include: common-tasks/dynamic-grouping.yml
      vars:
        src_group: "nova_compute"
        dest_group: "neutron_l3_agent, neutron_metadata_agent"
        group_when: "{{ neutron_plugin_type == 'ml2.ovs.dvr' }}"



- name: Install neutron server
  include: common-playbooks/neutron.yml
  vars:
    neutron_hosts: "neutron_server"
    neutron_serial: "{{ neutron_server_serial | default('100%') }}"



- name: Install neutron L2 agents
  include: common-playbooks/neutron.yml
  vars:
    neutron_hosts: "neutron_linuxbridge_agent:neutron_openvswitch_agent:!neutron_server"
    neutron_serial: "{{ neutron_agent_serial | default('50%') }}"



- name: Install all other neutron agents
  include: common-playbooks/neutron.yml
  vars:
    neutron_hosts: "neutron_all:!neutron_linuxbridge_agent:!neutron_openvswitch_agent:!neutron_server"
    neutron_serial: "{{ neutron_other_serial | default('20%') }}"

**********
DECISION===>: PASS
**********
=========================:::540:::END!!!=========================
=========================:::541:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/security-hardening.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# As an additional safeguard, this playbook requires the
# 'apply_security_hardening' boolean set to True for it to apply security
# hardening standards to a system.

- name: Apply security hardening configurations
  hosts: "{{ security_host_group|default('hosts') }}"
  gather_facts: "{{ osa_gather_facts | default(True) }}"
  user: root
  roles:
    - role: "ansible-hardening"
      when: apply_security_hardening | bool
  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - security

**********
DECISION===>: PASS
**********
=========================:::541:::END!!!=========================
=========================:::542:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/haproxy-install.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: haproxy base config
  hosts: haproxy
  gather_facts: "{{ osa_gather_facts | default(True) }}"
  serial: "50%"
  user: root
  pre_tasks:
    - include: "common-tasks/os-{{ container_tech | default('lxc') }}-container-setup.yml"
      static: no
      when: not is_metal
    - include: common-tasks/os-log-dir-setup.yml
      vars:
        log_dirs:
          - src: "/openstack/log/{{ inventory_hostname }}-haproxy"
            dest: "/var/log/haproxy"
    - include: common-tasks/unbound-clients.yml
      static: no
      when:
        - hostvars['localhost']['resolvconf_enabled'] | bool
    - name: Remove legacy haproxy configuration files
      file:
        dest: "/etc/haproxy/conf.d/{{ item.name }}"
        state: "absent"
      with_items:
        - name: "keystone_internal"
          when: "internal_lb_vip_address == external_lb_vip_address"
        - name: "heat_api_cloudwatch"
          when: "yes"
      when:
       - "item.when | bool"
      tags:
        - haproxy-config  # this tag is present because the task is ONLY a config task
    - name: Remove legacy haproxy logging file
      file:
        dest: "/etc/rsyslog.d/haproxy.conf"
        state: "absent"
      tags:
        - haproxy-config  # this tag is present because the task is ONLY a config task
  roles:
    - role: "keepalived"
      when: haproxy_use_keepalived | bool
      tags:
        - keepalived
    - role: "haproxy_server"
      haproxy_service_configs: "{{ haproxy_default_services + haproxy_extra_services|default([]) }}"

  post_tasks:
    - include_tasks: "common-tasks/rsyslog-client.yml"
      vars:
        rsyslog_client_log_rotate_file: haproxy_log_rotate
        rsyslog_client_log_dir: "/var/log/haproxy"
        rsyslog_client_config_name: "99-haproxy-rsyslog-client.conf"

  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - haproxy-config
    - haproxy

**********
DECISION===>: PASS
**********
=========================:::542:::END!!!=========================
=========================:::543:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/common-tasks/set-pip-vars.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This set of tasks checks whether the repo is up yet. If it is it
# will use it as the source for constraints and as the default index.
# If it is not yet up, then it will use the upstream upper constraints
# for the SHA currently pinned and will set the default index to pypi.

- name: Backup the default pip_install_upper_constraints
  run_once: yes
  set_fact:
    __pip_install_upper_constraints: "{{ pip_install_upper_constraints }}"
  when:
    - __pip_install_upper_constraints is not defined

- name: Backup the default pip_default_index
  run_once: yes
  set_fact:
    __pip_default_index: "{{ pip_default_index }}"
  when:
    - __pip_default_index is not defined

- name: Test internal repo URL for the current upper constraints file
  run_once: yes
  uri:
    url: "{{ __pip_install_upper_constraints }}"
    method: "HEAD"
    timeout: 3
  register: upper_constraints_check
  failed_when: false
  tags:
    - common-constraints

- name: Remove global requirement pins file from host
  file:
    path: "/opt/global-requirement-pins.txt"
    state: absent
  when: (upper_constraints_check.status | default(503)) == 200
  tags:
    - common-constraints

- name: Copy global requirement pins file to host
  copy:
    src: "../global-requirement-pins.txt"
    dest: "/opt/global-requirement-pins.txt"
  when: (upper_constraints_check.status | default(503)) != 200
  tags:
    - common-constraints

- name: Set pip install upper constraints
  run_once: yes
  set_fact:
    pip_install_upper_constraints: >-
      {{ ((upper_constraints_check.status | default(503)) != 200) | ternary(__upstream_constraints, __pip_install_upper_constraints) }}
  vars:
    # Use https when Python with native SNI support is available
    __pip_install_upper_constraints_proto: "{{ ansible_python_version | version_compare('2.7.9', '>=') | ternary('https','http') }}"
    __upstream_constraints: >-
      /opt/global-requirement-pins.txt
      --constraint {{ __pip_install_upper_constraints_proto }}://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt?id={{ requirements_git_install_branch | regex_replace(' #.*$','') }}

  tags:
    - common-constraints

- name: Fall back to repo_build_pip_default_index
  run_once: yes
  set_fact:
    pip_default_index: >-
      {{ ((upper_constraints_check.status | default(503)) != 200) | ternary(repo_build_pip_default_index | default('https://pypi.python.org/simple'), __pip_default_index) }}
  tags:
    - common-constraints

**********
DECISION===>: PASS
**********
=========================:::543:::END!!!=========================
=========================:::544:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/common-tasks/rsyslog-client.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Run the rsyslog client role
  include_role:
    name: rsyslog_client
    private: true
  when:
    - rsyslog_client_enabled | bool
  tags:
    - rsyslog

**********
DECISION===>: PASS
**********
=========================:::544:::END!!!=========================
=========================:::545:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/common-tasks/os-nspawn-container-setup.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Pull systemd version
  command: "systemctl --version"
  changed_when: false
  register: systemd_version
  delegate_to: "{{ physical_host }}"
  tags:
    - skip_ansible_lint
    - always

- name: Set facts
  set_fact:
    nspawn_systemd_version: "{{ systemd_version.stdout_lines[0].split()[-1] }}"
  tags:
    - always

- name: Escape quote container name
  command: "systemd-escape {{ inventory_hostname }}"
  changed_when: false
  register: systemd_escape
  delegate_to: "{{ physical_host }}"
  tags:
    - skip_ansible_lint
    - always

- name: Ensure mount directories exists (container)
  file:
    path: "{{ item['mount_path'] }}"
    state: "directory"
  with_items:
    - "{{ list_of_bind_mounts | default([]) }}"
  delegate_to: "{{ physical_host }}"
  tags:
    - common-nspawn

- name: Ensure mount directories exists (physical host)
  file:
    path: "{{ item['bind_dir_path'] }}"
    state: "directory"
  with_items:
    - "{{ list_of_bind_mounts | default([]) }}"
  tags:
    - common-nspawn

- name: Create container bind mount config
  lineinfile:
    dest: "/etc/systemd/nspawn/{{ inventory_hostname }}.nspawn"
    line: "Bind={{ item['mount_path'] }}:{{ item['bind_dir_path'] }}"
    insertafter: "^Bind"
    backup: "true"
  with_items:
    - "{{ list_of_bind_mounts | default([]) }}"
  delegate_to: "{{ physical_host }}"
  register: add_bind
  when:
    - nspawn_systemd_version | int > 219
  tags:
    - common-nspawn

- name: Create container bind mount config (old)
  block:
    - name: Get ExecStart from config
      shell: >-
        grep -w '^ExecStart=/usr/bin/systemd-nspawn'
        /etc/systemd/system/systemd-nspawn@$(/usr/bin/systemd-escape {{ inventory_hostname }}).service
      delegate_to: "{{ physical_host }}"
      register: _ec_old_start
      changed_when: false

    - name: set flag fact
      set_fact:
        nspawn_flags: "{{ _ec_old_start.stdout.split('ExecStart=/usr/bin/systemd-nspawn')[-1] }}"
        nspawn_extra_flags: "{% for item in list_of_bind_mounts %} --bind={{ item['mount_path'] }}:{{ item['bind_dir_path'] }}{% endfor %}"

    - name: set flag list
      set_fact:
        nspawn_flag_list: "{{ nspawn_flags.split() | union(nspawn_extra_flags.split()) | unique }}"

    - name: Add line in container start config
      lineinfile:
        dest: "/etc/systemd/system/systemd-nspawn@{{ systemd_escape.stdout }}.service"
        line: "ExecStart=/usr/bin/systemd-nspawn {{ nspawn_flag_list | join(' ') }}"
        regexp: "^ExecStart"
        backup: "true"
      delegate_to: "{{ physical_host }}"
      register: _ec
  when:
    - list_of_bind_mounts | default([])
    - nspawn_systemd_version | int < 220
  tags:
    - common-nspawn

- name: Restart container
  systemd:
    name: "systemd-nspawn@{{ systemd_escape.stdout }}"
    state: restarted
  register: _container_restart
  until: _container_restart is success
  retries: 3
  delay: 5
  delegate_to: "{{ physical_host }}"
  when:
    - (_ec is defined and _ec is changed) or
      (add_bind is defined and add_bind is changed)
  tags:
    - common-nspawn

- name: Wait for container connectivity
  wait_for_connection:
    delay: 3
    timeout: 60
  when:
    - _container_restart  is changed
  tags:
    - common-nspawn

**********
DECISION===>: PASS
**********
=========================:::545:::END!!!=========================
=========================:::546:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/common-tasks/remove_container_journal.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Destroy container journal directories
  file:
    path: "/var/log/journal/{{ container_machine_id }}"
    state: "absent"
  delegate_to: "{{ physical_host }}"
  when:
    - not _container_machine_id is failed
    - force_containers_destroy | bool

**********
DECISION===>: PASS
**********
=========================:::546:::END!!!=========================
=========================:::547:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/common-tasks/dynamic-address-fact.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Set IP to use for {{ network_address }}
  set_fact: "{{ network_address }}={{ hostvars[inventory_hostname] | json_query(query) }}"
  vars:
    query: "{{ is_metal | ternary(metal_query, non_metal_query) }}"
    non_metal_query: "container_networks.{{ network_address }}.address || ansible_host"
    find_bridge: "container_networks.{{ network_address }}.bridge"
    metal_query: "'ansible_{{ hostvars[inventory_hostname] | json_query(find_bridge) | replace('-','_') }}'.ipv4.address || {{ non_metal_query }}"
  tags:
    - common-address
    - always

**********
DECISION===>: PASS
**********
=========================:::547:::END!!!=========================
=========================:::548:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/common-tasks/package-cache-proxy.yml
**********
---
# Copyright 2016, Logan Vig <logan2211@gmail.com>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# TODO(odyssey4me):
# Remove these tasks in T. They are only present for the
# Q->R upgrade or for R->S upgrades for environments which
# were installed prior to R's release.

- name: Remove apt package manager proxy
  file:
    dest: "/etc/apt/apt.conf.d/00apt-cacher-proxy"
    state: "absent"
  register: _apt_proxy_removed
  when:
    - ansible_os_family == 'Debian'
  tags:
    - common-proxy

- name: Update apt when proxy is added/removed
  apt:
    update_cache: yes
  retries: 5
  delay: 2
  when:
    - _apt_proxy_removed is mapping
    - _apt_proxy_removed | changed
  tags:
    - common-proxy

# NOTE(mhayden): We always deploy the proxy configuration for yum on CentOS
# even if dnf is present.
- name: Remove yum package manager proxy
  lineinfile:
    line: >-
      proxy="http://{{ internal_lb_vip_address }}:{{ repo_pkg_cache_port | default('3142') }}"
    dest: "/etc/yum.conf"
    state: absent
  when:
    - ansible_os_family == 'RedHat'
  tags:
    - common-proxy

# NOTE(mhayden): If dnf and yum are installed on CentOS, we need to configure
# a proxy for dnf as well.
- name: Remove dnf package manager proxy
  lineinfile:
    line: >-
      proxy="http://{{ internal_lb_vip_address }}:{{ repo_pkg_cache_port | default('3142') }}"
    dest: "/etc/dnf/dnf.conf"
    state: absent
  when:
    - ansible_os_family == 'RedHat'
    - ansible_pkg_mgr == 'dnf'
  tags:
    - common-proxy

**********
DECISION===>: PASS
**********
=========================:::548:::END!!!=========================
=========================:::549:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/common-tasks/unbound-clients.yml
**********
---
# Copyright 2017, Logan Vig <logan2211@gmail.com>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

#create a sorted resolver list with affinity toward unbound container(s)
#on the same physical_host
- name: Apply resolver sorting
  set_fact:
    resolver_list: |-
      {% set _var = [] %}
      {% for host in groups[resolvconf_resolver_group] %}
      {%   if physical_host is defined and
              hostvars[host]['physical_host'] is defined
              and physical_host == hostvars[host]['physical_host'] %}
      {%     set _prio = 100 %}
      {%   else %}
      {%     set _prio = 50 %}
      {%   endif %}
      {%   set _ = _var.append({
             'host': hostvars[host]['ansible_host'],
             'priority': _prio
           })
      %}
      {% endfor %}
      {{ _var |
         sort(reverse=true, attribute='priority') |
         map(attribute='host') |
         list
      }}
  when:
    - physical_host is defined
    - physical_host in hostvars['localhost']['unbound_physical_hosts']

- name: Set resolver IP list fact
  set_fact:
    resolvconf_resolver_ips: "{{ resolver_list }}"
    resolvconf_options:
      - 'timeout:1'
  when:
    - resolver_list is defined
    - resolver_list | length > 0

#rotate is only used when no physical_host affinity is defined
- name: Set resolver rotate when physical_host is not an unbound host
  set_fact:
    resolvconf_options:
      - 'timeout:1'
      - 'rotate'
  when:
    - resolver_list is not defined

- name: Include the resolvconf role
  include_role:
    name: resolvconf

**********
DECISION===>: PASS
**********
=========================:::549:::END!!!=========================
=========================:::550:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/common-tasks/haproxy-endpoint-manage.yml
**********
---
# Copyright 2017, Logan Vig <logan2211@gmail.com>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Set haproxy service state
  haproxy:
    socket: /var/run/haproxy.stat
    backend: "{{ haproxy_backend | default(omit) }}"
    host: "{{ inventory_hostname }}"
    state: "{{ haproxy_state | default('enabled') }}"
    shutdown_sessions: "{{ haproxy_shutdown_sessions | default(False) | bool }}"
    wait: "{{ haproxy_wait | default(False) | bool }}"
    wait_interval: "{{ haproxy_wait_interval | default(5) }}"
    wait_retries: "{{ haproxy_wait_retries | default(24) }}"
    weight: "{{ haproxy_weight | default(omit) }}"
  delegate_to: "{{ item }}"
  with_items: "{{ groups['haproxy'] }}"
  tags:
    - common-haproxy

**********
DECISION===>: PASS
**********
=========================:::550:::END!!!=========================
=========================:::551:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/common-tasks/restart-service.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This is a generic task set which can be used to execute
# a service action on target hosts for any services. This
# is useful for executing a SIGHUP (reload) to load up any
# configuration changes or to restart services as required.
#
# Inputs:
# - service_name: Any service found matching this prefix will be acted on.
# - service_action: The action to execute [stop, start, restart, reload].

- name: Gather service list
  shell: "systemctl list-unit-files --state=enabled --type=service | awk '/{{ service_name }}.* enabled$/ {print $1}'"
  args:
    executable: "/bin/bash"
  register: _enabled_services
  changed_when: false
  tags:
    - skip_ansible_lint

- name: Execute service action
  service:
    name: "{{ service_file }}"
    state: "{{ service_action }}"
  with_items: "{{ (_enabled_services.stdout_lines | difference(service_negate | default([]))) | list }}"
  loop_control:
    loop_var: service_file

- name: Disable the service restart requirement
  ini_file:
    dest: "/etc/ansible/facts.d/openstack_ansible.fact"
    section: "{{ service_fact | default(service_name) }}"
    option: need_service_restart
    value: False

**********
DECISION===>: PASS
**********
=========================:::551:::END!!!=========================
=========================:::552:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/common-tasks/os-lxc-container-setup.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Usage:
#  This common task will update lxc containers to use the lxc-openstack
#  app-armor profile by default however this profile can be changed as needed.

#  This will also load in a list of bind mounts for a given container. To load
#  in a list of bind mounts the variable, "list_of_bind_mounts" must be used
#  containing at least one dictionary with the keys "bind_dir_path",
#  "relative_bind_dir_path", and "mount_path".
#    * bind_dir_path = Container path used in a bind mount
#    * mount_path = Local path on the physical host used for a bind mount

#  If extra container configurations are desirable set the
#  "extra_container_config" list to strings containing the options needed.

- name: Set default bind mounts (bind var/log)
  set_fact:
    lxc_default_bind_mounts: '{{ lxc_default_bind_mounts | default([{"bind_dir_path": "/var/log", "mount_path": "/openstack/log/{{ inventory_hostname }}"}]) }}'
  when:
    - default_bind_mount_logs | bool
  tags:
    - common-lxc

- name: Ensure mount directories exists
  file:
    path: "{{ item['mount_path'] }}"
    state: "directory"
  with_items:
    - "{{ lxc_default_bind_mounts | default([]) }}"
    - "{{ list_of_bind_mounts | default([]) }}"
  delegate_to: "{{ physical_host }}"
  tags:
    - common-lxc

- name: Add bind mount configuration to container
  lineinfile:
    dest: "/var/lib/lxc/{{ inventory_hostname }}/config"
    line: "lxc.mount.entry = {{ item['mount_path'] }} {{ item['bind_dir_path'].lstrip('/') }} none bind,create=dir 0 0"
    backup: "true"
  with_items:
    - "{{ lxc_default_bind_mounts | default([]) }}"
    - "{{ list_of_bind_mounts | default([]) }}"
  delegate_to: "{{ physical_host }}"
  register: _mc
  tags:
    - common-lxc

- name: Extra lxc config
  lineinfile:
    dest: "/var/lib/lxc/{{ inventory_hostname }}/config"
    line: "{{ item.split('=')[0] }} = {{ item.split('=', 1)[1] }}"
    insertafter: "^{{ item.split('=')[0] }}"
    backup: "true"
  with_items: "{{ extra_container_config | default([]) }}"
  delegate_to: "{{ physical_host }}"
  register: _ec
  tags:
    - common-lxc

- name: Extra lxc config no restart
  lineinfile:
    dest: "/var/lib/lxc/{{ inventory_hostname }}/config"
    line: "{{ item.split('=')[0] }} = {{ item.split('=', 1)[1] }}"
    insertafter: "^{{ item.split('=')[0] }}"
    backup: "true"
  with_items: "{{ extra_container_config_no_restart | default(['lxc.start.order=100']) }}"
  delegate_to: "{{ physical_host }}"
  tags:
    - common-lxc

- name: Check container state
  command: "lxc-info -n {{ inventory_hostname }} --state"
  changed_when: false
  delegate_to: "{{ physical_host }}"
  register: _lxc_container_state
  until: _lxc_container_state is success
  retries: 3
  delay: 5
  when:
    - (_mc is defined and _mc | changed) or (_ec is defined and _ec | changed)

# Due to https://github.com/ansible/ansible-modules-extras/issues/2691
# this uses the LXC CLI tools to ensure that we get logging.
# TODO(odyssey4me): revisit this once the bug is fixed and released
# NOTE(cloudnull): The `lxc-stop` command will have an RC of 2 if the command
#                  fails due to a container already being in a stopped state.
- name: Lxc container restart
  command: >
    lxc-stop --name {{ inventory_hostname }}
    --logfile {{ lxc_container_log_path }}/lxc-{{ inventory_hostname }}.log
    --logpriority {{ (debug | bool) | ternary('DEBUG', 'INFO') }}
  delegate_to: "{{ physical_host }}"
  register: container_stop
  until: container_stop is success
  retries: 3
  failed_when:
    - container_stop.rc not in [0, 2]
  when:
    - lxc_container_allow_restarts | default(True) | bool
    - (_mc is defined and _mc | changed) or (_ec is defined and _ec | changed)
    - _lxc_container_state.stdout.find('RUNNING') != -1
  tags:
    - common-lxc

# Due to https://github.com/ansible/ansible-modules-extras/issues/2691
# this uses the LXC CLI tools to ensure that we get logging.
# TODO(odyssey4me): revisit this once the bug is fixed and released
- name: Start Container
  command: >
    lxc-start --daemon --name {{ inventory_hostname }}
    --logfile {{ lxc_container_log_path }}/lxc-{{ inventory_hostname }}.log
    --logpriority {{ (debug | bool) | ternary('DEBUG', 'INFO') }}
  delegate_to: "{{ physical_host }}"
  register: container_start
  until: container_start is success
  retries: 3
  when:
    - (_mc is defined and _mc | changed) or (_ec is defined and _ec | changed)
  tags:
    - common-lxc

- name: Wait for container connectivity
  wait_for_connection:
    connect_timeout: "{{ lxc_container_wait_params.connect_timeout | default(omit) }}"
    delay: "{{ lxc_container_wait_params.delay | default(omit) }}"
    sleep: "{{ lxc_container_wait_params.sleep | default(omit) }}"
    timeout: "{{ lxc_container_wait_params.timeout | default(omit) }}"
  when:
    - (_mc is defined and _mc | changed) or (_ec is defined and _ec | changed)
  tags:
    - common-lxc

**********
DECISION===>: PASS
**********
=========================:::552:::END!!!=========================
=========================:::553:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/common-tasks/os-log-dir-setup.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Usage:
#  This common task is used to create log directories and links
#  if the "log_dirs" list is passed. "log_dirs" must be used
#  containing at least one dictionary with the keys "dest" and
#  "src". Optionally the "owner" and "group" can be provided as well.
#    * dest = destination
#    * src = source
#    * owner = user
#    * group = group

- name: Create log dir
  file:
    path: "{{ item.src }}"
    state: directory
  with_items: "{{ log_dirs|default([]) }}"
  when: is_metal | bool
  tags:
    - common-log

- name: Create log aggregation links
  file:
    src: "{{ item.src }}"
    dest: "{{ item.dest }}"
    state: "link"
    force: "yes"
  with_items: "{{ log_dirs|default([]) }}"
  when: is_metal | bool
  tags:
    - common-log

**********
DECISION===>: PASS
**********
=========================:::553:::END!!!=========================
=========================:::554:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/common-tasks/dynamic-grouping.yml
**********
---
# Copyright 2016, Logan Vig <logan2211@gmail.com>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Add hosts to dynamic inventory group
  add_host:
    group: "{{ dest_group }}"
    name: "{{ item }}"
  with_items: "{{ groups[src_group] }}"
  when:
    - "group_when | default(True)"
  tags:
    - common-grouping

**********
DECISION===>: PASS
**********
=========================:::554:::END!!!=========================
=========================:::555:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/roles/system_crontab_coordination/tasks/main.yml
**********
---
# Copyright 2015, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Create crontab
  template:
    src: "crontab.j2"
    dest: "/etc/crontab"
    owner: "root"
    group: "root"
    mode: "0644"
  when:
    - ansible_os_family == 'Debian'

**********
DECISION===>: PASS
**********
=========================:::555:::END!!!=========================
=========================:::556:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/roles/system_crontab_coordination/meta/main.yml
**********
---
# Copyright 2015, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

galaxy_info:
  author: rcbops
  company: Rackspace
  description: Co-ordinating /etc/crontab times across multiple hosts
  license: Apache 2.0
  min_ansible_version: 1.9
  platforms:
  - name: Ubuntu
    versions:
    - xenial
  categories:
    - cloud
    - openstack

**********
DECISION===>: PASS
**********
=========================:::556:::END!!!=========================
=========================:::557:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/roles/system_crontab_coordination/defaults/main.yml
**********
---
# Copyright 2015, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# 0 <= minute_start <= 59
minute_start: 0
# 0 <= minute_end <= 59
minute_end: 59
# 0 <= hour_start <= 23
hour_start: 0
# 0 <= hour_end <= 23
hour_end: 23
# 0 <= day_of_week_start <= 6
day_of_week_start: 0
# 0 <= day_of_week_end <= 6
day_of_week_end: 6
# 1 <= day_of_month_start <= 28
day_of_month_start: 1
# 1 <= day_of_month_end <= 28
day_of_month_end: 28

**********
DECISION===>: PASS
**********
=========================:::557:::END!!!=========================
=========================:::558:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/common-playbooks/cinder.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Install cinder services
  hosts: "{{ cinder_hosts }}"
  serial: "{{ cinder_serial }}"
  gather_facts: "{{ osa_gather_facts | default(True) }}"
  user: root
  environment: "{{ deployment_environment_variables | default({}) }}"
  vars_files:
    - "../defaults/{{ install_method }}_install.yml"
  tags:
    - cinder
  pre_tasks:

    # In order to ensure that any container, software or
    # config file changes which causes a container/service
    # restart do not cause an unexpected outage, we drain
    # the load balancer back end for this container.
    - include: ../common-tasks/haproxy-endpoint-manage.yml
      vars:
        haproxy_backend: cinder_api-back
        haproxy_state: disabled
      when:
        - "'cinder_api' in group_names"
        - "groups['cinder_api'] | length > 1"

    - name: Determine storage bridge IP address
      include: ../common-tasks/dynamic-address-fact.yml
      vars:
        network_address: "storage_address"

    - name: Configure container (cinder-volume)
      include: "../common-tasks/os-{{ container_tech | default('lxc') }}-container-setup.yml"
      static: no
      vars:
        extra_container_config:
          - "lxc.autodev=0"
          - "lxc.cgroup.devices.allow=a *:* rmw"
          - "lxc.mount.entry=udev dev devtmpfs defaults 0 0"
        extra_container_config_no_restart:
          - "lxc.start.order=39"
      when:
        - "not is_metal"
        - "'cinder_volume' in group_names"
        - "cinder_backend_lvm_inuse | bool"

    - name: Configure container (other services)
      include: "../common-tasks/os-{{ container_tech | default('lxc') }}-container-setup.yml"
      static: no
      when:
        - "not is_metal"
        - "'cinder_volume' not in group_names"

    - name: Configure log directories (on metal)
      include: ../common-tasks/os-log-dir-setup.yml
      vars:
        log_dirs:
          - src: "/openstack/log/{{ inventory_hostname }}-cinder"
            dest: "/var/log/cinder"

    - include: ../common-tasks/unbound-clients.yml
      static: no
      when:
        - hostvars['localhost']['resolvconf_enabled'] | bool

    - name: Add volume group block device to cinder
      shell: |
        {% if item.value.volume_group is defined %}
        if [ "$(pvdisplay | grep -B1 {{ item.value.volume_group }} | awk '/PV/ {print $3}')" ];then
          for device in `pvdisplay | grep -B1 {{ item.value.volume_group }} | awk '/PV/ {print $3}'`
            do lxc-device -n {{ container_name }} add $device
          done
        fi
        {% else %}
        echo "{{ item.key }} volume_group not defined"
        {% endif %}
      with_dict: "{{ cinder_backends | default({}) }}"
      when:
        - container_tech | default('lxc') == 'lxc'
        - physical_host != container_name
        - cinder_backend_lvm_inuse | bool
      delegate_to: "{{ physical_host }}"

    - name: udevadm trigger
      command: udevadm trigger
      delegate_to: "{{ physical_host }}"
      when: cinder_backend_lvm_inuse | bool

  roles:
    - role: "os_cinder"
      cinder_storage_address: "{{ storage_address }}"

    - role: "system_crontab_coordination"
      tags:
        - crontab

  post_tasks:
    - include_tasks: "../common-tasks/rsyslog-client.yml"
      vars:
        rsyslog_client_log_rotate_file: cinder_log_rotate
        rsyslog_client_log_dir: "/var/log/cinder"
        rsyslog_client_config_name: "99-cinder-rsyslog-client.conf"

    # Now that container changes are done, we can set
    # the load balancer back end for this container
    # to available again.
    - include: ../common-tasks/haproxy-endpoint-manage.yml
      vars:
        haproxy_backend: cinder_api-back
        haproxy_state: enabled
      when:
        - "'cinder_api' in group_names"
        - "groups['cinder_api'] | length > 1"

**********
DECISION===>: PASS
**********
=========================:::558:::END!!!=========================
=========================:::559:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/common-playbooks/glance.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Install glance services
  hosts: "{{ glance_hosts }}"
  serial: "{{ glance_serial }}"
  gather_facts: "{{ osa_gather_facts | default(True) }}"
  user: root
  environment: "{{ deployment_environment_variables | default({}) }}"
  vars_files:
    - "../defaults/{{ install_method }}_install.yml"
  tags:
    - glance
  pre_tasks:
    # In order to ensure that any container, software or
    # config file changes which causes a container/service
    # restart do not cause an unexpected outage, we drain
    # the load balancer back end for this container.
    - include: ../common-tasks/haproxy-endpoint-manage.yml
      vars:
        haproxy_backend: glance_api-back
        haproxy_state: disabled
      when:
        - "'glance_api' in group_names"
        - "groups['glance_api'] | length > 1"

    - name: Configure container (non-nfs)
      include: "../common-tasks/os-{{ container_tech | default('lxc') }}-container-setup.yml"
      vars:
        list_of_bind_mounts: "{{ glance_container_bind_mounts }}"
      static: no
      when:
        - not is_metal
        - glance_default_store == "file"
        - (glance_nfs_client is not defined) or (glance_nfs_client | length == 0)

    - name: Configure container (nfs)
      include: "../common-tasks/os-{{ container_tech | default('lxc') }}-container-setup.yml"
      static: no
      when:
        - not is_metal
        - (glance_default_store != "file") or (glance_nfs_client is defined)

    - name: Configure log directories (on metal)
      include: ../common-tasks/os-log-dir-setup.yml
      vars:
        log_dirs:
          - src: "/openstack/log/{{ inventory_hostname }}-glance"
            dest: "/var/log/glance"

    - include: ../common-tasks/unbound-clients.yml
      static: no
      when:
        - hostvars['localhost']['resolvconf_enabled'] | bool

  roles:
    - role: "os_glance"
    - role: "system_crontab_coordination"
      tags:
        - crontab

  post_tasks:
    - include_tasks: "../common-tasks/rsyslog-client.yml"
      vars:
        rsyslog_client_log_rotate_file: glance_log_rotate
        rsyslog_client_log_dir: "/var/log/glance"
        rsyslog_client_config_name: "99-glance-rsyslog-client.conf"

    # Now that container changes are done, we can set
    # the load balancer back end for this container
    # to available again.
    - include: ../common-tasks/haproxy-endpoint-manage.yml
      vars:
        haproxy_backend: glance_api-back
        haproxy_state: enabled
      when:
        - "'glance_api' in group_names"
        - "groups['glance_api'] | length > 1"

**********
DECISION===>: PASS
**********
=========================:::559:::END!!!=========================
=========================:::560:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/common-playbooks/nova.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Install nova services
  hosts: "{{ nova_hosts }}"
  serial: "{{ nova_serial }}"
  gather_facts: "{{ osa_gather_facts | default(True) }}"
  user: root
  environment: "{{ deployment_environment_variables | default({}) }}"
  vars_files:
    - ../defaults/repo_packages/nova_consoles.yml
    - "../defaults/{{ install_method }}_install.yml"
  tags:
    - nova
  tasks:
    # Enable execution of ceph_client on the nova compute hosts if cinder RBD
    # backends are used. This is necessary to ensure that volume-backed Nova
    # instances can function when RBD is the volume backend.
    - name: Set cinder RBD inuse fact
      set_fact:
        nova_cinder_rbd_inuse: "{{ True in groups['cinder_volume'] | map('extract', hostvars, 'cinder_backend_rbd_inuse') }}"
      delegate_to: localhost
      delegate_facts: True
      when:
        - "'nova_compute' in group_names"
        - "inventory_hostname == ((groups['nova_compute'] | intersect(ansible_play_hosts)) | list)[0]"
        - "hostvars['localhost']['nova_cinder_rbd_inuse'] is not defined"
      tags:
        - always

    # In order to ensure that any container, software or
    # config file changes which causes a container/service
    # restart do not cause an unexpected outage, we drain
    # the load balancer back end for this container.
    - include: ../common-tasks/haproxy-endpoint-manage.yml
      vars:
        haproxy_backend: "{{ backend_name }}-back"
        haproxy_state: disabled
      loop_control:
        loop_var: backend_name
      when:
        - "backend_name in group_names"
        - "groups[backend_name] | length > 1"
      with_items:
        - "nova_api_metadata"
        - "nova_api_os_compute"
        - "nova_api_placement"
        - "nova_console"

    - name: Determine management bridge IP address
      include: ../common-tasks/dynamic-address-fact.yml
      vars:
        network_address: "management_address"

    - name: Configure container
      include: "../common-tasks/os-{{ container_tech | default('lxc') }}-container-setup.yml"
      static: no
      when: not is_metal
      vars:
        extra_container_config_no_restart:
          - "lxc.start.order=39"

    - name: Configure log directories (on metal)
      include: ../common-tasks/os-log-dir-setup.yml
      vars:
        log_dirs:
          - src: "/openstack/log/{{ inventory_hostname }}-nova"
            dest: "/var/log/nova"

    - include: ../common-tasks/unbound-clients.yml
      static: no
      when:
        - hostvars['localhost']['resolvconf_enabled'] | bool

    - name: Add nbd devices to the compute
      shell: |
        for i in /dev/nbd*;do
          lxc-device -n {{ container_name }} add $i $i
        done
      failed_when: false
      register: device_add
      changed_when: >
        'added' in device_add.stdout.lower()
      delegate_to: "{{ physical_host }}"
      when:
        - container_tech | default('lxc') == 'lxc'
        - "'nova_compute' in group_names"
        - "not is_metal | bool"
      tags:
        - always

    - name: Add net/tun device to the compute
      command: |
        lxc-device -n {{ container_name }} add /dev/net/tun /dev/net/tun
      delegate_to: "{{ physical_host }}"
      when:
        - container_tech | default('lxc') == 'lxc'
        - "'nova_compute' in group_names"
        - "not is_metal | bool"
      tags:
        - always

    - name: Check if kvm device exists
      stat:
        path: /dev/kvm
      delegate_to: "{{ physical_host }}"
      register: kvm_device
      when:
        - container_tech | default('lxc') == 'lxc'
        - "'nova_compute' in group_names"
        - "not is_metal | bool"
      tags:
        - always

    - name: Add kvm device to the compute
      command: |
        lxc-device -n {{ container_name }} add /dev/kvm /dev/kvm
      delegate_to: "{{ physical_host }}"
      register: device_add
      failed_when: false
      changed_when: >
        'added' in device_add.stdout.lower()
      when:
        - container_tech | default('lxc') == 'lxc'
        - "'nova_compute' in group_names"
        - "not is_metal | bool"
        - "'ischr' in kvm_device.stat and kvm_device.stat.ischr | bool"
      tags:
        - always

    - name: Installing the Nova service (source)
      include_role:
        name: "os_nova"
      vars:
        nova_novncproxy_git_repo: "{{ openstack_repo_git_url }}/novnc"
        nova_novncproxy_git_install_branch: "{{ novncproxy_git_install_branch }}"
        nova_spicehtml5_git_repo: "{{ openstack_repo_git_url }}/spice-html5"
        nova_spicehtml5_git_install_branch: "{{ spicehtml5_git_install_branch }}"
        nova_management_address: "{{ management_address }}"
        nova_cinder_rbd_inuse: "{{ hostvars['localhost']['nova_cinder_rbd_inuse'] }}"
      when: install_method == "source"

    - name: Installing the Nova service (distro)
      include_role:
        name: "os_nova"
      vars:
        nova_management_address: "{{ management_address }}"
        nova_cinder_rbd_inuse: "{{ hostvars['localhost']['nova_cinder_rbd_inuse'] }}"
      when: install_method == "distro"

    - name: Configuring system crontab
      include_role:
        name: "system_crontab_coordination"
      tags:
        - crontab

    - include_tasks: "../common-tasks/rsyslog-client.yml"
      vars:
        rsyslog_client_log_rotate_file: nova_log_rotate
        rsyslog_client_log_dir: "/var/log/nova"
        rsyslog_client_config_name: "99-nova-rsyslog-client.conf"

    # Now that container changes are done, we can set
    # the load balancer back end for this container
    # to available again.
    - include: ../common-tasks/haproxy-endpoint-manage.yml
      vars:
        haproxy_backend: "{{ backend_name }}-back"
        haproxy_state: enabled
      loop_control:
        loop_var: backend_name
      when:
        - "backend_name in group_names"
        - "groups[backend_name] | length > 1"
      with_items:
        - "nova_api_metadata"
        - "nova_api_os_compute"
        - "nova_api_placement"
        - "nova_console"

**********
DECISION===>: PASS
**********
=========================:::560:::END!!!=========================
=========================:::561:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/common-playbooks/neutron.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Install neutron services
  hosts: "{{ neutron_hosts }}"
  serial: "{{ neutron_serial }}"
  gather_facts: "{{ osa_gather_facts | default(True) }}"
  user: root
  environment: "{{ deployment_environment_variables | default({}) }}"
  vars_files:
    - "../defaults/{{ install_method }}_install.yml"
  tags:
    - neutron
  pre_tasks:

    - name: Determine tunnel bridge IP address
      include: ../common-tasks/dynamic-address-fact.yml
      vars:
        network_address: "tunnel_address"

    - name: Configure container (neutron-agent)
      include: "../common-tasks/os-{{ container_tech | default('lxc') }}-container-setup.yml"
      vars:
        list_of_bind_mounts:
          - bind_dir_path: "{{ (ansible_pkg_mgr == 'apt') | ternary('/lib/modules', '/usr/lib/modules') }}"
            mount_path: "{{ (ansible_pkg_mgr == 'apt') | ternary('/lib/modules', '/usr/lib/modules') }}"
        extra_container_config:
          - "lxc.cgroup.devices.allow=a *:* rmw"
        extra_container_config_no_restart:
          - "lxc.start.order=29"
      static: no
      when:
        - "not is_metal"
        - "'neutron_agent' in group_names"

    - name: Configure container (other services)
      include: "../common-tasks/os-{{ container_tech | default('lxc') }}-container-setup.yml"
      when:
        - "not is_metal"
        - "'neutron_agent' not in group_names"

    - name: Configure log directories (on metal)
      include: ../common-tasks/os-log-dir-setup.yml
      vars:
        log_dirs:
          - src: "/openstack/log/{{ inventory_hostname }}-neutron"
            dest: "/var/log/neutron"

    - name: Configure log directories (on metal) (calico)
      include: ../common-tasks/os-log-dir-setup.yml
      vars:
        log_dirs:
          - src: "/openstack/log/{{ inventory_hostname }}-calico"
            dest: "/var/log/calico"
      when:
        - "'neutron_calico_dhcp_agent' in group_names"

    - include: ../common-tasks/unbound-clients.yml
      static: no
      when:
        - hostvars['localhost']['resolvconf_enabled'] | bool

    - name: Create the neutron provider networks facts
      provider_networks:
        provider_networks: "{{ provider_networks }}"
        bind_prefix: "{{ provider_network_bind_prefix | default('') }}"
        is_metal: "{{ is_metal }}"
        group_names: "{{ group_names }}"
      register: pndata
      when: neutron_provider_networks is not defined
      tags:
        - always

    - name: Set provider network fact(s)
      set_fact:
        _provider_networks: "{{ neutron_provider_networks | default(pndata) }}"
      tags:
        - always

  roles:
    - role: "os_neutron"
      neutron_overlay_network: "{{ _overlay_network }}"
      neutron_provider_networks: "{{ _provider_networks }}"
      neutron_local_ip: "{{ tunnel_address }}"

    - role: "bird"
      when:
        - "'neutron_calico_dhcp_agent' in group_names"
      tags:
        - bird

    - role: "system_crontab_coordination"
      tags:
        - crontab

  post_tasks:
    - include_tasks: "../common-tasks/rsyslog-client.yml"
      vars:
        rsyslog_client_log_rotate_file: neutron_log_rotate
        rsyslog_client_log_dir: "/var/log/neutron"
        rsyslog_client_log_files:
          - /var/log/conntrackd.log
          - /var/log/conntrackd-stats.log
        rsyslog_client_config_name: "99-neutron-rsyslog-client.conf"

    - include_tasks: "../common-tasks/rsyslog-client.yml"
      vars:
        rsyslog_client_log_rotate_file: calico_log_rotate
        rsyslog_client_log_dir: "/var/log/calico"
        rsyslog_client_config_name: "99-calico-rsyslog-client.conf"
      when:
        - "'neutron_calico_dhcp_agent' in group_names"

**********
DECISION===>: PASS
**********
=========================:::561:::END!!!=========================
=========================:::562:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/defaults/healthchecks-vars.yml
**********
---
# Copyright 2018, SUSE LINUX GmbH.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# (c) 2018, Jean-Philippe Evrard <jean-philippe@evrard.me>
#ansible_python_interpreter: "{{ ansible_playbook_python }}"
glance_images:
  - url: "http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img"
    dest: "/tmp/cirros-0.3.5.img"
    checksum: "sha256:e137062a4dfbb4c225971b67781bc52183d14517170e16a3841d16f962ae7470"
    format: "qcow2"
    name: "cirros-healthcheck"

cinder_volumes:
  - name: healthcheck1
    size: 1

public_net_cidr: "{{ tempest_public_subnet_cidr | default('10.1.13.0/24') }}"
private_net_cidr: "{{ tempest_private_subnet_cidr | default('192.168.74.0/28') }}"
public_dns_servers:
  - "8.8.8.8"
  - "8.8.4.4"

neutron_networks:
  public:
    name: "{{ tempest_public_net_name | default('public') }}"
    shared: True
    external: True
    pn_type: "{{ tempest_public_net_provider_type | default('flat') }}"
    physical_network: "{{ tempest_public_net_physical_type | default('flat') }}"
    subnets:
      - name: "{{ tempest_public_subnet_name | default('public-subnet') }}"
        ip_version: 4
        cidr: "{{ public_net_cidr }}"
        enable_dhcp: "yes"
        dns_nameservers: "{{ public_dns_servers }}"
  private:
    name: "{{ tempest_private_net_name | default('private') }}"
    shared: True
    external: True
    pn_type: "{{ tempest_private_net_provider_type | default('vxlan') }}"
    segmentation_id: "{{ tempest_private_net_seg_id | default('1') }}"
    subnets:
      - name: "{{ tempest_private_subnet_name | default('private-subnet') }}"
        ip_version: 4
        cidr: "{{ private_net_cidr }}"
        enable_dhcp: "yes"

heat_stack:
  # Please use the following for a nova app:
  # http://git.openstack.org/cgit/openstack/heat-templates/plain/hot/hello_world.yaml
  source_url: http://git.openstack.org/cgit/openstack/heat-templates/plain/hot/keystone/keystone_domain.yaml
  dest_file: /tmp/mystack.yaml
  name: babar
  tag: dumbo
  parameters:
    domain_name: "babar"
    domain_description: "Babar Kingdom"
    domain_enabled: False # you don't want babar to impact the world of non-elephants.

nova_flavors:
  - name: healthcheck1
    ram: 256
    vcpus: 1
    disk: 1
    swap: 0
    ephemeral: 0

nova_vm:
  name: vm1-healthcheck
  image: cirros-healthcheck
  flavor: healthcheck1
  network: "{{ neutron_networks.private.name }}"

swift_object:
  name: fstab
  container: config
  filename: /etc/fstab

security_group:
  name: healthcheck
  rules:
    - protocol: tcp
      port_range_min: 22
      port_range_max: 22
      remote_ip_prefix: 0.0.0.0/0
    - protocol: tcp
      port_range_min: 5000
      port_range_max: 5000
      remote_ip_prefix: 0.0.0.0/0
    - protocol: icmp
      port_range_min: -1
      port_range_max: -1
      remote_ip_prefix: 0.0.0.0/0

ssh_key: "/root/.ssh/id_rsa-healthcheck"

**********
DECISION===>: PASS
**********
=========================:::562:::END!!!=========================
=========================:::563:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/defaults/source_install.yml
**********
---
# Copyright 2018, SUSE LINUX GmbH.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

cinder_bin: "/openstack/venvs/cinder-{{ venv_tag }}/bin"
glance_bin: "/openstack/venvs/glance-{{ venv_tag }}/bin"
keystone_bin: "/openstack/venvs/keystone-{{ venv_tag }}/bin"
nova_bin: "/openstack/venvs/nova-{{ venv_tag }}/bin"
octavia_bin: "/openstack/venvs/octavia-{{ venv_tag }}/bin"
tempest_venv_bin: "/openstack/venvs/tempest-{{ venv_tag }}/bin"

# URL for the frozen internal openstack repo.
repo_release_path: "{{ openstack_repo_url }}/os-releases/{{ openstack_release }}/{{ os_distro_version }}"

## OpenStack source options
openstack_repo_url: "http://{{ internal_lb_vip_address }}:{{ repo_server_port }}"
openstack_repo_git_url: "git://{{ internal_lb_vip_address }}"

venv_base_download_url: "{{ openstack_repo_url }}/venvs/{{ openstack_release }}/{{ os_distro_version }}"
tempest_venv_download_url: "{{ venv_base_download_url }}/tempest-{{ openstack_release }}-{{ ansible_architecture | lower }}.tgz"
# The URL to the repo server's pypi reverse proxy simple index
pip_default_index: "{{ openstack_repo_url }}/simple"
# The upper constraints to apply to all pip installations
pip_install_upper_constraints: "{{ repo_release_path }}/requirements_absolute_requirements.txt"
# locations for fetching the default files from the git source
gnocchi_git_config_lookup_location: "{{ openstack_repo_url }}/openstackgit/gnocchi"
# locations for fetching the default files from the git source
ceilometer_git_config_lookup_location: "{{ openstack_repo_url }}/openstackgit/ceilometer"
# locations for fetching the default files from the git source
tacker_git_config_lookup_location: "{{ openstack_repo_url }}/openstackgit/tacker"
# locations for fetching the default files from the git source
keystone_git_config_lookup_location: "{{ openstack_repo_url }}/openstackgit/keystone"

**********
DECISION===>: PASS
**********
=========================:::563:::END!!!=========================
=========================:::564:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/defaults/distro_install.yml
**********
---
# Copyright 2018, SUSE LINUX GmbH.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

#
# Use $role_install_method=distro so we can test the combined
# result. We add all the os_* roles here even though some of them
# may not have been converted to support the dual installation method.
#
# NOTE(hwoarang): We need to define the various $role_bin variables because
# some playbooks in this repository are explicitly using them to perform
# post deployment actions such as the playbooks/os-{cinder,keystone,nova}-install.yml
# playbooks.
#
almanach_install_method: distro
aodh_install_method: distro
barbican_install_method: distro
blazar_install_method: distro
ceilometer_install_method: distro
cinder_install_method: distro
cinder_bin: /usr/bin
cloudkitty_install_method: distro
congress_install_method: distro
designate_install_method: distro
glance_install_method: distro
glance_bin: /usr/bin
gnocchi_install_method: distro
heat_install_method: distro
horizon_install_method: distro
ironic_install_method: distro
karbor_install_method: distro
keystone_install_method: distro
keystone_bin: /usr/bin
magnum_install_method: distro
masakari_install_method: distro
monasca_install_method: distro
monasca-agent_install_method: distro
monasca-ui_install_method: distro
neutron_install_method: distro
neutron_bin: /usr/bin
nova_install_method: distro
nova_bin: /usr/bin
octavia_install_method: distro
octavia_bin: /usr/bin
panko_install_method: distro
rally_install_method: distro
sahara_install_method: distro
searchlight_install_method: distro
swift_install_method: distro
tacker_install_method: distro
tempest_install_method: distro
tempest_bin: /usr/bin
trove_install_method: distro
watcher_install_method: distro
zaqar_install_method: distro
zun_install_method: distro

# default variables for PIP since we are not using the repo server
pip_default_index: "https://pypi.python.org/simple"

tempest_venv_download: false

**********
DECISION===>: PASS
**********
=========================:::564:::END!!!=========================
=========================:::565:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/defaults/repo_packages/gnocchi.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


## NOTICE on items in this file:
##   * If you use anything in the *._git_install_branch field that is not a TAG
##     make sure to leave an in-line comment as to "why".

## For the sake of anyone else editing this file:
##   * If you add services to this file please do so in alphabetical order.
##   * Every entry should be name spaced with the name of the client followed by an "_"
##   * All items with this file should be separated by `name_` note that the name of the
##     package should be one long name with no additional `_` separating it.


### Before this is shipped all of these services should have a tag set as the branch,
### or have a comment / reason attached to them as to why a tag can not work.


## Gnocchi service
## This service has a different stable branch strategy to the rest of OpenStack.
## The SHA is recorded here to make the SHA updating easier.
gnocchi_git_repo: https://github.com/gnocchixyz/gnocchi
gnocchi_git_install_branch: 8099dfc2a30ddf305d9f904de0106e4dd5e56147 # HEAD of "master" as of 08.08.2018
gnocchi_git_project_group: gnocchi_all
gnocchi_git_track_branch: master

**********
DECISION===>: PASS
**********
=========================:::565:::END!!!=========================
=========================:::566:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/defaults/repo_packages/openstack_services.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


## NOTICE on items in this file:
##   * If you use anything in the *._git_install_branch field that is not a TAG
##     make sure to leave an in-line comment as to "why".

## For the sake of anyone else editing this file:
##   * If you add services to this file please do so in alphabetical order.
##   * Every entry should be name spaced with the name of the client followed by an "_"
##   * All items with this file should be separated by `name_` note that the name of the
##     package should be one long name with no additional `_` separating it.


### Before this is shipped all of these services should have a tag set as the branch,
### or have a comment / reason attached to them as to why a tag can not work.


## Global Requirements
requirements_git_repo: https://git.openstack.org/openstack/requirements
requirements_git_install_branch: 4425ce22fda513fb7a20e77f28685004296731d0 # HEAD of "master" as of 08.08.2018
requirements_git_track_branch: master


## Aodh service
aodh_git_repo: https://git.openstack.org/openstack/aodh
aodh_git_install_branch: d7dc751a7922fc0a5ea08ec80e3acb2db4b6979e # HEAD of "master" as of 08.08.2018
aodh_git_project_group: aodh_all
aodh_git_track_branch: master


## Barbican service
barbican_git_repo: https://git.openstack.org/openstack/barbican
barbican_git_install_branch: 08ca2287dd845011d940a722f6418c3b73c6c7ae # HEAD of "master" as of 08.08.2018
barbican_git_project_group: barbican_all
barbican_git_track_branch: master


## Ceilometer service
ceilometer_git_repo: https://git.openstack.org/openstack/ceilometer
ceilometer_git_install_branch: 413f9a3261c2b247395c36eef938b53ff8279214 # HEAD of "master" as of 08.08.2018
ceilometer_git_project_group: all
ceilometer_git_track_branch: master


## Cinder service
cinder_git_repo: https://git.openstack.org/openstack/cinder
cinder_git_install_branch: a27d0eb32afc32d745de6a3aafb905ea6151813c # HEAD of "master" as of 08.08.2018
cinder_git_project_group: cinder_all
cinder_git_track_branch: master


## Designate service
designate_git_repo: https://git.openstack.org/openstack/designate
designate_git_install_branch: 6daedf125c6126bd1c32a377fded9d7b46a2b4e9 # HEAD of "master" as of 08.08.2018
designate_git_project_group: designate_all
designate_git_track_branch: master


## Horizon Designate dashboard plugin
designate_dashboard_git_repo: https://git.openstack.org/openstack/designate-dashboard
designate_dashboard_git_install_branch: e41d74a03d46d678c3e86bf98703bcc16dff71f6 # HEAD of "master" as of 08.08.2018
designate_dashboard_git_project_group: horizon_all
designate_dashboard_git_track_branch: master


## Glance service
glance_git_repo: https://git.openstack.org/openstack/glance
glance_git_install_branch: bfa25c5e5c05399506404e66d53b0d61eaa06ab7 # HEAD of "master" as of 08.08.2018
glance_git_project_group: glance_all
glance_git_track_branch: master


## Heat service
heat_git_repo: https://git.openstack.org/openstack/heat
heat_git_install_branch: 8ca06cfeafc94e739947cf89affa4db57b6bf3c9 # HEAD of "master" as of 08.08.2018
heat_git_project_group: heat_all
heat_git_track_branch: master

## Horizon Heat dashboard plugin
heat_dashboard_git_repo: https://git.openstack.org/openstack/heat-dashboard
heat_dashboard_git_install_branch: df563384901294ac118c45a1e92734f67b6593d8 # HEAD of "master" as of 08.08.2018
heat_dashboard_git_project_group: horizon_all
heat_dashboard_git_track_branch: master

## Horizon service
horizon_git_repo: https://git.openstack.org/openstack/horizon
horizon_git_install_branch: a4443f4be7a7e38ce052080ed157337bc778c18d # HEAD of "master" as of 08.08.2018
horizon_git_project_group: horizon_all
horizon_git_track_branch: master

## Horizon Ironic dashboard plugin
ironic_dashboard_git_repo: https://git.openstack.org/openstack/ironic-ui
ironic_dashboard_git_install_branch: 36840aaa0da8053d2e4032c060a6a45af224572b # HEAD of "master" as of 08.08.2018
ironic_dashboard_git_project_group: horizon_all
ironic_dashboard_git_track_branch: master

## Horizon Magnum dashboard plugin
magnum_dashboard_git_repo: https://git.openstack.org/openstack/magnum-ui
magnum_dashboard_git_install_branch: dcf62a6e80fd3733b530cb76218b2ec5c3532cb6 # HEAD of "master" as of 08.08.2018
magnum_dashboard_git_project_group: horizon_all
magnum_dashboard_git_track_branch: master

## Horizon LBaaS dashboard plugin
neutron_lbaas_dashboard_git_repo: https://git.openstack.org/openstack/neutron-lbaas-dashboard
neutron_lbaas_dashboard_git_install_branch: dde6dfb2eba8eb2f1d9cd61986032b512330b281 # HEAD of "master" as of 08.08.2018
neutron_lbaas_dashboard_git_project_group: horizon_all
neutron_lbaas_dashboard_git_track_branch: master

## Horizon FWaaS dashboard plugin
neutron_fwaas_dashboard_git_repo: https://git.openstack.org//openstack/neutron-fwaas-dashboard
neutron_fwaas_dashboard_git_install_branch: 5ece747e15896cf998e3787aa07f547fa39e3e44 # HEAD of "master" as of 08.08.2018
neutron_fwaas_dashboard_git_project_group: horizon_all
neutron_fwaas_dashboard_git_track_branch: master

## Horizon Sahara dashboard plugin
sahara_dashboard_git_repo: https://git.openstack.org/openstack/sahara-dashboard
sahara_dashboard_git_install_branch: 4585a9d004427f52e34f0cd89374e8ba1cba2dff # HEAD of "master" as of 08.08.2018
sahara_dashboard_git_project_group: horizon_all
sahara_dashboard_git_track_branch: master


## Keystone service
keystone_git_repo: https://git.openstack.org/openstack/keystone
keystone_git_install_branch: a2b510c17638d31d2983317a4261f9dc27507d24 # HEAD of "master" as of 08.08.2018
keystone_git_project_group: keystone_all
keystone_git_track_branch: master


## Neutron service
neutron_git_repo: https://git.openstack.org/openstack/neutron
neutron_git_install_branch: 06f1aa6629d3e54c04ab06ca2808479f5ed9f186 # HEAD of "master" as of 08.08.2018
neutron_git_project_group: neutron_all
neutron_git_track_branch: master

neutron_lbaas_git_repo: https://git.openstack.org/openstack/neutron-lbaas
neutron_lbaas_git_install_branch: e4a9d3c1dfb06482f90699e60b98a94481af5f75 # HEAD of "master" as of 08.08.2018
neutron_lbaas_git_project_group: neutron_all
neutron_lbaas_git_track_branch: master

neutron_vpnaas_git_repo: https://git.openstack.org/openstack/neutron-vpnaas
neutron_vpnaas_git_install_branch: da4fff7e7aa756cd8280e8dd14fb8cccc5777277 # HEAD of "master" as of 08.08.2018
neutron_vpnaas_git_project_group: neutron_all
neutron_vpnaas_git_track_branch: master

neutron_fwaas_git_repo: https://git.openstack.org/openstack/neutron-fwaas
neutron_fwaas_git_install_branch: d61bd2961c5117f22d227a910b7a20e65322bb82 # HEAD of "master" as of 08.08.2018
neutron_fwaas_git_project_group: neutron_all
neutron_fwaas_git_track_branch: master

neutron_dynamic_routing_git_repo: https://git.openstack.org/openstack/neutron-dynamic-routing
neutron_dynamic_routing_git_install_branch: ac63f126c6bd0ab12d6cd80077023c3e5c264e98 # HEAD of "master" as of 08.08.2018
neutron_dynamic_routing_git_project_group: neutron_all
neutron_dynamic_routing_git_track_branch: master

networking_calico_git_repo: https://git.openstack.org/openstack/networking-calico
networking_calico_git_install_branch: 5d852f653552f2332dce48aa425ee842b5b684ad # HEAD of "master" as of 08.08.2018
networking_calico_git_project_group: neutron_all
networking_calico_git_track_branch: master

networking_odl_git_repo: https://git.openstack.org/openstack/networking-odl
networking_odl_git_install_branch: ecde0a165f6145d8257fd52d50ee6f417b0b6ff0 # HEAD of "master" as of 08.08.2018
networking_odl_git_project_group: neutron_all
networking_odl_git_track_branch: master

networking_ovn_git_repo: https://git.openstack.org/openstack/networking-ovn
networking_ovn_git_install_branch: 378f4ec58e16a363aeabd16da1911775d0b36487 # HEAD of "master" as of 08.08.2018
networking_ovn_git_project_group: neutron_all

# BGPVPN is frozen until further notice due to
# https://github.com/openstack/networking-bgpvpn/commit/e9a0ea199b47f76f69545e04bdb4db44869c388b#diff-b4ef698db8ca845e5845c4618278f29a
networking_bgpvpn_git_repo: https://git.openstack.org/openstack/networking-bgpvpn
networking_bgpvpn_git_install_branch: 3b93ddacd390d92fb144e5660324d4da064ad9a4 # FROZEN HEAD of "master" as of 31.03.2018
networking_bgpvpn_git_project_group: neutron_all
networking_bgpvpn_git_track_branch: None

networking_sfc_git_repo: https://git.openstack.org/openstack/networking-sfc
networking_sfc_git_install_branch: 4c38303620c8a3f38d7261a64ce8532979bf7560 # HEAD of "master" as of 08.08.2018
networking_sfc_git_project_group: neutron_all
networking_sfc_git_track_branch: master


## Nova service
nova_git_repo: https://git.openstack.org/openstack/nova
nova_git_install_branch: c52c2caf97a90de8770e9296d553e0e4a65ac946 # HEAD of "master" as of 08.08.2018
nova_git_project_group: nova_all
nova_git_track_branch: master


## PowerVM Virt Driver
nova_powervm_git_repo: https://git.openstack.org/openstack/nova-powervm
nova_powervm_git_install_branch: 9b518d8c9986249a06e3f5dc1450b66283af91f1 # HEAD of "master" as of 08.08.2018
nova_powervm_git_project_group: nova_all
nova_powervm_git_track_branch: master


## LXD Virt Driver
nova_lxd_git_repo: https://git.openstack.org/openstack/nova-lxd
nova_lxd_git_install_branch: bc8d540c95b3209321658000fd74b0e5065a7ee2 # HEAD of "master" as of 08.08.2018
nova_lxd_git_project_group: nova_all
nova_lxd_git_track_branch: master


## Sahara service
sahara_git_repo: https://git.openstack.org/openstack/sahara
sahara_git_install_branch: 2c6232c9ad37079020ac72a29a54ab794cc80500 # HEAD of "master" as of 08.08.2018
sahara_git_project_group: sahara_all
sahara_git_track_branch: master


## Swift service
swift_git_repo: https://git.openstack.org/openstack/swift
swift_git_install_branch: 7f7482c096d6c587c64a75e207842ab4dee6e8dd # HEAD of "master" as of 08.08.2018
swift_git_project_group: swift_all
swift_git_track_branch: master


## Swift3 middleware
swift_swift3_git_repo: https://git.openstack.org/openstack/swift3
swift_swift3_git_install_branch: 90db5d1510b2a770387961e7bf0fbeae8101ba45 # HEAD of "master" as of 08.08.2018
swift_swift3_git_project_group: swift_all
swift_swift3_git_track_branch: master


## Ironic service
ironic_git_repo: https://git.openstack.org/openstack/ironic
ironic_git_install_branch: 89f68e70e06e24b100d93e751e2a3e8cb8dd9b61 # HEAD of "master" as of 08.08.2018
ironic_git_project_group: ironic_all
ironic_git_track_branch: master


## Magnum service
magnum_git_repo: https://git.openstack.org/openstack/magnum
magnum_git_install_branch: 97b34e67508a69d800239087d0131c6ea128e790 # HEAD of "master" as of 08.08.2018
magnum_git_project_group: magnum_all
magnum_git_track_branch: master


## Trove service
trove_git_repo: https://git.openstack.org/openstack/trove
trove_git_install_branch: 5f2462f0ea4ec2d084db102dbad35bf97eca1135 # HEAD of "master" as of 08.08.2018
trove_git_project_group: trove_all
trove_git_track_branch: master

## Horizon Trove dashboard plugin
trove_dashboard_git_repo: https://git.openstack.org/openstack/trove-dashboard
trove_dashboard_git_install_branch: 9b7f3d9561ce47f370642a3d169fce6469203148 # HEAD of "master" as of 08.08.2018
trove_dashboard_git_project_group: horizon_all
trove_dashboard_git_track_branch: master


## Octavia service
octavia_git_repo: https://git.openstack.org/openstack/octavia
octavia_git_install_branch: a166c89b643c1bdaf3f36004fede25eb7a1c26f5 # HEAD of "master" as of 08.08.2018
octavia_git_project_group: octavia_all
octavia_git_track_branch: master


## Tacker service
tacker_git_repo: https://git.openstack.org/openstack/tacker
tacker_git_install_branch: 5987ad8c56a61e3a6d8fcf37a2557926c585de41 # HEAD of "master" as of 08.08.2018
tacker_git_project_group: tacker_all
tacker_git_track_branch: master

## Congress service
congress_git_repo: https://git.openstack.org/openstack/congress
congress_git_install_branch: 502f40a7d24dd2603bc9e026edc685a956a52e15 # HEAD of "master" as of 08.08.2018
congress_git_project_group: congress_all
congress_git_track_branch: master

## Horizon Octavia dashboard plugin
octavia_dashboard_git_repo: https://git.openstack.org/openstack/octavia-dashboard
octavia_dashboard_git_install_branch: 4f7a5591ae8dd61b25af7f746f20d8f058aa991c # HEAD of "master" as of 08.08.2018
octavia_dashboard_git_project_group: horizon_all
octavia_dashboard_git_track_branch: master


## Blazar service
blazar_git_repo: https://git.openstack.org/openstack/blazar
blazar_git_install_branch: 3cdd01a3cd5235489b290a3eeb5f4af8301adf60 # HEAD of "master" as of 08.08.2018
blazar_git_project_group: blazar_all
blazar_git_track_branch: master

## Blazar Nova Service
blazar_nova_git_repo: https://git.openstack.org/openstack/blazar-nova
blazar_nova_git_install_branch: 67f04e32cc7d701ee60132645cf5cd1258fe1722 # HEAD of "master" as of 08.08.2018
blazar_nova_git_project_group: blazar_all
blazar_nova_git_track_branch: master
**********
DECISION===>: PASS
**********
=========================:::566:::END!!!=========================
=========================:::567:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/defaults/repo_packages/nova_consoles.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


## NOTICE on items in this file:
##   * If you use anything in the *._git_install_branch field that is not a TAG
##     make sure to leave an in-line comment as to "why".

## For the sake of anyone else editing this file:
##   * If you add clients to this file please do so in alphabetical order.
##   * Every entry should be name spaced with the name of the client followed by an "_"
##   * All items with this file should be separated by `name_` note that the name of the
##     package should be one long name with no additional `_` separating it.


## NOVNC from source
novncproxy_git_repo: https://github.com/novnc/noVNC
novncproxy_git_install_branch: b3ac94a97802ea8eba0a895d594a2dd2c0f820aa # HEAD of "master" as of 08.08.2018
novncproxy_git_project_group: nova_console
novncproxy_git_track_branch: master


## spice-html5 from source
spicehtml5_git_repo: https://gitlab.freedesktop.org/spice/spice-html5.git
spicehtml5_git_install_branch: f9f700ee549d9d0fd08263f36bbebebe6b011789 # HEAD of "master" as of 08.08.2018
spicehtml5_git_project_group: nova_console
spicehtml5_git_track_branch: master


**********
DECISION===>: PASS
**********
=========================:::567:::END!!!=========================
=========================:::568:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/playbooks/defaults/repo_packages/openstack_testing.yml
**********
---
# Copyright 2018, Jean-Philippe Evrard <jean-philippe@evrard.me>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# TODO(evrardjp): Remove this file from stable branches to allow the latest tempest
# release to be used instead, when a PyPI published version of tempest contains
# https://github.com/openstack/tempest/commit/7d2b636a30057ed8db8cfd4fe2248f509b3570f1#diff-5c9acbc10dc9d27b47985cd74ab100f6
tempest_git_repo: https://git.openstack.org/openstack/tempest
tempest_git_install_branch: master
tempest_git_project_group: utility_all
tempest_git_track_branch: master

**********
DECISION===>: PASS
**********
=========================:::568:::END!!!=========================
=========================:::569:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/tacker_all.yml
**********
---
# Copyright 2017, SUSE LINUX GmbH
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

tacker_service_user_name: tacker
tacker_service_tenant_name: service

tacker_service_publicuri: "{{ openstack_service_publicuri_proto|default(tacker_service_proto) }}://{{ external_lb_vip_address }}:{{ tacker_service_port }}"
tacker_service_adminurl: "{{ tacker_service_adminuri }}/"
tacker_service_region: "{{ service_region }}"
tacker_service_in_ldap: "{{ service_ldap_backend_enabled }}"

tacker_aodh_enabled: "{{ groups['aodh_all'] is defined and groups['aodh_all'] | length > 0 }}"
tacker_gnocchi_enabled: "{{ groups['gnocchi_all'] is defined and groups['gnocchi_all'] | length > 0 }}"

# Ensure that the package state matches the global setting
tacker_package_state: "{{ package_state }}"

**********
DECISION===>: PASS
**********
=========================:::569:::END!!!=========================
=========================:::570:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/cinder_volume.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# cinder_backend_rbd_inuse: True if current host has an rbd backend
# this is defined identically downstream in the os_cinder role, but redefined
# here so it can be consumed by the nova group vars
cinder_backend_rbd_inuse: '{{ (cinder_backends|default("")|to_json).find("cinder.volume.drivers.rbd.RBDDriver") != -1 }}'

lxc_container_config_list:
  - "lxc.aa_profile=unconfined"

**********
DECISION===>: PASS
**********
=========================:::570:::END!!!=========================
=========================:::571:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/blazar_all.yml
**********
---
# Copyright 2018, taseer94@gmail.com
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

blazar_service_region: "{{ service_region }}"
blazar_service_in_ldap: "{{ service_ldap_backend_enabled }}"

# Ensure that the package state matches the global setting
blazar_package_state: "{{ package_state }}"

**********
DECISION===>: PASS
**********
=========================:::571:::END!!!=========================
=========================:::572:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/horizon_all.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

horizon_external_ssl: "{{ openstack_external_ssl }}"
horizon_service_region: "{{ service_region }}"
horizon_enable_cinder_backup: "{{ hostvars['localhost']['cinder_service_backup_program_enabled'] }}"
horizon_enable_heat_ui: "{{ (groups['heat_all'] is defined) and (groups['heat_all'] | length > 0) }}"
horizon_enable_ironic_ui: "{{ (groups['ironic_all'] is defined) and (groups['ironic_all'] | length > 0) }}"
horizon_enable_magnum_ui: "{{ (groups['magnum_all'] is defined) and (groups['magnum_all'] | length > 0) }}"
horizon_enable_designate_ui: "{{ (groups['designate_all'] is defined) and (groups['designate_all'] | length > 0) }}"
horizon_enable_octavia_ui: "{{ (groups['octavia-infra_all'] is defined) and (groups['octavia-infra_all'] | length > 0) }}"
# NOTE(mhayden): neutron-lbaas is a separate plugin and requires the full
# namespace to be specified. Also, LBaaS v1 was removed in Newton.
horizon_enable_neutron_lbaas: "{{ neutron_plugin_base is defined and 'neutron_lbaas.services.loadbalancer.plugin.LoadBalancerPluginv2' in neutron_plugin_base }}"
horizon_enable_neutron_fwaas: "{{ neutron_plugin_base is defined and (neutron_plugin_base | intersect(['firewall', 'firewall_v2']) | length > 0) }}"
horizon_enable_neutron_vpnaas: "{{ neutron_plugin_base is defined and 'vpnaas' in neutron_plugin_base }}"
horizon_enable_ha_router: "{{ neutron_plugin_type.split('.')[0] == 'ml2' and (groups['neutron_l3_agent'] | length >= 2) }}"

# Ensure that the package state matches the global setting
horizon_package_state: "{{ package_state }}"

# If there are any Sahara hosts in the environment, then enable sahara-dashboard
horizon_enable_sahara_ui: "{{ (groups['sahara_all'] is defined) and (groups['sahara_all'] | length > 0) }}"
# If there are any Trove hosts in the environment, then enable trove-dashboard
horizon_enable_trove_ui: "{{ (groups['trove_all'] is defined) and (groups['trove_all'] | length > 0) }}"

**********
DECISION===>: PASS
**********
=========================:::572:::END!!!=========================
=========================:::573:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/trove_all.yml
**********
---
# Copyright 2016 Internet Solutions (Pty) Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

swift_proxy_port: "{{ hostvars['localhost']['swift_proxy_port'] }}"

trove_service_region: "{{ service_region }}"

# If there are any Ceilometer hosts in the environment, then enable its usage
trove_ceilometer_enabled: "{{ (groups['trove_all'] is defined) and (groups['trove_all'] | length > 0) and (groups['ceilometer_all'] is defined) and (groups['ceilometer_all'] | length > 0) }}"

# Ensure that the package state matches the global setting
trove_package_state: "{{ package_state }}"

**********
DECISION===>: PASS
**********
=========================:::573:::END!!!=========================
=========================:::574:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/ironic_all.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

ironic_service_name: ironic

# Ensure that the package state matches the global setting
ironic_package_state: "{{ package_state }}"

**********
DECISION===>: PASS
**********
=========================:::574:::END!!!=========================
=========================:::575:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/all_containers.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This is the default LXC AppArmor profile
# Groups which need the unbound profile have a specific override
lxc_container_config_list:
  - "lxc.aa_profile=lxc-openstack"

# Needed by playbooks/common-tasks/os-lxc-container-setup.yml
lxc_container_log_path: "/var/log/lxc"

## Parameters provided to the wait_for_connection module after a container
## reboot is triggered by the playbook
lxc_container_wait_params:
  # Wait 3 seconds before attempting the first connection
  delay: 3
  # Wait 60 seconds for the container to respond
  timeout: 60

**********
DECISION===>: PASS
**********
=========================:::575:::END!!!=========================
=========================:::576:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/barbican_all.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

barbican_service_region: "{{ service_region }}"
barbican_service_in_ldap: "{{ service_ldap_backend_enabled }}"
barbican_keystone_auth: yes

**********
DECISION===>: PASS
**********
=========================:::576:::END!!!=========================
=========================:::577:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/neutron_all.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# If there are any Designate hosts in the environment, then enable its usage
neutron_designate_enabled: "{{ hostvars['localhost']['neutron_designate_enabled'] }}"
# If there are any Ceilometer hosts in the environment, then enable its usage
neutron_ceilometer_enabled: "{{ hostvars['localhost']['neutron_ceilometer_enabled'] }}"

neutron_dns_domain: "{{ dhcp_domain }}"
neutron_service_in_ldap: "{{ service_ldap_backend_enabled }}"

# Ensure that the package state matches the global setting
neutron_package_state: "{{ package_state }}"

neutron_lbaas_octavia: "{{ (groups['octavia_all'] is defined) and (groups['octavia_all'] | length > 0) }}"

**********
DECISION===>: PASS
**********
=========================:::577:::END!!!=========================
=========================:::578:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/repo_all.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Ensure that the package state matches the global setting
repo_server_package_state: "{{ package_state }}"
repo_build_package_state: "{{ package_state }}"

# Optionally set this variable to the location on the deployment
# host where a set of git clones may be sourced to stage the repo
# server.
#repo_build_git_cache: /opt/git/openstack/

# The folder in the repo container where the git clones should
# be synchronised to.
repo_build_git_dir: /var/www/repo/openstackgit

# The folder in the repo container which is bind-mounted to
# the host.
repo_service_home_folder: /var/www

# The folder on the repo container's host which will hold
# the git clones via the container-host bind-mount
repo_build_git_bind_mount: "/openstack/{{ inventory_hostname }}{{ repo_build_git_dir | replace(repo_service_home_folder, '') }}"

# The appropriate user:group names for the repo_build_git_dir
# folder/file attributes.
repo_service_user_name: nginx
repo_service_group_name: www-data

# Ensure that the repo service and the repo build use the same user:group
repo_build_service_user_name: "{{ repo_service_user_name }}"
repo_build_service_group_name: "{{ repo_service_group_name }}"

# The following package must always build from source.
#
# libvirt-python:
# A pre-built wheel can be missing libvirt capabilities from the installed
# version of libvirt-bin, leading to nova-compute failing to start.
#
# NOTE(hwoarang) cryptography may bundle openssl in the wheel and that
# causes symbol conflicts if a different openssl is provided by the
# distribution. As such, it's probably safer to re-build cryptography
# ourselves just to be sure that the correct distro libraries are used
# see https://github.com/pyca/cryptography/issues/3804
# This keeps popping up every now and then so it might worth keeping this
# around even if the upstream issue is resolved
# The upstream issue should be resolved now, and we are testing
# cryptography with the usage of wheels by removing it from no_binary.
repo_build_pip_no_binary:
  - libvirt-python

# Set the build tag and the repo version
repo_build_release_tag: "{{ openstack_release }}"
repo_build_os_distro_version: "{{ os_distro_version }}"

# This is required because the nova package list has a conditional package
# based on this var.
nova_barbican_enabled: "{{ hostvars['localhost']['nova_barbican_enabled'] }}"

pkg_locations:
  - "{{ playbook_dir }}/../"
  - /etc/ansible/roles
  - /etc/openstack_deploy

**********
DECISION===>: PASS
**********
=========================:::578:::END!!!=========================
=========================:::579:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/network_hosts.yml
**********
openstack_host_specific_kernel_modules:
  - name: "ebtables"
    pattern: "CONFIG_BRIDGE_NF_EBTABLES"

**********
DECISION===>: PASS
**********
=========================:::579:::END!!!=========================
=========================:::580:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/kvm-compute_hosts.yml
**********
---
# Copyright 2017, Logan Vig <logan2211@gmail.com>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

nova_virt_type: kvm

**********
DECISION===>: PASS
**********
=========================:::580:::END!!!=========================
=========================:::581:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/utility_all.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Set this if ssh access from the utility container to all other hosts is
# desired
# utility_ssh_private_key: "{{ lookup('file', '/root/.ssh/id_rsa') }}"

galera_client_drop_config_file: true

# Ensure that the package state matches the global setting
utility_package_state: "{{ package_state }}"
utility_pip_package_state: "latest"

# Path to the utility host openstack client venv binaries
utility_venv_bin: "/openstack/venvs/utility-{{ openstack_release }}/bin"

# Distribution packages to be installed into the utility container
utility_distro_packages:
  - git
  - bash-completion

utility_distro_openstack_clients_packages:
  - python-keystoneclient
  - python-neutronclient
  - python-novaclient
  - python-cinderclient
  - python-openstackclient

# Python packages to be installed into the utility container
utility_pip_packages:
  - cryptography
  - python-memcached

# Determines whether Cinder backup should be tested
cinder_service_backup_program_enabled: "{{ hostvars['localhost']['cinder_service_backup_program_enabled'] }}"

#
# Tempest settings
#

# If cinder has a backup service enabled, make sure that Tempest tests it
tempest_volume_backup_enabled: "{{ cinder_service_backup_program_enabled | bool }}"

# Activate tempest testing based on the inventory content
tempest_service_available_aodh: "{{ groups['aodh_all'] is defined and groups['aodh_all'] | length > 0 }}"
tempest_service_available_ceilometer: "{{ groups['ceilometer_all'] is defined and groups['ceilometer_all'] | length > 0 }}"
tempest_service_available_cinder: "{{ groups['cinder_all'] is defined and groups['cinder_all'] | length > 0 }}"
tempest_service_available_glance: "{{ groups['glance_all'] is defined and groups['glance_all'] | length > 0 }}"
tempest_service_available_heat: "{{ groups['heat_all'] is defined and groups['heat_all'] | length > 0 }}"
tempest_service_available_horizon: "{{ groups['horizon_all'] is defined and groups['horizon_all'] | length > 0 }}"
tempest_service_available_neutron: "{{ groups['neutron_all'] is defined and groups['neutron_all'] | length > 0 }}"
tempest_service_available_nova: "{{ groups['nova_all'] is defined and groups['nova_all'] | length > 0 }}"
tempest_service_available_swift: "{{ (groups['swift_all'] is defined and groups['swift_all'] | length > 0) or (groups['ceph-rgw'] is defined and groups['ceph-rgw'] | length > 0) or (ceph_rgws | length > 0) }}"
tempest_service_available_congress: "{{ groups['congress_all'] is defined and groups['congress_all'] | length > 0 }}"

tempest_log_dir: /var/log/utility

# This sets the tempest group to the utility group
tempest_main_group: utility_all

**********
DECISION===>: PASS
**********
=========================:::581:::END!!!=========================
=========================:::582:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/glance_all.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# If there are any Ceilometer hosts in the environment, then enable its usage
glance_ceilometer_enabled: "{{ (groups['ceilometer_all'] is defined) and (groups['ceilometer_all'] | length > 0) }}"

glance_service_region: "{{ service_region }}"
glance_service_in_ldap: "{{ service_ldap_backend_enabled }}"

# If there are Swift hosts in the environment, then use it as the default Glance store
glance_default_store: "{{ ((groups['swift_all'] is defined) and (groups['swift_all'] | length > 0)) | ternary('swift', 'file') }}"

# Ensure that the package state matches the global setting
glance_package_state: "{{ package_state }}"

# glance default list of bind mounts
glance_container_bind_mounts:
  - bind_dir_path: "/var/lib/glance/images"
    mount_path: "/openstack/{{ inventory_hostname }}"
  - bind_dir_path: "/var/lib/glance/cache"
    mount_path: "/openstack/{{ inventory_hostname }}"

**********
DECISION===>: PASS
**********
=========================:::582:::END!!!=========================
=========================:::583:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/memcached.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

memcached_listen: "{{ ansible_host }}"

# Ensure that the package state matches the global setting
memcached_package_state: "{{ package_state }}"

# Disable PrivateDevices for MemcacheD on CentOS 7
# See https://bugs.launchpad.net/openstack-ansible/+bug/1697531 for details.
memcached_disable_privatedevices: "{{ not is_metal }}"

**********
DECISION===>: PASS
**********
=========================:::583:::END!!!=========================
=========================:::584:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/physical_hosts.yml
**********
---
is_metal: True

**********
DECISION===>: PASS
**********
=========================:::584:::END!!!=========================
=========================:::585:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/aodh_all.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

aodh_service_region: "{{ service_region }}"

aodh_service_in_ldap: "{{ service_ldap_backend_enabled }}"
aodh_service_publicuri: "{{ openstack_service_publicuri_proto|default(aodh_service_proto) }}://{{ external_lb_vip_address }}:{{ aodh_service_port }}"
aodh_service_internaluri: "{{ openstack_service_internaluri_proto|default(aodh_service_proto) }}://{{ internal_lb_vip_address }}:{{ aodh_service_port }}"
aodh_service_adminuri: "{{ openstack_service_adminuri_proto|default(aodh_service_proto) }}://{{ internal_lb_vip_address }}:{{ aodh_service_port }}"

# Ensure that the package state matches the global setting
aodh_package_state: "{{ package_state }}"

**********
DECISION===>: PASS
**********
=========================:::585:::END!!!=========================
=========================:::586:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/sahara_all.yml
**********
---
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# If there are any Ceilometer and Sahara hosts in the environment, then enable its usage
sahara_ceilometer_enabled: "{{ (groups['ceilometer_all'] is defined) and (groups['sahara_all'] is defined) and (groups['ceilometer_all'] | length > 0) and (groups['sahara_all'] | length > 0) }}"

sahara_service_region: "{{ service_region }}"
sahara_service_in_ldap: "{{ service_ldap_backend_enabled }}"

**********
DECISION===>: PASS
**********
=========================:::586:::END!!!=========================
=========================:::587:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/ironic_compute.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

nova_virt_type: ironic

**********
DECISION===>: PASS
**********
=========================:::587:::END!!!=========================
=========================:::588:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/nova_all.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

nova_service_port: 8774
nova_service_proto: http
nova_metadata_protocol: "{{ openstack_service_internaluri_proto | default(nova_service_proto) }}"
nova_metadata_insecure: False
nova_service_adminuri_proto: "{{ openstack_service_adminuri_proto | default(nova_service_proto) }}"
nova_service_adminuri: "{{ nova_service_adminuri_proto }}://{{ internal_lb_vip_address }}:{{ nova_service_port }}"
nova_service_adminurl: "{{ nova_service_adminuri }}/v2.1"
nova_console_type: spice
nova_novncproxy_port: 6080
nova_spice_html5proxy_base_port: 6082
nova_serialconsoleproxy_port: 6083
nova_consoles:
  spice:
    port: "{{ nova_spice_html5proxy_base_port }}"
    path: "/spice_auto.html"
  novnc:
    port: "{{ nova_novncproxy_port }}"
    path: "/vnc.html"
  serial:
    port: "{{ nova_serialconsoleproxy_port }}"
    path: "/"

nova_console_port: "{{ nova_consoles[nova_console_type]['port'] }}"
nova_console_path: "{{ nova_consoles[nova_console_type]['path'] }}"

# These are here rather than in nova_all because
# both the os_ceilometer and os_nova roles require them

# If there are any Designate hosts in the environment, then enable its usage
nova_designate_enabled: "{{ (groups['designate_all'] is defined) and (groups['designate_all'] | length > 0) }}"
# If there are any Ceilometer hosts in the environment, then enable its usage
nova_ceilometer_enabled: "{{ (groups['ceilometer_all'] is defined) and (groups['ceilometer_all'] | length > 0) }}"
# If there are any Barbican hosts in the environment, then enable its usage
nova_barbican_enabled: "{{ hostvars['localhost']['nova_barbican_enabled'] }}"

nova_external_ssl: "{{ openstack_external_ssl }}"
nova_ceph_client_uuid: '{{ cinder_ceph_client_uuid | default() }}'
nova_dhcp_domain: "{{ dhcp_domain }}"
nova_service_in_ldap: "{{ service_ldap_backend_enabled }}"

# Ensure that the package state matches the global setting
nova_package_state: "{{ package_state }}"

# The system user for all nova services
nova_system_user_name: nova

# TODO: (andymccr) remove this once https://review.openstack.org/#/c/428120/ merges
nova_reserved_host_disk_mb: 0

# If there are any Designate hosts in the environment, then enable its usage
neutron_designate_enabled: "{{ hostvars['localhost']['neutron_designate_enabled'] }}"
# If there are any Ceilometer hosts in the environment, then enable its usage
neutron_ceilometer_enabled: "{{ hostvars['localhost']['neutron_ceilometer_enabled'] }}"

**********
DECISION===>: Hardcoded Secret
**********
=========================:::588:::END!!!=========================
=========================:::589:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/ironic-compute_hosts.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

nova_virt_type: ironic

**********
DECISION===>: PASS
**********
=========================:::589:::END!!!=========================
=========================:::590:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/octavia_all.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

octavia_service_internalurl: "{{ octavia_service_internaluri }}/v1/%(project_id)s"
octavia_service_user_name: octavia
octavia_service_region: "{{ service_region }}"

**********
DECISION===>: PASS
**********
=========================:::590:::END!!!=========================
=========================:::591:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/ceph_all.yml
**********
---
# Copyright 2017, Ravi Kumar Boyapati <rboyapat@gmail.com>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# ceph default list of bind mounts
ceph_container_bind_mounts:
  - bind_dir_path: "/var/lib/ceph"
    mount_path: "/openstack/{{ inventory_hostname }}"

# To extend ceph_conf_overrides use the ceph_conf_overrides_custom which will
# combine any ceph_conf_overrides with other RGW specific overrides.
ceph_conf_overrides_custom: {}
ceph_conf_overrides: "{{ (ceph_conf_overrides_rgw | default({})) | combine(ceph_conf_overrides_custom, recursive=True) }}"

# Disable the NFS gateway PPA and package install by default as it is not
# needed.
nfs_file_gw: False
nfs_obj_gw: False

# NTP in an OSA environment is handled by ansible-hardening using chrony
# ceph-ansible's default enabling of ntpd conflicts with the OSA defaults
ntp_service_enabled: False

**********
DECISION===>: PASS
**********
=========================:::591:::END!!!=========================
=========================:::592:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/lxd-compute_hosts.yml
**********
---
# Copyright 2017, Logan Vig <logan2211@gmail.com>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

nova_virt_type: lxd

**********
DECISION===>: PASS
**********
=========================:::592:::END!!!=========================
=========================:::593:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/congress_all.yml
**********
---
# Copyright 2017, taseer94@gmail.com
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

congress_service_region: "{{ service_region }}"
congress_service_in_ldap: "{{ service_ldap_backend_enabled }}"

# Ensure that the package state matches the global setting
congress_package_state: "{{ package_state }}"

**********
DECISION===>: PASS
**********
=========================:::593:::END!!!=========================
=========================:::594:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/neutron_agent.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Set basic DHCP configuration for neutron. These options simply allow
#  A neutron DHCP server to coexist with other DHCP servers within the
#  same broadcast domain. The log option provides basic logging for
#  neutron DHCP.
neutron_dhcp_config:
  dhcp-ignore: "tag:!known"
  log-facility: "/var/log/neutron/neutron-dnsmasq.log"

lxc_container_config_list:
  - "lxc.aa_profile=unconfined"

# Ensure that all neutron agent containers get a fixed mac address
lxc_container_fixed_mac: true

**********
DECISION===>: PASS
**********
=========================:::594:::END!!!=========================
=========================:::595:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/gnocchi_all.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

gnocchi_service_port: 8041
gnocchi_service_proto: http
gnocchi_service_internaluri_proto: "{{ openstack_service_internaluri_proto | default(gnocchi_service_proto) }}"
gnocchi_service_internalurl: "{{ gnocchi_service_internaluri_proto }}://{{ internal_lb_vip_address }}:{{ gnocchi_service_port }}"

gnocchi_ssl_external: "{{ openstack_external_ssl }}"
gnocchi_service_region: "{{ service_region }}"

# Ensure that the package state matches the global setting
gnocchi_package_state: "{{ package_state }}"

# Ensure that keystone authentication is enabled for gnocchi
gnocchi_keystone_auth: "{{ (groups['keystone_all'] is defined) and (groups['keystone_all'] | length > 0) }}"

# Gnocchi default list of bind mounts
gnocchi_container_bind_mounts:
  - bind_dir_path: "/var/lib/gnocchi"
    mount_path: "/openstack/{{ inventory_hostname }}"

**********
DECISION===>: PASS
**********
=========================:::595:::END!!!=========================
=========================:::596:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/cinder_all.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

cinder_service_region: "{{ service_region }}"
# If there are Swift hosts in the environment, then enable cinder backups to it
cinder_service_backup_program_enabled: "{{ hostvars['localhost']['cinder_service_backup_program_enabled'] }}"

# These are here rather than in cinder_all because
# both the os_ceilometer and os_cinder roles require them

# If there are any Ceilometer hosts in the environment, then enable its usage
cinder_ceilometer_enabled: "{{ (groups['cinder_all'] is defined) and (groups['cinder_all'] | length > 0) and (groups['ceilometer_all'] is defined) and (groups['ceilometer_all'] | length > 0) }}"

# The address used to listen for communications
cinder_management_address: "{{ ansible_host }}"

# The address used for communications with the glance service
cinder_glance_host: "{{ internal_lb_vip_address }}"

# If there are Swift hosts in the environment, then use it as the default Glance store
# This is specifically duplicated from glance_all for the cinder_glance_api_version
# setting below.
glance_default_store: "{{ ((groups['swift_all'] is defined) and (groups['swift_all'] | length > 0)) | ternary('swift', 'file') }}"

# cinder_backend_lvm_inuse: True if current host has an lvm backend
cinder_backend_lvm_inuse: '{{ (cinder_backends|default("")|to_json).find("cinder.volume.drivers.lvm.LVMVolumeDriver") != -1 }}'
cinder_service_in_ldap: "{{ service_ldap_backend_enabled }}"

# Ensure that the package state matches the global setting
cinder_package_state: "{{ package_state }}"

# The system user for all cinder services
cinder_system_user_name: cinder

# If there are any Barbican hosts in the environment, then enable its usage
cinder_barbican_enabled: "{{ (groups['barbican_all'] is defined) and (groups['barbican_all'] | length > 0) }}"

**********
DECISION===>: Hardcoded Secret
**********
=========================:::596:::END!!!=========================
=========================:::597:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/ceilometer_all.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

ceilometer_service_user_name: "{{ hostvars['localhost']['ceilometer_service_user_name'] }}"
ceilometer_service_tenant_name: "{{ hostvars['localhost']['ceilometer_service_tenant_name'] }}"

ceilometer_service_port: 8777
ceilometer_service_proto: http
ceilometer_service_publicuri: "{{ openstack_service_publicuri_proto|default(ceilometer_service_proto) }}://{{ external_lb_vip_address }}:{{ ceilometer_service_port }}"
ceilometer_service_region: "{{ service_region }}"
ceilometer_service_in_ldap: "{{ service_ldap_backend_enabled }}"

ceilometer_aodh_enabled: "{{ groups['aodh_all'] is defined and groups['aodh_all'] | length > 0 }}"
ceilometer_gnocchi_enabled: "{{ groups['gnocchi_all'] is defined and groups['gnocchi_all'] | length > 0 }}"

# Ensure that the package state matches the global setting
ceilometer_package_state: "{{ package_state }}"

# Swift vars used when swift is enabled
swift_system_user_name: "{{ hostvars['localhost']['swift_system_user_name'] }}"
swift_system_shell: "{{ hostvars['localhost']['swift_system_shell'] }}"
swift_system_comment: "{{ hostvars['localhost']['swift_system_comment'] }}"
swift_system_home_folder: "{{ hostvars['localhost']['swift_system_home_folder'] }}"

**********
DECISION===>: Use of HTTP without TLS
**********
=========================:::597:::END!!!=========================
=========================:::598:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/ceph-rgw.yml
**********
---
ceph_conf_overrides_rgw:
  "client.rgw.{{ hostvars[inventory_hostname]['ansible_hostname'] }}":
    # OpenStack integration with Keystone
    rgw_keystone_url: "{{ keystone_service_adminuri }}"
    rgw_keystone_api_version: 3
    rgw_keystone_admin_user: "{{ radosgw_admin_user }}"
    rgw_keystone_admin_password: "{{ radosgw_admin_password }}"
    rgw_keystone_admin_tenant: "{{ radosgw_admin_tenant }}"
    rgw_keystone_admin_domain: default
    rgw_keystone_accepted_roles: 'member, _member_, admin, swiftoperator'
    rgw_s3_auth_use_keystone: true
    rgw_enable_apis: swift

**********
DECISION===>: PASS
**********
=========================:::598:::END!!!=========================
=========================:::599:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/heat_all.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# If there are any Ceilometer hosts in the environment, then enable its usage
heat_ceilometer_enabled: "{{ (groups['ceilometer_all'] is defined) and (groups['ceilometer_all'] | length > 0) }}"

heat_service_region: "{{ service_region }}"
heat_service_in_ldap: "{{ service_ldap_backend_enabled }}"

# Ensure that the package state matches the global setting
heat_package_state: "{{ package_state }}"

# Only enable the heat cinder backups functionality if the cinder backup
# service is enabled.
heat_cinder_backups_enabled: "{{ hostvars['localhost']['cinder_service_backup_program_enabled'] }}"

**********
DECISION===>: PASS
**********
=========================:::599:::END!!!=========================
=========================:::600:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/rsyslog.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

rsyslog_server_storage_directory: /var/log/log-storage

# Ensure that the package state matches the global setting
rsyslog_package_state: "{{ package_state }}"

**********
DECISION===>: PASS
**********
=========================:::600:::END!!!=========================
=========================:::601:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/keystone_all.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# These are here rather than in keystone_all because
# both the os_ceilometer and os_keystone roles require them

# If there are any Ceilometer hosts in the environment, then enable its usage
keystone_ceilometer_enabled: "{{ (groups['ceilometer_all'] is defined) and (groups['ceilometer_all'] | length > 0) }}"

# The system user for all keystone services
keystone_system_user_name: keystone

keystone_external_ssl: "{{ openstack_external_ssl }}"

keystone_cache_servers: "{{ memcached_servers.split(',') }}"

keystone_service_in_ldap: "{{ service_ldap_backend_enabled }}"

# Hosts allowed to override remote IP with X-Forwarded-For
keystone_set_real_ip_from: "{{ groups['haproxy'] | map('extract', hostvars, 'container_address') | list }}"

# Ensure that the package state matches the global setting
keystone_package_state: "{{ package_state }}"

**********
DECISION===>: PASS
**********
=========================:::601:::END!!!=========================
=========================:::602:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/designate_all.yml
**********
---
# Copyright 2016 Internet Solutions (Pty) Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# If there are any Ceilometer hosts in the environment, then enable its usage
designate_ceilometer_enabled: "{{ (groups['designate_all'] is defined) and (groups['designate_all'] | length > 0) and (groups['ceilometer_all'] is defined) and (groups['ceilometer_all'] | length > 0) }}"

# Ensure that the package state matches the global setting
designate_package_state: "{{ package_state }}"

**********
DECISION===>: PASS
**********
=========================:::602:::END!!!=========================
=========================:::603:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/powervm-compute_hosts.yml
**********
---
# Copyright 2017, Logan Vig <logan2211@gmail.com>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

nova_virt_type: powervm

**********
DECISION===>: PASS
**********
=========================:::603:::END!!!=========================
=========================:::604:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/qemu-compute_hosts.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

nova_virt_type: qemu

**********
DECISION===>: PASS
**********
=========================:::604:::END!!!=========================
=========================:::605:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/rabbitmq_all.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

rabbitmq_cluster_name: openstack

# Ensure that the package state matches the global setting
rabbitmq_package_state: "{{ package_state }}"

# Ensure that all rabbitmq containers get a fixed mac address
lxc_container_fixed_mac: true

**********
DECISION===>: PASS
**********
=========================:::605:::END!!!=========================
=========================:::606:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/neutron_calico_dhcp_agent.yml
**********
---
# Copyright 2016, Logan Vig <logan2211@gmail.com>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Based on the default Calico BIRD template at
# https://github.com/projectcalico/felix/blob/master/etc/bird/calico-bird.conf.template

# BGP peer configuration for Calico by default will attempt to configure peering
# sessions with the host's default gateway over IPv4/IPv6. This is just one
# example of the various BGP peering configurations that could be used here
# and should be customized further to match the deployer's upstream BGP
# configuration. Calico has documented some example BGP topologies at:
# http://docs.projectcalico.org/master/reference/private-cloud/l2-interconnect-fabric
# http://docs.projectcalico.org/master/reference/private-cloud/l3-interconnect-fabric

# Set to your iBGP ASN
bird_bgp_asn: 65000

bird_bgp_ipv4_peer_ip: "{{ ansible_default_ipv4['gateway'] }}"
#calculate the first address in the subnet since the IPv6 "gateway" may be a
#link local address that we cannot peer to.
bird_bgp_ipv6_peer_ip: >-
  {% if ansible_default_ipv6['address'] is defined
        and ansible_default_ipv6['prefix'] is defined %}
  {{
     ((ansible_default_ipv6['address'] ~ '/' ~ ansible_default_ipv6['prefix']) |
     ipaddr('network') ~ '/' ~ ansible_default_ipv6['prefix']
     ) | ipaddr('net') | ipaddr(1) | ipaddr('address')
  }}
  {% endif %}

bird_ipv4_protocols:
  kernel: |
    learn;
    persist;
    scan time 2;
    graceful restart;
  device: |
    scan time 2;
  direct: |
    interface "-dummy0", "dummy1", "eth*", "em*", "en*";
  bgp:
    UPLINK: |
      description "Connection to BGP route reflector";
      local as {{ bird_bgp_asn }};
      neighbor {{ bird_bgp_ipv4_peer_ip }} as {{ bird_bgp_asn }};
      hold time 15;
      graceful restart;
      check link;
      direct;
      gateway direct;
      export filter export_bgp;
      next hop self;

bird_ipv6_protocols:
  kernel: |
    learn;
    persist;
    scan time 2;
    graceful restart;
  device: |
    scan time 2;
  direct: |
    interface "-dummy0", "dummy1", "eth*", "em*", "en*";
  bgp:
    UPLINK: |
      description "Connection to BGP route reflector";
      local as {{ bird_bgp_asn }};
      neighbor {{ bird_bgp_ipv6_peer_ip }} as {{ bird_bgp_asn }};
      hold time 15;
      graceful restart;
      check link;
      direct;
      gateway direct;
      export filter export_bgp;
      next hop self;

#configure bird to advertise subnets bound to these interface wildcards
bird_advertise_interfaces:
  - 'tap*'
  - 'cali*'
  - 'dummy1'

bird_ipv4_filters:
  export_bgp: |
    if ( {% for i in bird_advertise_interfaces %}(ifname ~ "{{ i }}"){% if not loop.last %} || {% endif %}{% endfor %} ) then {
      if  net != 0.0.0.0/0 then accept;
    }
    reject;

bird_ipv6_filters:
  export_bgp: |
    if ( {% for i in bird_advertise_interfaces %}(ifname ~ "{{ i }}"){% if not loop.last %} || {% endif %}{% endfor %} ) then {
      if  net != ::/0 then accept;
    }
    reject;

**********
DECISION===>: PASS
**********
=========================:::606:::END!!!=========================
=========================:::607:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/swift_all.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

swift_proxy_port: "{{ hostvars['localhost']['swift_proxy_port'] }}"
swift_system_user_name: "{{ hostvars['localhost']['swift_system_user_name'] }}"
swift_system_shell: "{{ hostvars['localhost']['swift_system_shell'] }}"
swift_system_comment: "{{ hostvars['localhost']['swift_system_comment'] }}"
swift_system_home_folder: "{{ hostvars['localhost']['swift_system_home_folder'] }}"

# If there are any Ceilometer and Swift hosts in the environment, then enable its usage
swift_ceilometer_enabled: "{{ (groups['ceilometer_all'] is defined) and (groups['swift_proxy'] is defined) and (groups['ceilometer_all'] | length > 0) and (groups['swift_proxy'] | length > 0) }}"

swift_service_region: "{{ service_region }}"
swift_service_in_ldap: "{{ service_ldap_backend_enabled }}"

# Ensure that the package state matches the global setting
swift_package_state: "{{ package_state }}"

# Used to optionally filter Gnocchi-originated traffic in Ceilometermiddleware
swift_gnocchi_enabled: "{{ (groups['gnocchi_all'] is defined and groups['gnocchi_all'] | length > 0) }}"

# Ceilometer vars used when ceilometer is enabled
ceilometer_service_user_name: "{{ hostvars['localhost']['ceilometer_service_user_name'] }}"
ceilometer_service_tenant_name: "{{ hostvars['localhost']['ceilometer_service_tenant_name'] }}"

**********
DECISION===>: PASS
**********
=========================:::607:::END!!!=========================
=========================:::608:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/hosts.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Ensure that the package state matches the global setting
lxc_hosts_package_state: "{{ package_state }}"
openstack_hosts_package_state: "{{ package_state }}"
security_package_state: "{{ package_state }}"

# Disable /etc/hosts management if unbound DNS resolution containers exist
openstack_host_manage_hosts_file: "{{ groups['unbound'] is not defined or groups['unbound'] | length < 1 }}"

# Use the RHEL 7 STIG content from the ansible-hardening role
stig_version: rhel7

# Temporarily avoid putting SELinux into enforcing mode on CentOS 7 until some
# additional policy is written. See LP Bug 1657517 for more details.
security_rhel7_enable_linux_security_module: "{{ ansible_os_family == 'RedHat' | ternary(false, true) }}"

# All our ansible tasks run as root user, we need to allow direct root login
security_sshd_permit_root_login: 'without-password'

**********
DECISION===>: Hardcoded Secret
**********
=========================:::608:::END!!!=========================
=========================:::609:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/magnum_all.yml
**********
---
# Copyright 2016 Internet Solutions (Pty) Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

magnum_bind_port: 9511
magnum_service_proto: http
magnum_service_publicuri_proto: "{{ openstack_service_publicuri_proto | default(magnum_service_proto) }}"
magnum_service_publicurl: "{{ magnum_service_publicuri_proto }}://{{ external_lb_vip_address }}:{{ magnum_bind_port }}"
magnum_service_internaluri_proto: "{{ openstack_service_internaluri_proto | default(magnum_service_proto) }}"
magnum_service_internalurl: "{{ magnum_service_internaluri_proto }}://{{ internal_lb_vip_address }}:{{ magnum_bind_port }}"
magnum_service_adminuri_proto: "{{ openstack_service_adminuri_proto | default(magnum_service_proto) }}"
magnum_service_adminurl: "{{ magnum_service_adminuri_proto }}://{{ internal_lb_vip_address }}:{{ magnum_bind_port }}"
magnum_service_region: "{{ service_region }}"

# Ensure that the package state matches the global setting
magnum_package_state: "{{ package_state }}"

**********
DECISION===>: PASS
**********
=========================:::609:::END!!!=========================
=========================:::610:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/galera_all.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

galera_client_drop_config_file: true

# Ensure that the package state matches the global setting
galera_server_package_state: "{{ package_state }}"

# Galera default list of bind mounts
galera_container_bind_mounts:
  - bind_dir_path: "/var/lib/mysql"
    mount_path: "/openstack/{{ inventory_hostname }}"

# Disable PrivateDevices for MariaDB on CentOS 7
# See https://bugs.launchpad.net/openstack-ansible/+bug/1697531 for details.
galera_disable_privatedevices: "{{ not is_metal }}"

# By default galera_monitoring xinetd app is open to 0.0.0.0/0
# This makes sure the monitoring is only restricted to the necessary nodes:
# the load balancers, and the galera nodes.
galera_monitoring_allowed_source: >-
  {{
    groups['galera_all'] | union(groups['haproxy'])
      | map('extract', hostvars, 'ansible_host')
      | list
      | join(' ') ~ ' 127.0.0.1'
  }}

# Galera sessions are long lived, so if we do endpoint maintenance we will
# force kill the sessions to force a failover to the active endpoint.
haproxy_shutdown_sessions: yes

**********
DECISION===>: PASS
**********
=========================:::610:::END!!!=========================
=========================:::611:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/all/cinder.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Consumed by the Nova role so it must remain in the 'all' scoped vars
cinder_ceph_client: cinder
cinder_service_port: 8776

**********
DECISION===>: PASS 
**********
=========================:::611:::END!!!=========================
=========================:::612:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/all/glance.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This var is used by glance and ironic
glance_service_user_name: glance

glance_service_publicurl: "{{ openstack_service_publicuri_proto }}://{{ external_lb_vip_address }}:9292"
glance_service_internalurl: "{{ openstack_service_internaluri_proto }}://{{ internal_lb_vip_address }}:9292"
glance_service_adminurl: "{{ openstack_service_adminuri_proto }}://{{ internal_lb_vip_address }}:9292"

# When running RBD or horizon image upload mode is direct allow multiple locations.
# See https://bugs.launchpad.net/openstack-ansible/+bug/1730722 for more on the
# this topic.
glance_show_multiple_locations: "{{ (glance_default_store == 'rbd') or (horizon_image_upload_mode == 'direct') }}"

**********
DECISION===>: PASS
**********
=========================:::612:::END!!!=========================
=========================:::613:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/all/nova.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

nova_service_port: 8774
# Consumed by Neutron role and must remained scoped to 'all' group
nova_metadata_port: 8775
nova_service_region: "{{ service_region }}"
nova_service_user_name: nova
nova_service_project_name: service
nova_service_project_domain_id: default
nova_service_user_domain_id: default
nova_keystone_auth_plugin: password

**********
DECISION===>: Hardcoded Secret
**********
=========================:::613:::END!!!=========================
=========================:::614:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/all/octavia.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# used by neutron role to specify octavia v1 service url
octavia_service_internaluri: "http://{{ internal_lb_vip_address }}:9876"

**********
DECISION===>: PASS
**********
=========================:::614:::END!!!=========================
=========================:::615:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/all/neutron.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Referenced by nova role and must remain in 'all' group scoping
neutron_service_port: 9696
neutron_service_proto: http
neutron_service_adminuri_proto: "{{ openstack_service_adminuri_proto | default(neutron_service_proto) }}"
neutron_service_adminuri: "{{ neutron_service_adminuri_proto }}://{{ internal_lb_vip_address }}:{{ neutron_service_port }}"
neutron_service_adminurl: "{{ neutron_service_adminuri }}"
neutron_service_user_name: neutron
neutron_service_project_name: service
neutron_service_region: "{{ service_region }}"

# Horizon consumes this var so it must be in the global vars namespace
neutron_plugin_type: ml2.lxb

**********
DECISION===>: PASS
**********
=========================:::615:::END!!!=========================
=========================:::616:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/all/pip.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

pip_install_package_state: "{{ package_state }}"

# Allow the deployer to force pip to download locally to the deployment host
# and copy it to the remote container for installation. Useful for environments
# where the containers lack internet access.
pip_offline_install: false

**********
DECISION===>: PASS
**********
=========================:::616:::END!!!=========================
=========================:::617:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/all/oslo-messaging.yml
**********
---
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

## Main
# RPC
oslomsg_rpc_transport: rabbit
oslomsg_rpc_port: "{{ rabbitmq_port }}"
oslomsg_rpc_servers: "{{ rabbitmq_servers }}"
oslomsg_rpc_use_ssl: "{{ rabbitmq_use_ssl }}"
oslomsg_rpc_host_group: "{{ rabbitmq_host_group }}"

# Notify
oslomsg_notify_transport: rabbit
oslomsg_notify_port: "{{ rabbitmq_port }}"
oslomsg_notify_servers: "{{ rabbitmq_servers }}"
oslomsg_notify_use_ssl: "{{ rabbitmq_use_ssl }}"
oslomsg_notify_host_group: "{{ rabbitmq_host_group }}"

**********
DECISION===>: PASS
**********
=========================:::617:::END!!!=========================
=========================:::618:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/all/ssl.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

## SSL
# These do not need to be configured unless you're creating certificates for
# services running behind Apache (currently, Horizon and Keystone).
ssl_protocol: "ALL -SSLv2 -SSLv3"
# Cipher suite string from https://hynek.me/articles/hardening-your-web-servers-ssl-ciphers/
ssl_cipher_suite: "ECDH+AESGCM:DH+AESGCM:ECDH+AES256:DH+AES256:ECDH+AES128:DH+AES:RSA+AESGCM:RSA+AES:!aNULL:!MD5:!DSS"

**********
DECISION===>: PASS
**********
=========================:::618:::END!!!=========================
=========================:::619:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/all/designate.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Used by both neutron and designate, and therefore must be in 'all' scope
designate_keystone_auth_plugin: password
designate_service_user_name: designate
designate_service_project_name: service
designate_service_project_domain_id: default
designate_service_user_domain_id: default
designate_service_region: "{{ service_region }}"

designate_service_adminurl: "http://{{ internal_lb_vip_address }}:9001/v2"


**********
DECISION===>: Hardcoded Secret
**********
=========================:::619:::END!!!=========================
=========================:::620:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/all/all.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

## OpenStack Source Code Release
openstack_release: 19.0.0.0b1

## Verbosity Options
debug: False

## SSH connection wait time
ssh_delay: 5

# Set the package install state for distribution packages
# Options are 'present' and 'latest'.
# NOTE(mhayden): Allowing CentOS 7 and openSUSE to use package_state=present should give
# gate jobs a better chance to finish and expose more issues to fix.
package_state: "{{ (ansible_pkg_mgr in ['dnf', 'yum', 'zypper']) | ternary('present', 'latest') }}"

# Set "/var/log" to be a bind mount to the physical host.
default_bind_mount_logs: true

# Set distro variable
# NOTE(hwoarang): ansible_distribution may return a string with spaces
# such as "openSUSE Leap" so we need to replace the space with underscore
# in order to create a more sensible repo name for the distro.
os_distro_version: "{{ (ansible_distribution | lower) | replace(' ', '_') }}-{{ ansible_distribution_version.split('.')[:2] | join('.') }}-{{ ansible_architecture | lower }}"

# Set the systemd prefix based on the base OS.
systemd_utils_distro_prefix:
  apt: "/lib/systemd"
  yum: "/lib/systemd"
  dnf: "/lib/systemd"
  zypper: "/usr/lib/systemd"

systemd_utils_prefix: "{{ systemd_utils_distro_prefix[ansible_pkg_mgr] }}"

# Ensure that the package state matches the global setting
rsyslog_client_package_state: "{{ package_state }}"
# At this time there's no suitable package available for systemd-journal-remote/gateway
# When installing on SUSE 42.x. For now this playbook will omit suse when the package
# manager is "zypper". When a suitable package is available on SUSE this should be removed.
rsyslog_client_enabled: "{{ ansible_pkg_mgr == 'zypper' }}"
rsyslog_server_enabled: "{{ ansible_pkg_mgr == 'zypper' }}"

# URL for the frozen internal openstack repo.
repo_server_port: 8181

## Default installation method for OpenStack services
install_method: "source"

## DNS resolution (resolvconf) options
#Group containing resolvers to configure
resolvconf_resolver_group: unbound

## Enable external SSL handling for general OpenStack services
openstack_external_ssl: true

## OpenStack global Endpoint Protos
openstack_service_publicuri_proto: https
openstack_service_adminuri_proto: http
openstack_service_internaluri_proto: http

## Region Name
service_region: RegionOne

## OpenStack Domain
openstack_domain: openstack.local
lxc_container_domain: "{{ container_domain }}"
container_domain: "{{ openstack_domain }}"

## DHCP Domain Name
dhcp_domain: openstacklocal

## LDAP enabled toggle
service_ldap_backend_enabled: "{{ keystone_ldap is defined and keystone_ldap.Default is defined }}"

## Base venv configuration
venv_tag: "{{ openstack_release }}"

## Gnocchi
# Used in both Gnocchi and Swift roles.
gnocchi_service_project_name: "{{ (gnocchi_storage_driver is defined and gnocchi_storage_driver == 'swift') | ternary('gnocchi_swift', 'service') }}"

## OpenStack Openrc
openrc_os_auth_url: "{{ keystone_service_internalurl }}"
openrc_os_password: "{{ keystone_auth_admin_password }}"
openrc_os_domain_name: "Default"
openrc_region_name: "{{ service_region }}"

## Host security hardening
# The ansible-hardening role provides security hardening for hosts
# by applying security configurations from the STIG. Hardening is enabled by
# default, but an option to opt out is available by setting the following
# variable to 'false'.
# Docs: https://docs.openstack.org/ansible-hardening/latest/
apply_security_hardening: true

## Ansible ssh configuration
ansible_ssh_extra_args: >
  -o UserKnownHostsFile=/dev/null
  -o StrictHostKeyChecking=no
  -o ServerAliveInterval=64
  -o ServerAliveCountMax=1024
  -o Compression=no
  -o TCPKeepAlive=yes
  -o VerifyHostKeyDNS=no
  -o ForwardX11=no
  -o ForwardAgent=yes
  -T

# Toggle whether the service is deployed in a container or not
is_metal: >-
  {{ (properties is defined) and
     (properties.is_metal is defined) and
     (properties.is_metal | bool) }}

**********
DECISION===>: PASS
**********
=========================:::620:::END!!!=========================
=========================:::621:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/all/horizon.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

horizon_image_upload_mode: direct

**********
DECISION===>: PASS
**********
=========================:::621:::END!!!=========================
=========================:::622:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/all/ceph-rgw.yml
**********
---
radosgw_service_name: "radosgw"
radosgw_service_type: "object-store"
radosgw_service_description: "Object Storage Service"
radosgw_service_region: "{{ service_region }}"
radosgw_admin_user: radosgw
radosgw_admin_tenant: service

radosgw_service_port: "{{ (groups['swift_proxy'] is defined and groups['swift_proxy'] | length > 0) | ternary(7980,8080) }}"
radosgw_address: "{{ container_address }}"
radosgw_service_proto: http
radosgw_service_publicuri_proto: "{{ openstack_service_publicuri_proto | default(radosgw_service_proto) }}"
radosgw_service_adminuri_proto: "{{ openstack_service_adminuri_proto | default(radosgw_service_proto) }}"
radosgw_service_internaluri_proto: "{{ openstack_service_internaluri_proto | default(radosgw_service_proto) }}"
radosgw_service_publicuri: "{{ radosgw_service_publicuri_proto }}://{{ external_lb_vip_address }}:{{ radosgw_service_port }}"
radosgw_service_publicurl: "{{ radosgw_service_publicuri }}/swift/v1"
radosgw_service_adminuri: "{{ radosgw_service_adminuri_proto }}://{{ internal_lb_vip_address }}:{{ radosgw_service_port }}"
radosgw_service_adminurl: "{{ radosgw_service_adminuri }}/swift/v1"
radosgw_service_internaluri: "{{ radosgw_service_internaluri_proto }}://{{ internal_lb_vip_address }}:{{ radosgw_service_port }}"
radosgw_service_internalurl: "{{ radosgw_service_internaluri }}/swift/v1"

**********
DECISION===>: PASS
**********
=========================:::622:::END!!!=========================
=========================:::623:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/all/keystone.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# OpenRC and various OpenStack roles require the vars below so they are scoped
# to 'all' hosts.

keystone_admin_user_name: admin
keystone_admin_tenant_name: admin
keystone_admin_port: 5000
keystone_service_port: 5000
keystone_service_proto: http
keystone_service_region: "{{ service_region }}"

keystone_service_adminuri_proto: "{{ openstack_service_adminuri_proto | default(keystone_service_proto) }}"
keystone_service_adminuri_insecure: >-
  {{
    (keystone_service_adminuri_proto == 'https') and
    (not (keystone_user_ssl_cert is defined or haproxy_user_ssl_cert is defined))
  }}

keystone_service_adminuri: "{{ keystone_service_adminuri_proto }}://{{ internal_lb_vip_address }}:{{ keystone_admin_port }}"
keystone_service_adminurl: "{{ keystone_service_adminuri }}/v3"

keystone_service_internaluri_proto: "{{ openstack_service_internaluri_proto | default(keystone_service_proto) }}"
keystone_service_internaluri_insecure: >-
  {{
    (keystone_service_internaluri_proto == 'https') and
    (not (keystone_user_ssl_cert is defined or haproxy_user_ssl_cert is defined))
  }}

keystone_service_internaluri: "{{ keystone_service_internaluri_proto }}://{{ internal_lb_vip_address }}:{{ keystone_service_port }}"
keystone_service_internalurl: "{{ keystone_service_internaluri }}/v3"

keystone_service_publicuri_proto: "{{ openstack_service_publicuri_proto | default(keystone_service_proto) }}"
keystone_service_publicuri_insecure: >-
  {{
    (keystone_service_publicuri_proto == 'https') and
    (not (keystone_user_ssl_cert is defined or haproxy_user_ssl_cert is defined))
  }}

keystone_service_publicuri: "{{ keystone_service_publicuri_proto }}://{{ external_lb_vip_address }}:{{ keystone_service_port }}"
keystone_service_publicurl: "{{ keystone_service_publicuri }}/v3"

**********
DECISION===>: hardcoded secret
**********
=========================:::623:::END!!!=========================
=========================:::624:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/all/ceph.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

ceph_client_package_state: "{{ package_state }}"

## ceph-ansible configuration
mon_group_name: ceph-mon
mgr_group_name: "{{ mon_group_name }}"
osd_group_name: ceph-osd
rgw_group_name: ceph-rgw
ceph_origin: "{{ (ansible_pkg_mgr == 'zypper') | ternary('distro', 'repository') }}"
ceph_repository: community
# The _stable_release var is used by both the OSA ceph_client role and the
# ceph-ansible roles. It is defaulted in ceph_client but set here to keep the
# OSA/ceph-ansible integrations in sync.
ceph_stable_release: mimic
fetch_directory: /etc/openstack_deploy/ceph-fetch/
# tries to create /var/log/ceph as a directory and fails if the log link already
# exists. we handle the log dir creation so this is not something we need
# ceph-common to prepare for us.
rbd_client_directories: false

# The OSA ceph_client role does not support loading IPs from an inventory group,
# so we have to feed it a list of IPs
ceph_mons: "{{ groups[mon_group_name]
               | map('extract', hostvars, 'ansible_host')
               | list }}"

# Provide a variable which can be overidden by a deployer to specify a list of
# dicts describing RadosGW provisioned by means other than OpenStack-Ansible.
# The ip_addr should be accessible by the haproxy internal interface.
# - name: ceph-rgw-name
#   ip_addr: x.x.x.x
ceph_rgws: []

**********
DECISION===>: PASS
**********
=========================:::624:::END!!!=========================
=========================:::625:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/all/infra.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

## Rabbit options
rabbitmq_host_group: "rabbitmq_all"
rabbitmq_port: "{{ (rabbitmq_use_ssl | bool) | ternary(5671, 5672) }}"

rabbitmq_use_ssl: True
rabbitmq_servers: >-
  {{
    groups[rabbitmq_host_group]
      | map('extract', hostvars, 'ansible_host')
      | list | join(',')
  }}

## Galera options
galera_client_package_state: "{{ package_state }}"
galera_address: "{{ internal_lb_vip_address }}"
galera_root_user: "root"

## Memcached options
memcached_port: 11211
memcached_servers: >-
  {{
    (groups['memcached'] | map('extract', hostvars, 'ansible_host') | list)
      | map('regex_replace', '(.*)' ,'\1:' ~ memcached_port)
      | list
      | join(',')
  }}

**********
DECISION===>: hardcoded secret
**********
=========================:::625:::END!!!=========================
=========================:::626:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/all/ironic.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# These vars are used for ironic and nova
ironic_keystone_auth_plugin: password
ironic_service_user_name: ironic
ironic_service_project_name: service
ironic_service_proto: http
ironic_service_port: 6385
ironic_service_adminuri_proto: "{{ openstack_service_adminuri_proto | default(ironic_service_proto) }}"
ironic_service_adminuri: "{{ ironic_service_adminuri_proto }}://{{ internal_lb_vip_address }}:{{ ironic_service_port }}"
ironic_service_adminurl: "{{ ironic_service_adminuri }}/v1"

**********
DECISION===>: hardcoded secret
**********
=========================:::626:::END!!!=========================
=========================:::627:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/haproxy/haproxy.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

haproxy_bind_on_non_local: "{{ (groups.haproxy | length) > 1 }}"
haproxy_use_keepalived: "{{ (groups.haproxy | length) > 1 }}"
keepalived_selinux_compile_rules:
  - keepalived_ping
  - keepalived_haproxy_pid_file

# Ensure that the package state matches the global setting
haproxy_package_state: "{{ package_state }}"

haproxy_whitelist_networks:
  - 192.168.0.0/16
  - 172.16.0.0/12
  - 10.0.0.0/8

haproxy_galera_whitelist_networks: "{{ haproxy_whitelist_networks }}"
haproxy_glance_registry_whitelist_networks: "{{ haproxy_whitelist_networks }}"
haproxy_keystone_admin_whitelist_networks: "{{ haproxy_whitelist_networks }}"
haproxy_nova_metadata_whitelist_networks: "{{ haproxy_whitelist_networks }}"
haproxy_nova_placement_whitelist_networks: "{{ haproxy_whitelist_networks }}"
haproxy_rabbitmq_management_whitelist_networks: "{{ haproxy_whitelist_networks }}"
haproxy_repo_git_whitelist_networks: "{{ haproxy_whitelist_networks }}"
haproxy_repo_cache_whitelist_networks: "{{ haproxy_whitelist_networks }}"
haproxy_opendaylight_whitelist_networks: "{{ haproxy_whitelist_networks }}"

haproxy_default_services:
  - service:
      haproxy_service_name: galera
      haproxy_backend_nodes: "{{ (groups['galera_all'] | default([]))[:1] }}"  # list expected
      haproxy_backup_nodes: "{{ (groups['galera_all'] | default([]))[1:] }}"
      haproxy_bind: "{{ [internal_lb_vip_address] }}"
      haproxy_port: 3306
      haproxy_check_port: 9200
      haproxy_balance_type: tcp
      haproxy_timeout_client: 5000s
      haproxy_timeout_server: 5000s
      haproxy_backend_options:
        - "httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"
      haproxy_whitelist_networks: "{{ haproxy_galera_whitelist_networks }}"
      haproxy_service_enabled: "{{ groups['galera_all'] is defined and groups['galera_all'] | length > 0 }}"
  - service:
      haproxy_service_name: repo_git
      haproxy_backend_nodes: "{{ groups['repo_all'] | default([]) }}"
      haproxy_bind: "{{ [internal_lb_vip_address] }}"
      haproxy_port: 9418
      haproxy_balance_type: tcp
      haproxy_backend_options:
        - tcp-check
      haproxy_whitelist_networks: "{{ haproxy_repo_git_whitelist_networks }}"
      haproxy_service_enabled: "{{ groups['repo_all'] is defined and groups['repo_all'] | length > 0 }}"
  - service:
      haproxy_service_name: repo_all
      haproxy_backend_nodes: "{{ groups['repo_all'] | default([]) }}"
      haproxy_bind: "{{ [internal_lb_vip_address] }}"
      haproxy_port: 8181
      haproxy_balance_type: http
      haproxy_backend_options:
        - "httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"
      haproxy_service_enabled: "{{ groups['repo_all'] is defined and groups['repo_all'] | length > 0 }}"
  - service:
      haproxy_service_name: glance_api
      haproxy_backend_nodes: "{{ groups['glance_api'] | default([]) }}"
      haproxy_ssl: "{{ haproxy_ssl }}"
      haproxy_port: 9292
      haproxy_balance_type: http
      haproxy_backend_options:
        - "httpchk GET /healthcheck HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"
      haproxy_service_enabled: "{{ groups['glance_api'] is defined and groups['glance_api'] | length > 0 }}"
  - service:
      haproxy_service_name: glance_registry
      haproxy_backend_nodes: "{{ groups['glance_registry'] | default([]) }}"
      haproxy_ssl: "{{ haproxy_ssl }}"
      haproxy_port: 9191
      haproxy_balance_type: http
      haproxy_backend_options:
        - "httpchk GET /healthcheck HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"
      haproxy_whitelist_networks: "{{ haproxy_glance_registry_whitelist_networks }}"
      haproxy_service_enabled: >-
        {{ groups['glance_registry'] is defined and
           groups['glance_registry'] | length > 0 and
           (glance_enable_v2_registry | default(False)) | bool and
           (glance_enable_v1_api | default(False)) | bool }}
  - service:
      haproxy_service_name: gnocchi
      haproxy_backend_nodes: "{{ groups['gnocchi_all'] | default([]) }}"
      haproxy_port: 8041
      haproxy_ssl: "{{ haproxy_ssl }}"
      haproxy_balance_type: http
      haproxy_backend_options:
        - "httpchk GET /healthcheck HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"
      haproxy_service_enabled: "{{ groups['gnocchi_all'] is defined and groups['gnocchi_all'] | length > 0 }}"
  - service:
      haproxy_service_name: heat_api_cfn
      haproxy_backend_nodes: "{{ groups['heat_api_cfn'] | default([]) }}"
      haproxy_port: 8000
      haproxy_ssl: "{{ haproxy_ssl }}"
      haproxy_balance_type: http
      haproxy_backend_options:
        - "httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"
      haproxy_service_enabled: "{{ groups['heat_api_cfn'] is defined and groups['heat_api_cfn'] | length > 0 }}"
  - service:
      haproxy_service_name: heat_api
      haproxy_backend_nodes: "{{ groups['heat_api'] | default([]) }}"
      haproxy_port: 8004
      haproxy_ssl: "{{ haproxy_ssl }}"
      haproxy_balance_type: http
      haproxy_backend_options:
        - "httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"
      haproxy_service_enabled: "{{ groups['heat_api'] is defined and groups['heat_api'] | length > 0 }}"
  - service:
      haproxy_service_name: keystone_service
      haproxy_backend_nodes: "{{ groups['keystone_all'] | default([])  }}"
      haproxy_port: 5000
      haproxy_ssl: "{{ haproxy_ssl }}"
      haproxy_balance_type: "http"
      haproxy_backend_options:
        - "httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"
      haproxy_service_enabled: "{{ groups['keystone_all'] is defined and groups['keystone_all'] | length > 0 }}"
  - service:
      haproxy_service_name: neutron_server
      haproxy_backend_nodes: "{{ groups['neutron_server'] | default([]) }}"
      haproxy_port: 9696
      haproxy_ssl: "{{ haproxy_ssl }}"
      haproxy_balance_type: http
      haproxy_backend_options:
        - "httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"
      haproxy_service_enabled: "{{ groups['neutron_server'] is defined and groups['neutron_server'] | length > 0 }}"
  - service:
      haproxy_service_name: nova_api_metadata
      haproxy_backend_nodes: "{{ groups['nova_api_metadata'] | default([]) }}"
      haproxy_bind: "{{ [internal_lb_vip_address] }}"
      haproxy_port: 8775
      haproxy_ssl: False
      haproxy_balance_type: http
      haproxy_backend_options:
        - "httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"
      haproxy_whitelist_networks: "{{ haproxy_nova_metadata_whitelist_networks }}"
      haproxy_service_enabled: "{{ groups['nova_api_metadata'] is defined and groups['nova_api_metadata'] | length > 0 }}"
  - service:
      haproxy_service_name: nova_api_os_compute
      haproxy_backend_nodes: "{{ groups['nova_api_os_compute'] | default([]) }}"
      haproxy_ssl: "{{ haproxy_ssl }}"
      haproxy_port: 8774
      haproxy_balance_type: http
      haproxy_backend_options:
        - "httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"
      haproxy_service_enabled: "{{ groups['nova_api_os_compute'] is defined and groups['nova_api_os_compute'] | length > 0 }}"
  - service:
      haproxy_service_name: nova_api_placement
      haproxy_backend_nodes: "{{ groups['nova_api_placement'] | default([]) }}"
      haproxy_ssl: False
      haproxy_bind: "{{ [internal_lb_vip_address] }}"
      haproxy_port: 8780
      haproxy_balance_type: http
      haproxy_backend_options:
        - "httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"
      haproxy_backend_httpcheck_options:
        - "expect status 200"
      haproxy_whitelist_networks: "{{ haproxy_nova_placement_whitelist_networks }}"
      haproxy_service_enabled: "{{ groups['nova_api_placement'] is defined and groups['nova_api_placement'] | length > 0 }}"
  - service:
      haproxy_service_name: nova_console
      haproxy_backend_nodes: "{{ groups['nova_console'] | default([]) }}"
      haproxy_ssl: "{{ haproxy_ssl }}"
      haproxy_port: "{{ hostvars[(groups['nova_console'] | default(['localhost']))[0] | default('localhost')]['nova_console_port'] | default(6082) }}"
      haproxy_balance_type: http
      haproxy_timeout_client: 60m
      haproxy_timeout_server: 60m
      haproxy_balance_alg: source
      haproxy_backend_options:
        - "httpchk HEAD {{ hostvars[(groups['nova_console'] | default(['localhost']))[0] | default('localhost')]['nova_console_path'] | default('/spice_auto.html') }} HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"
      haproxy_backend_httpcheck_options:
        - "expect status 200"
      haproxy_service_enabled: "{{ groups['nova_console'] is defined and groups['nova_console'] | length > 0 }}"
  - service:
      haproxy_service_name: cinder_api
      haproxy_backend_nodes: "{{ groups['cinder_api'] | default([]) }}"
      haproxy_ssl: "{{ haproxy_ssl }}"
      haproxy_port: 8776
      haproxy_balance_type: http
      haproxy_backend_options:
        - "httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"
      haproxy_service_enabled: "{{ groups['cinder_api'] is defined and groups['cinder_api'] | length > 0 }}"
  - service:
      haproxy_service_name: horizon
      haproxy_backend_nodes: "{{ groups['horizon_all'] | default([]) }}"
      haproxy_ssl: "{{ haproxy_ssl }}"
      haproxy_ssl_all_vips: true
      haproxy_port: "{{ haproxy_ssl | ternary(443,80) }}"
      haproxy_backend_port: 80
      haproxy_redirect_http_port: 80
      haproxy_balance_type: http
      haproxy_balance_alg: source
      haproxy_backend_options:
        - "httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"
      haproxy_service_enabled: "{{ groups['horizon_all'] is defined and groups['horizon_all'] | length > 0 }}"
  - service:
      haproxy_service_name: sahara_api
      haproxy_backend_nodes: "{{ groups['sahara_api'] | default([]) }}"
      haproxy_ssl: "{{ haproxy_ssl }}"
      haproxy_balance_alg: source
      haproxy_port: 8386
      haproxy_balance_type: http
      haproxy_backend_options:
        - "httpchk GET /healthcheck HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"
      haproxy_service_enabled: "{{ groups['sahara_api'] is defined and groups['sahara_api'] | length > 0 }}"
  - service:
      haproxy_service_name: swift_proxy
      haproxy_backend_nodes: "{{ groups['swift_proxy'] | default([]) }}"
      haproxy_ssl: "{{ haproxy_ssl }}"
      haproxy_balance_alg: source
      haproxy_port: 8080
      haproxy_balance_type: http
      haproxy_backend_options:
        - "httpchk GET /healthcheck HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"
      haproxy_service_enabled: "{{ groups['swift_proxy'] is defined and groups['swift_proxy'] | length > 0 }}"
  - service:
      haproxy_service_name: aodh_api
      haproxy_backend_nodes: "{{ groups['aodh_api'] | default([]) }}"
      haproxy_ssl: "{{ haproxy_ssl }}"
      haproxy_port: 8042
      haproxy_balance_type: http
      haproxy_backend_options:
        - "httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"
      haproxy_service_enabled: "{{ groups['aodh_api'] is defined and groups['aodh_api'] | length > 0 }}"
  - service:
      haproxy_service_name: ironic_api
      haproxy_backend_nodes: "{{ groups['ironic_api'] | default([]) }}"
      haproxy_ssl: "{{ haproxy_ssl }}"
      haproxy_port: 6385
      haproxy_balance_type: http
      haproxy_backend_options:
        - "httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"
      haproxy_service_enabled: "{{ groups['ironic_api'] is defined and groups['ironic_api'] | length > 0 }}"
  - service:
      haproxy_service_name: rabbitmq_mgmt
      haproxy_backend_nodes: "{{ groups['rabbitmq'] | default([]) }}"
      haproxy_ssl: False
      haproxy_bind: "{{ [internal_lb_vip_address] }}"
      haproxy_port: 15672
      haproxy_balance_type: http
      haproxy_backend_options:
        - "httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"
      haproxy_whitelist_networks: "{{ haproxy_rabbitmq_management_whitelist_networks }}"
      haproxy_service_enabled: "{{ groups['rabbitmq'] is defined and groups['rabbitmq'] | length > 0 }}"
  - service:
      haproxy_service_name: magnum
      haproxy_backend_nodes: "{{ groups['magnum_all'] | default([]) }}"
      haproxy_ssl: "{{ haproxy_ssl }}"
      haproxy_port: 9511
      haproxy_balance_type: http
      haproxy_backend_options:
        - "httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"
      haproxy_service_enabled: "{{ groups['magnum_all'] is defined and groups['magnum_all'] | length > 0 }}"
  - service:
      haproxy_service_name: trove
      haproxy_backend_nodes: "{{ groups['trove_api'] | default([]) }}"
      haproxy_ssl: "{{ haproxy_ssl }}"
      haproxy_port: 8779
      haproxy_balance_type: http
      haproxy_backend_options:
        - "httpchk HEAD / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"
      haproxy_service_enabled: "{{ groups['trove_api'] is defined and groups['trove_api'] | length > 0 }}"
  - service:
      haproxy_service_name: barbican
      haproxy_backend_nodes: "{{ groups['barbican_api'] | default([]) }}"
      haproxy_ssl: "{{ haproxy_ssl }}"
      haproxy_port: 9311
      haproxy_balance_type: http
      haproxy_backend_options:
        - "httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"
      haproxy_service_enabled: "{{ groups['barbican_api'] is defined and groups['barbican_api'] | length > 0 }}"
  - service:
      haproxy_service_name: designate_api
      haproxy_backend_nodes: "{{ groups['designate_api'] | default([]) }}"
      haproxy_ssl: "{{ haproxy_ssl }}"
      haproxy_port: 9001
      haproxy_balance_type: http
      haproxy_backend_options:
        - "forwardfor"
        - "httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"
        - "httplog"
      haproxy_service_enabled: "{{ groups['designate_api'] is defined and groups['designate_api'] | length > 0 }}"
  - service:
      haproxy_service_name: octavia
      haproxy_backend_nodes: "{{ groups['octavia_all'] | default([]) }}"
      haproxy_ssl: "{{ haproxy_ssl }}"
      haproxy_port: 9876
      haproxy_balance_type: http
      haproxy_backend_options:
        - "httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"
      haproxy_service_enabled: "{{ groups['octavia_all'] is defined and groups['octavia_all'] | length > 0 }}"
  - service:
      haproxy_service_name: tacker
      haproxy_backend_nodes: "{{ groups['tacker_all'] | default([]) }}"
      haproxy_ssl: "{{ haproxy_ssl }}"
      haproxy_port: 9890
      haproxy_balance_type: http
      haproxy_backend_options:
        - "forwardfor"
        - "httpchk GET / HTTP/1.0\\r\\nUser-agent:\\ osa-haproxy-healthcheck"
        - "httplog"
      haproxy_service_enabled: "{{ groups['tacker_all'] is defined and groups['tacker_all'] | length > 0 }}"
  - service:
      haproxy_service_name: opendaylight-neutron
      haproxy_backend_nodes: "{{ groups['neutron_server'] | default([]) }}"
      haproxy_bind: "{{ [internal_lb_vip_address] }}"
      haproxy_port: 8180
      haproxy_balance_type: tcp
      haproxy_timeout_client: 5000s
      haproxy_timeout_server: 5000s
      haproxy_whitelist_networks: "{{ haproxy_opendaylight_whitelist_networks }}"
      haproxy_service_enabled: "{{ neutron_plugin_type == 'ml2.opendaylight' }}"
  - service:
      haproxy_service_name: opendaylight-websocket
      haproxy_backend_nodes: "{{ groups['neutron_server'] | default([]) }}"
      haproxy_bind: "{{ [internal_lb_vip_address] }}"
      haproxy_port: 8185
      haproxy_balance_type: tcp
      haproxy_timeout_client: 5000s
      haproxy_timeout_server: 5000s
      haproxy_whitelist_networks: "{{ haproxy_opendaylight_whitelist_networks }}"
      haproxy_service_enabled: "{{ neutron_plugin_type == 'ml2.opendaylight' }}"
  - service:
      haproxy_service_name: ceph-rgw
      haproxy_backend_nodes: "{{ groups['ceph-rgw'] | default(ceph_rgws) }}"
      haproxy_ssl: "{{ haproxy_ssl }}"
      haproxy_balance_alg: source
      haproxy_port: "{{ radosgw_service_port | default(7980) }}"
      haproxy_balance_type: http
      haproxy_backend_options:
        - httpchk HEAD /
      haproxy_backend_httpcheck_options:
        - expect rstatus 200|405
      haproxy_service_enabled: "{{ (groups['ceph-rgw'] is defined and groups['ceph-rgw'] | length > 0) or (ceph_rgws | length > 0) }}"

**********
DECISION===>: PASS
**********
=========================:::627:::END!!!=========================
=========================:::628:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/group_vars/haproxy/keepalived.yml
**********
---
# Copyright 2015, Jean-Philippe Evrard <jean-philippe@evrard.me>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

keepalived_ping_count: 1
keepalived_ping_interval: 10
keepalived_ubuntu_src: "native"
keepalived_ping_address: "{{ ansible_default_ipv4['gateway'] | default('127.0.0.1') }}"

keepalived_sync_groups:
  haproxy:
    instances:
      - external
      - internal
    notify_script: /etc/keepalived/haproxy_notify.sh
    ##if a src_*_script is defined, it will be uploaded from src_*_script
    ##on the deploy host to the *_script location. Make sure *_script is
    ##a location in that case.
    src_notify_script: "{{ playbook_dir }}/../scripts/keepalived_haproxy_notifications.sh"

keepalived_global_defs:
  - "enable_script_security"

keepalived_scripts:
  haproxy_check_script:
    check_script: "/bin/kill -0 `cat /var/run/haproxy.pid`"
  pingable_check_script:
    check_script: "/bin/ping -c {{ keepalived_ping_count }} {{ keepalived_ping_address }} 1>&2"
    interval: "{{ keepalived_ping_interval }}"
    fall: 2
    rise: 4

# If you have more than 5 keepalived nodes, you should build your own script
# (handling master and backups servers), and replace in keepalived_instances:
#    priority: "{{ (groups['haproxy']|length-groups['haproxy'].index(inventory_hostname)*50 }}"
# by
#    priority: "{{ (groups['haproxy'].index(inventory_hostname) == 0) | ternary('100','50') }}"
keepalived_instances:
  external:
    interface: "{{ haproxy_keepalived_external_interface | default(management_bridge) }}"
    state: "{{ (groups['haproxy'].index(inventory_hostname) == 0) | ternary('MASTER', 'BACKUP') }}"
    virtual_router_id: "{{ haproxy_keepalived_external_virtual_router_id | default ('10') }}"
    priority: "{{ (groups['haproxy']|length-groups['haproxy'].index(inventory_hostname))*50 }}"
    authentication_password: "{{ haproxy_keepalived_authentication_password }}"
    vips:
      - "{{ haproxy_keepalived_external_vip_cidr | default('169.254.1.1/24')  }} dev {{ haproxy_keepalived_external_interface | default(management_bridge) }}"
    track_scripts:
      - haproxy_check_script
      - pingable_check_script
  internal:
    interface: "{{ haproxy_keepalived_internal_interface | default(management_bridge) }}"
    state: "{{ (groups['haproxy'].index(inventory_hostname) == 0) | ternary('MASTER', 'BACKUP') }}"
    virtual_router_id: "{{ haproxy_keepalived_internal_virtual_router_id | default ('11') }}"
    priority: "{{ (groups['haproxy']|length-groups['haproxy'].index(inventory_hostname))*50 }}"
    authentication_password: "{{ haproxy_keepalived_authentication_password }}"
    track_scripts:
      - haproxy_check_script
      - pingable_check_script
    vips:
      - "{{ haproxy_keepalived_internal_vip_cidr | default('169.254.2.1/24') }} dev {{ haproxy_keepalived_internal_interface | default(management_bridge) }}"

**********
DECISION===>: PASS
**********
=========================:::628:::END!!!=========================
=========================:::629:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/env.d/barbican.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

component_skel:
  barbican_api:
    belongs_to:
      - barbican_all

container_skel:
  barbican_container:
    belongs_to:
      - key-manager_containers
    contains:
      - barbican_api

physical_skel:
  key-manager_containers:
    belongs_to:
      - all_containers
  key-manager_hosts:
    belongs_to:
      - hosts

**********
DECISION===>: PASS
**********
=========================:::629:::END!!!=========================
=========================:::630:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/env.d/cinder.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

component_skel:
  cinder_api:
    belongs_to:
      - cinder_all
  cinder_scheduler:
    belongs_to:
      - cinder_all
  cinder_volume:
    belongs_to:
      - cinder_all
  cinder_backup:
    belongs_to:
      - cinder_all


container_skel:
  cinder_api_container:
    belongs_to:
      - storage-infra_containers
    contains:
      - cinder_api
      - cinder_scheduler
  cinder_volumes_container:
    belongs_to:
      - storage_containers
    contains:
      - cinder_volume
      - cinder_backup
    properties:
# When using LVM or any iSCSI based (see LP#1226855) cinder backends, such as
# NetApp with iSCSI protocol, it is advised to run cinder-volumes on metal.
# If you are using a different backend you may want to remove "is_metal: true".
# Otherwise if cinder-volumes is already running in containers you may want to
# leave is_metal off, alternatively you will have to migrate your volumes once
# deployed on metal.
      is_metal: true


physical_skel:
  storage-infra_containers:
    belongs_to:
      - all_containers
  storage-infra_hosts:
    belongs_to:
      - hosts
  storage_containers:
    belongs_to:
      - all_containers
  storage_hosts:
    belongs_to:
      - hosts

**********
DECISION===>: PASS
**********
=========================:::630:::END!!!=========================
=========================:::631:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/env.d/os-infra.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

physical_skel:
  os-infra_containers:
    belongs_to:
      - all_containers
  os-infra_hosts:
    belongs_to:
      - hosts

**********
DECISION===>: PASS
**********
=========================:::631:::END!!!=========================
=========================:::632:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/env.d/glance.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

component_skel:
  glance_api:
    belongs_to:
      - glance_all
  glance_registry:
    belongs_to:
      - glance_all


container_skel:
  glance_container:
    belongs_to:
      - image_containers
      - os-infra_containers
    contains:
      - glance_api
      - glance_registry
    properties:
      container_fs_size: 12G


physical_skel:
  image_containers:
    belongs_to:
    - all_containers
  image_hosts:
    belongs_to:
    - hosts

**********
DECISION===>: PASS
**********
=========================:::632:::END!!!=========================
=========================:::633:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/env.d/nova.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

component_skel:
  nova_api_metadata:
    belongs_to:
      - nova_all
  nova_api_os_compute:
    belongs_to:
      - nova_all
  nova_api_placement:
    belongs_to:
      - nova_all
  nova_compute:
    belongs_to:
      - nova_all
  nova_conductor:
    belongs_to:
      - nova_all
  nova_scheduler:
    belongs_to:
      - nova_all
  nova_console:
    belongs_to:
      - nova_all


container_skel:
  nova_api_container:
    belongs_to:
      - compute-infra_containers
      - os-infra_containers
    contains:
      - nova_api_metadata
      - nova_api_os_compute
      - nova_api_placement
      - nova_conductor
      - nova_scheduler
      - nova_console
  nova_compute_container:
    belongs_to:
      - compute_containers
      - kvm-compute_containers
      - lxd-compute_containers
      - qemu-compute_containers
      - powervm-compute_containers
    contains:
      - neutron_linuxbridge_agent
      - neutron_openvswitch_agent
      - neutron_sriov_nic_agent
      - nova_compute
    properties:
      is_metal: true


physical_skel:
  compute-infra_containers:
    belongs_to:
      - all_containers
  compute-infra_hosts:
    belongs_to:
      - hosts
  compute_containers:
    belongs_to:
      - all_containers
  compute_hosts:
    belongs_to:
      - hosts
  lxd-compute_containers:
    belongs_to:
      - all_containers
  lxd-compute_hosts:
    belongs_to:
      - hosts
  kvm-compute_containers:
    belongs_to:
      - all_containers
  kvm-compute_hosts:
    belongs_to:
      - hosts
  qemu-compute_containers:
    belongs_to:
      - all_containers
  qemu-compute_hosts:
    belongs_to:
      - hosts
  powervm-compute_containers:
    belongs_to:
      - all_containers
  powervm-compute_hosts:
    belongs_to:
      - hosts

**********
DECISION===>: PASS
**********
=========================:::633:::END!!!=========================
=========================:::634:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/env.d/octavia.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

component_skel:
  octavia-api:
    belongs_to:
      - octavia_all
  octavia-worker:
    belongs_to:
      - octavia_all
  octavia-housekeeping:
    belongs_to:
      - octavia_all
  octavia-health-manager:
    belongs_to:
      - octavia_all


container_skel:
  octavia_server_container:
    belongs_to:
      - octavia-infra_containers
    contains:
      - octavia-api
      - octavia-worker
      - octavia-housekeeping
      - octavia-health-manager

physical_skel:
  octavia-infra_containers:
    belongs_to:
      - all_containers
  octavia-infra_hosts:
    belongs_to:
      - hosts

**********
DECISION===>: PASS
**********
=========================:::634:::END!!!=========================
=========================:::635:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/env.d/sahara.yml
**********
---
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

component_skel:
  sahara_api:
    belongs_to:
      - sahara_all
  sahara_engine:
    belongs_to:
      - sahara_all

container_skel:
  sahara_container:
    belongs_to:
      - sahara-infra_containers
    contains:
      - sahara_api
      - sahara_engine

physical_skel:
  sahara-infra_containers:
    belongs_to:
      - all_containers
  sahara-infra_hosts:
    belongs_to:
      - hosts

**********
DECISION===>: PASS
**********
=========================:::635:::END!!!=========================
=========================:::636:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/env.d/aodh.yml
**********
---
component_skel:
  aodh_api:
    belongs_to:
    - aodh_all
  aodh_listener:
    belongs_to:
    - aodh_all
  aodh_alarm_evaluator:
    belongs_to:
    - aodh_all
  aodh_alarm_notifier:
    belongs_to:
    - aodh_all

container_skel:
  aodh_container:
    belongs_to:
      - metering-alarm_containers
    contains:
      - aodh_api
      - aodh_listener
      - aodh_alarm_evaluator
      - aodh_alarm_notifier

physical_skel:
  metering-alarm_containers:
    belongs_to:
    - all_containers
  metering-alarm_hosts:
    belongs_to:
    - hosts

**********
DECISION===>: PASS
**********
=========================:::636:::END!!!=========================
=========================:::637:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/env.d/neutron.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

component_skel:
  neutron_agent:
    belongs_to:
      - neutron_all
  neutron_dhcp_agent:
    belongs_to:
      - neutron_all
  neutron_linuxbridge_agent:
    belongs_to:
      - neutron_all
  neutron_openvswitch_agent:
    belongs_to:
      - neutron_all
  neutron_metering_agent:
    belongs_to:
      - neutron_all
  neutron_l3_agent:
    belongs_to:
      - neutron_all
  neutron_lbaas_agent:
    belongs_to:
      - neutron_all
  neutron_bgp_dragent:
    belongs_to:
      - neutron_all
  neutron_metadata_agent:
    belongs_to:
      - neutron_all
  neutron_sriov_nic_agent:
    belongs_to:
      - neutron_all
  neutron_server:
    belongs_to:
      - neutron_all
  opendaylight:
    belongs_to:
      - neutron_all


container_skel:
  neutron_agents_container:
    belongs_to:
      - network_containers
    contains:
      - neutron_agent
      - neutron_bgp_dragent
      - neutron_dhcp_agent
      - neutron_l3_agent
      - neutron_lbaas_agent
      - neutron_linuxbridge_agent
      - neutron_metadata_agent
      - neutron_metering_agent
      - neutron_openvswitch_agent
      - neutron_sriov_nic_agent
    properties:
      is_metal: true
  neutron_server_container:
    belongs_to:
      - network_containers
    contains:
      - neutron_server
      - opendaylight


physical_skel:
  network_containers:
    belongs_to:
      - all_containers
  network_hosts:
    belongs_to:
      - hosts

**********
DECISION===>: PASS
**********
=========================:::637:::END!!!=========================
=========================:::638:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/env.d/rabbitmq.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

component_skel:
  rabbitmq:
    belongs_to:
      - rabbitmq_all


container_skel:
  rabbit_mq_container:
    belongs_to:
      - mq_containers
      - shared-infra_containers
    contains:
      - rabbitmq


physical_skel:
  mq_containers:
    belongs_to:
      - all_containers
  mq_hosts:
    belongs_to:
      - hosts

**********
DECISION===>: PASS
**********
=========================:::638:::END!!!=========================
=========================:::639:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/env.d/pkg_repo.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

component_skel:
  pkg_repo:
    belongs_to:
      - repo_all


container_skel:
  repo_container:
    belongs_to:
      - repo-infra_containers
    contains:
      - pkg_repo


physical_skel:
  repo-infra_hosts:
    belongs_to:
      - hosts
  repo-infra_containers:
    belongs_to:
      - all_containers

**********
DECISION===>: PASS
**********
=========================:::639:::END!!!=========================
=========================:::640:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/env.d/swift-remote.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

component_skel:
  swift_remote:
    belongs_to:
      - swift_remote_all


container_skel:
  swift_remote_container:
    belongs_to:
      - swift-remote_containers
    contains:
      - swift_remote
    properties:
      is_metal: true


physical_skel:
  swift-remote_containers:
    belongs_to:
      - remote_containers
  swift-remote_hosts:
    belongs_to:
      - remote

**********
DECISION===>: PASS
**********
=========================:::640:::END!!!=========================
=========================:::641:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/env.d/congress.yml
**********
---
# Copyright 2017, taseer94@gmail.com
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

component_skel:
  congress_server:
    belongs_to:
      - congress_all


container_skel:
  congress_container:
    belongs_to:
      - policy_containers
    contains:
      - congress_server


physical_skel:
  policy_containers:
    belongs_to:
      - all_containers
  policy_hosts:
    belongs_to:
      - hosts

**********
DECISION===>: PASS
**********
=========================:::641:::END!!!=========================
=========================:::642:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/env.d/gnocchi.yml
**********
---
# Copyright 2015, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

component_skel:
  gnocchi_api:
    belongs_to:
      - gnocchi_all
  gnocchi_metricd:
    belongs_to:
      - gnocchi_all

container_skel:
  gnocchi_container:
    belongs_to:
      - metrics_containers
    contains:
      - gnocchi_api
      - gnocchi_metricd

physical_skel:
  metrics_containers:
    belongs_to:
      - all_containers
  metrics_hosts:
    belongs_to:
      - hosts


**********
DECISION===>: PASS
**********
=========================:::642:::END!!!=========================
=========================:::643:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/env.d/heat.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

component_skel:
  heat_api:
    belongs_to:
      - heat_all
  heat_api_cfn:
    belongs_to:
      - heat_all
  heat_engine:
    belongs_to:
      - heat_all


container_skel:
  heat_api_container:
    belongs_to:
      - orchestration_containers
      - os-infra_containers
    contains:
      - heat_api_cfn
      - heat_api
      - heat_engine


physical_skel:
  orchestration_containers:
    belongs_to:
    - all_containers
  orchestration_hosts:
    belongs_to:
    - hosts

**********
DECISION===>: PASS
**********
=========================:::643:::END!!!=========================
=========================:::644:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/env.d/swift.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

component_skel:
  swift_proxy:
    belongs_to:
      - swift_all
  swift_acc:
    belongs_to:
      - swift_all
  swift_obj:
    belongs_to:
      - swift_all
  swift_cont:
    belongs_to:
      - swift_all


container_skel:
  swift_proxy_container:
    belongs_to:
      - swift-proxy_containers
    contains:
      - swift_proxy
  swift_acc_container:
    belongs_to:
      - swift_containers
    contains:
      - swift_acc
    properties:
      is_metal: true
  swift_obj_container:
    belongs_to:
      - swift_containers
    contains:
      - swift_obj
    properties:
      is_metal: true
  swift_cont_container:
    belongs_to:
      - swift_containers
    contains:
      - swift_cont
    properties:
      is_metal: true


physical_skel:
  swift_containers:
    belongs_to:
      - all_containers
  swift_hosts:
    belongs_to:
      - hosts
  swift-proxy_containers:
    belongs_to:
      - all_containers
  swift-proxy_hosts:
    belongs_to:
      - hosts

**********
DECISION===>: PASS
**********
=========================:::644:::END!!!=========================
=========================:::645:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/env.d/galera.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

component_skel:
  galera:
    belongs_to:
      - galera_all


container_skel:
  galera_container:
    belongs_to:
      - database_containers
      - shared-infra_containers
    contains:
      - galera


physical_skel:
  database_containers:
    belongs_to:
      - all_containers
  database_hosts:
    belongs_to:
      - hosts

**********
DECISION===>: PASS
**********
=========================:::645:::END!!!=========================
=========================:::646:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/env.d/designate.yml
**********
---
# Copyright 2016, Tata Consultancy Services
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

component_skel:
  designate_api:
    belongs_to:
      - designate_all
  designate_central:
    belongs_to:
      - designate_all
  designate_mdns:
    belongs_to:
      - designate_all
  designate_worker:
    belongs_to:
      - designate_all
  designate_producer:
    belongs_to:
      - designate_all
  designate_sink:
    belongs_to:
      - designate_all

container_skel:
  designate_container:
    belongs_to:
      - dnsaas_containers
    contains:
      - designate_api
      - designate_central
      - designate_mdns
      - designate_worker
      - designate_producer
      - designate_sink

physical_skel:
  dnsaas_containers:
    belongs_to:
      - all_containers
  dnsaas_hosts:
    belongs_to:
      - hosts

**********
DECISION===>: PASS
**********
=========================:::646:::END!!!=========================
=========================:::647:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/env.d/ceilometer.yml
**********
---
component_skel:
  ceilometer_agent_compute:
    belongs_to:
    - ceilometer_all
  ceilometer_agent_central:
    belongs_to:
    - ceilometer_all
  ceilometer_agent_notification:
    belongs_to:
    - ceilometer_all

container_skel:
  ceilometer_central_container:
    belongs_to:
      - metering-infra_containers
    contains:
      - ceilometer_agent_central
      - ceilometer_agent_notification
  metering-compute_container:
    belongs_to:
    - metering-compute_containers
    contains:
    - ceilometer_agent_compute
    properties:
      is_metal: true

physical_skel:
  metering-compute_containers:
    belongs_to:
    - all_containers
  metering-compute_hosts:
    belongs_to:
    - hosts
  metering-infra_containers:
    belongs_to:
    - all_containers
  metering-infra_hosts:
    belongs_to:
    - hosts

**********
DECISION===>: PASS
**********
=========================:::647:::END!!!=========================
=========================:::648:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/env.d/unbound.yml
**********
---
# Copyright 2016, Logan Vig <logan2211@gmail.com>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

component_skel:
  unbound:
    belongs_to:
      - unbound_all

container_skel:
  unbound_container:
    belongs_to:
      - unbound_containers
    contains:
      - unbound

physical_skel:
  unbound_containers:
    belongs_to:
      - all_containers
  unbound_hosts:
    belongs_to:
      - hosts

**********
DECISION===>: PASS
**********
=========================:::648:::END!!!=========================
=========================:::649:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/env.d/horizon.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

component_skel:
  horizon:
    belongs_to:
      - horizon_all


container_skel:
  horizon_container:
    belongs_to:
      - dashboard_containers
      - os-infra_containers
    contains:
      - horizon


physical_skel:
  dashboard_containers:
    belongs_to:
    - all_containers
  dashboard_hosts:
    belongs_to:
    - hosts

**********
DECISION===>: PASS
**********
=========================:::649:::END!!!=========================
=========================:::650:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/env.d/tacker.yml
**********
---
# Copyright 2017, SUSE Linux GmbH
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

component_skel:
  tacker_server:
    belongs_to:
      - tacker_all


container_skel:
  tacker_container:
    belongs_to:
      - mano_containers
    contains:
      - tacker_server


physical_skel:
  mano_containers:
    belongs_to:
    - all_containers
  mano_hosts:
    belongs_to:
    - hosts

**********
DECISION===>: PASS
**********
=========================:::650:::END!!!=========================
=========================:::651:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/env.d/blazar.yml
**********
---
# Copyright 2018, taseer94@gmail.com
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

component_skel:
  blazar_api:
    belongs_to:
      - blazar_all
  blazar_manager:
    belongs_to:
      - blazar_all


container_skel:
  blazar_container:
    belongs_to:
      - reservation_containers
    contains:
      - blazar_api
      - blazar_manager

physical_skel:
  reservation_containers:
    belongs_to:
      - all_containers
  reservation_hosts:
    belongs_to:
      - hosts

**********
DECISION===>: PASS
**********
=========================:::651:::END!!!=========================
=========================:::652:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/env.d/haproxy.yml
**********
---
# Copyright 2015, Jean-Philippe Evrard <jean-philippe@evrard.me>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

component_skel:
  haproxy:
    belongs_to:
      # This is a meta group of a given component type.
      - haproxy_all

container_skel:
  haproxy_container:
    belongs_to:
      - haproxy_containers
    contains:
      - haproxy
    properties:
      is_metal: true

physical_skel:
  haproxy_containers:
    belongs_to:
      - all_containers
  haproxy_hosts:
    belongs_to:
      - hosts

**********
DECISION===>: PASS
**********
=========================:::652:::END!!!=========================
=========================:::653:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/env.d/magnum.yml
**********
---
# Copyright 2016 Internet Solutions (Pty) Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# (c) 2016 Donovan Francesco <donovan.francesco@is.co.za>
# (c) 2016 Paul Stevens <paul.stevens@is.co.za>

component_skel:
  magnum:
    belongs_to:
      - magnum_all

container_skel:
  magnum_container:
    belongs_to:
      - magnum-infra_containers
    contains:
      - magnum

physical_skel:
  magnum-infra_containers:
    belongs_to:
      - all_containers
  magnum-infra_hosts:
    belongs_to:
      - hosts

**********
DECISION===>: PASS
**********
=========================:::653:::END!!!=========================
=========================:::654:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/env.d/trove.yml
**********
---
# Copyright 2016 Internet Solutions (Pty) Ltd
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# (c) 2016 Donovan Francesco <donovan.francesco@is.co.za>
# (c) 2016 Paul Stevens <paul.stevens@is.co.za>

component_skel:
  trove_api:
    belongs_to:
      - trove_all
  trove_conductor:
    belongs_to:
      - trove_all
  trove_taskmanager:
    belongs_to:
      - trove_all


container_skel:
  trove_api_container:
    belongs_to:
      - trove-infra_containers
    contains:
      - trove_api
      - trove_conductor
      - trove_taskmanager


physical_skel:
  trove-infra_containers:
    belongs_to:
      - all_containers
  trove-infra_hosts:
    belongs_to:
      - hosts

**********
DECISION===>: PASS
**********
=========================:::654:::END!!!=========================
=========================:::655:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/env.d/rsyslog.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

component_skel:
  rsyslog:
    belongs_to:
      - rsyslog_all


container_skel:
  rsyslog_container:
    belongs_to:
      - log_containers
    contains:
      - rsyslog


physical_skel:
  log_containers:
    belongs_to:
      - all_containers
  log_hosts:
    belongs_to:
      - hosts

**********
DECISION===>: PASS
**********
=========================:::655:::END!!!=========================
=========================:::656:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/env.d/keystone.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

component_skel:
  keystone:
    belongs_to:
      - keystone_all


container_skel:
  keystone_container:
    belongs_to:
      - identity_containers
    contains:
      - keystone


physical_skel:
  identity_containers:
    belongs_to:
      - all_containers
  identity_hosts:
    belongs_to:
      - hosts

**********
DECISION===>: PASS
**********
=========================:::656:::END!!!=========================
=========================:::657:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/env.d/ceph.yml
**********
---
# Copyright 2016, Logan Vig <logan2211@gmail.com>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

component_skel:
  ceph-mon:
    belongs_to:
      - ceph_all
  ceph-osd:
    belongs_to:
      - ceph_all
  ceph-rgw:
    belongs_to:
      - ceph_all

container_skel:
  ceph-mon_container:
    belongs_to:
      - ceph-mon_containers
    contains:
      - ceph-mon
  ceph-osd_container:
    belongs_to:
      - ceph-osd_containers
    contains:
      - ceph-osd
    properties:
      is_metal: true
  ceph-rgw_container:
    belongs_to:
      - ceph-rgw_containers
    contains:
      - ceph-rgw

physical_skel:
  ceph-mon_containers:
    belongs_to:
      - all_containers
  ceph-mon_hosts:
    belongs_to:
      - hosts
  ceph-osd_containers:
    belongs_to:
      - all_containers
  ceph-osd_hosts:
    belongs_to:
      - hosts
  ceph-rgw_containers:
    belongs_to:
      - all_containers
  ceph-rgw_hosts:
    belongs_to:
      - hosts

**********
DECISION===>: PASS
**********
=========================:::657:::END!!!=========================
=========================:::658:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/env.d/shared-infra.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

physical_skel:
  shared-infra_containers:
    belongs_to:
      - all_containers
  shared-infra_hosts:
    belongs_to:
      - hosts

**********
DECISION===>: PASS
**********
=========================:::658:::END!!!=========================
=========================:::659:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/env.d/etcd.yml
**********
---
# Copyright 2017, Logan Vig <logan2211@gmail.com>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

component_skel:
  etcd:
    belongs_to:
      - etcd_all

container_skel:
  etcd_container:
    belongs_to:
      - etcd_containers
    contains:
      - etcd

physical_skel:
  etcd_containers:
    belongs_to:
      - all_containers
  etcd_hosts:
    belongs_to:
      - hosts

**********
DECISION===>: PASS
**********
=========================:::659:::END!!!=========================
=========================:::660:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/env.d/ironic.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


component_skel:
  ironic_api:
    belongs_to:
      - ironic_all
  ironic_conductor:
    belongs_to:
      - ironic_all
  ironic_server:
    belongs_to:
      - ironic_all
      - ironic_servers
  ironic_compute:
    belongs_to:
      - nova_all


container_skel:
  ironic_api_container:
    belongs_to:
      - ironic-infra_containers
    contains:
      - ironic_api
      - ironic_conductor
  ironic_server_container:
    belongs_to:
      - ironic-server_containers
    contains:
      - ironic_server
    properties:
      is_metal: true
  ironic_compute_container:
    belongs_to:
      - ironic-compute_containers
    contains:
      - ironic_compute
      - nova_compute
      - nova_scheduler
      - neutron_linuxbridge_agent
      - neutron_openvswitch_agent
    properties:
      is_metal: false


physical_skel:
  ironic-infra_containers:
    belongs_to:
      - all_containers
  ironic-infra_hosts:
    belongs_to:
      - hosts
  ironic-server_containers:
    belongs_to:
      - all_containers
  ironic-server_hosts:
    belongs_to:
      - hosts
  ironic-compute_containers:
    belongs_to:
      - all_containers
  ironic-compute_hosts:
    belongs_to:
      - hosts

**********
DECISION===>: PASS
**********
=========================:::660:::END!!!=========================
=========================:::661:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/env.d/memcache.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

component_skel:
  memcached:
    belongs_to:
      - memcached_all


container_skel:
  memcached_container:
    belongs_to:
      - memcaching_containers
      - shared-infra_containers
    contains:
      - memcached


physical_skel:
  memcaching_containers:
    belongs_to:
      - all_containers
  memcaching_hosts:
    belongs_to:
      - hosts

**********
DECISION===>: PASS
**********
=========================:::661:::END!!!=========================
=========================:::662:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/env.d/utility.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

component_skel:
  utility:
    belongs_to:
      - utility_all


container_skel:
  utility_container:
    belongs_to:
      - operator_containers
      - shared-infra_containers
    contains:
      - utility


physical_skel:
  operator_containers:
    belongs_to:
      - all_containers
  operator_hosts:
    belongs_to:
      - hosts

**********
DECISION===>: PASS
**********
=========================:::662:::END!!!=========================
=========================:::663:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/host_vars/localhost/cinder.yml
**********
---
# Copyright 2017, Logan Vig <logan2211@gmail.com>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# If there are Swift hosts in the environment, then enable cinder backups to it
# cinder and tempest groups consume this
cinder_service_backup_program_enabled: "{{ groups['swift_all'] is defined and groups['swift_all'] | length > 0 }}"

**********
DECISION===>: PASS
**********
=========================:::663:::END!!!=========================
=========================:::664:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/host_vars/localhost/nova.yml
**********
---
# Copyright 2017, Logan Vig <logan2211@gmail.com>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Enable barbican if the group is populated. repo and nova use this.
nova_barbican_enabled: "{{ (groups['barbican_all'] is defined) and (groups['barbican_all'] | length > 0) }}"

**********
DECISION===>: PASS
**********
=========================:::664:::END!!!=========================
=========================:::665:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/host_vars/localhost/neutron.yml
**********
---
# Copyright 2017, Logan Vig <logan2211@gmail.com>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Nova and Neutron roles both consume these
# If there are any Designate hosts in the environment, then enable its usage
neutron_designate_enabled: "{{ (groups['designate_all'] is defined) and (groups['designate_all'] | length > 0) }}"
# If there are any Ceilometer hosts in the environment, then enable its usage
neutron_ceilometer_enabled: "{{ (groups['ceilometer_all'] is defined) and (groups['ceilometer_all'] | length > 0) }}"

**********
DECISION===>: PASS
**********
=========================:::665:::END!!!=========================
=========================:::666:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/host_vars/localhost/swift.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

swift_proxy_port: 8080
swift_system_user_name: swift
swift_system_shell: /bin/bash
swift_system_comment: swift system user
swift_system_home_folder: "/var/lib/{{ swift_system_user_name }}"

**********
DECISION===>: Hardcoded Secret
**********
=========================:::666:::END!!!=========================
=========================:::667:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/host_vars/localhost/ceilometer.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

ceilometer_service_user_name: ceilometer
ceilometer_service_tenant_name: service

**********
DECISION===>: hardcoded secret
**********
=========================:::667:::END!!!=========================
=========================:::668:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/inventory/host_vars/localhost/unbound.yml
**********
---
# Copyright 2017, Logan Vig <logan2211@gmail.com>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

resolvconf_enabled: "{{ groups['unbound'] is defined and groups['unbound'] | length > 0 }}"
unbound_physical_hosts: >-
  {{ groups[resolvconf_resolver_group] |
    map('extract', hostvars, 'physical_host') |
    select('defined') |
    list
  }}

**********
DECISION===>: PASS
**********
=========================:::668:::END!!!=========================
=========================:::669:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/scripts/get-ansible-role-requirements.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Clone the role ansible-role-requirements
  hosts: localhost
  connection: local
  user: root
  tasks:
    - name: Remove target directory if required
      file:
        path: "{{ item.path | default(role_path_default) }}/{{ item.name | default(item.src | basename) }}"
        state: absent
      when:
        - item.scm == "git" or item.scm is undefined
        - "(item.path | default(role_path_default) ~ '/' ~ item.name | default(item.src | basename) ~ '/.git') is not directory"
      with_items: "{{ required_roles }}"

    - name: Ensure the default roles directory exists
      file:
        path: "{{ role_path_default }}"
        state: directory

    - name: Use Zuul provided sources in Zuul environment
      block:
        - name: Set Zuul sources path
          set_fact:
            zuul_src_path: "{{ lookup('env', 'ZUUL_SRC_PATH') }}"
        - name: Check the Zuul src dir for cloned roles
          stat:
            path: "{{ zuul_src_path }}/{{ item.src.split('/')[-3:] | join('/') }}"
            get_attributes: no
            get_checksum: no
            get_mime: no
          register: zuul_roles
          when:
            - item.scm == "git" or item.scm is undefined
          with_items: "{{ required_roles }}"
        - name: Link the Zuul provided roles
          file:
            src: "{{ zuul_src_path }}/{{ item.item.src.split('/')[-3:] | join('/') }}"
            dest: "{{ item.item.path | default(role_path_default) }}/{{ item.item.name | default(item.item.src | basename) }}"
            state: link
            owner: root
            group: root
          with_items: "{{ zuul_roles.results
                          | selectattr('stat.exists')
                          | list }}"
      when:
        - "lookup('env', 'ZUUL_SRC_PATH') != ''"

    - name: Clone git repos (with git)
      git:
        repo: "{{ item.src }}"
        dest: "{{ item.path | default(role_path_default) }}/{{ item.name | default(item.src | basename) }}"
        version: "{{ item.version | default('master') }}"
        refspec: "{{ item.refspec | default(omit) }}"
        depth: "{{ item.depth | default('10') }}"
        update: true
        force: true
      when:
        - item.scm == "git" or item.scm is undefined
      with_items: "{{ (zuul_roles.results | default([]) |
                       selectattr('stat', 'defined') |
                       rejectattr('stat.exists') |
                       map(attribute='item') | list)
                      | default(required_roles, True) }}"
      register: git_clone
      until: git_clone is success
      retries: "{{ git_clone_retries }}"
      delay: "{{ git_clone_retry_delay }}"

  vars:
    required_roles: "{{ lookup('file', role_file) | from_yaml }}"
    role_file: "{{ playbook_dir }}/../ansible-role-requirements.yml"
    role_path_default: '/etc/ansible/roles'
    git_clone_retries: 2
    git_clone_retry_delay: 5

**********
DECISION===>: hardcoded secret
**********
=========================:::669:::END!!!=========================
=========================:::670:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/scripts/upgrade-utilities/playbooks/ceph-galaxy-removal.yml
**********
---
# Copyright 2017, Logan Vig <logan2211@gmail.com>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Remove the ceph galaxy named roles
  hosts: localhost
  gather_facts: true
  user: root
  tasks:
    # These roles used to be named using galaxy format due to the naming of the
    # meta dependencies in ceph-ansible. Now the meta dependencies no longer
    # exist so we are free to name them more consistently with the rest of
    # OSA's roles.
    - name: Remove ceph galaxy named roles if found
      file:
        path: "/etc/ansible/roles/{{ item }}"
        state: "absent"
      with_items:
        - ceph.ceph-docker-common
        - ceph.ceph-common

**********
DECISION===>: PASS
**********
=========================:::670:::END!!!=========================
=========================:::671:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/scripts/upgrade-utilities/playbooks/ansible_fact_cleanup.yml
**********
---
# Copyright 2015, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Ansible fact cleanup
  hosts: localhost
  connection: local
  gather_facts: false
  user: root
  tasks:
    - name: Remove any of the stored facts ansible may already have
      command: "{{ upgrade_scripts }}/ansible_fact_cleanup.sh"
  vars:
      upgrade_scripts: "{{ playbook_dir }}/../scripts"
      ansible_python_interpreter: "/usr/bin/python"

**********
DECISION===>: hardcoded secret
**********
=========================:::671:::END!!!=========================
=========================:::672:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/scripts/upgrade-utilities/playbooks/memcached-flush.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Memcached cache flush
  hosts: memcached
  gather_facts: true
  user: root
  vars:
    memcached_conf_dest:
      debian: "/etc/memcached.conf"
      redhat: "/etc/sysconfig/memcached"
    netcat_package:
      debian: "netcat-openbsd"
      redhat: "nmap-ncat"
  tasks:
    - name: Ensuring netcat is installed
      package:
        name: "{{ netcat_package.get(ansible_os_family | lower) }}"
        state: present
    - name: Flush all of the cache in memcached
      shell: |
        echo 'flush_all' | nc $(awk '/^\-l/ {print $2}' {{ memcached_conf_dest.get(ansible_os_family | lower) }} | awk -F, '{ print $1 }') $(awk '/^\-p/ {print $2}' {{ memcached_conf_dest.get(ansible_os_family | lower) }} )

**********
DECISION===>: hardcoded secret
**********
=========================:::672:::END!!!=========================
=========================:::673:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/scripts/upgrade-utilities/playbooks/pip-conf-removal.yml
**********
---
# Copyright 2015, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Remove pip.conf if found
  hosts: hosts:repo_all
  gather_facts: true
  user: root
  tasks:
    - name: Remove pip.conf
      file:
        path: "{{ ansible_env.HOME }}/.pip/pip.conf"
        state: "absent"

**********
DECISION===>: hardcoded secret
**********
=========================:::673:::END!!!=========================
=========================:::674:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/scripts/upgrade-utilities/playbooks/user-secrets-adjustment.yml
**********
---
# Copyright 2015, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: User secrets adjustments
  hosts: localhost
  connection: local
  gather_facts: false
  user: root
  tasks:
    - name: Read example user secrets file
      shell: "grep '^[a-zA-Z]' {{ playbook_dir }}/../../../etc/openstack_deploy/user_secrets.yml"
      register: secrets

    - name: Rename changed secrets
      lineinfile:
        dest: "/etc/openstack_deploy/{{ _osa_secrets_file_name }}"
        regexp: "^{{ item.old_name }}: (.*)$"
        line: "{{ item.new_name }}: \\1"
        backrefs: yes
      with_items:
        - old_name: "keystone_rabbitmq_password"
          new_name: "keystone_oslomsg_rpc_password"
        - old_name: "ceilometer_rabbitmq_password"
          new_name: "ceilometer_oslomsg_rpc_password"
        - old_name: "aodh_rabbitmq_password"
          new_name: "aodh_oslomsg_rpc_password"
        - old_name: "cinder_rabbitmq_password"
          new_name: "cinder_oslomsg_rpc_password"
        - old_name: "glance_rabbitmq_password"
          new_name: "glance_oslomsg_rpc_password"
        - old_name: "heat_rabbitmq_password"
          new_name: "heat_oslomsg_rpc_password"
        - old_name: "ironic_rabbitmq_password"
          new_name: "ironic_oslomsg_rpc_password"
        - old_name: "neutron_rabbitmq_password"
          new_name: "neutron_oslomsg_rpc_password"
        - old_name: "nova_rabbitmq_password"
          new_name: "nova_oslomsg_rpc_password"
        - old_name: "octavia_rabbitmq_password"
          new_name: "octavia_oslomsg_rpc_password"
        - old_name: "sahara_rabbitmq_password"
          new_name: "sahara_oslomsg_rpc_password"
        - old_name: "swift_rabbitmq_telemetry_password"
          new_name: "swift_oslomsg_notify_password"
        - old_name: "magnum_rabbitmq_password"
          new_name: "magnum_oslomsg_rpc_password"
        - old_name: "trove_rabbitmq_password"
          new_name: "trove_oslomsg_rpc_password"
        - old_name: "barbican_rabbitmq_password"
          new_name: "barbican_oslomsg_rpc_password"
        - old_name: "designate_rabbitmq_password"
          new_name: "designate_oslomsg_rpc_password"
        - old_name: "tacker_rabbitmq_password"
          new_name: "tacker_oslomsg_rpc_password"

    - name: Read user secrets file
      shell: "grep '^[a-zA-Z]' /etc/openstack_deploy/{{ _osa_secrets_file_name }}"
      register: user_secrets

    - name: Add missing secrets
      lineinfile:
        dest: "/etc/openstack_deploy/{{ _osa_secrets_file_name }}"
        line: "{{ item }}"
      with_items: "{{ secrets.stdout_lines }}"
      when:
        - "user_secrets.stdout.find(item) == -1"

    - name: Generate new secrets
      shell: "/opt/ansible-runtime/bin/python {{ playbook_dir }}/../../../scripts/pw-token-gen.py --file /etc/openstack_deploy/{{ _osa_secrets_file_name }}"
  vars:
    _osa_secrets_file_name: "{{ osa_secrets_file_name | default('user_secrets.yml') }}"
    ansible_python_interpreter: "/usr/bin/python"

**********
DECISION===>: hardcoded secret
**********
=========================:::674:::END!!!=========================
=========================:::675:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/scripts/upgrade-utilities/playbooks/galera-cluster-rolling-restart.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Gracefully restart mariadb/galera cluster
  hosts: galera_all
  serial: 1
  max_fail_percentage: 0
  gather_facts: false
  user: root
  tasks:
    - name: Stop mariadb
      service:
        name: mysql
        state: stopped
      retries: 5
      delay: 10

    - name: Stop container
      lxc_container:
        name: "{{ inventory_hostname }}"
        state: "stopped"
      delegate_to: "{{ physical_host }}"

    - name: Start container
      lxc_container:
        name: "{{ inventory_hostname }}"
        state: "started"
      delegate_to: "{{ physical_host }}"

  post_tasks:
    - name: Wait for mariadb port 3306 to be available
      wait_for:
        port: "3306"
        host: "{{ ansible_host | default(ansible_ssh_host | default(inventory_hostname)) }}"
      retries: 10
      delay: 10
      delegate_to: "{{ groups['utility_all'][0] }}"

    - name: Check that WSREP is ready and Synced
      shell: "/usr/bin/mysqladmin extended-status | egrep '(wsrep_local_state_comment)'"
      register: mysql_ready
      until:
        - mysql_ready.rc == 0
        - (mysql_ready.stdout).find("Synced") != -1
      retries: 60
      delay: 1

**********
DECISION===>: hardcoded secret
**********
=========================:::675:::END!!!=========================
=========================:::676:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/scripts/upgrade-utilities/playbooks/deploy-config-changes.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Upgrade environment/inventory configuration
  hosts: localhost
  connection: local
  gather_facts: false
  user: root
  vars:
      upgrade_scripts: "{{ playbook_dir }}/../scripts"
      repo_root_dir: "{{ playbook_dir }}/../../../"
      source_series: "rocky"
      ansible_python_interpreter: "/usr/bin/python"
  tasks:
      - name: Create an old copy of openstack_deploy
        copy:
          src: "/etc/openstack_deploy/"
          dest: "/etc/openstack_deploy.{{ source_series | upper }}/"
          force: no

      - name: Check if there is a user-space env.d directory
        stat:
          path: "/etc/openstack_deploy/env.d"
        register: _envd_dir

      - block:

        - name: Retrieve differences
          shell: rsync -avun "{{ repo_root_dir }}/inventory/env.d/" "/etc/openstack_deploy/env.d/" | grep "yml$"
          failed_when: false
          register: diff_result

        - name: Copy new env.d files into place
          copy:
              src: "{{ repo_root_dir }}/inventory/env.d/{{ item }}"
              dest: "/etc/openstack_deploy/env.d/{{ item }}"
              force: no
          with_items:
              - "{{ diff_result.stdout_lines }}"
          when: diff_result.stdout != ""

        - name: Check result for emptiness
          debug: msg="All new env.d files are placed in the stock repo. No new changes"
          when: diff_result.stdout == ""

        when: _envd_dir.stat.exists | bool

      - name: Update OpenStack variable names
        command: "{{ upgrade_scripts }}/migrate_openstack_vars.py {{ item }} {{ (item | basename)[:-4] }}"
        args:
            creates: "/etc/openstack_deploy.{{ source_series | upper }}/VARS_MIGRATED_{{ (item | basename)[:-4] }}"
        with_fileglob:
          - "/etc/openstack_deploy/user_*.yml"

      - name: Write vars required for upgrade
        lineinfile:
          dest: /etc/openstack_deploy/user_variables.yml
          regexp: "{{ item.regexp | default('^' + item.key) }}"
          line: "{{ item.key }}: {{ item.value }}"
          backrefs: "{{ item.backrefs | default('no') }}"
          state: present
        with_items:
          # Replace "10.0" with "10.1" within galera_repo_url
          - key: "galera_repo_url"
            regexp: '^galera_repo_url: (https?://.*10)\.0(.*)$'
            value: '\1.1\2'
            backrefs: yes
          # Replace "10.0" with "10.1" within galera_client_apt_repo_url
          - key: "galera_client_apt_repo_url"
            regexp: '^galera_client_apt_repo_url: (https?://.*10)\.0(.*)$'
            value: '\1.1\2'
            backrefs: yes
          # Replace "10.0" with "10.1" within galera_client_repo_url
          - key: "galera_client_repo_url"
            regexp: '^galera_client_repo_url: (https?://.*10)\.0(.*)$'
            value: '\1.1\2'
            backrefs: yes

**********
DECISION===>: PASS
**********
=========================:::676:::END!!!=========================
=========================:::677:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/zuul.d/playbooks/run.yml
**********
- hosts: all
  tasks:
    - name: Set the Zuul sources path
      set_fact:
        zuul_src_path: "{{ ansible_user_dir }}/src"

    - name: Set current test repo (cross-repo)
      set_fact:
        current_test_repo: "git.openstack.org/{{ osa_test_repo }}"
      when:
        - osa_test_repo is defined

    - name: Set current test repo (non-cross-repo)
      set_fact:
        current_test_repo: "{{ zuul.project.canonical_name }}"
      when:
        - osa_test_repo is not defined

    - name: Run gate-check-commit.sh script
      become: yes
      become_user: root
      command: "scripts/gate-check-commit.sh {{ scenario }} {{ action }} {{ install_method }}"
      args:
        chdir: "src/{{ current_test_repo }}"
      environment:
        # ZUUL_SRC_PATH is used by tests/get-ansible-role-requirements to
        # where the CI provided git sources were cloned.
        ZUUL_SRC_PATH: "{{ zuul_src_path }}"
        ANSIBLE_PACKAGE: "{{ ansible_package | default('') }}"

**********
DECISION===>: PASS
**********
=========================:::677:::END!!!=========================
=========================:::678:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/zuul.d/playbooks/post.yml
**********
---
# Copyright 2017, Logan Vig <logan2211@gmail.com>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- hosts: all
  tasks:
    - name: Set current test repo (cross-repo)
      set_fact:
        current_test_repo: "git.openstack.org/{{ osa_test_repo }}"
      when:
        - osa_test_repo is defined

    - name: Set current test repo (non-cross-repo)
      set_fact:
        current_test_repo: "{{ zuul.project.canonical_name }}"
      when:
        - osa_test_repo is not defined

    - name: Run log collection script
      shell: |
        source scripts/scripts-library.sh
        gate_job_exit_tasks
      become: yes
      become_user: root
      args:
        chdir: "{{ ansible_user_dir }}/src/{{ current_test_repo }}"
        executable: /bin/bash
      environment:
        # ZUUL_PROJECT is used by the log collection functions to enable
        # log collection configuration specific to OpenStack CI
        ZUUL_PROJECT: "{{ zuul.project.short_name }}"
        TEST_EXIT_CODE: "{{ zuul_success | lower }}"
        GATE_LOG_DIR: "{{ ansible_user_dir }}/src/{{ current_test_repo }}/logs"

    - name: Check whether a logs folder exists
      stat:
        path: "{{ ansible_user_dir }}/src/{{ current_test_repo }}/logs"
        get_attributes: no
        get_checksum: no
        get_md5: no
        get_mime: no
      register: logs_folder

    - name: Copy logs back to the executor
      synchronize:
        src: "{{ ansible_user_dir }}/src/{{ current_test_repo }}/logs"
        dest: "{{ zuul.executor.log_root }}/"
        mode: pull
        rsync_opts:
          - "--quiet"
      when:
        - logs_folder.stat is defined
        - logs_folder.stat.exists | bool

**********
DECISION===>: PASS
**********
=========================:::678:::END!!!=========================
=========================:::679:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/releasenotes/notes/inventory-arg-change-7d882d024187eb15.yaml
**********
---
upgrade:
  - The ``dynamic_inventory.py`` script now takes a
    ``--config`` argument rather than a ``--file``
    argument.
deprecations:
  - The ``dynamic_inventory.py`` script now takes a
    ``--config`` argument rather than a ``--file``
    argument.

**********
DECISION===>: PASS
**********
=========================:::679:::END!!!=========================
=========================:::680:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/releasenotes/notes/inventory_host_containers_naming-d1f42a0c91d68154.yaml
**********
---
fixes:
  - Changed the way we name host containers groups in
    dynamic_inventory.py for a hostname from
    hostname_containers to hostname-host_containers to
    prevent failing in the case where containers groups
    have the same name as host containers when choosing
    hostnames inspired from containers group names. This
    change fixes the following bugs
    https://bugs.launchpad.net/openstack-ansible/+bug/1512883 and
    https://bugs.launchpad.net/openstack-ansible/+bug/1528953.

**********
DECISION===>: PASS
**********
=========================:::680:::END!!!=========================
=========================:::681:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/releasenotes/notes/run-playbooks-refactor-c89400feb692cd91.yaml
**********
---
other:
  - The ``run-playbooks.sh`` script has been refactored to run all playbooks
    using our core tool set and run order. The refactor work updates the old
    special case script to a tool that simply runs the integrated playbooks
    as they've been designed.

**********
DECISION===>: PASS
**********
=========================:::681:::END!!!=========================
=========================:::682:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/releasenotes/notes/add-keystone-admin-roles-setting-83198a721c64ee3c.yaml
**********
---
features:
  - The ``horizon_keystone_admin_roles`` variable is added to support the
    ``OPENSTACK_KEYSTONE_ADMIN_ROLES`` list in the horizon_local_settings.py
    file.

**********
DECISION===>: PASS
**********
=========================:::682:::END!!!=========================
=========================:::683:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/releasenotes/notes/configurable_inventory_group-9f5b193221b7006d.yaml
**********
---
features:
  - The ``rabbitmq_server`` now supports a configurable inventory
    host group. Deployers can override the ``rabbitmq_host_group`` variable
    if they wish to use the role to create additional RabbitMQ clusters
    on a custom host group.


**********
DECISION===>: PASS
**********
=========================:::683:::END!!!=========================
=========================:::684:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/releasenotes/notes/inventory-main-function-arguments-8c43e4c7175937d3.yaml
**********
---
deprecations:
  - The ``main`` function in ``dynamic_inventory.py`` now
    takes named arguments instead of dictionary. This is to support
    future code changes that will move construction logic into
    separate files.

**********
DECISION===>: PASS
**********
=========================:::684:::END!!!=========================
=========================:::685:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/releasenotes/notes/ansible-role-fetch-mode-cd163877e96d504a.yaml
**********
---
features:
  - A new option has been added to ``bootstrap-ansible.sh`` to set
    the role fetch mode. The environment variable ``ANSIBLE_ROLE_FETCH_MODE``
    sets how role dependencies are resolved.

**********
DECISION===>: PASS
**********
=========================:::685:::END!!!=========================
=========================:::686:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/releasenotes/notes/inventory-debug-flag-ead0ae2a2a1d7b90.yaml
**********
---
features:
  - A new debug flag has been added to ``dynamic_inventory.py``. This
    should make it easier to understand what's happening with the inventory
    script, and provide a way to gather output for more detailed bug reports.
    See the developer docs for more details.

**********
DECISION===>: PASS
**********
=========================:::686:::END!!!=========================
=========================:::687:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/releasenotes/notes/non_inventory_hosts-c0fa4c185a01e78b.yaml
**********
---
features:
  - HAProxy services that use backend nodes that are not
    in the Ansible inventory can now be specified manually
    by setting ``haproxy_backend_nodes`` to a list of
    ``name`` and ``ip_addr`` settings.

**********
DECISION===>: PASS
**********
=========================:::687:::END!!!=========================
=========================:::688:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/releasenotes/notes/os-tempest-roles-cead45b2cd38811f.yaml
**********
---
features:
  - A new variable, ``tempest_roles``, has been added to the
    os_tempest role allowing users to define keystone roles
    to be during tempest testing.

**********
DECISION===>: PASS
**********
=========================:::688:::END!!!=========================
=========================:::689:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/releasenotes/notes/inventory-python-imports-c967b20e64b43758.yaml
**********
---
other:
  - The inventory generation code has been switched to use standard Python
    packaging tools. For most, this should not be a visible change. However,
    running the dynamic inventory script on a local development environment
    should now be called via ``python dynamic_inventory.py``.

**********
DECISION===>: PASS
**********
=========================:::689:::END!!!=========================
=========================:::690:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/releasenotes/notes/inventory-check-groups-1cc245cdcbb999df.yaml
**********
---
features:
  - The ``--check`` parameter for ``dynamic_inventory.py`` will now raise
    warnings if there are any groups defined in the user configuration that
    are not also found in the environment definition.

**********
DECISION===>: PASS
**********
=========================:::690:::END!!!=========================
=========================:::691:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/releasenotes/notes/combine_pip_roles-ba524dbaa601e1a1.yaml
**********
---
features:
  - The pip_install role can now configure pip to be locked down to the
    repository built by OpenStack-Ansible. To enable the lockdown
    configuration, deployers may set ``pip_lock_to_internal_repo`` to
    ``true`` in ``/etc/openstack_deploy/user_variables.yml``.

**********
DECISION===>: PASS
**********
=========================:::691:::END!!!=========================
=========================:::692:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/releasenotes/notes/ceph-galaxy-roles-1a0a13be026e45d8.yaml
**********
---
upgrade:
  - The ceph-ansible common roles are no longer namespaced with a galaxy-style
    '.' (ie. ``ceph.ceph-common`` is now cloned as ``ceph-common``), due to a
    change in the way upstream meta dependencies are handled in the ceph roles.
    The roles will be cloned according to the new naming, and an upgrade
    playbook ``ceph-galaxy-removal.yml`` has been added to clean up the stale
    galaxy-named roles.

**********
DECISION===>: PASS
**********
=========================:::692:::END!!!=========================
=========================:::693:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/releasenotes/notes/db-create-in-playbooks-6fb8232da53fe1e1.yaml
**********
---
features:
  - All of the database and database user creates have
    been removed from the roles into the playbooks. This
    allows the roles to be tested independently of the
    deployed database and also allows the roles to be
    used independently of infrastructure choices made by
    the integrated OSA project.

**********
DECISION===>: PASS
**********
=========================:::693:::END!!!=========================
=========================:::694:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible/releasenotes/notes/security-playbook-hosts-var-a9b71f3dbcda2cad.yaml
**********
---
features:
  - The security-hardening playbook hosts target can now be filtered using the
    ``security_host_group`` var.

**********
DECISION===>: PASS
**********
=========================:::694:::END!!!=========================
=========================:::695:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/multi-node-aio/playbooks/save-vms.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in witing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Save VM disk images for re-use
  hosts: vm_hosts
  gather_facts: "{{ gather_facts | default(true) }}"
  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - save-vms
  tasks:
    - name: Get info about existing virt storage pools
      virt_pool:
        command: info
      register: _virt_pools

    - name: Get info about existing VM's
      virt:
        command: list_vms
      register: _virt_list

    - name: Shut down all running VM's
      virt:
        name: "{{ item }}"
        command: shutdown
      failed_when: false
      with_items: "{{ _virt_list.list_vms }}"

    - name: Wait for shut down to complete
      command: |
        virsh domstate {{ item }}
      register: _vm_shutdown
      until: _vm_shutdown.stdout.find('shut off') != -1
      retries: 5
      delay: 60
      with_items: "{{ _virt_list.list_vms }}"

    - name: Commit, compress and save VM Disk Image and prepare new copy-on-write image
      shell: |
        if [[ -e {{ item }}.img ]]; then
          if [[ -e {{ item }}-base.img ]]; then
            qemu-img commit {{ item }}.img
          else
            qemu-img convert -O qcow2 -c {{ item }}.img {{ item }}-base.img
            qemu-img create -f qcow2 -b {{ item }}-base.img {{ item }}.img
          fi
          exit 2
        fi
      args:
        executable: /bin/bash
        chdir: "{{ _virt_pools.pools.default.path | default('/data/images') }}"
      with_items: "{{ _virt_list.list_vms }}"
      register: _save_disk_image
      changed_when: _save_disk_image.rc == 2
      failed_when: _save_disk_image.rc not in [0, 2]

    - name: Save VM definition
      copy:
        src: "/etc/libvirt/qemu/{{ item }}.xml"
        dest: "{{ _virt_pools.pools.default.path | default('/data/images') }}/"
        remote_src: yes
      with_items: "{{ _virt_list.list_vms }}"

    - name: Get the current SHA1 for the manifest
      command: "git rev-parse HEAD"
      args:
        chdir: "{{ playbook_dir }}"
      register: _repo_sha
      changed_when: false

    - name: Add pip freeze results to the data
      shell: "pip --disable-pip-version-check freeze > pip-requirements.txt"
      args:
        executable: /bin/bash
        chdir: "{{ _virt_pools.pools.default.path | default('/data/images') }}"
      changed_when: false

    - name: Find all the files for the manifest
      find:
        paths: "{{ _virt_pools.pools.default.path | default('/data/images') }}"
        patterns:
          - "*-base.img"
          - "*.xml"
          - "*.txt"
        get_checksum: yes
      register: _manifest_files

    - name: Prepare the manifest file content
      set_fact:
        _manifest_content: >-
          { 'openstack-ansible-ops_SHA1': '{{ _repo_sha.stdout }}', 'files': {{ _manifest_files.files | json_query('[*].{path: path, checksum: checksum}') | sort(attribute='path') }} }

    - name: Write out the manifest file
      copy:
        content: "{{ _manifest_content | to_nice_json }}"
        dest: "{{ _virt_pools.pools.default.path | default('/data/images') }}/manifest.json"

**********
DECISION===>: PASS
**********
=========================:::695:::END!!!=========================
=========================:::696:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/multi-node-aio/playbooks/deploy-osa.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in witing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Setup deploy host
  hosts: deploy_hosts
  gather_facts: "{{ gather_facts | default(true) }}"
  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - deploy-osa
  tasks:
    - name: Gather variables for each operating system
      include_vars: "{{ item }}"
      with_first_found:
        - "{{ playbook_dir }}/vars/{{ ansible_distribution | lower }}-{{ ansible_distribution_version | lower }}.yml"
        - "{{ playbook_dir }}/vars/{{ ansible_distribution | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
        - "{{ playbook_dir }}/vars/{{ ansible_os_family | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
        - "{{ playbook_dir }}/vars/{{ ansible_distribution | lower }}.yml"
        - "{{ playbook_dir }}/vars/{{ ansible_os_family | lower }}.yml"
      tags:
        - always

    # Example read-write git checkout from github
    - name: Get OSA
      git:
        repo: "{{ osa_repo | default('https://git.openstack.org/openstack/openstack-ansible') }}"
        dest: /opt/openstack-ansible
        version: "{{ osa_branch | default('master') }}"
      when:
        - pre_config_osa | default(true) | bool
        - clone_osa | default(true) | bool

    - name: Create OSA configuration directory
      file:
        path: "/etc/openstack_deploy"
        state: directory
        owner: "root"
        group: "root"
        mode: "0755"
      when:
        - pre_config_osa | default(true) | bool

    - name: Copy default config files and directories
      shell: >-
        rsync
        -av
        --include='*.yml'
        --include='*/'
        --exclude='*'
        /opt/openstack-ansible/etc/openstack_deploy/
        /etc/openstack_deploy/
      args:
        executable: /bin/bash
        chdir: /opt/openstack-ansible
        warn: no
      when:
        - pre_config_osa | default(true) | bool

    - name: Drop osa config
      template:
        src: "osa/openstack_user_config.yml"
        dest: /etc/openstack_deploy/openstack_user_config.yml
        mode: "0644"
        owner: root
        group: root
      when:
        - pre_config_osa | default(true) | bool

    - name: Drop osa user variables
      template:
        src: "osa/user_mnaio_variables.yml"
        dest: /etc/openstack_deploy/user_mnaio_variables.yml
        mode: "0644"
        owner: root
        group: root
      when:
        - pre_config_osa | default(true) | bool

    - name: Drop config to disable serial throttle settings
      template:
        src: "osa/user_unserial_variables.yml"
        dest: /etc/openstack_deploy/user_unserial_variables.yml
        mode: "0644"
        owner: root
        group: root
      when:
        - pre_config_osa | default(true) | bool
        - osa_disable_serial | default(false) | bool

    - name: Drop ELK env.d config
      template:
        src: "osa/elk-envd.yml"
        dest: "/etc/openstack_deploy/env.d/elk.yml"
        mode: "0644"
        owner: root
        group: root
      when:
        - pre_config_osa | default(true) | bool
        - osa_enable_elk_metrics | default(false) | bool

    - name: Drop ELK conf.d config
      template:
        src: "osa/elk-confd.yml"
        dest: "/etc/openstack_deploy/conf.d/elk.yml"
        mode: "0644"
        owner: root
        group: root
      when:
        - pre_config_osa | default(true) | bool
        - osa_enable_elk_metrics | default(false) | bool

    - name: Ensure the user_variables file is populated
      lineinfile:
        path: /etc/openstack_deploy/user_variables.yml
        regexp: '^{{ item }}'
        line: '{{ item }}'
        create: yes
      with_items:
        - '---'
        - 'osa_ops_mnaio: true'
      when:
        - pre_config_osa | default(true) | bool

    - name: Bootstrap ansible
      command: bash ./scripts/bootstrap-ansible.sh
      args:
        chdir: /opt/openstack-ansible
      when:
        - run_osa | default(true) | bool

    - name: Create passwords
      command: ./scripts/pw-token-gen.py --file /etc/openstack_deploy/user_secrets.yml
      args:
        chdir: /opt/openstack-ansible
      when:
        - run_osa | default(true) | bool

    - name: Config Tmux
      lineinfile:
        path: /root/.tmux.conf
        regexp: '^set-option'
        line: 'set-option -g history-limit 20000'
        owner: root
        group: root
        mode: 0644
        create: yes

    - name: Run OSA
      command: "{{ item }}"
      args:
        chdir: /opt/openstack-ansible/playbooks
      with_items:
        - tmux new-session -d -s build-osa
        - tmux select-pane -t 0
        - tmux send-keys "ulimit -n 10240" C-m
        - tmux send-keys "openstack-ansible setup-hosts.yml setup-infrastructure.yml setup-openstack.yml" C-m
      when:
        - inventory_hostname == groups['deploy_hosts'][0]
        - run_osa | default(true) | bool

    - name: Finished notice
      debug:
        msg: |
          OSA deploy running. To check on the state of this deployment, login
          to the {{ groups['deploy_hosts'][0] }} VM and attach to the "build-osa" tmux session.
      when:
        - run_osa | default(true) | bool

**********
DECISION===>: Hardcoded Secret
**********
=========================:::696:::END!!!=========================
=========================:::697:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/multi-node-aio/playbooks/deploy-acng.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in witing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Gather facts
  hosts: pxe_hosts
  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - deploy-acng
  tasks:
    - name: Gather variables for each operating system
      include_vars: "{{ item }}"
      with_first_found:
        - "{{ playbook_dir }}/vars/{{ ansible_distribution | lower }}-{{ ansible_distribution_version | lower }}.yml"
        - "{{ playbook_dir }}/vars/{{ ansible_distribution | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
        - "{{ playbook_dir }}/vars/{{ ansible_os_family | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
        - "{{ playbook_dir }}/vars/{{ ansible_distribution | lower }}.yml"
        - "{{ playbook_dir }}/vars/{{ ansible_os_family | lower }}.yml"
      tags:
        - always

    - name: Install repo caching server packages
      package:
        name: "{{ mnaio_pkg_cache_server_distro_packages }}"
        state: "latest"
        update_cache: yes
        cache_valid_time: 600
      register: _install_host_packages
      until: _install_host_packages is success
      retries: 3
      delay: 15

    - name: Create cache directory
      file:
        path: "/var/www/pkg-cache"
        state: "directory"
        owner: "apt-cacher-ng"
        group: "www-data"
        mode: "02775"

    - name: Stat the cache path
      stat:
        path: /var/cache/apt-cacher-ng
      register: acs

    - name: Remove cacher directory if its a directory
      file:
        path: "/var/cache/apt-cacher-ng"
        state: "absent"
      when:
        - acs.stat.isdir is defined and acs.stat.isdir

    - name: Link cacher to the repo path
      file:
        src: "/var/www/pkg-cache"
        dest: "/var/cache/apt-cacher-ng"
        state: "link"

    - name: create yum merged mirror list
      shell: |
        curl https://www.centos.org/download/full-mirrorlist.csv | sed 's/^.*"http:/http:/' | sed 's/".*$//' | grep ^http >/etc/apt-cacher-ng/centos_mirrors
        echo "http://mirror.centos.org/centos/" >>/etc/apt-cacher-ng/centos_mirrors

    - name: override default ubuntu mirror list
      copy:
        dest: /etc/apt-cacher-ng/backends_ubuntu
        mode: 0644
        owner: root
        group: root
        content: 'http://archive.ubuntu.com/ubuntu/'
      notify:
        - reload acng

    - name: Drop acng.conf
      template:
        src: "pxe/acng.conf.j2"
        dest: "/etc/apt-cacher-ng/acng.conf"
      notify:
        - reload acng

  handlers:
    - name: reload acng
      service:
        name: "apt-cacher-ng"
        state: restarted
        enabled: yes

**********
DECISION===>: PASS
**********
=========================:::697:::END!!!=========================
=========================:::698:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/multi-node-aio/playbooks/setup-host.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in witing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Gather facts
  hosts: vm_hosts
  gather_facts: "{{ gather_facts | default(true) }}"
  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - setup-host
  tasks:
    - name: Check for a supported Operating System
      assert:
        that:
          - (ansible_distribution == 'Ubuntu' and ansible_distribution_release == 'xenial') or
            (ansible_distribution == 'Ubuntu' and ansible_distribution_release == 'bionic')
        msg: >-
          The only supported host platforms for this tooling are Ubuntu 16.04 LTS (Xenial)
          and Ubuntu 18.04 LTS (Bionic). Patches to add support for other distributions are
          most welcome.

    - name: Gather variables for each operating system
      include_vars: "{{ item }}"
      with_first_found:
        - "{{ playbook_dir }}/vars/{{ ansible_distribution | lower }}-{{ ansible_distribution_version | lower }}.yml"
        - "{{ playbook_dir }}/vars/{{ ansible_distribution | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
        - "{{ playbook_dir }}/vars/{{ ansible_os_family | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
        - "{{ playbook_dir }}/vars/{{ ansible_distribution | lower }}.yml"
        - "{{ playbook_dir }}/vars/{{ ansible_os_family | lower }}.yml"
      tags:
        - always

    - name: Install pre-requisite host distro packages
      package:
        name: "{{ mnaio_host_required_distro_packages }}"
        state: "latest"
        update_cache: yes
        cache_valid_time: 600
      register: _install_required_host_packages
      until: _install_required_host_packages is success
      retries: 3
      delay: 15
      when:
        - "mnaio_host_required_distro_packages | length > 0"

    - name: Add/Remove/Update apt repositories
      apt_repository:
        repo: "{{ repo.repo }}"
        state: "{{ repo.state | default('present') }}"
        filename: "{{ repo.filename | default(omit) }}"
        update_cache: no
      with_items: "{{ mnaio_host_package_repos }}"
      loop_control:
        loop_var: repo
      register: _add_apt_repo
      when:
        - "ansible_os_family == 'Debian'"
        - "mnaio_host_package_repos | length > 0"
        - "(repo.condition | default(True)) | bool"

    - name: Update apt cache
      apt:
        update_cache: yes
      register: _update_apt_cache
      until: _update_apt_cache is success
      retries: 3
      delay: 15
      when:
        - "ansible_os_family == 'Debian'"
        - "_add_apt_repo is changed"

    - name: Install host distro packages
      package:
        name: "{{ mnaio_host_distro_packages }}"
        state: "latest"
        update_cache: yes
        cache_valid_time: 600
      register: _install_host_packages
      until: _install_host_packages is success
      retries: 3
      delay: 15

    - name: Get version of libguestfs
      shell: >-
        guestfish --version | awk '{print $2}'
      changed_when: false
      register: _libguestfs_version

    # See:
    # https://bugzilla.redhat.com/show_bug.cgi?id=1591617
    # https://bugs.launchpad.net/ubuntu/+source/libguestfs/+bug/1615337
    - name: Apply workaround for older versions to make guestfish work
      shell: |
        echo dash > /usr/lib/x86_64-linux-gnu/guestfs/supermin.d/zz-dash-packages
        rm -rf /var/tmp/.guestfs*
      when:
        - "{{ (_libguestfs_version.stdout is version('1.38.1', '<')) or
              ((_libguestfs_version.stdout is version('1.39.0', '>=')) and
               (_libguestfs_version.stdout is version('1.39.1', '<'))) }}"

    # If the host had already installed kvm_intel.ko without nested=1, then
    # re-load it now, honoring whatever is in qemu-system-x86.modprobe
    # Exit codes:
    # 0 - Nested virt already enabled
    # 1 - Error
    # 2 - Nested virt enabled by task (should show task as changed)
    # 3 - Nested virt not available
    - name: Ensure that nested virtualization is enabled (if it is available)
      shell: |
        INTEL_NESTED=/sys/module/kvm_intel/parameters/nested
        if grep -q kvm_intel /proc/modules; then
          echo "Intel CPU found. Checking for nested virtualization capabilities."
          if [ -f ${INTEL_NESTED} ]; then
            echo "Nested virtualization capability found. Checking if it is enabled."
            v=$(cat ${INTEL_NESTED})
            if [ "x${v}" != "xY" ]; then
              echo "Nested virtualization not enabled. Enabling it now."
              rmmod kvm_intel && modprobe kvm_intel
              exit 2
            else
              echo "Nested virtualization already enabled."
            fi
          else
            echo "Nested virtualization capability not found."
            exit 3
          fi
        else
          echo "Intel CPU not found."
          exit 3
        fi
      args:
        executable: /bin/bash
      register: _enable_nested_virt
      changed_when: _enable_nested_virt.rc == 2
      failed_when: _enable_nested_virt.rc not in [0, 2, 3]

    - name: Ensure root has a .ssh directory
      file:
        path: /root/.ssh
        state: directory
        owner: root
        group: root
        mode: 0700

    - name: Create ssh key pair for root
      user:
        name: root
        generate_ssh_key: yes
        ssh_key_bits: 2048
        ssh_key_file: /root/.ssh/id_rsa

    - name: Get root public key
      command: cat /root/.ssh/id_rsa.pub
      register: public_key_get
      changed_when: false

    - name: Set key facts
      set_fact:
        root_public_key: "{{ public_key_get.stdout }}"

    - name: Ensure root can ssh to localhost
      authorized_key:
        user: "root"
        key: "{{ root_public_key }}"

    - name: Setup SSH client to disable strict host key checks
      lineinfile:
        path: /etc/ssh/ssh_config
        regexp: "^.*StrictHostKeyChecking.*$"
        line: "    StrictHostKeyChecking no"
        insertafter: "^Host \\*$"
        state: present

    - name: Setup SSH client to have a non-persistant known hosts file
      lineinfile:
        path: /etc/ssh/ssh_config
        regexp: "^.*UserKnownHostsFile.*$"
        line: "    UserKnownHostsFile=/dev/null"
        insertafter: "^Host \\*$"
        state: present

    - name: Setup SSH client to disable DNS host key checks
      lineinfile:
        path: /etc/ssh/ssh_config
        regexp: "^.*VerifyHostKeyDNS.*$"
        line: "    VerifyHostKeyDNS no"
        insertafter: "^Host \\*$"
        state: present

    - name: Add sysctl options
      sysctl:
        name: net.ipv4.ip_forward
        value: 1
        sysctl_set: yes
        state: present
        reload: yes
        sysctl_file: /etc/sysctl.conf

    - name: Get gateway interface
      shell: "/sbin/ip r g 1 | awk '{print $5}'"
      register: gw_iface

    - set_fact:
        masquerade_interface: "{{ gw_iface.stdout.strip() }}"

    - name: Add IPtables rules
      iptables:
        table: "{{ item.table | default(omit) }}"
        chain: "{{ item.chain | default(omit) }}"
        in_interface: "{{ item.in_interface | default(omit) }}"
        out_interface: "{{ item.out_interface | default(omit) }}"
        source: "{{ item.source | default(omit) }}"
        destination: "{{ item.destination | default(omit) }}"
        protocol: "{{ item.protocol | default(omit) }}"
        match: "{{ item.match | default(omit) }}"
        destination_port: "{{ item.destination_port | default(omit) }}"
        jump: "{{ item.jump | default(omit) }}"
        to_ports: "{{ item.to_ports | default(omit) }}"
      with_items: "{{ mnaio_host_iptables_rules }}"

    # These rules are added manually due to bugs in the iptables module.
    - name: Add IPtables rules
      shell: |
        if ! iptables -w -t {{ item.table }} -C {{ item.rule }};then
          iptables -w -t {{ item.table }} -I {{ item.rule }}
        fi
      with_items:
        - table: 'nat'
          rule: 'POSTROUTING -s 10.0.2.0/22 ! -d 10.0.2.0/22 -j MASQUERADE'
        - table: 'mangle'
          rule: 'POSTROUTING -s 10.0.2.0/22 -o vm-br-dhcp -p udp -m udp --dport 68 -j CHECKSUM --checksum-fill'
        - table: 'mangle'
          rule: 'POSTROUTING -s 10.0.2.0/22 -o vm-br-dhcp -p udp -m udp --dport 68 -j CHECKSUM --checksum-fill'

    - name: Add IPtables pre-routing rules to allow external access to VMs
      shell: |
        if ! iptables -w -t nat -C PREROUTING -p tcp -d {{ ansible_default_ipv4.address }} --dport {{ item.host_port }} -j DNAT --to {{ item.vm_ip }}:{{ item.vm_port }};then
          iptables -w -t nat -I PREROUTING -p tcp -d {{ ansible_default_ipv4.address }} --dport {{ item.host_port }} -j DNAT --to {{ item.vm_ip }}:{{ item.vm_port }}
        fi
      with_items: "{{ mnaio_host_iptables_prerouting_ports }}"
      when: config_prerouting | default(false) | bool

    - name: Start netfilter persistent
      service:
        name: "{{ mnaio_host_iptables_service }}"
        state: started
        enabled: yes
      when:
        - ansible_distribution | lower == 'ubuntu'

    - name: Deploy systemd-networkd bridge devices
      template:
        src: "mnaio_host/systemd-networkd-bridges-netdev.j2"
        dest: /etc/systemd/network/{{ item.value.iface }}.netdev
        mode: "0644"
        owner: root
        group: root
      with_dict:
        - "{{ mnaio_host_networks }}"
      register: mnaio_bridges

    - name: Deploy systemd-networkd bridge networks
      template:
        src: "mnaio_host/systemd-networkd-bridges-network.j2"
        dest: /etc/systemd/network/{{ item.value.iface }}.network
        mode: "0644"
        owner: root
        group: root
      with_dict:
        - "{{ mnaio_host_networks }}"
      register: mnaio_bridges

    - name: Restart the systemd-networkd daemon to load new networks
      systemd:
        name: systemd-networkd
        daemon_reload: yes
        state: restarted
      when:
        - mnaio_bridges is changed

    - name: Disable default virt network
      virt_net:
        name: "default"
        state: inactive

    - name: Prevent default virt network autostart
      virt_net:
        name: "default"
        autostart: no

    - name: Define virt network(s)
      virt_net:
        name: "{{ item.value.iface }}"
        state: present
        xml: "{{ lookup('template', 'kvm/libvirt-network-template.xml.j2') }}"
      with_dict: "{{ mnaio_host_networks }}"

    - name: Set virt network(s) to active
      virt_net:
        name: "{{ item.value.iface }}"
        state: active
      with_dict: "{{ mnaio_host_networks }}"

    - name: Set virt network(s) to autostart
      virt_net:
        name: "{{ item.value.iface }}"
        autostart: yes
      with_dict: "{{ mnaio_host_networks }}"

    - name: Locate the largest writable data disk if mnaio_data_disk is not set
      shell: >
        lsblk -brndo NAME,TYPE,FSTYPE,RO,SIZE | awk '/d[b-z]+ disk +0/{ if ($4>m){m=$4; d=$1}}; END{print d}'
      register: lsblk
      changed_when: false
      when:
        - mnaio_data_disk is undefined

    - name: Setup the data disk partition
      parted:
        device: "/dev/{{ mnaio_data_disk | default(lsblk.stdout) }}"
        label: gpt
        number: 1
        name: data1
        state: present
      register: _add_partition

    - name: Prepare the data disk file system
      filesystem:
        fstype: ext4
        dev: "/dev/{{ mnaio_data_disk | default(lsblk.stdout) }}1"
        force: yes
      when:
        - _add_partition is changed

    - name: Mount the data disk
      mount:
        src: "/dev/{{ mnaio_data_disk | default(lsblk.stdout) }}1"
        path: /data
        state: mounted
        fstype: ext4

    - name: Create the images directory
      file:
        path: /data/images
        owner: root
        group: root
        mode: "0755"
        state: directory

    - name: Define the default virt storage pool
      virt_pool:
        name: default
        state: present
        xml: |
          <pool type='dir'>
            <name>default</name>
            <target>
              <path>/data/images</path>
              <permissions>
                <mode>0755</mode>
                <owner>0</owner>
                <group>0</group>
              </permissions>
            </target>
          </pool>

    - name: Set default virt storage pool to active
      virt_pool:
        name: default
        state: active

    - name: Set default virt storage pool to autostart
      virt_pool:
        name: default
        autostart: yes

    - name: Load virtio kernel modules
      shell: |
        for mod in $(find /lib/modules/$(uname -r) -type f -name 'virtio*.ko'); do
          module=$(echo $(basename $mod) | sed 's/\.ko//g')
          modprobe ${module}
          if ! grep ${module} /etc/modules; then
            echo ${module} | tee -a /etc/modules
          fi
        done

    - name: Wait for guest capabilities to appear
      command: "virsh capabilities"
      register: virsh_caps
      until: "'<guest>' in virsh_caps.stdout"
      retries: 6
      delay: 10

**********
DECISION===>: Suspicious Comment, hardcoded Secret
**********
=========================:::698:::END!!!=========================
=========================:::699:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/multi-node-aio/playbooks/site.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in witing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- import_playbook: setup-host.yml
  when:
    - setup_host | default(true) | bool

- import_playbook: deploy-acng.yml
  when:
    - setup_pxeboot | default(true) | bool

- import_playbook: deploy-pxe.yml
  when:
    - setup_pxeboot | default(true) | bool

- import_playbook: deploy-dhcp.yml
  when:
    - setup_dhcpd | default(true) | bool

- import_playbook: deploy-vms.yml
  when:
    - deploy_vms | default(true) | bool

- import_playbook: deploy-osa.yml
  when:
    - deploy_osa | default(true) | bool

- import_playbook: deploy-elk.yml
  when:
    - deploy_elk | default(false) | bool

- import_playbook: openstack-service-setup.yml
  when:
    - configure_openstack | default(true) | bool

**********
DECISION===>: PASS
**********
=========================:::699:::END!!!=========================
=========================:::700:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/multi-node-aio/playbooks/openstack-image-setup.yml
**********
---
# These tasks are included in openstack-service-setup.yml playbook and
# are repeated for each required image file.

- name: Download system image file
  get_url:
    url: "{{ item.url }}"
    dest: "/tmp/os_image_{{ item.name }}"
    timeout: 600   # big files might take a while to download
  register: download_result
  until: download_result|succeeded
  retries: 10
  delay: 15
  failed_when: download_result is failure

- name: Install system image
  os_image:
    endpoint_type: internal
    cloud: default
    state: present
    is_public: true
    name: "{{ item.name }}"
    filename: "/tmp/os_image_{{ item.name }}"
    disk_format: "{{ item.format }}"

- name: Clean up temp file
  file:
    path: "/tmp/os_image_{{ item.name }}"
    state: absent


**********
DECISION===>: PASS
**********
=========================:::700:::END!!!=========================
=========================:::701:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/multi-node-aio/playbooks/deploy-pxe.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in witing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Gather facts
  hosts: pxe_hosts
  gather_facts: "{{ gather_facts | default(true) }}"
  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - deploy-pxe
  tasks:
    - name: Gather variables for each operating system
      include_vars: "{{ item }}"
      with_first_found:
        - "{{ playbook_dir }}/vars/{{ ansible_distribution | lower }}-{{ ansible_distribution_version | lower }}.yml"
        - "{{ playbook_dir }}/vars/{{ ansible_distribution | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
        - "{{ playbook_dir }}/vars/{{ ansible_os_family | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
        - "{{ playbook_dir }}/vars/{{ ansible_distribution | lower }}.yml"
        - "{{ playbook_dir }}/vars/{{ ansible_os_family | lower }}.yml"
      tags:
        - always

    - name: Install host distro packages
      package:
        name: "{{ mnaio_pxe_distro_packages }}"
        state: "latest"
        update_cache: yes
        cache_valid_time: 600
      register: _install_host_packages
      until: _install_host_packages is success
      retries: 3
      delay: 15

    - name: Create base directories
      file:
        path: "{{ item }}"
        state: directory
        owner: "root"
        group: "root"
        mode: "0755"
      with_items:
        - /var/www/pxe
        - /var/www/pxe/configs
        - /var/www/pxe/images
        - /var/www/pxe/networking
        - /var/www/pxe/scripts
        - /var/www/pxe/templates
        - /var/lib/tftpboot
        - /var/lib/tftpboot/ipxe

    - name: Get root public key
      command: cat /root/.ssh/id_rsa.pub
      register: public_key_get
      changed_when: false
      when:
        - tftp_ssh_key is undefined

    - name: Set key facts
      set_fact:
        tftp_ssh_key: "{{ public_key_get.stdout }}"
      when:
        - tftp_ssh_key is undefined

    - name: Drop NGINX config
      copy:
        src: "pxe/sites-enabled.default"
        dest: /etc/nginx/sites-enabled/default
        mode: "0644"
        owner: root
        group: root
      notify:
        - restart nginx

    - name: Drop tftp-hpa configs
      template:
        src: "pxe/tftp/tftp-hpa"
        dest: /etc/default/tftpd-hpa
        mode: "0644"
        owner: root
        group: root
      notify:
        - restart tftp-hpa

    - name: Download iPXE
      get_url:
        url: "{{ ipxe_kernel_base_url }}/{{ item.filename }}"
        dest: "/var/lib/tftpboot/{{ item.dest }}"
        tmp_dest: /tmp/
      with_items:
        - { filename: 'ipxe.lkrn', dest: 'ipxe.lkrn' }
        - { filename: 'ipxe.efi', dest: 'ipxe.efi' }
        - { filename: 'undionly.kpxe', dest: 'undionly.kpxe' }

    - name: Drop ipxe default menu
      template:
        src: "pxe/tftp/boot.ipxe.j2"
        dest: "/var/lib/tftpboot/boot.ipxe"
        mode: "0644"
        owner: root
        group: root

    - name: Register network_setup fact
      set_fact:
        network_setup: "{{ images[default_vm_image]['network_setup'] }}"

# ENI Block
    - name: Generate guest networking scripts for /e/n/i family
      template:
        src: "pxe/configs/eni/vm-bridges.cfg.j2"
        dest: /var/www/pxe/networking/{{ hostvars[item]['server_hostname'] }}-bridges.cfg
        mode: "0644"
        owner: root
        group: root
      with_items: "{{ groups['pxe_servers'] }}"
      when: network_setup | lower == "eni"

    - name: Generate post-install network scripts for /e/n/i family
      template:
        src: "pxe/configs/eni/{{ item.src }}"
        dest: /var/www/pxe/{{ item.dir }}/{{ item.dest }}
        mode: "0644"
        owner: root
        group: root
      with_items:
        - src: basic-interface.cfg
          dest: basic-debian-interface.cfg
          dir: networking
        - src: eni-post-network-script.sh.j2
          dest: vm-post-network-script.sh
          dir: scripts
      when: network_setup | lower == "eni"

# Systemd-networkd Block
    - name: Generate vm network scripts for systemd-network family
      template:
        src: "pxe/configs/systemd-networkd/systemd-network.sh.j2"
        dest: /var/www/pxe/networking/{{ hostvars[item]['server_hostname'] }}-systemd-network.sh
        mode: "0644"
        owner: root
        group: root
      with_items: "{{ groups['pxe_servers'] }}"
      when: network_setup | lower == "systemd-networkd"

    - name: Generate post-install networks scripts for systemd-networkd family
      template:
        src: "pxe/configs/systemd-networkd/systemd-networkd-post-network-script.sh.j2"
        dest: /var/www/pxe/scripts/vm-post-network-script.sh
        mode: "0644"
        owner: root
        group: root
      with_items: "{{ groups['pxe_servers'] }}"
      when: network_setup | lower == "systemd-networkd"

# Debian Block
    - name: Generate post-install scripts for Debian family
      template:
        src: "pxe/configs/debian/vm-post-install-script.sh.j2"
        dest: /var/www/pxe/scripts/vm-post-install-debian-script.sh
        mode: "0644"
        owner: root
        group: root
      with_items: "{{ groups['pxe_servers'] }}"
      when: images[default_vm_image]['image_type'] | lower == "debian"

# Redhat Block
    - name: Generate post-install scripts for RedHat family
      template:
        src: "pxe/configs/redhat/vm-post-install-script.sh.j2"
        dest: /var/www/pxe/scripts/vm-post-install-redhat-script.sh
        mode: "0644"
        owner: root
        group: root
      with_items: "{{ groups['pxe_servers'] }}"
      when: images[default_vm_image]['image_type'] | lower == "redhat"

    - name: tftp configs for servers
      template:
        src: "pxe/tftp/boot.ipxe.macaddr.j2"
        dest: "/var/lib/tftpboot/ipxe/{{ hostvars[item]['server_mac_address'] | replace(':', '-') | lower }}"
        mode: "0644"
        owner: root
        group: root
      with_items: "{{ groups['pxe_servers'] }}"

    - name: Preseeds for pxe vm
      template:
        src: "pxe/configs/{{ images[default_vm_image]['image_type'] | lower }}/vm.config.j2"
        dest: /var/www/pxe/configs/vm.config
        mode: "0644"
        owner: root
        group: root
      with_dict: "{{ images }}"

    - name: Preseeds for pxe vm-compute
      template:
        src: "pxe/configs/{{ images[default_vm_image]['image_type'] | lower }}/vm-compute.config.j2"
        dest: /var/www/pxe/configs/vm-compute.config
        mode: "0644"
        owner: root
        group: root
      with_dict: "{{ images }}"

    - name: Ensure permissions are correct
      file:
        dest: "{{ item }}"
        mode: u=rwX,g=rX,o=rX
        recurse: yes
      with_items:
        - "/var/lib/tftpboot"
        - "/var/www/pxe"

  handlers:
    - name: restart nginx
      service:
        name: "nginx"
        state: restarted
        enabled: yes

    - name: restart tftp-hpa
      service:
        name: "tftpd-hpa"
        state: restarted
        enabled: yes

    - name: restart inetd
      service:
        name: "inetutils-inetd"
        state: restarted
        enabled: yes

**********
DECISION===>: hardcoded secret
**********
=========================:::701:::END!!!=========================
=========================:::702:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/multi-node-aio/playbooks/deploy-elk.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in witing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Setup deploy host
  hosts: deploy_hosts
  gather_facts: "{{ gather_facts | default(true) }}"
  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - deploy-osa
  tasks:
    - name: Gather variables for each operating system
      include_vars: "{{ item }}"
      with_first_found:
        - "{{ playbook_dir }}/vars/{{ ansible_distribution | lower }}-{{ ansible_distribution_version | lower }}.yml"
        - "{{ playbook_dir }}/vars/{{ ansible_distribution | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
        - "{{ playbook_dir }}/vars/{{ ansible_os_family | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
        - "{{ playbook_dir }}/vars/{{ ansible_distribution | lower }}.yml"
        - "{{ playbook_dir }}/vars/{{ ansible_os_family | lower }}.yml"
      tags:
        - always

    # Example read-write git checkout from github
    - name: Get openstack-ansible-ops
      git:
        repo: "{{ os_ops_repo | default('https://git.openstack.org/openstack/openstack-ansible-ops') }}"
        dest: /opt/openstack-ansible-ops
        version: "{{ os_ops_branch | default('master') }}"
        force: true
      when:
        - deploy_elk | default(false) | bool

    - name: Run ELK
      command: "{{ item }}"
      args:
        chdir: /opt/openstack-ansible-ops/elk_metrics_6x
      with_items:
        - tmux attach -t build-osa
        - tmux select-pane -t 0
        - tmux send-keys "cd /opt/openstack-ansible-ops/elk_metrics_6x" C-m
        - tmux send-keys "openstack-ansible site.yml" C-m
      when:
        - inventory_hostname == groups['deploy_hosts'][0]
        - run_elk | default(false) | bool

    - name: Finished notice
      debug:
        msg: |
          ELK deploy running. To check on the state of this deployment, login
          to the {{ groups['deploy_hosts'][0] }} VM and attach to the "build-osa" tmux session.
      when:
        - run_elk | default(false) | bool

**********
DECISION===>: PASS
**********
=========================:::702:::END!!!=========================
=========================:::703:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/multi-node-aio/playbooks/vm-status.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in witing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Create vm_servers group
  hosts: localhost
  connection: local
  gather_facts: false
  tasks:
    - name: Create vm_servers group
      add_host:
        name: "{{ item }}"
        groups: vm_servers
      when:
        - (hostvars[item]['server_vm'] | default(false)) | bool
      with_items: "{{ groups['pxe_servers'] }}"

- name: VM Status
  hosts: vm_servers
  gather_facts: false
  tasks:
    - name: VM Connectivity Check
      block:
        - name: Wait for VM
          wait_for_connection:
            connect_timeout: 10
            sleep: 20
            timeout: "{{ vm_ssh_timeout }}"
      rescue:
        - name: Gather VM info (rescue)
          virt:
            command: status
            name: "{{ inventory_hostname }}"
          connection: local
          register: vm_info

        - name: Stop VM (rescue)
          virt:
            command: destroy
            name: "{{ inventory_hostname }}"
          connection: local
          when: vm_info.status == 'running'

        - name: Start VM (rescue)
          virt:
            command: start
            name: "{{ inventory_hostname }}"
          connection: local

        - name: Wait for VM (rescue)
          wait_for_connection:
            connect_timeout: 10
            sleep: 20
            timeout: "{{ vm_ssh_timeout }}"
          register: vm_rescue
          ignore_errors: true

        - name: Gather VM info 2nd pass (rescue)
          virt:
            command: status
            name: "{{ inventory_hostname }}"
          connection: local
          register: vm_info_2

        - name: Fail if VM still offline (rescue)
          fail:
            msg: "{{ inventory_hostname }} is not responding and cannot be rescued"
          when:
            - vm_info_2.status != 'running'
            - vm_rescue.failed == 'true'

- name: Refresh the inventory
  hosts: localhost
  connection: local
  gather_facts: false
  tasks:
    - name: Refresh the inventory
      meta: refresh_inventory

    - name: Create vm_servers group
      add_host:
        name: "{{ item }}"
        groups: vm_servers
      when:
        - (hostvars[item]['server_vm'] | default(false)) | bool
      with_items: "{{ groups['pxe_servers'] }}"

- name: Container Status
  hosts: all_containers
  gather_facts: false
  tasks:
    - name: Wait for container connectivity
      wait_for_connection:
        connect_timeout: 10
        delay: 3
        sleep: 20
        timeout: "{{ vm_ssh_timeout }}"

**********
DECISION===>: PASS
**********
=========================:::703:::END!!!=========================
=========================:::704:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/multi-node-aio/playbooks/deploy-vms.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in witing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Gather Facts for vm_hosts
  hosts: vm_hosts
  gather_facts: yes
  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - deploy-vms
  tasks:
    - name: Get info about existing virt storage pools
      virt_pool:
        command: info
      register: _virt_pools

    - name: Set virt_pools host fact
      set_fact:
        virt_pools: "{{ _virt_pools }}"

    - name: Get info about existing VM's
      virt:
        command: list_vms
      register: _virt_list

    - name: Stop all running VM's
      virt:
        name: "{{ item }}"
        command: destroy
      failed_when: false
      with_items: "{{ _virt_list.list_vms }}"

    - name: Delete any disk images related to running VM's
      file:
        path: "{{ _virt_pools.pools.default.path | default('/data/images') }}/{{ item }}.img"
        state: absent
      with_items: "{{ _virt_list.list_vms }}"

    - name: Undefine all running VM's
      virt:
        name: "{{ item }}"
        command: undefine
      failed_when: false
      with_items: "{{ _virt_list.list_vms }}"

    - name: Find existing base image files
      find:
        paths: "{{ _virt_pools.pools.default.path | default('/data/images') }}"
        patterns: '*-base.img'
      register: _base_images

    - name: Enable/disable vm_use_snapshot based on whether there are base image files
      set_fact:
        vm_use_snapshot: "{{ _base_images['matched'] > 0 }}"

    - name: Clean up base image files if they are not being used
      file:
        path: "{{ item.path }}"
        state: absent
      with_items: "{{ _base_images.files }}"
      when:
        - not (vm_use_snapshot | bool)


- name: Prepare VM storage
  hosts: pxe_servers
  gather_facts: no
  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - deploy-vms
  tasks:
    - name: Create VM Disk Image
      command: >-
        qemu-img create
        -f qcow2
        {% if hostvars[item]['vm_use_snapshot'] | bool %}
        -b {{ hostvars[item]['virt_pools'].pools.default.path | default('/data/images') }}/{{ server_hostname }}-base.img
        {% endif %}
        {{ hostvars[item]['virt_pools'].pools.default.path | default('/data/images') }}/{{ server_hostname }}.img
        {{ default_vm_storage }}m
      when:
        - server_vm | default(false) | bool
      delegate_to: "{{ item }}"
      with_items: "{{ groups['vm_hosts'] }}"


- name: Prepare file-based disk images
  hosts: vm_hosts
  gather_facts: yes
  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - deploy-vms
  tasks:
    # Note (odyssey4me):
    # This will only work on a host which has
    # libguestfs >= 1.35.2 and >= 1.34.1
    # Ubuntu bionic works, but xenial does not (even with UCA).
    # ref: https://bugs.launchpad.net/ubuntu/+source/libguestfs/+bug/1615337.
    - name: Prepare file-based disk images
      when:
        - vm_use_snapshot | bool
      block:
        - name: Inject the host ssh key into the VM disk image
          command: >-
            virt-sysprep
            --enable customize
            --ssh-inject root:file:/root/.ssh/id_rsa.pub
            --add {{ virt_pools.pools.default.path | default('/data/images') }}/{{ hostvars[item]['server_hostname'] }}.img
          when:
            - hostvars[item]['server_vm'] | default(false) | bool
          with_items: "{{ groups['pxe_servers'] }}"

        - name: Copy over prepare-image-galera.sh
          copy:
            src: kvm/prepare-image-galera.sh
            dest: /opt/prepare-image-galera.sh
            mode: "0755"

        - name: Prepare the galera containers for startup
          command: /opt/prepare-image-galera.sh
          register: _galera_prepare

        # guestfissh does not always give a return code which indicates
        # failure, so we look for our final stdout output as an indicator
        - name: Fail if the preparation script did not complete
          fail:
            msg: "The galera container preparation failed."
          when:
            - "'Image preparation completed.' not in _galera_prepare.stdout_lines"


- name: Prepare VM's
  hosts: pxe_servers
  gather_facts: no
  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - deploy-vms
  tasks:
    - name: Define the VM
      virt:
        name: "{{ server_hostname }}"
        command: define
        xml: >-
          {%- if hostvars[item]['vm_use_snapshot'] | bool %}
          {{ lookup('file', hostvars[item]['virt_pools'].pools.default.path | default('/data/images') ~ '/' ~ server_hostname ~ '.xml') }}
          {%- else %}
          {{ lookup('template', 'kvm/kvm-vm.xml.j2') }}
          {%- endif %}
      failed_when: false
      when:
        - server_vm | default(false) | bool
      delegate_to: "{{ item }}"
      with_items: "{{ groups['vm_hosts'] }}"

    - name: Get the VM xml
      virt:
        command: get_xml
        name: "{{ server_hostname }}"
      register: vm_xml
      when:
        - server_vm | default(false) | bool
      delegate_to: "{{ item }}"
      with_items: "{{ groups['vm_hosts'] }}"

    - name: Write the VM xml
      copy:
        content: "{{ item.1.get_xml }}"
        dest: "/etc/libvirt/qemu/{{ item.1.item }}.xml"
      when:
        - server_vm | default(false) | bool
      delegate_to: "{{ item.0 }}"
      with_nested:
        - "{{ groups['vm_hosts'] }}"
        - "{{ vm_xml.results }}"


- name: Start VM's
  hosts: vm_hosts
  gather_facts: "{{ gather_facts | default(true) }}"
  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - deploy-vms
  tasks:
    - name: Gather variables for each operating system
      include_vars: "{{ item }}"
      with_first_found:
        - "{{ playbook_dir }}/vars/{{ ansible_distribution | lower }}-{{ ansible_distribution_version | lower }}.yml"
        - "{{ playbook_dir }}/vars/{{ ansible_distribution | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
        - "{{ playbook_dir }}/vars/{{ ansible_os_family | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
        - "{{ playbook_dir }}/vars/{{ ansible_distribution | lower }}.yml"
        - "{{ playbook_dir }}/vars/{{ ansible_os_family | lower }}.yml"
      tags:
        - always

    - name: Start VM
      virt:
        name: "{{ hostvars[item]['server_hostname'] }}"
        command: start
        state: running
      failed_when: false
      when:
        - hostvars[item]['server_vm'] | default(false) | bool
      with_items: "{{ groups['pxe_servers'] }}"

    - name: Add VM to /etc/hosts file
      lineinfile:
        path: "/etc/hosts"
        line: "{{ hostvars[item]['ansible_host'] }} {{ hostvars[item]['server_hostname'] }}"
      when:
        - hostvars[item]['server_vm'] | default(false) | bool
      with_items: "{{ groups['pxe_servers'] }}"


- name: Check VM Connectivity
  import_playbook: vm-status.yml


- name: Add SSH keys to VM's and containers
  hosts: vm_servers:all_containers
  gather_facts: false
  any_errors_fatal: true
  tasks:
    - name: Copy Host SSH Keys
      copy:
        src: "{{ item.src }}"
        dest: "{{ item.dest }}"
        mode: "0600"
      with_items:
        - src: "{{ lookup('env', 'HOME') }}/.ssh/id_rsa"
          dest: /root/.ssh/id_rsa
        - src: "{{ lookup('env', 'HOME') }}/.ssh/id_rsa.pub"
          dest: /root/.ssh/id_rsa.pub

    - name: Add authorized key
      authorized_key:
        user: root
        state: present
        key: "{{ lookup('file', '~/.ssh/id_rsa.pub') }}"


# In vm-post-install-script.sh.j2 we chattr +i the interfaces file to prevent
# the preseed system from overwriting the file after we've modified it.  The
# task below simply removes the immutable attribute.
- name: Remove immutable attr from /etc/network/interfaces
  hosts: vm_servers
  gather_facts: true
  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - deploy-vms
  tasks:
    - name: Remove immutable attr from /etc/network/interfaces
      file:
        path: /etc/network/interfaces
        attr: ""
      when:
        - ansible_distribution | lower == "ubuntu"
        - ansible_distribution_release | lower == "trusty"


- name: Set MaxSessions and MaxStartups to reduce connection failures
  hosts: vm_servers
  gather_facts: "{{ gather_facts | default(true) }}"
  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - deploy-vms
  tasks:
    - name: Gather variables for each operating system
      include_vars: "{{ item }}"
      with_first_found:
        - "{{ playbook_dir }}/vars/{{ ansible_distribution | lower }}-{{ ansible_distribution_version | lower }}.yml"
        - "{{ playbook_dir }}/vars/{{ ansible_distribution | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
        - "{{ playbook_dir }}/vars/{{ ansible_os_family | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
        - "{{ playbook_dir }}/vars/{{ ansible_distribution | lower }}.yml"
        - "{{ playbook_dir }}/vars/{{ ansible_os_family | lower }}.yml"
      tags:
        - always

    - name: Set MaxStartups
      lineinfile:
        path: /etc/ssh/sshd_config
        line: MaxStartups 100
        state: present
        regexp: '^MaxStartups.*$'
      notify:
        - restart sshd

    - name: Set MaxSessions
      lineinfile:
        path: /etc/ssh/sshd_config
        line: MaxSessions 100
        state: present
        regexp: '^MaxSessions.*$'
      notify:
        - restart sshd

  handlers:
    - name: restart sshd
      service:
        name: "{{ ssh_service_name }}"
        state: restarted


- name: Make space for swift/cinder/ceph volumes
  hosts: cinder_hosts:swift_hosts:ceph_hosts:&vm_servers
  gather_facts: "{{ gather_facts | default(true) }}"
  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - deploy-vms
  tasks:
    - name: Unmount unnecessary mounts
      mount:
        name: "{{ item }}"
        state: absent
      with_items:
        - "/var/lib/lxc"
        - "/var/lib/machines"
      register: _remove_mounts

    - name: Remove unnecessary logical volumes
      lvol:
        vg: vmvg00
        lv: "{{ item }}"
        force: true
        state: absent
      with_items:
        - "lxc00"
        - "machines00"
      register: _remove_lvs

    - name: Reload systemd to remove generated unit files for mount
      systemd:
        daemon_reload: yes
      when:
        - "ansible_service_mgr == 'systemd'"
        - "(_remove_mounts is changed) or (_remove_lvs is changed)"

    - name: Set fact to indicate that the volumes changed (later used to force formatting)
      set_fact:
        _force_format_disks: "{{ (_remove_mounts is changed) or (_remove_lvs is changed) }}"

- name: Setup cinder host volume
  hosts: cinder_hosts:&vm_servers
  gather_facts: "{{ gather_facts | default(true) }}"
  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - deploy-vms
  tasks:
    - name: Create cinder-volumes LV
      lvol:
        vg: vmvg00
        lv: cinder-volumes00
        size: "100%FREE"
        shrink: false

    - name: Create data cinder-volumes VG
      lvg:
        vg: cinder-volumes
        pvs: "/dev/vmvg00/cinder-volumes00"


- name: Setup swift host volume
  hosts: swift_hosts:&vm_servers
  gather_facts: "{{ gather_facts | default(true) }}"
  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - deploy-vms
  tasks:
    - name: Create swift disk LV's
      lvol:
        vg: vmvg00
        lv: "{{ item }}"
        size: 4G
      with_items:
        - disk1
        - disk2
        - disk3

    - name: Format swift drives
      filesystem:
        fstype: xfs
        dev: "/dev/vmvg00/{{ item }}"
        force: "{{ _force_format_disks | default(False) }}"
      with_items:
        - disk1
        - disk2
        - disk3

    - name: Mount swift drives
      mount:
        name: "/srv/{{ item }}"
        src: "/dev/mapper/vmvg00-{{ item }}"
        fstype: xfs
        state: mounted
        opts: defaults,discard
      with_items:
        - disk1
        - disk2
        - disk3

- name: Setup ceph OSD volumes
  hosts: ceph_hosts:&vm_servers
  gather_facts: "{{ gather_facts | default(true) }}"
  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - deploy-vms
  tasks:
    - name: Create ceph OSD journal LV's
      lvol:
        vg: vmvg00
        lv: "{{ item }}"
        size: "{{ ceph_journal_size }}"
      with_items:
        - journal1
        - journal2
        - journal3

    - name: Create ceph OSD disk LV's
      lvol:
        vg: vmvg00
        lv: "{{ item }}"
        size: "{{ ceph_osds_size }}"
      with_items:
        - data1
        - data2
        - data3

**********
DECISION===>: hardcoded secret
**********
=========================:::704:::END!!!=========================
=========================:::705:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/multi-node-aio/playbooks/deploy-dhcp.yml
**********
---
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Gather facts
  hosts: dhcp_hosts
  gather_facts: "{{ gather_facts | default(true) }}"
  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - deploy-dhcpd
  tasks:
    - name: Gather variables for each operating system
      include_vars: "{{ item }}"
      with_first_found:
        - "{{ playbook_dir }}/vars/{{ ansible_distribution | lower }}-{{ ansible_distribution_version | lower }}.yml"
        - "{{ playbook_dir }}/vars/{{ ansible_distribution | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
        - "{{ playbook_dir }}/vars/{{ ansible_os_family | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
        - "{{ playbook_dir }}/vars/{{ ansible_distribution | lower }}.yml"
        - "{{ playbook_dir }}/vars/{{ ansible_os_family | lower }}.yml"
      tags:
        - always

    - name: Install all required packages for dhcpd_install
      package:
        name: "{{ mnaio_dhcp_distro_packages }}"
        state: "latest"
        update_cache: yes
        cache_valid_time: 600
      register: _install_host_packages
      until: _install_host_packages is success
      retries: 3
      delay: 15

    - name: Enable services
      service:
        name: "{{ item }}"
        enabled: yes
      with_items: "{{ mnaio_dhcp_distro_packages }}"

    - name: Create a template in /etc/dhcp/dhcpd.conf
      template:
        src: dhcp/dhcpd.conf.j2
        dest: /etc/dhcp/dhcpd.conf
        mode: 0644
        owner: root
        group: root
      notify: restart dhcpd

    - name: Create a template in /etc/dhcp/dhcpd.conf
      template:
        src: dhcp/isc-dhcp-server
        dest: /etc/default/isc-dhcp-server
        mode: 0644
        owner: root
        group: root
      notify: restart dhcpd

  handlers:
    - name: restart dhcpd
      service:
        name: "{{ item }}"
        state: restarted
      with_items: "{{ mnaio_dhcp_distro_packages }}"

**********
DECISION===>: PASS
**********
=========================:::705:::END!!!=========================
=========================:::706:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/multi-node-aio/playbooks/download-vms.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in witing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Download saved files using a given manifest_url
  hosts: localhost
  connection: local
  gather_facts: no
  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - download-vms
  vars:
    aria2c_parameters: >-
        --log-level=notice
        --allow-overwrite=true
        --max-connection-per-server=4
        --check-integrity true
        --retry-wait=30
        --continue
    aria2c_log_path: >-
        /tmp
  tasks:
    - name: Get the manifest file
      uri:
        url: "{{ manifest_url }}"
        return_content: yes
      register: _manifest_file

    - name: Register manifest content as a fact
      set_fact:
        _manifest_content: "{{ _manifest_file.content | from_json }}"

    - name: Install aria download manager
      package:
        name: "aria2"
        state: present

    - name: Write artifact URL list
      copy:
        content: |
          {% for item in _manifest_content.files %}
          {{ manifest_url | regex_replace('/[^/]*$', '') }}/{{ item.path | basename}}
            dir={{ item.path | dirname }}
            checksum=sha-1={{ item.checksum }}
          {% endfor %}
        dest: "/tmp/aria2c.input"

    - name: Ensure that the aria log file path exists
      file:
        path: "{{ aria2c_log_path }}"
        state: directory

    - name: Download artifacts
      command: >-
        aria2c
        --input-file=/tmp/aria2c.input
        --log={{ aria2c_log_path }}/aria2c.log
        {{ aria2c_parameters }}
      register: _download_artifacts
      until: _download_artifacts is success
      retries: 3
      delay: 30

**********
DECISION===>: PASS
**********
=========================:::706:::END!!!=========================
=========================:::707:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/multi-node-aio/playbooks/test-host.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in witing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Gather facts
  hosts: vm_hosts
  gather_facts: "{{ gather_facts | default(true) }}"
  environment: "{{ deployment_environment_variables | default({}) }}"
  tags:
    - setup-host
  tasks:
    - name: Gather variables for each operating system
      include_vars: "{{ item }}"
      with_first_found:
        - "{{ playbook_dir }}/vars/{{ ansible_distribution | lower }}-{{ ansible_distribution_version | lower }}.yml"
        - "{{ playbook_dir }}/vars/{{ ansible_distribution | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
        - "{{ playbook_dir }}/vars/{{ ansible_os_family | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
        - "{{ playbook_dir }}/vars/{{ ansible_distribution | lower }}.yml"
        - "{{ playbook_dir }}/vars/{{ ansible_os_family | lower }}.yml"
      tags:
        - always

    - name: Check for networkd
      set_fact:
        networking_system: "systemd-networkd"
      when:
        - "ansible_distribution_major_version is version('18', '>=')"

    - name: Fall back on /e/n/i
      set_fact:
        networking_system: "eni"
      when:
        - "ansible_distribution_major_version is version('18', '<')"

    - name: Deploy systemd-networkd bridge devices
      template:
        src: "pxe/configs/{{ ansible_os_family | lower }}/systemd-networkd-bridges-netdev.j2"
        dest: /tmp/{{ item.value.iface }}.netdev
        mode: "0644"
        owner: root
        group: root
      with_dict:
        - "{{ mnaio_host_networks }}"
      register: mnaio_bridges

    - name: Deploy systemd-networkd bridge networks
      template:
        src: "pxe/configs/{{ ansible_os_family | lower }}/systemd-networkd-bridges-network.j2"
        dest: /tmp/{{ item.value.iface }}.network
        mode: "0644"
        owner: root
        group: root
      with_dict:
        - "{{ mnaio_host_networks }}"
      register: mnaio_bridges

**********
DECISION===>: PASS
**********
=========================:::707:::END!!!=========================
=========================:::708:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/multi-node-aio/playbooks/openstack-service-setup.yml
**********
---
#
# Playbook to populate a newly deployed OpenStack cloud with some flavors, images, etc.
#
# Runs against the Utility container on infra1, relying on the clouds.yaml file
# left there by the OpenStack-Ansible playbooks to specify the API endpoint and
# auth parameters to use.
#
- name: OpenStack service setup
  hosts: utility_all[0]
  user: root
  environment: "{{ deployment_environment_variables | default({}) }}"

# All the data is found in this file:
  vars_files:
    - vars/openstack-service-config.yml

  tasks:

  - name: Ensure python-shade library is present to run ansible os_xxx modules
    apt:
      name: python-shade
      state: present
    tags:
      - always

  - name: Create flavors of nova VMs
    os_nova_flavor:
      endpoint_type: internal
      cloud: default
      state: present
      name: "{{ item.name }}"
      ram: "{{ item.ram }}"
      vcpus: "{{ item.vcpus }}"
      disk: "{{ item.disk }}"
      swap: "{{ item.swap }}"
      ephemeral: "{{ item.ephemeral }}"
    with_items: "{{ vm_flavors }}"
    tags:
      - create_flavors

  - name: Create networks
    os_network:
      endpoint_type: internal
      cloud: default
      state: present
      name: "{{ item.name }}"
      shared: "{{ item.shared }}"
      external: "{{ item.external }}"
      provider_network_type: "{{ item.network_type }}"
      provider_physical_network: "{{ item.physical_network | default ('') }}"
    with_items: "{{ networks }}"
    tags:
      - create_networks

  - name: Create subnets on networks
    os_subnet:
      endpoint_type: internal
      cloud: default
      state: present
      name: "{{ item.name }}"
      network_name: "{{ item.network_name }}"
      ip_version: "{{ item.ip_version }}"
      cidr: "{{ item.cidr }}"
      gateway_ip: "{{ item.gateway_ip }}"
      enable_dhcp: "{{ item.enable_dhcp }}"
      allocation_pool_start: "{{ item.allocation_pool_start }}"
      allocation_pool_end: "{{ item.allocation_pool_end }}"
      dns_nameservers: "{{ item.dns_nameservers | default([]) }}"
    with_items: "{{ subnets }}"
    tags:
      - create_networks

  - name: Create a router on both public and private networks
    os_router:
      endpoint_type: internal
      cloud: default
      state: present
      name: "{{ router_name }}"
      network: "{{ provider_net_name }}"
      interfaces:
        - "{{ private_subnet_name }}"
    ignore_errors: yes  # will report error if this router already exists
    register: router_details
    tags:
      - create_networks

  - name: Get list of security groups
    # Must use shell here because Ansible does not have os_security_group_facts module
    shell: "source openrc ; openstack security group list -f yaml | awk '/ID/ {print $2}'"
    args:
      executable: /bin/bash
    register: sec_groups
    tags:
      - create_networks

  - name: Setup rules on all security groups
    os_security_group_rule:
      endpoint_type: internal
      cloud: default
      security_group: "{{ item[1] }}"
      protocol: "{{ item[0].protocol }}"
      direction: "{{ item[0].direction }}"
      port_range_min: "{{ item[0].port_min | default(-1) }}"
      port_range_max: "{{ item[0].port_max | default(-1) }}"
    with_nested:
      - "{{ security_group_rules }}"
      - "{{ sec_groups.stdout_lines }}"
    tags:
      - create_networks

# Install some Linux system images
  - include: "{{ playbook_dir }}/openstack-image-setup.yml"
    with_items: "{{ images }}"
    tags:
      - create_images


**********
DECISION===>: PASS
**********
=========================:::708:::END!!!=========================
=========================:::709:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/multi-node-aio/playbooks/vars/ubuntu.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in witing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

mnaio_host_required_distro_packages:
  - ubuntu-cloud-keyring

mnaio_host_package_repos:
  - repo: "deb http://ubuntu-cloud.archive.canonical.com/ubuntu {{ ansible_lsb.codename }}-updates/queens main"
    state: present
    filename: "uca"
    condition: "{{ ansible_lsb.codename == 'xenial' }}"
  - repo: "deb http://ubuntu-cloud.archive.canonical.com/ubuntu {{ ansible_lsb.codename }}-updates/rocky main"
    state: present
    filename: "uca"
    condition: "{{ ansible_lsb.codename == 'bionic' }}"

mnaio_host_distro_packages:
  - bridge-utils
  - ifenslave
  - iptables-persistent
  - libguestfs-tools
  - libvirt-bin
  - lvm2
  - ntp
  - openssh-server
  - python2.7
  - python-lxml
  - python-jmespath
  - qemu-kvm
  - qemu-utils
  - software-properties-common
  - virtinst
  - virt-manager
  - vlan

mnaio_pxe_distro_packages:
  - tftpd-hpa
  - inetutils-inetd
  - nginx
  - p7zip-full

mnaio_dhcp_distro_packages:
  - isc-dhcp-server

mnaio_pkg_cache_server_distro_packages:
  - apt-cacher-ng

mnaio_host_iptables_service: "{{ (ansible_lsb.codename == 'trusty') | ternary('iptables-persistent', 'netfilter-persistent') }}"

ssh_service_name: ssh

**********
DECISION===>: use of http without tls
**********
=========================:::709:::END!!!=========================
=========================:::710:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/multi-node-aio/playbooks/vars/openstack-service-config.yml
**********
---
# This file contains data that controls the post-deployment configuration
# of OpenStack by the Ansible playbook openstack-service-setup.yml

# Define a set of VM flavors to be created
vm_flavors:
  - name: m1.micro
    ram: 256
    vcpus: 1
    disk: 1
    swap: 0
    ephemeral: 0
  - name: m1.tiny
    ram: 512
    vcpus: 1
    disk: 1
    swap: 0
    ephemeral: 0
  - name: m1.mini
    ram: 1024
    vcpus: 2
    disk: 3
    swap: 0
    ephemeral: 0
  - name: m1.small
    ram: 2048
    vcpus: 3
    disk: 12
    swap: 4
    ephemeral: 4
  - name: m1.medium
    ram: 4096
    vcpus: 6
    disk: 60
    swap: 4
    ephemeral: 20
  - name: m1.large
    ram: 8192
    vcpus: 12
    disk: 300
    swap: 4
    ephemeral: 150
  - name: m1.xlarge
    ram: 16384
    vcpus: 24
    disk: 600
    swap: 4
    ephemeral: 256
  - name: m1.heavy
    ram: 32768
    vcpus: 48
    disk: 1200
    swap: 4
    ephemeral: 256

# Create shared networks and subnets:
provider_net_name: GATEWAY_NET
provider_net_cidr: 10.0.248.0/22
provider_dns_server: "{{ DNS_NAMESERVER | default('8.8.8.8') }}"
provider_subnet_name: "{{ provider_net_name }}_SUBNET"

private_net_name: PRIVATE_NET
private_net_cidr: 192.168.0.0/24
private_subnet_name: "{{ private_net_name }}_SUBNET"

networks:
  - name: "{{ provider_net_name }}"
    shared: true
    external: true
    network_type: flat
    physical_network: flat
  - name: "{{ private_net_name }}"
    shared: true
    external: true
    network_type: vxlan
    segmentation_id: 101

subnets:
  - name: "{{ provider_subnet_name }}"
    network_name: "{{ provider_net_name }}"
    ip_version: 4
    cidr: "{{ provider_net_cidr }}"
    gateway_ip: "{{ provider_net_cidr | ipaddr('1') | ipaddr('address') }}"
    enable_dhcp: "{{ enable_provider_net_dhcp | default(false) | bool }}"
    allocation_pool_start: "{{ provider_net_cidr | ipaddr('201') | ipaddr('address') }}"
    allocation_pool_end:   "{{ provider_net_cidr | ipaddr('255') | ipaddr('address') }}"
    dns_nameservers:
       - "{{ provider_dns_server }}"
  - name: "{{ private_subnet_name }}"
    network_name: "{{ private_net_name }}"
    ip_version: 4
    cidr: "{{ private_net_cidr }}"
    gateway_ip: "{{ private_net_cidr | ipaddr('1') | ipaddr('address') }}"
    enable_dhcp: true
    allocation_pool_start: "{{ private_net_cidr | ipaddr('10') | ipaddr('address') }}"
    allocation_pool_end:   "{{ private_net_cidr | ipaddr('254') | ipaddr('address') }}"

router_name: GATEWAY_NET_ROUTER
security_group_name: gateway_security
port_name: gateway_port

# Neutron security group setup
security_group_rules:
  - name: Allow ICMP
    protocol: icmp
    direction: ingress
  - name: Allow all TCP
    protocol: tcp
    direction: ingress
    port_min: 1
    port_max: 65535
  - name: Allow all UDP
    protocol: udp
    direction: ingress
    port_min: 1
    port_max: 65535

# Create some default images
images:
  - name: Ubuntu 14.04 LTS
    format: qcow2
    url: http://uec-images.ubuntu.com/releases/14.04/release/ubuntu-14.04-server-cloudimg-amd64-disk1.img
  - name: Ubuntu 16.04
    format: qcow2
    url: http://uec-images.ubuntu.com/releases/16.04/release/ubuntu-16.04-server-cloudimg-amd64-disk1.img
  - name: Fedora 27
    format: qcow2
    url: http://dfw.mirror.rackspace.com/fedora/releases/27/CloudImages/x86_64/images/Fedora-Cloud-Base-27-1.6.x86_64.qcow2
  - name: CentOS 7
    format: qcow2
    url: http://cloud.centos.org/centos/7/images/CentOS-7-x86_64-GenericCloud.qcow2
  - name: OpenSuse Leap 42.3
    format: qcow2
    url: http://download.opensuse.org/repositories/Cloud:/Images:/Leap_42.3/images/openSUSE-Leap-42.3-OpenStack.x86_64.qcow2
  - name: Debian 9 Latest
    format: qcow2
    url: http://cdimage.debian.org/cdimage/openstack/current-9/debian-9-openstack-amd64.qcow2
  - name: Debian TESTING
    format: qcow2
    url: http://cdimage.debian.org/cdimage/openstack/testing/debian-testing-openstack-amd64.qcow2
  - name: Cirros-0.3.5
    format: qcow2
    url: http://download.cirros-cloud.net/0.3.5/cirros-0.3.5-x86_64-disk.img

**********
DECISION===>: use of http wihtout tls
**********
=========================:::710:::END!!!=========================
=========================:::711:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/multi-node-aio/playbooks/group_vars/swift_hosts.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in witing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

ansible_os_family: "{{ images[default_vm_image]['image_type'] }}"

server_domain_name: 'openstack.local'
server_vm: "{{ osa_enable_object_storage | bool }}"
server_vm_ram: '{{ swift_vm_server_ram | default(1024) }}'
server_vm_vcpus: '{{ swift_vm_server_vcpus | default(2) }}'
server_vm_primary_network: 'dhcp'
server_image: "{{ default_vm_image }}"
server_default_interface: 'eth0'
server_preseed_ks: 'vm'
server_extra_options: ''

default_vm_storage: "{{ swift_vm_disk_size | default(92160) }}"

**********
DECISION===>: PASS
**********
=========================:::711:::END!!!=========================
=========================:::712:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/multi-node-aio/playbooks/group_vars/dhcp_hosts.yml
**********
---
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

dhcp_default_lease_time: 21600                   # Default lease time
dhcp_max_lease_time: 43200                       # Max lease time
ipxe_boot_file: "boot.ipxe"                      # Path of initial iPXE bootloader
# - List of DHCP Subnets - These are iterated though and each will be created
dhcp_list:
  - netmask: 255.255.252.0                       # Netmask
    gateway: 10.0.2.1                            # Gateway
    dns: 8.8.8.8                                 # DNS
    subnet: 10.0.0.0                             # Subnet mask
    range_start: 10.0.2.160                      # Start of DHCP range
    range_end: 10.0.3.254                        # End of DHCP range
    broadcast: 10.0.3.255                        # Network Broadcast address
    default_lease_time: 21600                    # Subnet Default lease time - The default is used if this is not defined
    max_lease_time: 43200                        # Subnet Max lease time - The default is used if this is not defined
    ipxe_boot_file: "boot.ipxe"                  # Path of initial iPXE bootloader to boot from first
    tftp_server: "{{ tftp_server }}"             # The server hosting the TFTP server - The default is used if this is not defined
    dhcp_default_domain_name: openstackci.local

**********
DECISION===>: PASS
**********
=========================:::712:::END!!!=========================
=========================:::713:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/multi-node-aio/playbooks/group_vars/vm_hosts.yml
**********
---
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

mnaio_host_iptables_rules:
  - table: filter
    chain: INPUT
    protocol: tcp
    match: tcp
    destination_port: 67
    jump: ACCEPT
  - table: filter
    chain: INPUT
    protocol: udp
    match: udp
    destination_port: 67
    jump: ACCEPT
  - table: filter
    chain: INPUT
    protocol: udp
    match: udp
    destination_port: 53
    jump: ACCEPT
  - table: filter
    chain: INPUT
    protocol: udp
    match: udp
    destination_port: 53
    jump: ACCEPT
  - table: filter
    chain: FORWARD
    in_interface: vm-br-dhcp
    jump: ACCEPT
  - table: filter
    chain: FORWARD
    out_interface: vm-br-dhcp
    jump: ACCEPT
  - table: nat
    chain: POSTROUTING
    out_interface: "{{ masquerade_interface | default(default_interface) }}"
    jump: MASQUERADE

mnaio_host_iptables_prerouting_ports:
  - host_port: 80
    vm_port: 80
    vm_ip: "{{ hostvars[groups['loadbalancer_hosts'][0]]['server_vm_fixed_addr'] }}"
  - host_port: 443
    vm_port: 443
    vm_ip: "{{ hostvars[groups['loadbalancer_hosts'][0]]['server_vm_fixed_addr'] }}"
  - host_port: 2222
    vm_port: 22
    vm_ip: "{{ hostvars[groups['deploy_hosts'][0]]['server_vm_fixed_addr'] }}"
  - host_port: 6080
    vm_port: 6080
    vm_ip: "{{ hostvars[groups['loadbalancer_hosts'][0]]['server_vm_fixed_addr'] }}"
  - host_port: 6082
    vm_port: 6082
    vm_ip: "{{ hostvars[groups['loadbalancer_hosts'][0]]['server_vm_fixed_addr'] }}"
  - host_port: 8443
    vm_port: 8443
    vm_ip: "{{ hostvars[groups['loadbalancer_hosts'][0]]['server_vm_fixed_addr'] }}"

**********
DECISION===>: PASS
**********
=========================:::713:::END!!!=========================
=========================:::714:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/multi-node-aio/playbooks/group_vars/loadbalancer_hosts.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in witing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

ansible_os_family: "{{ images[default_vm_image]['image_type'] }}"

server_domain_name: 'openstack.local'
server_vm: true
server_vm_ram: '{{ loadbalancer_vm_server_ram | default(1024) }}'
server_vm_vcpus: '{{ loadbalancer_vm_server_vcpus | default(1) }}'
server_vm_primary_network: 'dhcp'
server_image: "{{ default_vm_image }}"
server_default_interface: 'eth0'
server_preseed_ks: 'vm'
server_extra_options: ''

default_vm_storage: "{{ loadbalancer_vm_disk_size | default(46080) }}"

**********
DECISION===>: PASS
**********
=========================:::714:::END!!!=========================
=========================:::715:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/multi-node-aio/playbooks/group_vars/compute_hosts.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in witing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

ansible_os_family: "{{ images[default_vm_image]['image_type'] }}"

server_domain_name: 'openstack.local'
server_vm: "{{ osa_enable_compute | bool }}"
server_vm_ram: '{{ compute_vm_server_ram | default(8192) }}'
server_vm_vcpus: '{{ compute_vm_server_vcpus | default(4) }}'
server_vm_primary_network: 'dhcp'
server_image: "{{ default_vm_image }}"
server_default_interface: 'eth0'
server_preseed_ks: 'vm-compute'
server_extra_options: ''

default_vm_storage: "{{ compute_vm_disk_size | default(92160) }}"

**********
DECISION===>: PASS
**********
=========================:::715:::END!!!=========================
=========================:::716:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/multi-node-aio/playbooks/group_vars/all.yml
**********
---
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

default_interface: "{{ default_network | default('eth0') }}"
default_vm_image: "{{ default_image | default('ubuntu-16.04-amd64') }}"
default_vm_storage: "{{ vm_disk_size | default(92160) }}"
default_vm_root_disk_size: 8192
default_acng_bind_address: 0.0.0.0
default_os_families:
  ubuntu-16.04-amd64: debian
  ubuntu-14.04-amd64: debian

default_ubuntu_kernel: linux-generic
default_ubuntu_mirror_proxy: 'http://10.0.2.1:3142/'
default_ubuntu_mirror_hostname: archive.ubuntu.com
default_ubuntu_mirror_directory: /ubuntu

default_proxy_url: 'http://10.0.2.1:3142/'

default_container_tech: "{{ container_tech | default('lxc') }}"

ipxe_kernel_base_url: "http://boot.ipxe.org"

# The timeout for the SSH check to the vm_servers
vm_ssh_timeout: 1500

# Whether to use snapshots (if they are available) for file-backed VM's
vm_use_snapshot: yes

# IP address, or domain name of the TFTP server
tftp_server: "{{ hostvars[groups['pxe_hosts'][0]]['ansible_host'] | default(ansible_host) }}"
# tftp_ssh_key: ''  # user defined ssh key, used to access the host
tftp_port: 69

# Default ISO images
images:
  ubuntu-18.04-amd64:
    image_type: "debian"
    network_setup: "systemd-networkd"
    image_os: "ubuntu"
    image-version: "bionic"
    image_kernel_options: "biosdevname=0 net.ifnames=0 auto=true priority=critical"
    image_netboot_kernel_url: "http://archive.ubuntu.com/ubuntu/dists/bionic/main/installer-amd64/current/images/netboot/ubuntu-installer/amd64/linux"
    image_netboot_initrd_url: "http://archive.ubuntu.com/ubuntu/dists/bionic/main/installer-amd64/current/images/netboot/ubuntu-installer/amd64/initrd.gz"
    image_configs:
      vm:
        url: "http://{{ tftp_server }}/configs/vm.config"
        template_name: "vm.config"
      vm-compute:
        url: "http://{{ tftp_server }}/configs/vm-compute.config"
        template_name: "vm-compute.config"
  ubuntu-16.04-amd64:
    image_type: "debian"
    network_setup: "eni"
    image_os: "ubuntu"
    image-version: "xenial"
    image_kernel_options: "biosdevname=0 net.ifnames=0 auto=true priority=critical"
    image_netboot_kernel_url: "http://archive.ubuntu.com/ubuntu/dists/xenial/main/installer-amd64/current/images/netboot/ubuntu-installer/amd64/linux"
    image_netboot_initrd_url: "http://archive.ubuntu.com/ubuntu/dists/xenial/main/installer-amd64/current/images/netboot/ubuntu-installer/amd64/initrd.gz"
    image_configs:
      vm:
        url: "http://{{ tftp_server }}/configs/vm.config"
        template_name: "vm.config"
      vm-compute:
        url: "http://{{ tftp_server }}/configs/vm-compute.config"
        template_name: "vm-compute.config"
  ubuntu-14.04-amd64:
    image_type: "debian"
    network_setup: "eni"
    image_os: "ubuntu"
    image_version: "trusty"
    image_kernel_options: "biosdevname=0 net.ifnames=0 auto=true priority=critical quiet splash"
    image_netboot_kernel_url: "http://archive.ubuntu.com/ubuntu/dists/trusty/main/installer-amd64/current/images/netboot/ubuntu-installer/amd64/linux"
    image_netboot_initrd_url: "http://archive.ubuntu.com/ubuntu/dists/trusty/main/installer-amd64/current/images/netboot/ubuntu-installer/amd64/initrd.gz"
    image_configs:
      vm:
        url: "http://{{ tftp_server }}/configs/vm.config"
        template_name: "vm.config"
      vm-compute:
        url: "http://{{ tftp_server }}/configs/vm-compute.config"
        template_name: "vm-compute.config"
  centos-7-amd64:
    image_type: "redhat"
    network_setup: "systemd-networkd"
    image_version: 7
    image_netboot_kernel_url: "http://mirrors.edge.kernel.org/centos/7/os/x86_64/images/pxeboot/vmlinuz"
    image_netboot_initrd_url: "http://mirrors.edge.kernel.org/centos/7/os/x86_64/images/pxeboot/initrd.img"
    image_repo_base_url: "http://mirrors.edge.kernel.org/centos/7"
    image_kernel_options: ""
    image_configs:
      vm:
        url: "http://{{ tftp_server }}/configs/vm.config"
        template_name: "vm.config"
      vm-compute:
        url: "http://{{ tftp_server }}/configs/vm-compute.config"
        template_name: "vm-compute.config"

# mnaio_data_disk: 'sdc'  # str - not required, set this to define a given data disk if no data disk
#                                               is defined the largest unpartitioned disk will be used.
mnaio_host_networks:
  dhcp:
    iface: 'vm-br-dhcp'                 # str  - required, interface name
    inet_type: 'static'                 # str  - required, iface type [static, dhcp, manual]
    address: '10.0.2.1/22'              # str  - not required, must be in CIDR format
    iface_port: none                    # str  - required, physical port used within a host bridge
    address_aliases:                    # list - not required, items must be sting and in CIDR format
      - '10.0.2.2/22'
  mgmt:
    iface: 'vm-br-eth1'
    inet_type: 'static'
    address: '10.0.236.1/22'
    iface_port: none
  flat:
    iface: 'vm-br-eth2'
    inet_type: 'static'
    address: '10.0.248.1/22'
    iface_port: none
  vlan:
    iface: 'vm-br-eth3'
    inet_type: 'manual'
    iface_port: none
  vxlan:
    iface: 'vm-br-eth4'
    inet_type: 'static'
    address: '10.0.240.1/22'
    iface_port: none
  storage:
    iface: 'vm-br-eth5'
    inet_type: 'static'
    address: '10.0.244.1/22'
    iface_port: none
  lbaas:
    iface: 'vm-br-eth6'
    inet_type: 'static'
    address: '10.0.232.1/22'
    iface_port: none

osa_enable_infra: true
osa_enable_identity: true
osa_enable_block_storage: "{{ not (enable_ceph_storage | bool) }}"
osa_enable_image: true
osa_enable_lbaas: false
osa_enable_compute: true
osa_enable_orchestration: true
osa_enable_dashboard: true
osa_enable_network: true
osa_enable_meter: false
osa_enable_object_storage: "{{ not (enable_ceph_storage | bool) }}"
osa_enable_legacy_os_infra: "{{ (osa_enable_image | bool) and (osa_enable_orchestration | bool) and (osa_enable_dashboard | bool) and (osa_enable_compute | bool) }}"
osa_disable_serial: false
osa_enable_elk_metrics: false
osa_enable_os_profiler: false
osa_enable_uwsgi_stats: false

# Ceph
enable_ceph_storage: false
ceph_journal_size: 5120
ceph_osds_filesystem_type: 'xfs'

**********
DECISION===>: use of http without tls
**********
=========================:::716:::END!!!=========================
=========================:::717:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/multi-node-aio/playbooks/group_vars/infra_hosts.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in witing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

ansible_os_family: "{{ images[default_vm_image]['image_type'] }}"

server_domain_name: 'openstack.local'                # str  - required, domain name of server
server_vm: true                                             # bool - not required, used to specify a host is to become a VM
server_vm_ram: '{{ infra_vm_server_ram | default(16384) }}' # int  - not required, used to specify ram when provisioning a VM
server_vm_vcpus: '{{ infra_vm_server_vcpus | default(4) }}' # int  - not required, used to specify vcpus when provisioning a VM
server_vm_primary_network: 'dhcp'                           # str  - not required, primary network used to kick the VM
server_image: "{{ default_vm_image }}"                      # str  - required, image name
server_default_interface: 'eth0'                            # str  - required, default interface
server_preseed_ks: 'vm'                                     # str  - required, name of preseed/kickstart file
server_extra_options: ''                                    # str  - not required, added kernel options

default_vm_storage: "{{ infra_vm_disk_size | default(92160) }}"

**********
DECISION===>: PASS
**********
=========================:::717:::END!!!=========================
=========================:::718:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/multi-node-aio/playbooks/group_vars/log_hosts.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in witing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

ansible_os_family: "{{ images[default_vm_image]['image_type'] }}"

server_domain_name: 'openstack.local'
server_vm: true
server_vm_ram: '{{ logging_vm_server_ram | default(16384) }}'
server_vm_vcpus: '{{ logging_vm_server_vcpus | default(2) }}'
server_vm_primary_network: 'dhcp'
server_image: "{{ default_vm_image }}"
server_default_interface: 'eth0'
server_preseed_ks: 'vm'
server_extra_options: ''

default_vm_storage: "{{ log_vm_disk_size | default(92160) }}"

**********
DECISION===>: PASS
**********
=========================:::718:::END!!!=========================
=========================:::719:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/multi-node-aio/playbooks/group_vars/ceph_hosts.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in witing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

ansible_os_family: "{{ images[default_vm_image]['image_type'] }}"

server_domain_name: 'openstack.local'
server_vm: "{{ enable_ceph_storage | bool }}"
server_vm_ram: '{{ ceph_vm_server_ram | default(1024) }}'
server_vm_vcpus: '{{ ceph_vm_server_vcpus | default(2) }}'
server_vm_primary_network: 'dhcp'
server_image: "{{ default_vm_image }}"
server_default_interface: 'eth0'
server_preseed_ks: 'vm'
server_extra_options: ''

ceph_osds_size: 20480

default_vm_storage: "{{ ceph_vm_disk_size | default(122880) }}"

**********
DECISION===>: PASS
**********
=========================:::719:::END!!!=========================
=========================:::720:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/multi-node-aio/playbooks/group_vars/pxe_hosts.yml
**********
---
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

ipxe_ubuntu_version: "1.0.0+git-20150424.a25a16d-1ubuntu1.2"

**********
DECISION===>: PASS
**********
=========================:::720:::END!!!=========================
=========================:::721:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/multi-node-aio/playbooks/group_vars/cinder_hosts.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in witing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

ansible_os_family: "{{ images[default_vm_image]['image_type'] }}"

server_domain_name: 'openstack.local'
server_vm: "{{ osa_enable_block_storage | bool }}"
server_vm_ram: '{{ cinder_vm_server_ram | default(2048) }}'
server_vm_vcpus: '{{ cinder_vm_server_vcpus | default(2) }}'
server_vm_primary_network: 'dhcp'
server_image: "{{ default_vm_image }}"
server_default_interface: 'eth0'
server_preseed_ks: 'vm'
server_extra_options: ''

default_vm_storage: "{{ cinder_vm_disk_size | default(92160) }}"

**********
DECISION===>: PASS
**********
=========================:::721:::END!!!=========================
=========================:::722:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/multi-node-aio/playbooks/osa/elk-confd.yml
**********
# For the puposes of this example, the kibana nodes have been added to
# different host machines that the logging nodes. The intention here
# is to show that the different components can scale independently of
# one another.
kibana_hosts:
  infra1:
    ip: 10.0.236.100
  infra2:
    ip: 10.0.236.101
  infra3:
    ip: 10.0.236.102

elastic-logstash_hosts:
  logging1:
    ip: 10.0.236.110

apm-server_hosts:
  logging1:
    ip: 10.0.236.110

**********
DECISION===>: PASS
**********
=========================:::722:::END!!!=========================
=========================:::723:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/multi-node-aio/playbooks/osa/openstack_user_config.yml
**********
---
cidr_networks:
  lbaas: 10.0.232.0/22
  container: 10.0.236.0/22
  tunnel: 10.0.240.0/22
  storage: 10.0.244.0/22
  flat: 10.0.248.0/22

used_ips:
  - "10.0.232.0,10.0.232.200"
  - "10.0.236.0,10.0.236.200"
  - "10.0.240.0,10.0.240.200"
  - "10.0.244.0,10.0.244.200"
  - "10.0.248.0,10.0.248.200"

global_overrides:
  internal_lb_vip_address: "{{ internal_lb_vip_address | default(hostvars[groups['loadbalancer_hosts'][0]]['server_networks']['mgmt']['address'].split('/')[0]) }}"
  external_lb_vip_address: "{{ external_lb_vip_address | default(hostvars[groups['loadbalancer_hosts'][0]]['server_vm_fixed_addr']) }}"
  tunnel_bridge: "br-vxlan"
  management_bridge: "br-mgmt"
  provider_networks:
    - network:
        container_bridge: "br-mgmt"
        container_type: "veth"
        container_interface: "eth1"
        ip_from_q: "container"
        type: "raw"
        group_binds:
          - all_containers
          - hosts
        is_container_address: true
        is_ssh_address: true
    - network:
        container_bridge: "br-vxlan"
        container_type: "veth"
        container_interface: "eth10"
        ip_from_q: "tunnel"
        type: "vxlan"
        range: "1:1000"
        net_name: "vxlan"
        group_binds:
          - neutron_linuxbridge_agent
    - network:
        container_bridge: "br-flat"
        container_type: "veth"
        container_interface: "eth12"
        host_bind_override: "veth2"
        type: "flat"
        net_name: "flat"
        group_binds:
          - neutron_linuxbridge_agent
          - utility_all
    - network:
        container_bridge: "br-vlan"
        container_type: "veth"
        container_interface: "eth11"
        type: "vlan"
        range: "1:1"
        net_name: "vlan"
        group_binds:
          - neutron_linuxbridge_agent
    - network:
        container_bridge: "br-storage"
        container_type: "veth"
        container_interface: "eth2"
        ip_from_q: "storage"
        type: "raw"
        group_binds:
          - glance_api
          - cinder_api
          - cinder_volume
          - nova_compute
{% if (osa_enable_object_storage | bool) and not (enable_ceph_storage | bool) %}
          - swift_proxy
{% endif %}
{% if enable_ceph_storage | bool %}
          - ceph-osd
{% endif %}
    - network:
        container_bridge: "br-lbaas"
        container_type: "veth"
        container_interface: "eth13"
        ip_from_q: "lbaas"
        type: "flat"
        net_name: "lbaas"
        group_binds:
          - "neutron_linuxbridge_agent"
          - "octavia-worker"
          - "octavia-housekeeping"
          - "octavia-health-monitor"
{% if (osa_enable_object_storage | bool) and not (enable_ceph_storage | bool) %}
  swift:
    part_power: 8
    storage_network: 'br-storage'
    replication_network: 'br-storage'
    drives:
      - name: disk1
      - name: disk2
      - name: disk3
    mount_point: /srv
    storage_policies:
      - policy:
          name: default
          index: 0
          default: True
{% endif %}

###
### Anchors
###
{% if (osa_enable_block_storage | bool) and not (enable_ceph_storage | bool) %}
cinder_block: &cinder_block
{%   for host in groups['cinder_hosts'] %}
  {{ hostvars[host]['server_hostname'] }}:
    ip: {{ hostvars[host]['server_networks']['mgmt']['address'].split('/')[0] }}
    container_vars:
      container_tech: "{{ default_container_tech }}"
      cinder_backends:
        limit_container_types: cinder_volume
        lvm:
          volume_group: cinder-volumes
          volume_driver: cinder.volume.drivers.lvm.LVMVolumeDriver
          volume_backend_name: LVM_iSCSI
          iscsi_ip_address: {{ hostvars[host]['server_networks']['storage']['address'].split('/')[0] }}
{%   endfor %}
{% endif %}


{% if osa_enable_compute | bool %}
compute_block: &compute_block
{%   for host in groups['compute_hosts'] %}
  {{ hostvars[host]['server_hostname'] }}:
    ip: {{ hostvars[host]['server_networks']['mgmt']['address'].split('/')[0] }}
    container_vars:
      container_tech: "{{ default_container_tech }}"
{%   endfor %}
{% endif %}


infra_block: &infra_block
{% for host in groups['infra_hosts'] %}
  {{ hostvars[host]['server_hostname'] }}:
    ip: {{ hostvars[host]['server_networks']['mgmt']['address'].split('/')[0] }}
    container_vars:
      container_tech: "{{ default_container_tech }}"
{% endfor %}


loadbalancer_block: &loadbalancer_block
{% for host in groups['loadbalancer_hosts'] %}
  {{ hostvars[host]['server_hostname'] }}:
    ip: {{ hostvars[host]['server_networks']['mgmt']['address'].split('/')[0] }}
    container_vars:
      container_tech: "{{ default_container_tech }}"
{% endfor %}


log_block: &log_block
{% for host in groups['log_hosts'] %}
  {{ hostvars[host]['server_hostname'] }}:
    ip: {{ hostvars[host]['server_networks']['mgmt']['address'].split('/')[0] }}
    container_vars:
      container_tech: "{{ default_container_tech }}"
{% endfor %}


{% if (osa_enable_object_storage | bool) and not (enable_ceph_storage | bool) %}
swift_block: &swift_block
{%   for host in groups['swift_hosts'] %}
  {{ hostvars[host]['server_hostname'] }}:
    ip: {{ hostvars[host]['server_networks']['mgmt']['address'].split('/')[0] }}
    container_vars:
      container_tech: "{{ default_container_tech }}"
{%   endfor %}
{% endif %}


{% if enable_ceph_storage | bool %}
ceph_osds_block: &ceph_osds_block
{% for host in groups['ceph_hosts'] %}
  {{ hostvars[host]['server_hostname'] }}:
    ip: {{ hostvars[host]['server_networks']['mgmt']['address'].split('/')[0] }}
    container_vars:
      container_tech: "{{ default_container_tech }}"
      lvm_volumes:
        - data: data1
          data_vg: vmvg00
          journal: journal1
          journal_vg: vmvg00
        - data: data2
          data_vg: vmvg00
          journal: journal2
          journal_vg: vmvg00
        - data: data3
          data_vg: vmvg00
          journal: journal3
          journal_vg: vmvg00
{% endfor %}
{% endif %}


###
### Infrastructure
###

{% if osa_enable_infra | bool %}
# galera, memcache, rabbitmq, utility
shared-infra_hosts: *infra_block

# repository (apt cache, python packages, etc)
repo-infra_hosts: *infra_block

# rsyslog server
log_hosts: *log_block

# load balancer
haproxy_hosts: *loadbalancer_block
{% endif %}

{% if enable_ceph_storage | bool %}
# Ceph Mon Hosts
ceph-mon_hosts: *infra_block

# Ceph RGW Hosts
ceph-rgw_hosts: *infra_block

# Ceph OSDs Hosts
ceph-osd_hosts: *ceph_osds_block
{% endif %}

###
### OpenStack
###

{% if osa_enable_legacy_os_infra | bool %}
# Legacy infra group
# Contains glance, heat, horizon, nova
os-infra_hosts: *infra_block
{% endif %}

{% if osa_enable_identity | bool %}
# keystone
identity_hosts: *infra_block
{% endif %}

{% if (osa_enable_block_storage | bool) or (enable_ceph_storage | bool)  %}
# cinder api services
storage-infra_hosts: *infra_block

{% if not (enable_ceph_storage | bool) %}
# cinder storage host (LVM-backed)
storage_hosts: *cinder_block
{% endif %}
{% endif %}

{% if osa_enable_image | bool %}
# glance
image_hosts: *infra_block
{% endif %}

{% if osa_enable_lbaas | bool %}
# octavia
octavia-infra_hosts: *infra_block
{% endif %}

{% if osa_enable_compute | bool %}
# nova api, conductor, etc services
compute-infra_hosts: *infra_block

# nova hypervisors
compute_hosts: *compute_block
{% endif %}

{% if osa_enable_orchestration | bool %}
# heat
orchestration_hosts: *infra_block
{% endif %}

{% if osa_enable_dashboard | bool %}
# horizon
dashboard_hosts: *infra_block
{% endif %}

{% if osa_enable_network | bool %}
# neutron server, agents (L3, etc)
network_hosts: *infra_block
{% endif %}

{% if osa_enable_meter | bool %}
# ceilometer (telemetry data collection)
metering-infra_hosts: *infra_block

# aodh (telemetry alarm service)
metering-alarm_hosts: *infra_block

# gnocchi (telemetry metrics storage)
metrics_hosts: *infra_block

# ceilometer compute agent (telemetry data collection)
metering-compute_hosts: *compute_block
{% endif %}

{% if (osa_enable_object_storage | bool) and not (enable_ceph_storage | bool) %}
# swift storage hosts
swift_hosts: *swift_block

# swift infra hosts
swift-proxy_hosts: *infra_block
{% endif %}

{% if osa_enable_elk_metrics | bool %}
# kibana hosts
kibana_hosts: *infra_block

# elasticsearch/logstash hosts
elastic-logstash_hosts: *log_block

# apm hosts
apm-server_hosts: *log_block
{% endif %}

**********
DECISION===>: PASS
**********
=========================:::723:::END!!!=========================
=========================:::724:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/multi-node-aio/playbooks/osa/elk-envd.yml
**********
---
component_skel:
  apm-server:
    belongs_to:
      - elk_all
      - apm_all
  elastic-logstash:
    belongs_to:
      - elk_all
      - elasticsearch
      - elasticsearch_all
      - logstash
      - logstash_all
  kibana:
    belongs_to:
      - elk_all

container_skel:
  apm-server_container:
    belongs_to:
      - apm-server_containers
    contains:
      - apm-server
  elastic-logstash_container:
    belongs_to:
      - elastic-logstash_containers
    contains:
      - elastic-logstash
  kibana_container:
    belongs_to:
      - kibana_containers
    contains:
      - kibana

physical_skel:
  apm-server_containers:
    belongs_to:
      - all_containers
  apm-server_hosts:
    belongs_to:
      - hosts
  elastic-logstash_containers:
    belongs_to:
      - all_containers
  elastic-logstash_hosts:
    belongs_to:
      - hosts
  kibana_containers:
    belongs_to:
      - all_containers
  kibana_hosts:
    belongs_to:
      - hosts

**********
DECISION===>: PASS
**********
=========================:::724:::END!!!=========================
=========================:::725:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/multi-node-aio/playbooks/osa/user_mnaio_variables.yml
**********
---
# Tempest is being configured to use a known network
tempest_public_subnet_cidr: 10.0.248.0/26

# This makes running neutron in a distributed system easier and a lot less noisy
neutron_l2_population: True

{% if http_proxy is defined and http_proxy %}
proxy_env_url: "{{ http_proxy }}"

{% if global_environment_variables is defined and global_environment_variables | bool %}
{% raw %}
no_proxy_env: "localhost,127.0.0.1,{{ internal_lb_vip_address }},{{ external_lb_vip_address }},{% for host in groups['all_containers'] %}{{ hostvars[host]['container_address'] }}{% if not loop.last %},{% endif %}{% endfor %}"
global_environment_variables:
  HTTP_PROXY: "{{ proxy_env_url }}"
  HTTPS_PROXY: "{{ proxy_env_url }}"
  NO_PROXY: "{{ no_proxy_env }}"
  http_proxy: "{{ proxy_env_url }}"
  https_proxy: "{{ proxy_env_url }}"
  no_proxy: "{{ no_proxy_env }}"
{% endraw %}
{% endif %}

{% if deployment_environment_variables is defined and deployment_environment_variables | bool %}
{% raw %}
deployment_environment_variables:
  http_proxy: "{{ proxy_env_url }}"
  https_proxy: "{{ proxy_env_url }}"
  no_proxy: "localhost,127.0.0.1,{{ internal_lb_vip_address }},{{ external_lb_vip_address }},{% for host in groups['keystone_all'] %}{{ hostvars[host]['container_address'] }}{% if not loop.last %},{% endif %}{% endfor %}"
{% endraw %}
{% endif %}

glance_glance_api_conf_overrides:
  glance_store:
    http_proxy_information: "http:http://, https:http://"
{% endif %}

# Reduce memory footprint for mnaio
galera_innodb_buffer_pool_size: 1024M
galera_gcache_size: 128M

{% if enable_ceph_storage | bool %}
### Ceph Config Overrides
## Ceph cluster fsid (must be generated before first run)
generate_fsid: true

## ceph-ansible settings
## See https://github.com/ceph/ceph-ansible/tree/master/group_vars for
## additional configuration options availble.
monitor_address_block: 10.0.236.0/22
public_network: 10.0.236.0/22
cluster_network: 10.0.244.0/22
osd_scenario: lvm
journal_size: {{ ceph_journal_size }}
# ceph-ansible automatically creates pools & keys for OpenStack services
openstack_config: true
cinder_ceph_client: cinder
glance_ceph_client: glance
glance_default_store: rbd
glance_rbd_store_pool: images
nova_libvirt_images_rbd_pool: vms
{% raw %}
cinder_backends:
  ceph:
    volume_driver: cinder.volume.drivers.rbd.RBDDriver
    rbd_pool: volumes
    rbd_ceph_conf: /etc/ceph/ceph.conf
    rbd_store_chunk_size: 8
    volume_backend_name: rbddriver
    rbd_user: "{{ cinder_ceph_client }}"
    rbd_secret_uuid: "{{ cinder_ceph_client_uuid }}"
    report_discard_supported: true
{% endraw %}
{% endif %}

{% if osa_enable_elk_metrics | bool %}
# NOTE(d34dh0r53): The disk detection to determine the logstash_queue_type
# can fail spectacularly on an MNAIO so I'm hard setting it here to bypass
# the detection code.
{% raw %}
logstash_queue_type: memory
haproxy_extra_services:
  - service:
      haproxy_service_name: elastic-logstash
      haproxy_ssl: True
      haproxy_backend_nodes: "{{ groups['Kibana'] | default([]) }}"  # Kibana nodes are also Elasticsearch coordination nodes
      haproxy_port: 9201  # This is set using the "elastic_hap_port" variable
      haproxy_check_port: 9200  # This is set using the "elastic_port" variable
      haproxy_backend_port: 9200  # This is set using the "elastic_port" variable
      haproxy_balance_type: tcp
  - service:
      haproxy_service_name: Kibana
      haproxy_ssl: True
      haproxy_backend_nodes: "{{ groups['Kibana'] | default([]) }}"
      haproxy_port: 8443
      haproxy_backend_port: 81
      haproxy_balance_type: tcp
  - service:
      haproxy_service_name: apm-server
      haproxy_ssl: True
      haproxy_backend_nodes: "{{ groups['apm-server'] | default([]) }}"
      haproxy_port: 8200
      haproxy_balance_type: tcp
{% endraw %}
{% endif %}

{% if osa_enable_os_profiler | bool %}
{% raw %}
profiler_overrides: &os_profiler
  profiler:
    enabled: true
    trace_sqlalchemy: true
    hmac_keys: '{{ os_profiler_hmac_token }}'
    connection_string: "Elasticsearch://'{{ internal_lb_vip_address }}':9201"
    es_doc_type: "notification"
    es_scroll_time: "2m"
    es_scroll_size: "10000"
    filter_error_trace: "false"

aodh_aodh_conf_overrides: *os_profiler
barbican_config_overrides: *os_profiler
ceilometer_ceilometer_conf_overrides: *os_profiler
cinder_cinder_conf_overrides: *os_profiler
designate_designate_conf_overrides: *os_profiler
glance_glance_api_conf_overrides: *os_profiler
gnocchi_conf_overrides: *os_profiler
heat_heat_conf_overrides: *os_profiler
horizon_config_overrides: *os_profiler
ironic_ironic_conf_overrides: *os_profiler
keystone_keystone_conf_overrides: *os_profiler
magnum_config_overrides: *os_profiler
neutron_neutron_conf_overrides: *os_profiler
nova_nova_conf_overrides: *os_profiler
octavia_octavia_conf_overrides: *os_profiler
rally_config_overrides: *os_profiler
sahara_conf_overrides: *os_profiler
swift_swift_conf_overrides: *os_profiler
tacker_tacker_conf_overrides: *os_profiler
trove_config_overrides: *os_profiler
{% endraw %}
{% endif %}

{% if osa_enable_uwsgi_stats | bool %}
keystone_uwsgi_ini_overrides:
  uwsgi:
    stats: "/tmp/keystone-uwsgi-stats.sock"

cinder_api_uwsgi_ini_overrides:
  uwsgi:
    stats: "/tmp/cinder-api-uwsgi-stats.sock"

glance_api_uwsgi_ini_overrides:
  uwsgi:
    stats: "/tmp/glance-api-uwsgi-stats.sock"

heat_api_uwsgi_ini_overrides:
  uwsgi:
    stats: "/tmp/heat-api-uwsgi-stats.sock"

heat_api_cfn_init_overrides:
  uwsgi:
    stats: "/tmp/heat-api-cfn-uwsgi-stats.sock"

nova_api_metadata_uwsgi_ini_overrides:
  uwsgi:
    stats: "/tmp/nova-api-metadata-uwsgi-stats.sock"

nova_api_os_compute_uwsgi_ini_overrides:
  uwsgi:
    stats: "/tmp/nova-api-os-compute-uwsgi-stats.sock"

nova_placement_uwsgi_ini_overrides:
  uwsgi:
    stats: "/tmp/nova-placement-uwsgi-stats.sock"

octavia_api_uwsgi_ini_overrides:
  uwsgi:
    stats: "/tmp/octavia-api-uwsgi-stats.sock"

sahara_api_uwsgi_ini_overrides:
  uwsgi:
    stats: "/tmp/sahara-api-uwsgi-stats.sock"

ironic_api_uwsgi_ini_overrides:
  uwsgi:
    stats: "/tmp/ironic-api-uwsgi-stats.sock"

magnum_api_uwsgi_ini_overrides:
  uwsgi:
    stats: "/tmp/magnum-api-uwsgi-stats.sock"
{% endif %}

**********
DECISION===>: PASS
**********
=========================:::725:::END!!!=========================
=========================:::726:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/multi-node-aio/playbooks/osa/user_unserial_variables.yml
**********
cinder_api_serial: 100%
cinder_scheduler_serial: 100%
cinder_backend_serial: 100%
glance_api_serial: 100%
glance_registry_serial: 100%
neutron_server_serial: 100%
neutron_agent_serial: 100%
neutron_other_serial: 100%
nova_conductor_serial: 100%
nova_scheduler_serial: 100%
nova_api_serial: 100%
nova_console_serial: 100%
nova_compute_serial: 100%
nova_serial: 100%
#keystone_serial: 100%  # Do NOT enable due to race condition with authorized_keys module.


**********
DECISION===>: PASS
**********
=========================:::726:::END!!!=========================
=========================:::727:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/multi-node-aio/playbooks/host_vars/compute2.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in witing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

server_hostname: 'compute2'
server_vm_fixed_addr: '10.0.2.121'
server_mac_address: '52:54:00:bd:80:06'

server_networks:
  dhcp:
    iface: 'eth0'
    inet_type: 'dhcp'
    vm_int_iface: vm-br-dhcp
  mgmt:
    iface: 'eth1'
    inet_type: 'static'
    address: '10.0.236.121/22'
    vm_int_iface: vm-br-eth1
  flat:
    iface: 'eth2'
    inet_type: 'static'
    address: '10.0.248.121/22'
    vm_int_iface: vm-br-eth2
  vlan:
    iface: 'eth3'
    inet_type: 'manual'
    vm_int_iface: vm-br-eth3
  vxlan:
    iface: 'eth4'
    inet_type: 'static'
    address: '10.0.240.121/22'
    vm_int_iface: vm-br-eth4
  storage:
    iface: 'eth5'
    inet_type: 'static'
    address: '10.0.244.121/22'
    vm_int_iface: vm-br-eth5
  lbaas:
    iface: 'eth6'
    inet_type: 'static'
    address: '10.0.232.121/22'
    vm_int_iface: vm-br-eth6
**********
DECISION===>: PASS
**********
=========================:::727:::END!!!=========================
=========================:::728:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/multi-node-aio/playbooks/host_vars/compute1.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in witing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

server_hostname: 'compute1'
server_vm_fixed_addr: '10.0.2.120'
server_mac_address: '52:54:00:bd:80:05'

server_networks:
  dhcp:
    iface: 'eth0'
    inet_type: 'dhcp'
    vm_int_iface: vm-br-dhcp
  mgmt:
    iface: 'eth1'
    inet_type: 'static'
    address: '10.0.236.120/22'
    vm_int_iface: vm-br-eth1
  flat:
    iface: 'eth2'
    inet_type: 'static'
    address: '10.0.248.120/22'
    vm_int_iface: vm-br-eth2
  vlan:
    iface: 'eth3'
    inet_type: 'manual'
    vm_int_iface: vm-br-eth3
  vxlan:
    iface: 'eth4'
    inet_type: 'static'
    address: '10.0.240.120/22'
    vm_int_iface: vm-br-eth4
  storage:
    iface: 'eth5'
    inet_type: 'static'
    address: '10.0.244.120/22'
    vm_int_iface: vm-br-eth5
  lbaas:
    iface: 'eth6'
    inet_type: 'static'
    address: '10.0.232.120/22'
    vm_int_iface: vm-br-eth6
**********
DECISION===>: PASS
**********
=========================:::728:::END!!!=========================
=========================:::729:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/multi-node-aio/playbooks/host_vars/ceph3.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in witing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

ansible_os_family: "{{ images[default_vm_image]['image_type'] }}"

server_hostname: 'ceph3'
server_vm_fixed_addr: '10.0.2.162'
server_mac_address: '52:54:00:bd:80:15'

server_networks:
  dhcp:
    iface: 'eth0'
    inet_type: 'dhcp'
    vm_int_iface: vm-br-dhcp
  mgmt:
    iface: 'eth1'
    inet_type: 'static'
    address: '10.0.236.147/22'
    vm_int_iface: vm-br-eth1
  flat:
    iface: 'eth2'
    inet_type: 'static'
    address: '10.0.248.147/22'
    vm_int_iface: vm-br-eth2
  vlan:
    iface: 'eth3'
    inet_type: 'manual'
    vm_int_iface: vm-br-eth3
  vxlan:
    iface: 'eth4'
    inet_type: 'static'
    address: '10.0.240.147/22'
    vm_int_iface: vm-br-eth4
  storage:
    iface: 'eth5'
    inet_type: 'static'
    address: '10.0.244.147/22'
    vm_int_iface: vm-br-eth5

**********
DECISION===>: PASS
**********
=========================:::729:::END!!!=========================
=========================:::730:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/multi-node-aio/playbooks/host_vars/cinder1.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in witing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

server_hostname: 'cinder1'
server_vm_fixed_addr: '10.0.2.130'
server_mac_address: '52:54:00:bd:80:07'

server_networks:
  dhcp:
    iface: 'eth0'
    inet_type: 'dhcp'
    vm_int_iface: vm-br-dhcp
  mgmt:
    iface: 'eth1'
    inet_type: 'static'
    address: '10.0.236.130/22'
    vm_int_iface: vm-br-eth1
  flat:
    iface: 'eth2'
    inet_type: 'static'
    address: '10.0.248.130/22'
    vm_int_iface: vm-br-eth2
  vlan:
    iface: 'eth3'
    inet_type: 'manual'
    vm_int_iface: vm-br-eth3
  vxlan:
    iface: 'eth4'
    inet_type: 'static'
    address: '10.0.240.130/22'
    vm_int_iface: vm-br-eth4
  storage:
    iface: 'eth5'
    inet_type: 'static'
    address: '10.0.244.130/22'
    vm_int_iface: vm-br-eth5

**********
DECISION===>: PASS
**********
=========================:::730:::END!!!=========================
=========================:::731:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/multi-node-aio/playbooks/host_vars/ceph2.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in witing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

ansible_os_family: "{{ images[default_vm_image]['image_type'] }}"

server_hostname: 'ceph2'
server_vm_fixed_addr: '10.0.2.161'
server_mac_address: '52:54:00:bd:80:14'

server_networks:
  dhcp:
    iface: 'eth0'
    inet_type: 'dhcp'
    vm_int_iface: vm-br-dhcp
  mgmt:
    iface: 'eth1'
    inet_type: 'static'
    address: '10.0.236.146/22'
    vm_int_iface: vm-br-eth1
  flat:
    iface: 'eth2'
    inet_type: 'static'
    address: '10.0.248.146/22'
    vm_int_iface: vm-br-eth2
  vlan:
    iface: 'eth3'
    inet_type: 'manual'
    vm_int_iface: vm-br-eth3
  vxlan:
    iface: 'eth4'
    inet_type: 'static'
    address: '10.0.240.146/22'
    vm_int_iface: vm-br-eth4
  storage:
    iface: 'eth5'
    inet_type: 'static'
    address: '10.0.244.146/22'
    vm_int_iface: vm-br-eth5

**********
DECISION===>: PASS
**********
=========================:::731:::END!!!=========================
=========================:::732:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/multi-node-aio/playbooks/host_vars/cinder2.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in witing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

server_hostname: 'cinder2'
server_vm_fixed_addr: '10.0.2.131'
server_mac_address: '52:54:00:bd:80:08'

server_networks:
  dhcp:
    iface: 'eth0'
    inet_type: 'dhcp'
    vm_int_iface: vm-br-dhcp
  mgmt:
    iface: 'eth1'
    inet_type: 'static'
    address: '10.0.236.131/22'
    vm_int_iface: vm-br-eth1
  flat:
    iface: 'eth2'
    inet_type: 'static'
    address: '10.0.248.131/22'
    vm_int_iface: vm-br-eth2
  vlan:
    iface: 'eth3'
    inet_type: 'manual'
    vm_int_iface: vm-br-eth3
  vxlan:
    iface: 'eth4'
    inet_type: 'static'
    address: '10.0.240.131/22'
    vm_int_iface: vm-br-eth4
  storage:
    iface: 'eth5'
    inet_type: 'static'
    address: '10.0.244.131/22'
    vm_int_iface: vm-br-eth5

**********
DECISION===>: PASS
**********
=========================:::732:::END!!!=========================
=========================:::733:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/multi-node-aio/playbooks/host_vars/ceph1.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in witing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

ansible_os_family: "{{ images[default_vm_image]['image_type'] }}"

server_hostname: 'ceph1'
server_vm_fixed_addr: '10.0.2.145'
server_mac_address: '52:54:00:bd:80:13'

server_networks:
  dhcp:
    iface: 'eth0'
    inet_type: 'dhcp'
    vm_int_iface: vm-br-dhcp
  mgmt:
    iface: 'eth1'
    inet_type: 'static'
    address: '10.0.236.145/22'
    vm_int_iface: vm-br-eth1
  flat:
    iface: 'eth2'
    inet_type: 'static'
    address: '10.0.248.145/22'
    vm_int_iface: vm-br-eth2
  vlan:
    iface: 'eth3'
    inet_type: 'manual'
    vm_int_iface: vm-br-eth3
  vxlan:
    iface: 'eth4'
    inet_type: 'static'
    address: '10.0.240.145/22'
    vm_int_iface: vm-br-eth4
  storage:
    iface: 'eth5'
    inet_type: 'static'
    address: '10.0.244.145/22'
    vm_int_iface: vm-br-eth5

**********
DECISION===>: PASS
**********
=========================:::733:::END!!!=========================
=========================:::734:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/multi-node-aio/playbooks/host_vars/loadbalancer1.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in witing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

server_hostname: 'loadbalancer1'
server_vm_fixed_addr: '10.0.2.150'
server_mac_address: '52:54:00:bd:80:12'

server_networks:
  dhcp:
    iface: 'eth0'
    inet_type: 'dhcp'
    vm_int_iface: vm-br-dhcp
  mgmt:
    iface: 'eth1'
    inet_type: 'static'
    address: '10.0.236.150/22'
    vm_int_iface: vm-br-eth1


**********
DECISION===>: PASS
**********
=========================:::734:::END!!!=========================
=========================:::735:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/multi-node-aio/playbooks/host_vars/swift3.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in witing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

server_hostname: 'swift3'
server_vm_fixed_addr: '10.0.2.142'
server_mac_address: '52:54:00:bd:80:11'

server_networks:
  dhcp:
    iface: 'eth0'
    inet_type: 'dhcp'
    vm_int_iface: vm-br-dhcp
  mgmt:
    iface: 'eth1'
    inet_type: 'static'
    address: '10.0.236.142/22'
    vm_int_iface: vm-br-eth1
  flat:
    iface: 'eth2'
    inet_type: 'static'
    address: '10.0.248.142/22'
    vm_int_iface: vm-br-eth2
  vlan:
    iface: 'eth3'
    inet_type: 'manual'
    vm_int_iface: vm-br-eth3
  vxlan:
    iface: 'eth4'
    inet_type: 'static'
    address: '10.0.240.142/22'
    vm_int_iface: vm-br-eth4
  storage:
    iface: 'eth5'
    inet_type: 'static'
    address: '10.0.244.142/22'
    vm_int_iface: vm-br-eth5

**********
DECISION===>: PASS
**********
=========================:::735:::END!!!=========================
=========================:::736:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/multi-node-aio/playbooks/host_vars/logging1.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in witing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

server_hostname: 'logging1'
server_vm_fixed_addr: '10.0.2.110'
server_mac_address: '52:54:00:bd:80:03'

server_networks:
  dhcp:
    iface: 'eth0'
    inet_type: 'dhcp'
    vm_int_iface: vm-br-dhcp
  mgmt:
    iface: 'eth1'
    inet_type: 'static'
    address: '10.0.236.110/22'
    vm_int_iface: vm-br-eth1
  flat:
    iface: 'eth2'
    inet_type: 'static'
    address: '10.0.248.110/22'
    vm_int_iface: vm-br-eth2
  vlan:
    iface: 'eth3'
    inet_type: 'manual'
    vm_int_iface: vm-br-eth3
  vxlan:
    iface: 'eth4'
    inet_type: 'static'
    address: '10.0.240.110/22'
    vm_int_iface: vm-br-eth4
  storage:
    iface: 'eth5'
    inet_type: 'static'
    address: '10.0.244.110/22'
    vm_int_iface: vm-br-eth5

**********
DECISION===>: PASS
**********
=========================:::736:::END!!!=========================
=========================:::737:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/multi-node-aio/playbooks/host_vars/infra1.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in witing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

server_hostname: 'infra1'                                   # str  - required, hostname of server
server_vm_fixed_addr: '10.0.2.100'                          # str  - not required, used to specify fixed address when using internal DHCPD
server_mac_address: '52:54:00:bd:80:00'                     # str  - required, mac address of default interface

server_networks:                        # dict - required, hash of networks, can be empty, key is used to name the networks.
  dhcp:
    iface: 'eth0'                       # str  - required, interface name
    inet_type: 'dhcp'                   # str  - required, iface type [static, dhcp, manual]
    vm_int_iface: vm-br-dhcp            # str  - not Required, used to specify an integration networks interface when provisioning a VM
  mgmt:
    iface: 'eth1'                       # str  - required, interface name
    inet_type: 'static'                 # str  - required, iface type [static, dhcp, manual]
    address: '10.0.236.100/22'          # str  - not required, must be in CIDR format
    vm_int_iface: vm-br-eth1            # str  - not Required, used to specify an integration networks interface when provisioning a VM
  flat:
    iface: 'eth2'                       # str  - required, interface name
    inet_type: 'static'                 # str  - required, iface type [static, dhcp, manual]
    address: '10.0.248.100/22'          # str  - not required, must be in CIDR format
    vm_int_iface: vm-br-eth2            # str  - not Required, used to specify an integration networks interface when provisioning a VM
  vlan:
    iface: 'eth3'                       # str  - required, interface name
    inet_type: 'manual'                 # str  - required, iface type [static, dhcp, manual]
    vm_int_iface: vm-br-eth3            # str  - not Required, used to specify an integration networks interface when provisioning a VM
  vxlan:
    iface: 'eth4'                       # str  - required, interface name
    inet_type: 'static'                 # str  - required, iface type [static, dhcp, manual]
    address: '10.0.240.100/22'          # str  - not required, must be in CIDR format
    vm_int_iface: vm-br-eth4            # str  - not Required, used to specify an integration networks interface when provisioning a VM
  storage:
    iface: 'eth5'                       # str  - required, interface name
    inet_type: 'static'                 # str  - required, iface type [static, dhcp, manual]
    address: '10.0.244.100/22'          # str  - not required, must be in CIDR format
    vm_int_iface: vm-br-eth5            # str  - not Required, used to specify an integration networks interface when provisioning a VM
  lbaas:
    iface: 'eth6'                       # str  - required, interface name
    inet_type: 'static'                 # str  - required, iface type [static, dhcp, manual]
    address: '10.0.232.100/22'          # str  - not required, must be in CIDR format
    vm_int_iface: vm-br-eth6            # str  - not Required, used to specify an integration networks interface when provisioning a VM

**********
DECISION===>: PASS
**********
=========================:::737:::END!!!=========================
=========================:::738:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/multi-node-aio/playbooks/host_vars/swift2.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in witing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

server_hostname: 'swift2'
server_vm_fixed_addr: '10.0.2.141'
server_mac_address: '52:54:00:bd:80:10'

server_networks:
  dhcp:
    iface: 'eth0'
    inet_type: 'dhcp'
    vm_int_iface: vm-br-dhcp
  mgmt:
    iface: 'eth1'
    inet_type: 'static'
    address: '10.0.236.141/22'
    vm_int_iface: vm-br-eth1
  flat:
    iface: 'eth2'
    inet_type: 'static'
    address: '10.0.248.141/22'
    vm_int_iface: vm-br-eth2
  vlan:
    iface: 'eth3'
    inet_type: 'manual'
    vm_int_iface: vm-br-eth3
  vxlan:
    iface: 'eth4'
    inet_type: 'static'
    address: '10.0.240.141/22'
    vm_int_iface: vm-br-eth4
  storage:
    iface: 'eth5'
    inet_type: 'static'
    address: '10.0.244.141/22'
    vm_int_iface: vm-br-eth5

**********
DECISION===>: PASS
**********
=========================:::738:::END!!!=========================
=========================:::739:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/multi-node-aio/playbooks/host_vars/infra3.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in witing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

server_hostname: 'infra3'
server_vm_fixed_addr: '10.0.2.102'
server_mac_address: '52:54:00:bd:80:02'

server_networks:
  dhcp:
    iface: 'eth0'
    inet_type: 'dhcp'
    vm_int_iface: vm-br-dhcp
  mgmt:
    iface: 'eth1'
    inet_type: 'static'
    address: '10.0.236.102/22'
    vm_int_iface: vm-br-eth1
  flat:
    iface: 'eth2'
    inet_type: 'static'
    address: '10.0.248.102/22'
    vm_int_iface: vm-br-eth2
  vlan:
    iface: 'eth3'
    inet_type: 'manual'
    vm_int_iface: vm-br-eth3
  vxlan:
    iface: 'eth4'
    inet_type: 'static'
    address: '10.0.240.102/22'
    vm_int_iface: vm-br-eth4
  storage:
    iface: 'eth5'
    inet_type: 'static'
    address: '10.0.244.102/22'
    vm_int_iface: vm-br-eth5
  lbaas:
    iface: 'eth6'
    inet_type: 'static'
    address: '10.0.232.102/22'
    vm_int_iface: vm-br-eth6
**********
DECISION===>: PASS
**********
=========================:::739:::END!!!=========================
=========================:::740:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/multi-node-aio/playbooks/host_vars/infra2.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in witing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

server_hostname: 'infra2'
server_vm_fixed_addr: '10.0.2.101'
server_mac_address: '52:54:00:bd:80:01'

server_networks:
  dhcp:
    iface: 'eth0'
    inet_type: 'dhcp'
    vm_int_iface: vm-br-dhcp
  mgmt:
    iface: 'eth1'
    inet_type: 'static'
    address: '10.0.236.101/22'
    vm_int_iface: vm-br-eth1
  flat:
    iface: 'eth2'
    inet_type: 'static'
    address: '10.0.248.101/22'
    vm_int_iface: vm-br-eth2
  vlan:
    iface: 'eth3'
    inet_type: 'manual'
    vm_int_iface: vm-br-eth3
  vxlan:
    iface: 'eth4'
    inet_type: 'static'
    address: '10.0.240.101/22'
    vm_int_iface: vm-br-eth4
  storage:
    iface: 'eth5'
    inet_type: 'static'
    address: '10.0.244.101/22'
    vm_int_iface: vm-br-eth5
  lbaas:
    iface: 'eth6'
    inet_type: 'static'
    address: '10.0.232.101/22'
    vm_int_iface: vm-br-eth6

**********
DECISION===>: PASS
**********
=========================:::740:::END!!!=========================
=========================:::741:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/multi-node-aio/playbooks/host_vars/swift1.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in witing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

server_hostname: 'swift1'
server_vm_fixed_addr: '10.0.2.140'
server_mac_address: '52:54:00:bd:80:09'

server_networks:
  dhcp:
    iface: 'eth0'
    inet_type: 'dhcp'
    vm_int_iface: vm-br-dhcp
  mgmt:
    iface: 'eth1'
    inet_type: 'static'
    address: '10.0.236.140/22'
    vm_int_iface: vm-br-eth1
  flat:
    iface: 'eth2'
    inet_type: 'static'
    address: '10.0.248.140/22'
    vm_int_iface: vm-br-eth2
  vlan:
    iface: 'eth3'
    inet_type: 'manual'
    vm_int_iface: vm-br-eth3
  vxlan:
    iface: 'eth4'
    inet_type: 'static'
    address: '10.0.240.140/22'
    vm_int_iface: vm-br-eth4
  storage:
    iface: 'eth5'
    inet_type: 'static'
    address: '10.0.244.140/22'
    vm_int_iface: vm-br-eth5

**********
DECISION===>: PASS
**********
=========================:::741:::END!!!=========================
=========================:::742:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/osquery/inventory.example.yml
**********
---
all:
  hosts:
    # Local host
    localhost:
      ansible_connection: local
      ansible_host: 127.0.0.1
      ansible_user: root

hosts:
  hosts:
    localhost: {}


mariadb_all:
  children:
    mariadb:
      hosts:
        localhost: {}


fleet_all:
  children:
    kolide-fleet_all:
      children:
        kolide-fleet:
          hosts:
            localhost: {}

**********
DECISION===>: PASS
**********
=========================:::742:::END!!!=========================
=========================:::743:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/osquery/ansible-role-requirements.yml
**********
---
- name: systemd_service
  scm: git
  src: https://git.openstack.org/openstack/ansible-role-systemd_service
  version: master
- name: config_template
  scm: git
  src: https://git.openstack.org/openstack/ansible-config_template
  version: master
- name: redis
  scm: git
  src: https://github.com/geerlingguy/ansible-role-redis
  version: master
- name: galera_client
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-galera_client
  version: master
- name: galera_server
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-galera_server
  version: master
- name: apt_package_pinning
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-apt_package_pinning
  version: master
- name: plugins
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-plugins
  version: master

**********
DECISION===>: PASS
**********
=========================:::743:::END!!!=========================
=========================:::744:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/osquery/tests/ansible-role-requirements.yml
**********
---
- name: apt_package_pinning
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-apt_package_pinning
  version: master
- name: config_template
  scm: git
  src: https://git.openstack.org/openstack/ansible-config_template
  version: master
- name: nspawn_container_create
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-nspawn_container_create
  version: master
- name: nspawn_hosts
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-nspawn_hosts
  version: master
- name: plugins
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-plugins
  version: master
- name: systemd_mount
  scm: git
  src: https://git.openstack.org/openstack/ansible-role-systemd_mount
  version: master
- name: systemd_networkd
  scm: git
  src: https://git.openstack.org/openstack/ansible-role-systemd_networkd
  version: master
- name: systemd_service
  scm: git
  src: https://git.openstack.org/openstack/ansible-role-systemd_service
  version: master

**********
DECISION===>: PASS
**********
=========================:::744:::END!!!=========================
=========================:::745:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/osquery/tests/inventory/test-metal-inventory.yml
**********
---
all:
  hosts:
    # Local host
    localhost:
      ansible_connection: local
      ansible_host: 127.0.0.1
      ansible_user: root

hosts:
  hosts:
    localhost: {}


mariadb_all:
  children:
    mariadb:
      hosts:
        localhost: {}


fleet_all:
  children:
    kolide-fleet_all:
      children:
        kolide-fleet:
          hosts:
            localhost: {}

**********
DECISION===>: PASS
**********
=========================:::745:::END!!!=========================
=========================:::746:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/osquery/tests/inventory/test-container-inventory.yml
**********
---
all:
  hosts:
    # Local host
    localhost:
      ansible_connection: local
      ansible_host: 127.0.0.1
      ansible_user: root

    kolide-fleet0:
      ansible_host: 172.29.236.100
      ansible_user: root

    kolide-fleet1:
      ansible_host: 172.29.236.101
      ansible_user: root

    kolide-fleet2:
      ansible_host: 172.29.236.102
      ansible_user: root


hosts:
  vars:
    physical_host: localhost
    management_cidr: "172.29.236.0/24"
    container_networks:
      management_address:
        address: "172.29.236.1"
        netmask: "255.255.255.0"
        bridge: "{{ hostvars[physical_host]['ansible_default_ipv4']['alias'] }}"

  hosts:
    localhost: {}


all_containers:
  vars:
    physical_host: localhost
    container_tech: nspawn
    container_networks:
      management_address:
        address: "{{ ansible_host }}"
        netmask: "255.255.255.0"
        bridge: "{{ hostvars[physical_host]['ansible_default_ipv4']['alias'] }}"

  children:
    mariadb_all:
      children:
        mariadb:
          hosts:
            kolide-fleet0: {}
            kolide-fleet1: {}
            kolide-fleet2: {}

    fleet_all:
      children:
        kolide-fleet_all:
          children:
            kolide-fleet:
              hosts:
                kolide-fleet0: {}
                kolide-fleet1: {}
                kolide-fleet2: {}

**********
DECISION===>: PASS
**********
=========================:::746:::END!!!=========================
=========================:::747:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/osquery/roles/osquery/vars/redhat.yml
**********
---
osquery_required_packages:
  - logrotate

osquery_packages:
  - osquery
  - rsyslog

osquery_debug_packages:
  - osquery-debuginfo

_osquery_repository: "{{ osquery_repository | default('https://pkg.osquery.io/rpm/osquery-s3-rpm.repo') }}"
_osquery_repositorykey: "{{ osquery_repositorykey | default('https://pkg.osquery.io/rpm/GPG') }}"

varlog_group: root
varlog_mode: '0755'

**********
DECISION===>: PASS
**********
=========================:::747:::END!!!=========================
=========================:::748:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/osquery/roles/osquery/vars/debian.yml
**********
---
osquery_required_packages:
  - apt-transport-https
  - dirmngr
  - logrotate

osquery_packages:
  - osquery
  - rsyslog

osquery_debug_packages:
  - osquery-dbg

_osquery_repository: "{{ osquery_repository | default('deb [arch=amd64] https://pkg.osquery.io/deb deb main') }}"
_osquery_repositorykey: "{{ osquery_repositorykey | default('1484120AC4E9F8A1A577AEEE97A80C63C9D8B80B') }}"

varlog_group: syslog
varlog_mode: '0775'

**********
DECISION===>: Hardcoded Secret
**********
=========================:::748:::END!!!=========================
=========================:::749:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/osquery/roles/osquery/tasks/osquery_apt.yml
**********
---
- name: Ensure dirmngr is present for apt-key
  package:
    name: "{{ osquery_required_packages }}"
    state: present

- name: Download osquery APT key
  become: yes
  apt_key:
    keyserver: keyserver.ubuntu.com
    id: "{{ _osquery_repositorykey }}"
    state: present
  tags:
    - osquery

- name: Configure osquery APT repository
  become: yes
  apt_repository:
    repo: "{{ _osquery_repository }}"
    state: present
  tags:
    - osquery

**********
DECISION===>: PASS
**********
=========================:::749:::END!!!=========================
=========================:::750:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/osquery/roles/osquery/tasks/osquery_yum.yml
**********
---
- name: Install osquery repository
  get_url:
    url: "{{ _osquery_repository }}"
    dest: "/etc/yum.repos.d/{{ _osquery_repository | basename }}"
    mode: '0644'
    backup: yes

- name: Install osquery repository key
  rpm_key:
    state: present
    key: "{{ _osquery_repositorykey }}"

**********
DECISION===>: PASS
**********
=========================:::750:::END!!!=========================
=========================:::751:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/osquery/roles/osquery/tasks/osquery_dnf.yml
**********
---
- name: Install osquery repository
  get_url:
    url: "{{ _osquery_repository }}"
    dest: "/etc/yum.repos.d/{{ _osquery_repository | basename }}"
    mode: '0644'
    backup: yes

- name: Install osquery repository key
  rpm_key:
    state: present
    key: "{{ _osquery_repositorykey }}"

**********
DECISION===>: PASS
**********
=========================:::751:::END!!!=========================
=========================:::752:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/osquery/roles/osquery/tasks/osquery_configure.yml
**********
---
- name: Ensure directories exist
  file:
    dest: "/var/osquery"
    state: directory
    mode: "0755"

- name: Ensure target syslog dir exists
  file:
    dest: "/var/log/osquery"
    state: directory
    mode: "{{ varlog_mode }}"
    group: "{{ varlog_group }}"

- name: Push extra osquery packs file
  template:
    src: "{{ item }}.conf.j2"
    dest: "/usr/share/osquery/packs/{{ item | basename }}.conf"
    backup: yes
  with_items: "{{ osquery_upload_packs }}"
  notify:
    - restart osquery

- name: Print osquery packs
  debug: var=osquery_packs

- name: Configure osquery
  template:
    src: "osquery.conf.j2"
    dest: /etc/osquery/osquery.conf
    mode: '0644'
    backup: yes
    validate: 'osqueryi --config_path %s --config_check --verbose'
  notify:
    - restart osquery

- name: Express the osquery secret to disk
  lineinfile:
    path: "/etc/osquery/osquery_enroll_secret"
    line: "{{ osquery_enroll_secret }}"
    state: present
    owner: "root"
    group: "root"
    mode: "0600"
    create: true
  notify:
    - restart osquery
  when:
    - osquery_enroll_secret is defined

- name: Configure osquery flags
  template:
    src: "osquery.flags.j2"
    dest: /etc/osquery/osquery.flags
    mode: '0644'
    backup: yes
  notify:
    - restart osquery

- name: Re-validate whole osquery config
  command: 'osqueryi --config_path /etc/osquery/osquery.conf --config_check --verbose'
  changed_when: false
  register: confcheck
  failed_when: "'error' in confcheck.stdout or 'fail' in confcheck.stdout"

- name: Add logrotate configuration for osquery log
  copy:
    src: logrotate-osquery
    dest: /etc/logrotate.d/osquery
    mode: '0644'
    backup: yes

- name: Review inotify sysctl settings for osquery
  sysctl:
    name: "{{ item.n }}"
    value: "{{ item.v }}"
    sysctl_set: yes
    state: present
    reload: yes
    sysctl_file: /etc/sysctl.d/99-osquery.conf
  failed_when: false
  with_items:
    - n: 'fs.inotify.max_user_watches'
      v: 524288
    - n: 'fs.inotify.max_user_instances'
      v: 256
    - n: 'fs.inotify.max_queued_events'
      v: 32768

**********
DECISION===>: PASS
**********
=========================:::752:::END!!!=========================
=========================:::753:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/osquery/roles/osquery/tasks/main.yml
**********
---
- name: Gather variables for each operating system
  include_vars: "{{ item }}"
  with_first_found:
    - "{{ ansible_distribution | lower }}-{{ ansible_distribution_version | lower }}.yml"
    - "{{ ansible_distribution | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
    - "{{ ansible_os_family | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
    - "{{ ansible_distribution | lower }}.yml"
    - "{{ ansible_os_family | lower }}-{{ ansible_distribution_version.split('.')[0] }}.yml"
    - "{{ ansible_os_family | lower }}.yml"
  tags:
    - always

- include_tasks: "osquery_{{ ansible_pkg_mgr }}.yml"

- name: Install osquery
  package:
    name: "{{ osquery_packages }}"
    state: present

- name: Install osquery debug packages
  package:
    name: "{{ item }}"
    state: present
  with_items: "{{ osquery_debug_packages }}"
  when:
    - osquery_debug_packages_install | bool

- include: osquery_configure.yml
  tags:
    - osquery
    - config

**********
DECISION===>: PASS
**********
=========================:::753:::END!!!=========================
=========================:::754:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/osquery/roles/osquery/meta/main.yml
**********
---
galaxy_info:
  author: Kevin Brebanov
  description: Installs osquery
  company:

  # If the issue tracker for your role is not on github, uncomment the
  # next line and provide a value
  # issue_tracker_url: http://example.com/issue/tracker

  # Some suggested licenses:
  # - BSD (default)
  # - MIT
  # - GPLv2
  # - GPLv3
  # - Apache
  # - CC-BY
  license: BSD

  min_ansible_version: 1.9

  # Optionally specify the branch Galaxy will use when accessing the GitHub
  # repo for this role. During role install, if no tags are available,
  # Galaxy will use this branch. During import Galaxy will access files on
  # this branch. If travis integration is cofigured, only notification for this
  # branch will be accepted. Otherwise, in all cases, the repo's default branch
  # (usually master) will be used.
  github_branch: master

  #
  # Below are all platforms currently available. Just uncomment
  # the ones that apply to your role. If you don't see your
  # platform on this list, let us know and we'll get it added!
  #
  platforms:
  - name: EL
    versions:
  #  - all
  #  - 5
    - 6
    - 7
  #- name: GenericUNIX
  #  versions:
  #  - all
  #  - any
  #- name: Solaris
  #  versions:
  #  - all
  #  - 10
  #  - 11.0
  #  - 11.1
  #  - 11.2
  #  - 11.3
  #- name: Fedora
  #  versions:
  #  - all
  #  - 16
  #  - 17
  #  - 18
  #  - 19
  #  - 20
  #  - 21
  #  - 22
  #  - 23
  #- name: Windows
  #  versions:
  #  - all
  #  - 2012R2
  #- name: SmartOS
  #  versions:
  #  - all
  #  - any
  #- name: opensuse
  #  versions:
  #  - all
  #  - 12.1
  #  - 12.2
  #  - 12.3
  #  - 13.1
  #  - 13.2
  #- name: Amazon
  #  versions:
  #  - all
  #  - 2013.03
  #  - 2013.09
  #- name: GenericBSD
  #  versions:
  #  - all
  #  - any
  #- name: FreeBSD
  #  versions:
  #  - all
  #  - 8.0
  #  - 8.1
  #  - 8.2
  #  - 8.3
  #  - 8.4
  #  - 9.0
  #  - 9.1
  #  - 9.1
  #  - 9.2
  #  - 9.3
  #  - 10.0
  #  - 10.1
  #  - 10.2
  - name: Ubuntu
    versions:
  #  - all
  #  - lucid
  #  - maverick
  #  - natty
  #  - oneiric
  #  - precise
  #  - quantal
  #  - raring
  #  - saucy
    - trusty
  #  - utopic
  #  - vivid
  #  - wily
    - xenial
  #- name: SLES
  #  versions:
  #  - all
  #  - 10SP3
  #  - 10SP4
  #  - 11
  #  - 11SP1
  #  - 11SP2
  #  - 11SP3
  #- name: GenericLinux
  #  versions:
  #  - all
  #  - any
  #- name: Debian
  #  versions:
  #  - all
  #  - etch
  #  - jessie
  #  - lenny
  #  - squeeze
  #  - wheezy

  galaxy_tags:
    - monitoring
    - system
    # List tags for your role here, one per line. A tag is
    # a keyword that describes and categorizes the role.
    # Users find roles by searching for tags. Be sure to
    # remove the '[]' above if you add tags to this list.
    #
    # NOTE: A tag is limited to a single word comprised of
    # alphanumeric characters. Maximum 20 tags per role.

dependencies: []
  # List your role dependencies here, one per line.
  # Be sure to remove the '[]' above if you add dependencies
  # to this list.

**********
DECISION===>: violation of privacy
**********
=========================:::754:::END!!!=========================
=========================:::755:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/osquery/roles/osquery/defaults/main.yml
**********
---
# Enable or disable the installation of the osquery debug packages.
osquery_debug_packages_install: false

osquery_upload_packs:
  - osquery-snapshots-pack
  - osquery-monitoring2-pack

osquery_packs:
  - "osquery-monitoring"
  - "incident-response"
  - "it-compliance"
  - "ossec-rootkit"
  - "vuln-management"
  - "hardware-monitoring"
  - "osquery-snapshots-pack"
  - "osquery-monitoring2-pack"

# osquery_flags:
#   - '--enroll_secret_path=/etc/osquery/osquery_enroll_secret'
#   - '--tls_server_certs=/etc/osquery/kolide.crt'
#   - '--tls_hostname=acme.kolide.co'
#   - '--host_identifier=hostname'
#   - '--enroll_tls_endpoint=/api/v1/osquery/enroll'
#   - '--config_plugin=tls'
#   - '--config_tls_endpoint=/api/v1/osquery/config'
#   - '--config_tls_refresh=10'
#   - '--disable_distributed=false'
#   - '--distributed_plugin=tls'
#   - '--distributed_interval=10'
#   - '--distributed_tls_max_attempts=3'
#   - '--distributed_tls_read_endpoint=/api/v1/osquery/distributed/read'
#   - '--distributed_tls_write_endpoint=/api/v1/osquery/distributed/write'
#   - '--logger_plugin=tls'
#   - '--logger_tls_endpoint=/api/v1/osquery/log'
#   - '--logger_tls_period=10'
osquery_flags: []

## Take care if using a lot /tmp. can trigger
## 'Expiring events for subscriber: file_events (overflowed limit 1000)'
## => losing many queries results (fim or not)
osquery_fim_filepaths:
  - name: homes_sshdir
    list:
      - "/root/.ssh/%%"
      - "/home/%/.ssh/%%"
      - "/home/lib/%/.ssh/%%"
  - name: etc
    list:
      - "/etc/%%"
  - name: bin
    list:
      - "/bin/%%"
      - "/sbin/%%"
      - "/usr/bin/%%"
      - "/usr/sbin/%%"
      - "/usr/local/bin/%%"
      - "/usr/local/sbin/%%"
      - "/opt/bin/%%"
      - "/opt/sbin/%%"
  - name: webroot
    list:
      - "/var/www/%%"

osquery_fim_excludepaths:
  - name: tmp
    list:
      - /tmp/too_many_events/

## queries snapshots: 1/week
## Max interval 1/w: https://github.com/theopolis/osquery/commit/b76dee8a1fddccb500bc4a058daa1b39083b9dbb
osquery_snapshot_interval: 604800
osquery_snapshot_interval2: 604800

osquery_options:
  options:
    ## Splay the scheduled interval for queries.
    ## This is very helpful to prevent system performance impact when scheduling
    ## large numbers of queries that run a smaller or similar intervals.
    schedule_splay_percent: 10
    ## Clear events from the osquery backing store after a number of seconds.
    events_expiry: 3600
    ## Enable debug or verbose debug output when logging.
    verbose: false
    ## The number of threads for concurrent query schedule execution.
    worker_threads: 2
    ## Enable schedule profiling, this will fill in averages and totals for
    ## system/user CPU time and memory for every query in the schedule.
    ## Add a query: "select * from osquery_schedule" to record the performances.
    enable_monitor: true
    logger_snapshot_event_type: true
  ## Define a schedule of queries:
  schedule:
    ## This is a simple example query that outputs basic system information.
    system_info:
      ## The exact query to run.
      query: "SELECT hostname, cpu_brand, physical_memory FROM system_info;"
      ## The interval in seconds to run this query, not an exact interval.
      interval: 3600
    fim:
      query: "select * from file_events;"
      removed: false
      ## fim query interval
      interval: 900
  ## Decorators are normal queries that append data to every query.
  decorators:
    load:
      - "SELECT uuid AS host_uuid FROM system_info;"
      - "SELECT user AS username FROM logged_in_users ORDER BY time DESC LIMIT 1;"

**********
DECISION===>: PASS
**********
=========================:::755:::END!!!=========================
=========================:::756:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/osquery/roles/osquery/handlers/main.yml
**********
---
- name: Enable and stop the service
  systemd:
    name: osqueryd
    enabled: true
    state: stopped
  listen: restart osquery

- name: Enable and start the service
  systemd:
    name: osqueryd
    enabled: true
    state: started
  listen: restart osquery

- name: Enable and start the service
  systemd:
    name: rsyslog
    enabled: true
    state: restarted
  listen: restart rsyslog

**********
DECISION===>: PASS
**********
=========================:::756:::END!!!=========================
=========================:::757:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/osquery/roles/fleet/vars/debian.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

kolide_fleet_distro_packages:
  - apt-transport-https
  - ca-certificates
  - curl
  - python3-openssl
  - python-openssl
  - software-properties-common
  - unzip
**********
DECISION===>: PASS
**********
=========================:::757:::END!!!=========================
=========================:::758:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/osquery/roles/fleet/tasks/fleetMigrateDB.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Migrate the fleet database
  command: /usr/local/bin/fleet prepare db --config=/etc/fleet/fleet_config.yml  --no-prompt
  changed_when: false
  run_once: true
  register: _fleetctl_db_task
  until: _fleetctl_db_task is success
  retries: 3
  delay: 2

**********
DECISION===>: PASS
**********
=========================:::758:::END!!!=========================
=========================:::759:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/osquery/roles/fleet/tasks/fleetSSLkeyCreate.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Remove self signed certs and keys for regen
  file:
    dest: "{{ item }}"
    state: "absent"
  when:
    - kolide_fleet_ssl_key_purge | bool
  with_items:
    - "{{ kolide_fleet_ssl_cert }}"
    - "{{ kolide_fleet_ssl_key }}"
    - "{{ kolide_fleet_ssl_pem }}"
    - "{{ kolide_fleet_ssl_ca_cert }}"

- name: SSL Block
  block:
    - name: Generate service private key
      openssl_privatekey:
        path: "{{ kolide_fleet_ssl_key }}"
        size: 4096

    - name: Generate self signed CSR
      openssl_csr:
        path: "{{ kolide_fleet_ssl_csr }}"
        privatekey_path: "{{ kolide_fleet_ssl_key }}"
        common_name: "{{ ansible_domain }}"
        country_name: XX
        locality_name: Kolide-Server
        organization_name: OpenStack
        organizational_unit_name: OpenStack-Ansible-OPS

    - name: Generate a Self Signed OpenSSL certificate
      openssl_certificate:
        path: "{{ kolide_fleet_ssl_cert }}"
        privatekey_path: "{{ kolide_fleet_ssl_key }}"
        csr_path: "{{ kolide_fleet_ssl_csr }}"
        provider: selfsigned
        force: "{{ kolide_fleet_ssl_key_purge | bool }}"
        issuer:
          O: OpenStack-Ansible-OPS

    - name: Fetch Certificates
      fetch:
        flat: yes
        src: "{{ item.src }}"
        dest: "{{ item.dest }}"
      with_items:
        - src: "{{ kolide_fleet_ssl_csr }}"
          dest: "/tmp/{{ kolide_fleet_ssl_csr | basename }}"
        - src: "{{ kolide_fleet_ssl_cert }}"
          dest: "/tmp/{{ kolide_fleet_ssl_cert | basename }}"
        - src: "{{ kolide_fleet_ssl_key }}"
          dest: "/tmp/{{ kolide_fleet_ssl_key | basename }}"
      when:
        - (groups['kolide-fleet_all'] | length) > 1
      notify:
        - Cleanup certifactes
  when:
    - inventory_hostname == groups['kolide-fleet_all'][0]

- name: Copy certifactes over
  copy:
    src: "{{ item.src }}"
    dest: "{{ item.dest }}"
  with_items:
    - dest: "{{ kolide_fleet_ssl_csr }}"
      src: "/tmp/{{ kolide_fleet_ssl_csr | basename }}"
    - dest: "{{ kolide_fleet_ssl_cert }}"
      src: "/tmp/{{ kolide_fleet_ssl_cert | basename }}"
    - dest: "{{ kolide_fleet_ssl_key }}"
      src: "/tmp/{{ kolide_fleet_ssl_key | basename }}"
  when:
    - inventory_hostname != groups['kolide-fleet_all'][0]
    - (groups['kolide-fleet_all'] | length) > 1

**********
DECISION===>: PASS
**********
=========================:::759:::END!!!=========================
=========================:::760:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/osquery/roles/fleet/tasks/fleetServerInstall.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: create fleet dir
  file:
    path: "{{ item }}"
    state: directory
  with_items:
    - /etc/fleet
    - /etc/fleet/ssl
    - /etc/ssl/private

- name: Drop fleet conf file
  template:
    src: templates/fleet_config.yml.j2
    dest: /etc/fleet/fleet_config.yml
  notify:
    - Restart kolide (systemd)
  tags:
    - fleet_config

- name: Ensure required disto packages are installed
  package:
    name: "{{ kolide_fleet_distro_packages }}"
    state: "present"
    update_cache: "{{ (ansible_pkg_mgr == 'apt') | ternary('yes', omit) }}"
  register: _package_task
  until: _package_task is success
  retries: 3
  delay: 2
  tags:
    - package_install

- name: Create fleet dir
  file:
    path: '/tmp/fleet_{{ kolide_fleet_version }}'
    state: directory

- name: GET fleet
  get_url:
    url: "{{ kolide_fleet_url }}/{{ kolide_fleet_version }}/fleet_{{ kolide_fleet_version }}.zip"
    dest: "/var/cache/fleet_{{ kolide_fleet_version }}.zip"
  register: _get_task
  until: _get_task is success
  retries: 3
  delay: 2
  tags:
    - package_install

- name: Unarchive Fleet binaries
  unarchive:
    src: '/var/cache/fleet_{{ kolide_fleet_version }}.zip'
    dest: '/tmp/fleet_{{ kolide_fleet_version }}/'
    remote_src: yes
  notify:
    - Restart kolide (systemd)

- name: Copy unarchived binaries
  copy:
    src: '/tmp/fleet_{{ kolide_fleet_version }}/linux/{{ item }}'
    dest: '/usr/local/bin/'
    mode: '0755'
    owner: 'root'
    group: 'root'
    remote_src: yes
  with_items:
  - 'fleet'
  - 'fleetctl'

**********
DECISION===>: PASS
**********
=========================:::760:::END!!!=========================
=========================:::761:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/osquery/roles/fleet/tasks/fleetService.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Run the systemd service role
  include_role:
    name: systemd_service
    private: true
  vars:
    systemd_service_restart_changed: false
    systemd_services:
      - service_name: "kolide-fleet"
        execstarts:
          - /usr/local/bin/fleet serve --config=/etc/fleet/fleet_config.yml
        config_overrides:
          Unit:
            Wants: network-online.target
            Requires: redis-server.service
          Service:
            Slice: kolide-fleet.slice
  tags:
    - server-install

- name: Place the kolide-fleet socket
  template:
    src: 'kolide-fleet-proxy.socket.j2'
    dest: '/etc/systemd/system/kolide-fleet-proxy.socket'
  notify:
    - Restart kolide (systemd)

- name: Place the kolide-fleet proxy
  template:
    src: 'kolide-fleet-proxy.service.j2'
    dest: '/etc/systemd/system/kolide-fleet-proxy.service'
  notify:
    - Restart kolide (systemd)

**********
DECISION===>: PASS
**********
=========================:::761:::END!!!=========================
=========================:::762:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/osquery/roles/fleet/tasks/fleetSSL.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- include_tasks: fleetSSLkeyCreate.yml
  when:
    - kolide_fleet_user_ssl_cert is not defined or
      kolide_fleet_user_ssl_key is not defined

- name: Drop user provided ssl cert
  copy:
    src: "{{ kolide_fleet_user_ssl_cert }}"
    dest: "{{ kolide_fleet_ssl_cert }}"
    owner: "root"
    group: "root"
    mode: "0644"
  when:
    - kolide_fleet_user_ssl_cert is defined
  tags:
    - fleet-ssl

- name: Drop user provided ssl key
  copy:
    src: "{{ kolide_fleet_user_ssl_key }}"
    dest: "{{ kolide_fleet_ssl_key }}"
    owner: "root"
    group: "root"
    mode: "0640"
  when:
    - kolide_fleet_user_ssl_key is defined
  tags:
    - fleet-ssl

- name: Drop user provided ssl CA cert
  copy:
    src: "{{ kolide_fleet_user_ssl_ca_cert }}"
    dest: "{{ kolide_fleet_ssl_ca_cert }}"
    owner: "root"
    group: "root"
    mode: "0644"
  when:
    - kolide_fleet_user_ssl_ca_cert is defined
  tags:
    - fleet-ssl

**********
DECISION===>: PASS
**********
=========================:::762:::END!!!=========================
=========================:::763:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/osquery/roles/fleet/tasks/fleetRegisterAdmin.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: set fleetctl default context
  command: /usr/local/bin/fleetctl config set --address https://127.0.0.1:{{ kolide_fleet_port }} --tls-skip-verify
  changed_when: false
  register: _fleetctl_set_task
  until: _fleetctl_set_task is success
  retries: 3
  delay: 2

- name: register admin account
  command: /usr/local/bin/fleetctl setup --email {{ kolide_fleet_admin_email }} --password {{ kolide_fleet_admin_password }}
  register: fleet_register_admin
  changed_when:
    - fleet_register_admin.rc == 0
  failed_when:
    - fleet_register_admin.rc not in [0, 1]
  until: fleet_register_admin is success
  retries: 3
  delay: 2

- name: login admin account
  command: /usr/local/bin/fleetctl login --email {{ kolide_fleet_admin_email }} --password {{ kolide_fleet_admin_password }}
  changed_when: false
  register: _fleetctl_login_task
  until: _fleetctl_login_task is success
  retries: 3
  delay: 2

**********
DECISION===>: PASS
**********
=========================:::763:::END!!!=========================
=========================:::764:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/osquery/roles/fleet/tasks/createFleetDB.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Create DB for service
  mysql_db:
    login_user: "root"
    login_password: "{{ galera_root_password }}"
    login_host: "127.0.0.1"
    name: "{{ kolide_fleet_db_name }}"
    state: "present"
  delegate_to: "{{ groups['mariadb_all'][0] }}"
  no_log: False
  run_once: true

- name: Grant access to the DB for the service
  mysql_user:
    login_user: "root"
    login_password: "{{ galera_root_password }}"
    login_host: "127.0.0.1"
    name: "{{ kolide_fleet_db_user }}"
    password: "{{ kolide_fleet_db_password }}"
    host: "{{ item }}"
    state: "present"
    priv: "{{ kolide_fleet_db_name }}.*:ALL"
    append_privs: "{{ kolide_fleet_db_append_privs | default(omit) }}"
  delegate_to: "{{ groups['mariadb_all'][0] }}"
  with_items:
    - 'localhost'
    - '127.0.0.1'
    - '%'
  no_log: False
  run_once: true

**********
DECISION===>: hardcoded username
**********
=========================:::764:::END!!!=========================
=========================:::765:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/osquery/roles/fleet/tasks/main.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Gather variables for each operating system
  include_vars: "{{ item }}"
  with_first_found:
    - "{{ ansible_distribution | lower }}-{{ ansible_distribution_version | lower }}.yml"
    - "{{ ansible_distribution | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
    - "{{ ansible_os_family | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
    - "{{ ansible_distribution | lower }}.yml"
    - "{{ ansible_os_family | lower }}-{{ ansible_distribution_version.split('.')[0] }}.yml"
    - "{{ ansible_os_family | lower }}.yml"
  tags:
    - always

- name: Run the systemd service role
  include_role:
    name: redis
    private: true

# install kolide fleet server
- include_tasks: fleetServerInstall.yml

# install SSL certs
- include_tasks: createFleetDB.yml

# install SSL certs
- include_tasks: fleetSSL.yml

# add files for systemd
- include_tasks:  fleetService.yml

# migrate the database
- include_tasks:  fleetMigrateDB.yml

- name: Force kolide handlers
  meta: flush_handlers

# configure kolide fleet & set admin account
- include_tasks:  fleetRegisterAdmin.yml

**********
DECISION===>: PASS
**********
=========================:::765:::END!!!=========================
=========================:::766:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/osquery/roles/fleet/defaults/main.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Kolide Fleet vars
kolide_fleet_db_name: fleet
kolide_fleet_db_user: fleet

#kolide_fleet_db_password: fleetSecrete

kolide_fleet_port: "8443"
kolide_fleet_address: "127.0.0.1:{{ kolide_fleet_port }}"
kolide_fleet_version: "2.0.0"
kolide_fleet_url: "https://github.com/kolide/fleet/releases/download"

kolide_fleet_admin_email: admin@openstack.org

kolide_fleet_ssl_cert: /etc/ssl/certs/fleet.cert
kolide_fleet_ssl_key: /etc/ssl/private/fleet.key
kolide_fleet_ssl_csr: /etc/ssl/private/fleet.csr

kolide_fleet_ssl_protocol: "{{ ssl_protocol | default('ALL -SSLv2 -SSLv3') }}"
kolide_fleet_ssl_cipher_suite: "{{ ssl_cipher_suite | default('ECDH+AESGCM:DH+AESGCM:ECDH+AES256:DH+AES256:ECDH+AES128:DH+AES:RSA+AESGCM:RSA+AES:!aNULL:!MD5:!DSS') }}"

kolide_fleet_ssl_key_purge: false

**********
DECISION===>: PASS
**********
=========================:::766:::END!!!=========================
=========================:::767:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/osquery/roles/fleet/handlers/main.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Enable and restart kolide socket (systemd)
  systemd:
    name: "kolide-fleet-proxy.socket"
    enabled: true
    state: started
  listen: Restart kolide (systemd)

- name: Enable and restart kolide (systemd)
  systemd:
    name: "kolide-fleet.service"
    enabled: true
    state: restarted
  notify:
    - Enable and restart kolide proxy (systemd)
  listen: Restart kolide (systemd)

- name: Enable and restart kolide proxy (systemd)
  systemd:
    name: "kolide-fleet-proxy.service"
    enabled: true
    state: restarted
  listen: Restart kolide (systemd)

- name: Cleanup certifactes
  file:
    dest: "{{ item }}"
    state: "absent"
  delegate_to: localhost
  with_items:
    - "/tmp/{{ kolide_fleet_ssl_cert | basename }}"
    - "/tmp/{{ kolide_fleet_ssl_key | basename }}"
    - "/tmp/{{ kolide_fleet_ssl_csr | basename }}"

**********
DECISION===>: PASS
**********
=========================:::767:::END!!!=========================
=========================:::768:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/graylog/ansible-role-requirements.yml
**********
---
- name: elastic.elasticsearch
  src: https://github.com/elastic/ansible-elasticsearch.git
  version: 3bdcd8fe4d0afdc2da5e12475b2093bb2bb3326b

- name: jdauphant.nginx
  src: https://github.com/jdauphant/ansible-role-nginx.git
  version: 'v2.7.4'

- name: geerlingguy.java
  src: https://github.com/geerlingguy/ansible-role-java
  version: ebe72b1b52fe0053bb156fd1b29d044f2048556b

- name: Graylog2.graylog-ansible-role
  src: https://github.com/Graylog2/graylog-ansible-role.git
  version: e1159ec2712199f2da5768187cee84d1359bbd55

**********
DECISION===>: PASS
**********
=========================:::768:::END!!!=========================
=========================:::769:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/grafana/inventory.example.yml
**********
---

################################## ALL HOSTS ##################################
all:
  hosts:
    # Local host
    localhost:
      ansible_connection: local

################################## REQUIRED ###################################
    logging01:
      ansible_host: 172.16.27.100
      ansible_user: root

  vars: {}


################################### GROUPS ####################################

# The hosts group is used to target physical host machines. Enter all physical
# host machines here.
hosts:
  hosts:
    logging01:

# This is the location where grafana(s) will live
grafana:
  hosts:
    logging01:

**********
DECISION===>: PASS
**********
=========================:::769:::END!!!=========================
=========================:::770:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/cluster_metrics/playbook-metrics-lb.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Add haproxy config
  hosts: haproxy
  gather_facts: true
  user: root
  roles:
    - role: "haproxy_server"
      haproxy_service_configs:
        - service:
            haproxy_service_name: influxdb_admin
            haproxy_backend_nodes: "{{ groups['cluster-metrics'] | default([]) }}"
            haproxy_ssl: "{{ haproxy_ssl }}"
            haproxy_port: 8083
            haproxy_balance_type: tcp
            haproxy_backend_options:
              - tcp-check
            haproxy_whitelist_networks:
              - 192.168.0.0/16
              - 172.16.0.0/12
              - 10.0.0.0/8
        - service:
            haproxy_service_name: influxdb
            haproxy_backend_nodes: "{{ groups['cluster-metrics'] | default([]) }}"
            haproxy_ssl: "{{ haproxy_ssl }}"
            haproxy_port: 8086
            haproxy_backend_port: 8086
            haproxy_balance_type: http
            haproxy_backend_options:
              - "httpchk HEAD /ping"
            haproxy_whitelist_networks:
              - 192.168.0.0/16
              - 172.16.0.0/12
              - 10.0.0.0/8
            haproxy_acls:
              read_queries:
                rule: "path_sub -i query"
              write_queries:
                rule: "path_sub -i write"
                backend_name: "influxdb_relay"
        - service:
            haproxy_service_name: influxdb_relay
            haproxy_backend_nodes: "{{ groups['cluster-metrics'] | default([]) }}"
            haproxy_ssl: "{{ haproxy_ssl }}"
            haproxy_port: 8086
            haproxy_backend_port: 9096
            haproxy_balance_type: http
            haproxy_backend_options:
              - tcp-check
            haproxy_whitelist_networks:
              - 192.168.0.0/16
              - 172.16.0.0/12
              - 10.0.0.0/8
            haproxy_acls:
              write_queries:
                 rule: "path_sub -i write"
              read_queries:
                 rule: "path_sub -i query"
                 backend_name: "influxdb"

**********
DECISION===>: PASS
**********
=========================:::770:::END!!!=========================
=========================:::771:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/cluster_metrics/playbook-influx-db.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Deploy influxdb
  hosts: "cluster-metrics"
  gather_facts: true
  user: root
  tasks:
    - name: Check init system
      command: cat /proc/1/comm
      changed_when: false
      register: _pid1_name
      tags:
        - always
    - name: Set the name of pid1
      set_fact:
        pid1_name: "{{ _pid1_name.stdout }}"
      tags:
        - always
    - name: InfluxDB datapath bind mount
      lxc_container:
        name: "{{ inventory_hostname }}"
        container_command: |
          [[ ! -d "/var/lib/influxdb" ]] && mkdir -p "/var/lib/influxdb"
        container_config:
          - "lxc.mount.entry=/openstack/{{ inventory_hostname }} var/lib/influxdb none bind 0 0"
      delegate_to: "{{ physical_host }}"
    - name: Add influxdata apt-keys
      apt_key:
        url: "https://repos.influxdata.com/influxdb.key"
        state: "present"
    - name: Add influxdata repo
      apt_repository:
        repo: "deb https://repos.influxdata.com/{{ ansible_distribution | lower }} {{ ansible_distribution_release }} stable"
        state: "present"
        update_cache: yes
    - name: Install influxdb
      apt:
        pkg: "influxdb"
        state: "latest"
    - name: Drop influxdb config file
      template:
        src: templates/influxdb.conf.j2
        dest: /etc/influxdb/influxdb.conf
    - name: Enable and restart influxdb
      service:
        name: "influxdb"
        enabled: true
        state: restarted
    - name: Wait for influxdb to be ready
      wait_for:
        host: "{{ hostvars[item]['ansible_host'] }}"
        port: "{{ influxdb_port }}"
        delay: 1
      with_items: "{{ groups['cluster-metrics'] }}"
    - name: Create metrics DB
      shell: >
        influx -username {{ influxdb_db_root_name }}
        -password {{ influxdb_db_root_password }}
        -execute "{{ item }}"
      with_items:
        - "CREATE DATABASE {{ influxdb_db_name }}"
        - "CREATE RETENTION POLICY {{ influxdb_db_retention_policy }} ON {{ influxdb_db_name }} DURATION {{ influxdb_db_retention }} REPLICATION {{ influxdb_db_replication }}"
        - "CREATE USER {{ influxdb_db_metric_user }} WITH PASSWORD '{{ influxdb_db_metric_password }}'"
        - "GRANT ALL ON {{ influxdb_db_name }} TO {{ influxdb_db_metric_user }}"
    - name: Install git
      apt:
        pkg: "git"
        state: "latest"
    - name: Install GOLang
      script: files/deploy_go.sh
    - name: Download and install influx-relay
      script: files/deploy_influxdbrelay.sh
    - name: Drop influx relay toml file
      template:
        src: templates/relay.toml.j2
        dest: /opt/influxdb-relay/relay.toml
    - name: Drop Influx Relay upstart
      template:
        src: templates/influxdbrelay.conf.j2
        dest: /etc/init/influxdbrelay.conf
      when: pid1_name == "init"
    - name: Drop Influx Relay service file
      template:
        src: templates/influxdbrelay.service.j2
        dest: /etc/systemd/system/influxdbrelay.service
      when:  pid1_name == "systemd"
    - name: Enable and restart influxdb
      service:
        name: "influxdbrelay"
        state: restarted
  vars_files:
    - vars.yml


**********
DECISION===>: PASS
**********
=========================:::771:::END!!!=========================
=========================:::772:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/cluster_metrics/playbook-kapacitor.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Deploy kapacitor
  hosts: "cluster-metrics"
  gather_facts: true
  user: root
  tasks:
    - name: Add kapacitor repo
      apt_repository:
        repo: "deb https://repos.influxdata.com/{{ ansible_distribution | lower }} {{ ansible_distribution_release }} stable"
        state: "present"
        update_cache: yes
    - name: Install kapacitor
      apt:
        pkg: "kapacitor"
        state: "latest"
    - name: Drop kapacitor config file
      template:
        src: templates/kapacitor.conf.j2
        dest: /etc/kapacitor/kapacitor.conf
    - name: Start kapacitor server
      shell: kapacitord config > /etc/kapacitor/kapacitor.conf;kapacitord -config /etc/kapacitor/kapacitor.conf -log-file /var/log/kapacitor/kapacitor.log &
    - name: Copy tickscripts
      copy:
        src: /opt/openstack-ansible-ops/cluster_metrics/kapacitor_files
        dest: /opt/kapacitor/
    - name: Execute tickscripts
      shell: chmod 755 /opt/kapacitor/kapacitor_files/*.*;bash /opt/kapacitor/kapacitor_files/run_all.sh
  vars_files:
    - vars.yml

**********
DECISION===>: PASS
**********
=========================:::772:::END!!!=========================
=========================:::773:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/cluster_metrics/playbook-influx-telegraf.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Deploy telegraf
  hosts: "all:!elk_all"
  gather_facts: true
  user: root
  roles:
    - { role: openstack-ansible-telegraf }
  vars_files:
    - vars.yml
  vars:
    telegraf_output: influxdb
    telegraf_output_influxdb_database: "{{ influxdb_db_name }}"
    telegraf_output_influxdb_username: "{{ influxdb_db_metric_user }}"
    telegraf_output_influxdb_password: "{{ influxdb_db_metric_password }}"
    telegraf_openstack_scripts_data_format: influx
    commands : []
    telegraf_openstack_scripts:
      ironic:
        plugin_name: "ironic_nodes.py"
        plugin_source_path: "scripts/ironic_nodes.py"
        command:
          - "python /opt/telegraf/ironic_nodes.py"
        sudoers_entry:
          - "{{ telegraf_openstack_scripts_path }}/ironic_nodes.py"
        group: "{{ groups['utility_all'][0] }}"
        when_group: "{{ (groups['ironic_api'] | default([]) | length) > 0 }}"
      kvm:
        plugin_name: "kvm_virsh.py"
        plugin_source_path: "scripts/kvm_virsh.py"
        command:
          - "python /opt/telegraf/kvm_virsh.py"
        sudoers_entry:
          - "{{ telegraf_openstack_scripts_path }}/kvm_virsh.py"
        group: "{{ groups['nova_compute'] }}"
        when_group: "{{ (groups['nova_compute'] | default([]) | length) > 0 and (nova_virt_type | default('qemu') in ['kvm', 'qemu']) }}"
      cinder_pools_usage:
        plugin_name: "cinder_pools_usage.py"
        plugin_source_path: "scripts/cinder_pools_usage.py"
        command:
          - "python /opt/telegraf/cinder_pools_usage.py"
        sudoers_entry:
          - "{{ telegraf_openstack_scripts_path }}/cinder_pools_usage.py"
        group: "{{ groups['utility_all'][0] }}"
        when_group: "{{ (groups['cinder_volumes'] | default([]) | length) > 0 }}"
    telegraf_output_influxdb_targets:
      - "{{ influxdb_protocol|default('http') }}://{{ influxdb_host|default(hostvars[groups['cluster-metrics'][0]]['ansible_host']) }}:{{ influxdb_port }}"

**********
DECISION===>: PASS
**********
=========================:::773:::END!!!=========================
=========================:::774:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/pxelinux-provisioning/playbooks/setup-host.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in witing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Deploy PXE Host Setup
  hosts: pxe_hosts
  gather_facts: "{{ gather_facts | default(true) }}"
  pre_tasks:
    - name: Gather variables for each operating system
      include_vars: "{{ item }}"
      with_first_found:
        - "{{ playbook_dir }}/vars/{{ ansible_distribution | lower }}-{{ ansible_distribution_version | lower }}.yml"
        - "{{ playbook_dir }}/vars/{{ ansible_distribution | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
        - "{{ playbook_dir }}/vars/{{ ansible_os_family | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
        - "{{ playbook_dir }}/vars/{{ ansible_distribution | lower }}.yml"
        - "{{ playbook_dir }}/vars/{{ ansible_os_family | lower }}.yml"
      tags:
        - always

    - name: Install host distro packages
      package:
        pkg: "{{ item }}"
        state: "latest"
        update_cache: yes
        cache_valid_time: 600
      with_items: "{{ default_host_distro_packages }}"

  tasks:
    - name: Ensure root has a .ssh directory
      file:
        path: /root/.ssh
        state: directory
        owner: root
        group: root
        mode: 0700

    - name: Create ssh key pair for root
      user:
        name: root
        generate_ssh_key: yes
        ssh_key_bits: 2048
        ssh_key_file: /root/.ssh/id_rsa

    - name: Get root public key
      command: cat /root/.ssh/id_rsa.pub
      register: public_key_get
      changed_when: false

    - name: Set key facts
      set_fact:
        root_public_key: "{{ public_key_get.stdout }}"

    - name: Ensure root can ssh to localhost
      authorized_key:
        user: "root"
        key: "{{ root_public_key }}"

    - name: Add sysctl options
      sysctl:
        name: net.ipv4.ip_forward
        value: 1
        sysctl_set: yes
        state: present
        reload: yes
        sysctl_file: /etc/sysctl.conf

    - name: Start netfilter persistent
      systemd:
        name: "{{ default_host_iptables_service }}"
        state: started
        enabled: yes

    - name: Install repo caching server packages
      package:
        name: "{{ item }}"
        state: "latest"
      with_items: "{{ default_pkg_cache_server_distro_packages }}"

    - name: Create cache directory
      file:
        path: "/var/www/pkg-cache"
        state: "directory"
        owner: "apt-cacher-ng"
        group: "www-data"
        mode: "02775"

    - name: Stat the cache path
      stat:
        path: /var/cache/apt-cacher-ng
      register: acs

    - name: Remove cacher directory if its a directory
      file:
        path: "/var/cache/apt-cacher-ng"
        state: "absent"
      when:
        - acs.stat.isdir is defined and acs.stat.isdir

    - name: Link cacher to the repo path
      file:
        src: "/var/www/pkg-cache"
        dest: "/var/cache/apt-cacher-ng"
        state: "link"

    - name: create yum merged mirror list
      shell: |
        curl https://www.centos.org/download/full-mirrorlist.csv | sed 's/^.*"http:/http:/' | sed 's/".*$//' | grep ^http >/etc/apt-cacher-ng/centos_mirrors
        echo "http://mirror.centos.org/centos/" >>/etc/apt-cacher-ng/centos_mirrors

    - name: Drop acng.conf
      template:
        src: "templates/pxe/acng.conf.j2"
        dest: "/etc/apt-cacher-ng/acng.conf"
      notify:
        - reload acng

    - name: Drop apt package manager proxy
      copy:
        content: 'Acquire::http { Proxy "{{ default_mirror_proxy }}"; };'
        dest: "/etc/apt/apt.conf.d/00apt-cacher-proxy"

    - name: Update apt when proxy is added
      apt:
        update_cache: yes

  environment: "{{ deployment_environment_variables | default({}) }}"

  handlers:
    - name: reload acng
      service:
        name: "apt-cacher-ng"
        state: restarted
        enabled: yes

  tags:
    - setup-host

**********
DECISION===>: hardcoded location of ssh key pair
**********
=========================:::774:::END!!!=========================
=========================:::775:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/pxelinux-provisioning/playbooks/site.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in witing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- import_playbook: setup-host.yml
  when:
    - setup_host | default(true) | bool

- import_playbook: deploy-pxe.yml
  when:
    - setup_pxeboot | default(true) | bool

- import_playbook: deploy-dhcp.yml
  when:
    - setup_dhcpd | default(true) | bool

**********
DECISION===>: PASS
**********
=========================:::775:::END!!!=========================
=========================:::776:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/pxelinux-provisioning/playbooks/deploy-pxe.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in witing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Deploy PXE
  hosts: pxe_hosts
  gather_facts: "{{ gather_facts | default(true) }}"
  pre_tasks:
    - name: Gather variables for each operating system
      include_vars: "{{ item }}"
      with_first_found:
        - "{{ playbook_dir }}/vars/{{ ansible_distribution | lower }}-{{ ansible_distribution_version | lower }}.yml"
        - "{{ playbook_dir }}/vars/{{ ansible_distribution | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
        - "{{ playbook_dir }}/vars/{{ ansible_os_family | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
        - "{{ playbook_dir }}/vars/{{ ansible_distribution | lower }}.yml"
        - "{{ playbook_dir }}/vars/{{ ansible_os_family | lower }}.yml"
      tags:
        - always

    - name: Install host distro packages
      package:
        pkg: "{{ item }}"
        state: "latest"
        update_cache: yes
        cache_valid_time: 600
      with_items: "{{ default_pxe_distro_packages }}"

    - name: Create base directories
      file:
        path: "{{ item }}"
        state: directory
        owner: "root"
        group: "root"
        mode: "0755"
      with_items:
        - /var/www/pxe
        - /var/www/pxe/images
        - /var/www/pxe/iso
        - /var/www/pxe/networking
        - /var/www/pxe/scripts
        - /var/www/pxe/templates
        - /var/lib/tftpboot
        - /var/lib/tftpboot/boot-screens
        - /var/lib/tftpboot/preseed
        - /var/lib/tftpboot/pxelinux.cfg

    - name: Get root public key
      command: cat /root/.ssh/id_rsa.pub
      register: public_key_get
      changed_when: false
      when:
        - default_tftp_ssh_key is undefined

    - name: Set key facts
      set_fact:
        default_tftp_ssh_key: "{{ public_key_get.stdout }}"
      when:
        - default_tftp_ssh_key is undefined

  tasks:
    - name: Drop NGINX config
      copy:
        src: "templates/pxe/sites-enabled.default.j2"
        dest: /etc/nginx/sites-enabled/default
        mode: "0644"
        owner: root
        group: root
      notify:
        - restart nginx

    - name: Drop tftp-hpa configs
      copy:
        src: "templates/pxe/tftp/tftp-hpa.j2"
        dest: /etc/default/tftpd-hpa
        mode: "0644"
        owner: root
        group: root
      notify:
        - restart tftp-hpa

    - name: Drop inetd configs
      copy:
        src: "templates/pxe/tftp/inetd.conf.j2"
        dest: /etc/default/tftpd-hpa
        mode: "0644"
        owner: root
        group: root
      notify:
        - restart tftp-hpa

    - name: Download image iso(s)
      get_url:
        url: "{{ item.value.image_iso_url }}"
        dest: "/var/www/pxe/iso/{{ item.value.image_name }}"
      with_dict: "{{ default_images }}"

    - name: Clean image directory
      file:
        path: "/var/www/pxe/images/{{ item.value.image_short_name }}"
        state: absent
      with_dict: "{{ default_images }}"

    - name: Create image directory
      file:
        path: "/var/www/pxe/images/{{ item.value.image_short_name }}"
        state: directory
        owner: "root"
        group: "root"
        mode: "0755"
      with_dict: "{{ default_images }}"

    - name: Extract ISO(s) contents
      command: "7z x /var/www/pxe/iso/{{ item.value.image_name }}"
      args:
        chdir: "/var/www/pxe/images/{{ item.value.image_short_name }}"
      with_dict: "{{ default_images }}"

    - name: Download pxelinux
      get_url:
        url: "{{ default_pxelinux_url }}"
        dest: "/var/www/pxe/{{ default_pxelinux_name }}"
        tmp_dest: /tmp/

    - name: Clean pxe image directory
      file:
        path: "/var/www/pxe/{{ default_pxelinux_short_name }}"
        state: absent

    - name: Extract pxelinux contents
      command: "tar -xf /var/www/pxe/{{ default_pxelinux_name }}"
      args:
        chdir: "/var/www/pxe"

    - name: Drop pxelinux.cfg default menu
      copy:
        src: "templates/pxe/tftp/pxelinux.cfg.default.j2"
        dest: "{{ item }}"
        mode: "0644"
        owner: root
        group: root
      with_items:
        - /var/lib/tftpboot/pxelinux.cfg/default
        - /var/lib/tftpboot/boot-screens/syslinux.cfg

    # These links are using the shell command because the file module does not create hard links
    - name: Create hard links
      shell: |
        ln -f /var/www/pxe/{{ default_pxelinux_short_name }}/bios/com32/elflink/ldlinux/ldlinux.c32 /var/lib/tftpboot/ldlinux.c32
        ln -f /var/www/pxe/{{ default_pxelinux_short_name }}/bios/core/pxelinux.0 /var/lib/tftpboot/pxelinux.0
        ln -f /var/www/pxe/{{ default_pxelinux_short_name }}/bios/com32/lib/libcom32.c32 /var/lib/tftpboot/boot-screens/libcom32.c32
        ln -f /var/www/pxe/{{ default_pxelinux_short_name }}/bios/com32/libutil/libutil.c32 /var/lib/tftpboot/boot-screens/libutil.c32
        ln -f /var/www/pxe/{{ default_pxelinux_short_name }}/bios/com32/menu/vesamenu.c32 /var/lib/tftpboot/boot-screens/vesamenu.c32

    - name: Drop boot-screens default menu
      template:
        src: "templates/pxe/tftp/menu.cfg.j2"
        dest: /var/lib/tftpboot/boot-screens/menu.cfg
        mode: "0644"
        owner: root
        group: root

    - name: Drop tftp-hpa configs
      template:
        src: "templates/pxe/tftp/tftp-hpa.j2"
        dest: /etc/default/tftpd-hpa
        mode: "0644"
        owner: root
        group: root
      notify:
        - restart tftp-hpa

    - name: tftp configs for servers
      template:
        src: "templates/pxe/tftp/pxelinux.cfg.macaddr.j2"
        dest: "/var/lib/tftpboot/pxelinux.cfg/01-{{ hostvars[item]['server_mac_address'] | replace(':', '-') | upper }}"
        mode: "0644"
        owner: root
        group: root
      with_items: "{{ groups['pxe_servers'] }}"

    - name: Preseeds for pxe scripts
      template:
        src: "templates/pxe/{{ item.value.image_type }}/{{ item.value.image_preseed }}-post-install-script.sh.j2"
        dest: "/var/www/pxe/scripts/{{ item.value.image_preseed }}-post-install-script.sh"
        mode: "0644"
        owner: root
        group: root
      with_dict: "{{ default_images }}"

    - name: Preseeds for pxe
      template:
        src: "templates/pxe/{{ item.value.image_type }}/{{ item.value.image_preseed }}.preseed.j2"
        dest: "/var/lib/tftpboot/preseed/{{ item.value.image_preseed }}.preseed"
        mode: "0644"
        owner: root
        group: root
      with_dict: "{{ default_images }}"

    - name: Create netboot bind mount path
      file:
        path: "/var/lib/tftpboot/{{ item.value.image_short_name }}"
        state: directory
        owner: "root"
        group: "root"
        mode: "0755"
      with_dict: "{{ default_images }}"

    - name: Unbind mount netboot images
      mount:
        name: "/var/lib/tftpboot/{{ item.value.image_short_name }}"
        src: "/var/www/pxe/images/{{ item.value.image_netboot }}"
        opts: bind
        fstype: none
        state: unmounted
      register: fstab
      with_dict: "{{ default_images }}"

    - name: Ensure permissions are correct
      shell: |
        # Fix perms if needed
        find /var/lib/tftpboot -type d -exec chmod 0755 {} \;
        find /var/lib/tftpboot -type f -exec chmod 0644 {} \;
        find /var/www/pxe -type d -exec chmod 0755 {} \;

    - name: Bind mount netboot images
      mount:
        name: "/var/lib/tftpboot/{{ item.value.image_short_name }}"
        src: "/var/www/pxe/images/{{ item.value.image_netboot }}"
        opts: bind
        fstype: none
        state: mounted
      register: fstab
      with_dict: "{{ default_images }}"

  environment: "{{ deployment_environment_variables | default({}) }}"

  handlers:
    - name: restart nginx
      systemd:
        name: "nginx"
        state: restarted
        enabled: yes

    - name: restart tftp-hpa
      systemd:
        name: "tftpd-hpa"
        state: restarted
        enabled: yes

    - name: restart inetd
      systemd:
        name: "inetutils-inetd"
        state: restarted
        enabled: yes

  tags:
    - deploy-pxe

**********
DECISION===>: PASS
**********
=========================:::776:::END!!!=========================
=========================:::777:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/pxelinux-provisioning/playbooks/deploy-dhcp.yml
**********
---
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Deploy DHCP
  hosts: dhcp_hosts
  gather_facts: "{{ gather_facts | default(true) }}"
  pre_tasks:
    - name: Gather variables for each operating system
      include_vars: "{{ item }}"
      with_first_found:
        - "{{ playbook_dir }}/vars/{{ ansible_distribution | lower }}-{{ ansible_distribution_version | lower }}.yml"
        - "{{ playbook_dir }}/vars/{{ ansible_distribution | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
        - "{{ playbook_dir }}/vars/{{ ansible_os_family | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
        - "{{ playbook_dir }}/vars/{{ ansible_distribution | lower }}.yml"
        - "{{ playbook_dir }}/vars/{{ ansible_os_family | lower }}.yml"
      tags:
        - always

    - name: Install all required packages for dhcpd_install
      package:
        pkg: "{{ item }}"
        state: "latest"
        update_cache: yes
        cache_valid_time: 600
      with_items: "{{ default_dhcp_distro_packages }}"

    - name: Enable services
      systemd:
        name: "{{ item }}"
        enabled: yes
      with_items: "{{ default_dhcp_distro_packages }}"

  tasks:
    - name: Create a template in /etc/dhcp/dhcpd.conf
      template:
        src: templates/dhcp/dhcpd.conf.j2
        dest: /etc/dhcp/dhcpd.conf
        mode: 0644
        owner: root
        group: root
      notify: restart dhcpd

    - name: Create a template in /etc/dhcp/dhcpd.conf
      template:
        src: templates/dhcp/isc-dhcp-server.j2
        dest: /etc/default/isc-dhcp-server
        mode: 0644
        owner: root
        group: root
      notify: restart dhcpd

  environment: "{{ deployment_environment_variables | default({}) }}"

  handlers:
    - name: restart dhcpd
      systemd:
        name: "{{ item }}"
        state: restarted
      with_items: "{{ default_dhcp_distro_packages }}"

  tags:
    - deploy-dhcpd

**********
DECISION===>: PASS
**********
=========================:::777:::END!!!=========================
=========================:::778:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/pxelinux-provisioning/playbooks/idrac-config.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in witing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Run DRAC Config
  hosts: pxe_servers
  gather_facts: false
  connection: local
  tasks:
    - set_fact:
        racadm_path: "/opt/dell/srvadmin/sbin/racadm"
      tags:
        - always

    - name: check for racadm
      stat:
        path: "{{ racadm_path }}"
      register: racadm_command
      tags:
        - always

    - name: check for racadm_command
      fail:
        msg: "racadm command is not found."
      when:
        - not racadm_command.stat.exists
      tags:
        - always

    - set_fact:
        racadm: "{{ racadm_path }} -r {{ server_obm_ip }} -u root -p calvin"
      tags:
        - always

    - name: set cfgServerBootOnce
      command: "{{ racadm }} config -g cfgServerInfo -o cfgServerBootOnce 0"
      register: command
      until: command is success
      retries: 2
      delay: 2
      tags:
        - cfgServerFirstBootDevice

    - name: set cfgServerFirstBootDevice
      command: "{{ racadm }} config -g cfgServerInfo -o cfgServerFirstBootDevice HDD"
      register: command
      until: command is success
      retries: 2
      delay: 2
      tags:
        - cfgServerFirstBootDevice

    - name: set cfgServerBootOnce
      command: "{{ racadm }} config -g cfgServerInfo -o cfgServerBootOnce 1"
      register: command
      until: command is success
      retries: 2
      delay: 2
      tags:
        - cfgServerBootOnce

    - name: set cfgServerFirstBootDevice
      command: "{{ racadm }} config -g cfgServerInfo -o cfgServerFirstBootDevice PXE"
      register: command
      until: command is success
      retries: 2
      delay: 2
      tags:
        - cfgServerBootOnce

    - name: set cfgNicEnable
      command: "{{ racadm }} config -g cfgLanNetworking -o cfgNicEnable 1"
      register: command
      until: command is success
      retries: 2
      delay: 2
      tags:
        - cfgNicEnable

    - name: set cfgNicIPv4Enable
      command: "{{ racadm }} config -g cfgLanNetworking -o cfgNicIPv4Enable 1"
      register: command
      until: command is success
      retries: 2
      delay: 2
      tags:
        - cfgNicIPv4Enable

    - name: set cfgNicUseDhcp
      command: "{{ racadm }} config -g cfgLanNetworking -o cfgNicUseDhcp 0"
      register: command
      until: command is success
      retries: 2
      delay: 2
      tags:
        - cfgNicUseDhcp

    - name: set cfgNicVLanEnable
      command: "{{ racadm }} config -g cfgLanNetworking -o cfgNicVLanEnable 0"
      register: command
      until: command is success
      retries: 2
      delay: 2
      tags:
        - cfgNicVLanEnable

    - name: set cfgNicVLanID
      command: "{{ racadm }} config -g cfgLanNetworking -o cfgNicVLanID 1"
      register: command
      until: command is success
      retries: 2
      delay: 2
      tags:
        - cfgNicVLanID

    - name: set cfgNicVLanPriority
      command: "{{ racadm }} config -g cfgLanNetworking -o cfgNicVLanPriority 0"
      register: command
      until: command is success
      retries: 2
      delay: 2
      tags:
        - cfgNicVLanPriority

    - name: set cfgNicSelection
      command: "{{ racadm }} config -g cfgLanNetworking -o cfgNicSelection 2"
      register: command
      until: command is success
      retries: 2
      delay: 2
      tags:
        - cfgNicSelection

    - name: set cfgDNSServersFromDHCP
      command: "{{ racadm }} config -g cfgLanNetworking -o cfgDNSServersFromDHCP 0"
      register: command
      until: command is success
      retries: 2
      delay: 2
      tags:
        - cfgDNSServersFromDHCP

    - name: set cfgDNSRacName
      command: "{{ racadm }} config -g cfgLanNetworking -o cfgDNSRacName {{ server_hostname }}"
      register: command
      until: command is success
      retries: 2
      delay: 2
      tags:
        - cfgDNSRacName

    - name: set cfgNicIpAddress
      command: "{{ racadm }} config -g cfgLanNetworking -o cfgNicIpAddress {{ server_obm_ip }}"
      register: command
      until: command is success
      retries: 2
      delay: 2
      tags:
        - cfgNicIpAddress

    - name: set cfgDNSServer1
      command: "{{ racadm }} config -g cfgLanNetworking -o cfgDNSServer1 {{ server_gateway }}"
      register: command
      until: command is success
      retries: 2
      delay: 2
      tags:
        - cfgDNSServer1

    - name: set cfgDNSServer2
      command: "{{ racadm }} config -g cfgLanNetworking -o cfgDNSServer2 {{ server_dns }}"
      register: command
      until: command is success
      retries: 2
      delay: 2
      tags:
        - cfgDNSServer2

    - name: set cfgNicNetmask
      command: "{{ racadm }} config -g cfgLanNetworking -o cfgNicNetmask {{ server_netmask }}"
      register: command
      until: command is success
      retries: 2
      delay: 2
      tags:
        - cfgNicNetmask

    - name: set cfgNicGateway
      command: "{{ racadm }} config -g cfgLanNetworking -o cfgNicGateway {{ server_gateway }}"
      register: command
      until: command is success
      retries: 2
      delay: 2
      tags:
        - cfgNicGateway

    - name: set cfgDNSDomainName
      command: "{{ racadm }} config -g cfgLanNetworking -o cfgDNSDomainName {{ server_domain_name }}"
      register: command
      until: command is success
      retries: 2
      delay: 2
      tags:
        - cfgDNSDomainName

    - name: set cfgDNSDomainNameFromDHCP
      command: "{{ racadm }} config -g cfgLanNetworking -o cfgDNSDomainNameFromDHCP 0"
      register: command
      until: command is success
      retries: 2
      delay: 2
      tags:
        - cfgDNSDomainNameFromDHCP

    - name: set cfgDNSRegisterRac
      command: "{{ racadm }} config -g cfgLanNetworking -o cfgDNSRegisterRac 0"
      register: command
      until: command is success
      retries: 2
      delay: 2
      tags:
        - cfgDNSRegisterRac

    - name: set cfgIpmiLanEnable
      command: "{{ racadm }} config -g cfgIpmiLan -o cfgIpmiLanEnable 1"
      register: command
      until: command is success
      retries: 2
      delay: 2
      tags:
        - cfgIpmiLanEnable

    - name: set cfgIpmiLanPrivilegeLimit
      command: "{{ racadm }} config -g cfgIpmiLan -o cfgIpmiLanPrivilegeLimit 4"
      register: command
      until: command is success
      retries: 2
      delay: 2
      tags:
        - cfgIpmiLanPrivilegeLimit

    - name: set cfgIpmiLanAlertEnable
      command: "{{ racadm }} config -g cfgIpmiLan -o cfgIpmiLanAlertEnable 0"
      register: command
      until: command is success
      retries: 2
      delay: 2
      tags:
        - cfgIpmiLanAlertEnable

    - name: set cfgIpmiEncryptionKey
      command: "{{ racadm }} config -g cfgIpmiLan -o cfgIpmiEncryptionKey 0000000000000000000000000000000000000000"
      register: command
      until: command is success
      retries: 2
      delay: 2
      tags:
        - cfgIpmiEncryptionKey

    - name: set cfgIpmiPetCommunityName
      command: "{{ racadm }} config -g cfgIpmiLan -o cfgIpmiPetCommunityName public"
      register: command
      until: command is success
      retries: 2
      delay: 2
      tags:
        - cfgIpmiPetCommunityName

    - name: run sslresetcfg
      command: "{{ racadm }} sslresetcfg"
      register: command
      failed_when: not command.rc in [0, 2]
      until: command is success
      retries: 2
      delay: 2
      tags:
        - sslresetcfg

    - name: run serveraction powercycle
      command: "{{ racadm }} serveraction powercycle"
      register: command
      until: command is success
      retries: 2
      delay: 2
      when:
        - not inventory_hostname in groups['pxe_hosts']
      tags:
        - powercycle

    - name: run racreset
      command: "{{ racadm }} racreset"
      register: command
      until: command is success
      retries: 2
      delay: 2
      when:
        - not inventory_hostname in groups['pxe_hosts']
      tags:
        - racreset

**********
DECISION===>: hardcoded encryption key
**********
=========================:::778:::END!!!=========================
=========================:::779:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/pxelinux-provisioning/playbooks/inventory.yml
**********
---
################################## ALL HOSTS ##################################

all:
  vars:
    server_netmask: "255.255.255.0"
    server_gateway: "10.127.83.1"
    server_dns: "8.8.8.8"
    server_subnet: "10.127.83.0"

  hosts:
    # Local host
    localhost:
      ansible_host: 127.0.0.1

    # PXE Server
    n1:
      ansible_user: root

################################## PXE HOSTS ##################################

# The group "pxe_hosts" is used to setup all systems that will be responsible
#  for PXE boot. This will install all of the needed capabilities to TFTP serve
#  system images.
pxe_hosts:
  hosts:
    localhost: {}

dhcp_hosts:
  hosts:
    localhost: {}

################################# PXE TARGETS #################################

# The group "pxe_servers" is used for all servers that will be a PXE target.
pxe_servers:
  hosts:
    n1:
      ansible_os_family: "{{ default_images[default_image_name]['image_type'] }}"
      server_hostname: 'n1'
      server_image: "ubuntu-18.04-amd64"
      server_default_interface: 'eth0'
      server_obm_ip: 10.0.0.200
      server_model: PowerEdge R710
      server_mac_address: 00:11:22:33:44:55
      server_extra_options: ''
      server_fixed_addr: "10.0.0.100"
      server_domain_name: "{{ default_server_domain_name }}"
      ansible_host: "{{ server_fixed_addr }}"

**********
DECISION===>: PASS
**********
=========================:::779:::END!!!=========================
=========================:::780:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/pxelinux-provisioning/playbooks/vars/ubuntu-16.04.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in witing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

default_host_distro_packages:
  - bridge-utils
  - ifenslave
  - iptables-persistent
  - lvm2
  - ntp
  - openssh-server
  - python2.7
  - python-software-properties
  - python-netaddr
  - software-properties-common
  - vlan

default_pxe_distro_packages:
  - tftpd-hpa
  - inetutils-inetd
  - nginx
  - p7zip-full

default_dhcp_distro_packages:
  - isc-dhcp-server

default_pkg_cache_server_distro_packages:
  - apt-cacher-ng

default_host_iptables_service: "netfilter-persistent"

**********
DECISION===>: PASS
**********
=========================:::780:::END!!!=========================
=========================:::781:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/pxelinux-provisioning/playbooks/group_vars/all.yml
**********
---
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This is the default system root password. This should be changed.
default_root_password: secrete

# Depending on the kernel parameters passed into the physical machines when
# booted these options may be different or host specific.
default_interface: "{{ default_network | default('eth0') }}"
default_dhcp_interface: "{{ default_interface }}"

# To speed up the deployment apt-cacher NG is used on the pxe/dhcp server.
default_acng_bind_address: 0.0.0.0

# This is a mapping of OS familiies. While Ansible has a suitable interface
# for this it can vary in unpredictable ways. This setting it used to determine
# the type of preseed needed to deploy an given OS type.
default_os_families:
  ubuntu-16.04-amd64: debian
  ubuntu-18.04-amd64: debian

# Default setting for Apt-Cacher-NG.
default_mirror_proxy: 'http://{{ default_tftp_server }}:3142/'
default_mirror_hostname: archive.ubuntu.com
default_mirror_directory: /ubuntu

 # IP address, or domain name of the TFTP server
default_tftp_server: "{{ hostvars[groups['pxe_hosts'][0]]['ansible_host'] | default(ansible_host) }}"
# tftp_ssh_key: ''  # user defined ssh key, used to access the host
default_tftp_port: 69
default_tftp_boot_path: /pxelinux.0      # Path of where to boot from first

# Default ISO images
default_image_name: "ubuntu-18.04-amd64"
default_images:
  ubuntu-16.04-amd64:
    image_type: debian
    image_iso_url: "http://releases.ubuntu.com/16.04.2/ubuntu-16.04.2-server-amd64.iso"
    image_name: "ubuntu-16.04.2-server-amd64.iso"
    image_short_name: "ubuntu-16.04.2-server-amd64"
    image_default_boot: "ubuntu-16.04.2-server-amd64/amd64/boot-screens/menu.cfg"
    image_kernel_options: "biosdevname=0 net.ifnames=0 auto=true priority=critical quiet splash"
    image_kernel: "ubuntu-16.04.2-server-amd64/amd64/linux"
    image_initrd: "ubuntu-16.04.2-server-amd64/amd64/initrd.gz"
    image_netboot: "ubuntu-16.04.2-server-amd64/install/netboot/ubuntu-installer"
    image_preseed: basic
    image_preseed_option:
      url: "tftp://{{ default_tftp_server }}/preseed/basic.preseed"
  ubuntu-18.04-amd64:
    image_type: debian
    image_iso_url: "http://cdimage.ubuntu.com/ubuntu-server/daily/current/bionic-server-amd64.iso"
    image_name: "bionic-server-amd64.iso"
    image_short_name: "bionic-server-amd64"
    image_default_boot: "bionic-server-amd64/amd64/boot-screens/menu.cfg"
    image_kernel_options: "biosdevname=0 net.ifnames=0 auto=true priority=critical quiet splash"
    image_kernel: "bionic-server-amd64/amd64/linux"
    image_initrd: "bionic-server-amd64/amd64/initrd.gz"
    image_netboot: "bionic-server-amd64/install/netboot/ubuntu-installer"
    image_preseed: basic
    image_preseed_option:
      url: "tftp://{{ default_tftp_server }}/preseed/basic.preseed"

# PXELinux downloads. While pxelinux is available as a component of most distros
# the version may vary. This stabalizes on a known set.
default_pxelinux_url: "https://www.kernel.org/pub/linux/utils/boot/syslinux/syslinux-6.03.tar.gz"
default_pxelinux_name: "syslinux-6.03.tar.gz"
default_pxelinux_short_name: "syslinux-6.03"

# Default network / server setup used in DHCP
default_server_domain_name: "openstack.local"
default_server_netmask: "255.255.255.0"
default_server_gateway: "10.0.0.1"
default_server_dns: "8.8.8.8"
default_server_subnet: "10.0.0.0"

# List of DHCP Subnets - These are iterated though and each will be created
default_dhcp_default_lease_time: 21600                            # Default lease time
default_dhcp_max_lease_time: 43200                                # Max lease time

# DHCP system setup
default_dhcp_list:
  - netmask: "{{ default_server_netmask }}"                       # Netmask
    gateway: "{{ default_server_gateway }}"                       # Gateway
    dns: "{{ default_server_dns }}"                               # DNS
    subnet: "{{ default_server_subnet }}"                         # Subnet mask
    default_lease_time: "{{ default_dhcp_default_lease_time }}"   # Subnet Default lease time - The default is used if this is not defined
    max_lease_time: "{{ default_dhcp_max_lease_time }}"           # Subnet Max lease time - The default is used if this is not defined
    tftp_boot_path: /pxelinux.0                                   # Path for tftp of where to boot from first - The default is used if this is not defined
    tftp_server: "{{ default_tftp_server }}"                      # The server hosting the TFTP server - The default is used if this is not defined
    dhcp_default_domain_name: "{{ default_server_domain_name }}"  # Domain name

# Determine the root disk. This can be statically set. By default this function
# is run as an early command during preseed which will look at all active disks
# and use the first one.
default_root_disk: '$(fdisk -l | grep sd | grep -wo "dev.*:" | sed "s/\://" | head -n1)'

**********
DECISION===>: use of http without tls
**********
=========================:::781:::END!!!=========================
=========================:::782:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/prometheus/ansible-role-requirements.yml
**********
---
- name: node-exporter
  scm: git
  src: https://github.com/cloudalchemy/ansible-node-exporter
  version: master

**********
DECISION===>: PASS
**********
=========================:::782:::END!!!=========================
=========================:::783:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/ansible-role-requirements.yml
**********
---
- name: systemd_service
  scm: git
  src: https://git.openstack.org/openstack/ansible-role-systemd_service
  version: master
- name: systemd_mount
  scm: git
  src: https://git.openstack.org/openstack/ansible-role-systemd_mount
  version: master
- name: config_template
  scm: git
  src: https://git.openstack.org/openstack/ansible-config_template
  version: master

**********
DECISION===>: PASS
**********
=========================:::783:::END!!!=========================
=========================:::784:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/tests/ansible-role-requirements.yml
**********
---
- name: apt_package_pinning
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-apt_package_pinning
  version: master
- name: config_template
  scm: git
  src: https://git.openstack.org/openstack/ansible-config_template
  version: master
- name: nspawn_container_create
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-nspawn_container_create
  version: master
- name: nspawn_hosts
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-nspawn_hosts
  version: master
- name: plugins
  scm: git
  src: https://git.openstack.org/openstack/openstack-ansible-plugins
  version: master
- name: systemd_mount
  scm: git
  src: https://git.openstack.org/openstack/ansible-role-systemd_mount
  version: master
- name: systemd_networkd
  scm: git
  src: https://git.openstack.org/openstack/ansible-role-systemd_networkd
  version: master
- name: systemd_service
  scm: git
  src: https://git.openstack.org/openstack/ansible-role-systemd_service
  version: master

**********
DECISION===>: PASS
**********
=========================:::784:::END!!!=========================
=========================:::785:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/tests/inventory/test-metal-inventory.yml
**********
---
# The hosts group is used to target physical host machines. Enter all physical
# host machines here.
hosts:
  children:
    physical_hosts:
      hosts:
        localhost:
          ansible_host: 127.0.0.1
          ansible_user: root
      vars:
        physical_host: localhost

    elastic-logstash:
      hosts:
        localhost: {}

    kibana:
      hosts:
        localhost: {}

    apm-server:
      hosts:
        localhost: {}

**********
DECISION===>: PASS
**********
=========================:::785:::END!!!=========================
=========================:::786:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/tests/inventory/test-container-inventory.yml
**********
---
# The hosts group is used to target physical host machines. Enter all physical
# host machines here.
hosts:
  children:
    physical_hosts:
      hosts:
        localhost:
          ansible_host: 127.0.0.1
          ansible_user: root
      vars:
        physical_host: localhost
        management_cidr: "172.29.236.0/24"
        container_networks:
          management_address:
            address: "172.29.236.1"
            netmask: "255.255.255.0"
            bridge: "{{ hostvars[physical_host]['ansible_default_ipv4']['alias'] }}"


all_containers:
  vars:
    physical_host: localhost
    container_tech: nspawn
    container_networks:
      management_address:
        address: "{{ ansible_host }}"
        netmask: "255.255.255.0"
        bridge: "{{ hostvars[physical_host]['ansible_default_ipv4']['alias'] }}"
    # CI nodes havee limited resources, locking the memory is impossible.
    elastic_memory_lock: false

  children:
    elastic-logstash:
      children:
        kibana:
          hosts:
            elastic0:
              ansible_host: 172.29.236.100
              ansible_user: root

            elastic1:
              ansible_host: 172.29.236.101
              ansible_user: root

            elastic2:
              ansible_host: 172.29.236.102
              ansible_user: root

    apm-server:
      hosts:
        apm0:
          ansible_host: 172.29.236.120
          ansible_user: root

**********
DECISION===>: PASS
**********
=========================:::786:::END!!!=========================
=========================:::787:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_heartbeat/vars/redhat.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

heartbeat_distro_packages:
  - heartbeat-elastic

**********
DECISION===>: PASS
**********
=========================:::787:::END!!!=========================
=========================:::788:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_heartbeat/vars/suse.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

heartbeat_distro_packages:
  - heartbeat-elastic

**********
DECISION===>: PASS
**********
=========================:::788:::END!!!=========================
=========================:::789:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_heartbeat/vars/ubuntu.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

heartbeat_distro_packages:
  - heartbeat-elastic

**********
DECISION===>: PASS
**********
=========================:::789:::END!!!=========================
=========================:::790:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_heartbeat/tasks/heartbeat_setup.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Load templates
  shell: >-
    heartbeat setup
    {{ item }}
    -E 'output.logstash.enabled=false'
    -E 'output.elasticsearch.hosts={{ coordination_nodes | to_json }}'
    -E 'setup.template.enabled=true'
    -E 'setup.template.overwrite=true'
    -e -v
  with_items:
    - "--template"
    - "--pipelines"
    - "--machine-learning"
    - "--dashboards"
  register: templates
  until: templates is success
  retries: 5
  delay: 5
  run_once: true
  tags:
    - setup

**********
DECISION===>: PASS
**********
=========================:::790:::END!!!=========================
=========================:::791:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_heartbeat/tasks/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Gather variables for each operating system
  include_vars: "{{ item }}"
  with_first_found:
    - "{{ ansible_distribution | lower }}-{{ ansible_distribution_version | lower }}.yml"
    - "{{ ansible_distribution | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
    - "{{ ansible_os_family | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
    - "{{ ansible_distribution | lower }}.yml"
    - "{{ ansible_os_family | lower }}-{{ ansible_distribution_version.split('.')[0] }}.yml"
    - "{{ ansible_os_family | lower }}.yml"
  tags:
    - always

- name: Ensure beat is installed
  package:
    name: "{{ heartbeat_distro_packages }}"
    state: "{{ elk_package_state | default('present') }}"
    update_cache: "{{ (ansible_pkg_mgr == 'apt') | ternary('yes', omit) }}"
  register: _package_task
  until: _package_task is success
  retries: 3
  delay: 2
  when:
    - ansible_architecture == 'x86_64'
  notify:
    - Enable and restart heartbeat
  tags:
    - package_install

- name: Ensure beat is installed (aarch64)
  apt:
    deb: 'https://object-storage-ca-ymq-1.vexxhost.net/swift/v1/8709ca2640344a4ba85cba0a1d6eea69/aarch64/heartbeat-6.5.0-arm64.deb'
  when:
    - ansible_pkg_mgr == 'apt'
    - ansible_architecture == 'aarch64'
  notify:
    - Enable and restart heartbeat
  tags:
    - package_install

- name: Create heartbeat systemd service config dir
  file:
    path: "/etc/systemd/system/heartbeat.service.d"
    state: "directory"
    group: "root"
    owner: "root"
    mode: "0755"
  when:
    - ansible_service_mgr == 'systemd'

- name: Apply systemd options
  template:
    src: "{{ item.src }}"
    dest: "{{ item.dest }}"
    mode: "0644"
  when:
    - ansible_service_mgr == 'systemd'
  with_items:
    - src: "systemd.general-overrides.conf.j2"
      dest: "/etc/systemd/system/heartbeat.service.d/heartbeat-overrides.conf"
  notify:
    - Enable and restart heartbeat

- name: Create heartbeat configs
  template:
    src: "{{ item.src }}"
    dest: "{{ item.dest }}"
    mode: "0644"
  when:
    - ansible_service_mgr == 'systemd'
  with_items:
    - src: "heartbeat.yml.j2"
      dest: "/etc/heartbeat/heartbeat.yml"
  notify:
    - Enable and restart heartbeat

- include_tasks: heartbeat_setup.yml
  tags:
    - setup

- name: Force beat handlers
  meta: flush_handlers

- name: set heartbeat service state (upstart)
  service:
    name: "heartbeat-elastic"
    state: "{{ heartbeat_service_state }}"
    enabled: "{{ heartbeat_service_state in ['running', 'started', 'restarted'] }}"
  when:
    - ansible_service_mgr == 'upstart'
    - heartbeat_service_state in ['started', 'stopped']

- name: set heartbeat service state (systemd)
  systemd:
    name: "heartbeat-elastic"
    state: "{{ heartbeat_service_state }}"
    enabled: "{{ heartbeat_service_state in ['running', 'started', 'restarted'] }}"
  when:
    - ansible_service_mgr == 'systemd'
    - heartbeat_service_state in ['started', 'stopped']

**********
DECISION===>: PASS
**********
=========================:::791:::END!!!=========================
=========================:::792:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_heartbeat/meta/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

galaxy_info:
  author: OpenStack
  description: Elastic v6.x heartbeat role
  company: Rackspace
  license: Apache2
  min_ansible_version: 2.5
  platforms:
    - name: Ubuntu
      versions:
        - trusty
        - xenial
        - bionic
  categories:
    - cloud
    - development
    - elasticsearch
    - elastic-stack
dependencies:
  - role: elastic_data_hosts
  - role: elastic_repositories

**********
DECISION===>: PASS
**********
=========================:::792:::END!!!=========================
=========================:::793:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_heartbeat/defaults/main.yml
**********
---
# Copyright 2018, Vexxhost, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

heartbeat_service_state: restarted

**********
DECISION===>: PASS
**********
=========================:::793:::END!!!=========================
=========================:::794:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_heartbeat/handlers/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Enable and restart heartbeat (systemd)
  systemd:
    name: "heartbeat-elastic"
    enabled: true
    state: "{{ heartbeat_service_state }}"
    daemon_reload: true
  when:
    - ansible_service_mgr == 'systemd'
  listen: Enable and restart heartbeat

- name: Enable and restart heartbeat (upstart)
  service:
    name: "heartbeat-elastic"
    state: "{{ heartbeat_service_state }}"
    enabled: yes
  when:
    - ansible_service_mgr == 'upstart'
  listen: Enable and restart heartbeat

**********
DECISION===>: PASS
**********
=========================:::794:::END!!!=========================
=========================:::795:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_dependencies/vars/redhat.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

elastic_distro_packages:
  - java-1.8.0-openjdk

**********
DECISION===>: PASS
**********
=========================:::795:::END!!!=========================
=========================:::796:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_dependencies/vars/suse.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

elastic_distro_packages:
  - java-1_8_0-openjdk

**********
DECISION===>: PASS
**********
=========================:::796:::END!!!=========================
=========================:::797:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_dependencies/vars/vars_elasticsearch.yml
**********
---
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# The heap size is set using the a half of the total memory available with
# a cap of 32GiB. If the total available memory is less than 32GiB a buffer of
# 10% will be used to ensure the underlying system is not starved of memory.
_elastic_heap_size_default: "{{ ((h_mem | int) > 30720) | ternary(30720, ((h_mem | int) - ((h_mem | int) * 0.1))) }}"

**********
DECISION===>: PASS
**********
=========================:::797:::END!!!=========================
=========================:::798:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_dependencies/vars/ubuntu.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

elastic_distro_packages:
  - openjdk-8-jre

**********
DECISION===>: PASS
**********
=========================:::798:::END!!!=========================
=========================:::799:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_dependencies/vars/vars_logstash.yml
**********
---
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# The heap size is set using the a quarter of the total memory available with
# a cap of 32GiB. If the total available memory is less than 32GiB a buffer of
# 10% will be used to ensure the underlying system is not starved of memory.
_elastic_heap_size_default: "{{ ((q_mem | int) > 30720) | ternary(30720, ((q_mem | int) - ((q_mem | int) * 0.1))) }}"

**********
DECISION===>: PASS
**********
=========================:::799:::END!!!=========================
=========================:::800:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_dependencies/tasks/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Check for service_name var
  fail:
    msg: >-
      The required variable [ service_name ] is undefined.
  when:
    - service_name is undefined

- name: Check for service_owner var
  fail:
    msg: >-
      The required variable [ service_owner ] is undefined.
  when:
    - service_owner is undefined

- name: Check for service_group var
  fail:
    msg: >-
      The required variable [ service_group ] is undefined.
  when:
    - service_group is undefined

- name: Load service variables
  include_vars: "vars_{{ service_name }}.yml"

- name: Gather variables for each operating system
  include_vars: "{{ item }}"
  with_first_found:
    - "{{ ansible_distribution | lower }}-{{ ansible_distribution_version | lower }}.yml"
    - "{{ ansible_distribution | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
    - "{{ ansible_os_family | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
    - "{{ ansible_distribution | lower }}.yml"
    - "{{ ansible_os_family | lower }}-{{ ansible_distribution_version.split('.')[0] }}.yml"
    - "{{ ansible_os_family | lower }}.yml"
  tags:
    - always

- name: Set elastic heap defaults
  set_fact:
    elastic_heap_size_default: "{{ _elastic_heap_size_default }}"
    elastic_log_rotate_path: "/var/log/{{ service_name }}"

- name: Configure systcl vm.max_map_count=524288 on elastic hosts
  sysctl:
    name: "vm.max_map_count"
    value: "524288"
    state: "present"
    reload: "yes"
    sysctl_file: /etc/sysctl.d/99-elasticsearch.conf
  delegate_to: "{{ physical_host }}"
  tags:
    - sysctl

- name: Configure systcl fs.inotify.max_user_watches=1048576 on elastic hosts
  sysctl:
    name: "fs.inotify.max_user_watches"
    value: "1048576"
    state: "present"
    reload: "yes"
    sysctl_file: /etc/sysctl.d/99-elasticsearch.conf
  delegate_to: "{{ physical_host }}"
  tags:
    - sysctl

- name: Physical host block
  block:
    - name: Check for directory
      stat:
        path: "/var/lib/{{ service_name }}"
      register: service_dir

    - name: Check for data directory
      debug:
        msg: >-
          The service data directory [ /var/lib/{{ service_name }} ] already
          exists. To ensure no data is lost, the linked directory path to
          [ /openstack/{{ inventory_hostname }}/{{ service_name }} ] will not be
          created for this host.
      when:
        - service_dir.stat.isdir is defined and
          service_dir.stat.isdir

    - name: Ensure service directories data-path exists
      file:
        path: "/openstack/{{ inventory_hostname }}/{{ service_name }}"
        state: "directory"
        owner: "{{ service_owner }}"
        group: "{{ service_group }}"
      when:
        - service_dir.stat.isdir is defined and
          not service_dir.stat.isdir

    - name: Ensure data link exists
      file:
        src: "/openstack/{{ inventory_hostname }}/{{ service_name }}"
        dest: "/var/lib/{{ service_name }}"
        owner: "{{ service_owner }}"
        group: "{{ service_group }}"
        state: link
      when:
        - service_dir.stat.isdir is defined and
          not service_dir.stat.isdir
  when:
    - physical_host == inventory_hostname

- name: Container block
  block:
    - name: Ensure service directories data-path exists
      file:
        path: "/openstack/{{ inventory_hostname }}/{{ service_name }}"
        state: "directory"
      delegate_to: "{{ physical_host }}"
    - name: Pull lxc version
      command: "lxc-ls --version"
      delegate_to: "{{ physical_host }}"
      changed_when: false
      register: lxc_version
      when:
        - container_tech | default('lxc') == 'lxc'
      tags:
        - skip_ansible_lint
    - name: Enable or Disable lxc three syntax
      set_fact:
        lxc_major_version: "{{ lxc_version.stdout.split('.')[0] }}"
      when:
        - container_tech | default('lxc') == 'lxc'
    - name: elasticsearch datapath bind mount
      lxc_container:
        name: "{{ inventory_hostname }}"
        container_command: |
          [[ ! -d "/var/lib/{{ service_name }}" ]] && mkdir -p "/var/lib/{{ service_name }}"
        container_config:
          - "{{ elastic_lxc_template_config[(lxc_major_version | int)]['mount'] }}=/openstack/{{ inventory_hostname }}/{{ service_name }} var/lib/{{ service_name }} none bind 0 0"
          - "{{ elastic_lxc_template_config[(lxc_major_version | int)]['aa_profile'] }}=unconfined"
      delegate_to: "{{ physical_host }}"
      when:
        - container_tech | default('lxc') == 'lxc'
  when:
    - physical_host != inventory_hostname

- name: Ensure Java is installed
  package:
    name: "{{ elastic_distro_packages }}"
    state: "{{ elk_package_state | default('present') }}"
    install_recommends: "{{ (ansible_pkg_mgr == 'apt') | ternary('yes', omit) }}"
    update_cache: "{{ (ansible_pkg_mgr == 'apt') | ternary('yes', omit) }}"
  register: _package_task
  until: _package_task is success
  retries: 3
  delay: 2
  tags:
    - package_install

- name: Create the system group
  group:
    name: "{{ service_group }}"
    gid: "{{ service_group_gid | default(omit) }}"
    state: "present"
    system: "yes"

- name: Create the system user
  block:
    - name: Create the system user
      user:
        name: "{{ service_owner }}"
        uid: "{{ service_owner_uid | default(omit) }}"
        group: "{{ service_group }}"
        shell: "/bin/false"
        system: "yes"
        createhome: "yes"
        home: "/var/lib/{{ service_name }}"
  rescue:
    - name: Check for system user
      debug:
        msg: >-
          The general user creation task failed. This typically means that the
          user already exists and something in the user configuration provided
          is changing the system user in way that is simply not possible at this
          time. The playbooks will now simply ensure the user exists and before
          carrying on to the next task. While it's not required, it may be
          benificial to schedule a maintenance where the elastic services are
          stopped.

    - name: Ensure the system user exists
      user:
        name: "{{ service_owner }}"
        group: "{{ service_group }}"

- name: Ensure service directories exists
  file:
    path: "/etc/{{ service_name }}"
    state: "directory"
    owner: "{{ service_owner }}"
    group: "{{ service_group }}"

- name: Drop logrotate conf file(s)
  template:
    src: "{{ item.src }}"
    dest: "{{ item.dest }}"
  with_items:
    - src: "templates/logrotate.j2"
      dest: "/etc/logrotate.d/{{ service_name }}"

- name: Ensure host can resolve itself
  lineinfile:
    path: /etc/hosts
    regexp: '^{{ item }}'
    line: '{{ item }} {{ ansible_hostname }} {{ ansible_fqdn }}'
    owner: root
    group: root
    mode: 0644
  with_items:
    - "127.0.2.1"
    - "{{ ansible_host }}"

**********
DECISION===>: PASS
**********
=========================:::800:::END!!!=========================
=========================:::801:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_dependencies/meta/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

allow_duplicates: true
galaxy_info:
  author: OpenStack
  description: Elastic v6.x dependencies role
  company: Rackspace
  license: Apache2
  min_ansible_version: 2.5
  platforms:
    - name: Ubuntu
      versions:
        - trusty
        - xenial
        - bionic
  categories:
    - cloud
    - development
    - elasticsearch
    - elastic-stack
dependencies: []

**********
DECISION===>: PASS
**********
=========================:::801:::END!!!=========================
=========================:::802:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_dependencies/defaults/main.yml
**********
---
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

## Adds option to set the UID/GID of a given service user.
# service_group_gid: 5000
# service_owner_uid: 5000

# Option to define third memory
q_mem: "{{ (ansible_memtotal_mb | int) // 3 }}"

# Option to define half memory
h_mem: "{{ (ansible_memtotal_mb | int) // 2 }}"

#define this in host/group vars as needed to mount remote filesystems
#set the client address as appropriate, eth1 assumes osa container mgmt network
#mountpoints and server paths are just examples
#elastic_shared_fs_repos:
#  - fstype: nfs4
#    src: "<nfs-server-ip>:/esbackup"
#    opts: clientaddr="{{ ansible_eth1['ipv4']['address'] }}"
#    path: "/elastic-backup"
#    state: mounted

# NOTE(cloudnull) - When the heap size for a given elastic node is graeter than
#                   6GiB the G1 garbage collector can be enabled.
elastic_g1gc_enabled: true

elastic_lxc_template_config:
  3:
    aa_profile: lxc.apparmor.profile
    mount: lxc.mount.entry
  2:
    aa_profile: lxc.aa_profile
    mount: lxc.mount.entry

**********
DECISION===>: PASS
**********
=========================:::802:::END!!!=========================
=========================:::803:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_repositories/vars/redhat.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# elk apt repo
elastic_repo:
  repo: 'https://artifacts.elastic.co/packages/6.x/yum'
  state: "{{ ((elk_package_state | default('present')) == 'absent') | ternary('absent', 'present') }}"
  key_url: "https://artifacts.elastic.co/GPG-KEY-elasticsearch"

elastic_nginx_repo:
  repo: 'http://nginx.org/packages/centos/$releasever/$basearch/'
  state: "{{ ((elk_package_state | default('present')) == 'absent') | ternary('absent', 'present') }}"

**********
DECISION===>: PASS
**********
=========================:::803:::END!!!=========================
=========================:::804:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_repositories/vars/suse.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# elk apt repo
elastic_repo:
  repo: 'https://artifacts.elastic.co/packages/6.x/yum'
  state: "{{ ((elk_package_state | default('present')) == 'absent') | ternary('absent', 'present') }}"
  key_url: "https://artifacts.elastic.co/GPG-KEY-elasticsearch"

**********
DECISION===>: PASS
**********
=========================:::804:::END!!!=========================
=========================:::805:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_repositories/vars/ubuntu.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

elastic_repo_distro_packages:
  - apt-transport-https

# elk apt repo
elastic_repo:
  repo: 'deb https://artifacts.elastic.co/packages/6.x/apt stable main'
  state: "{{ ((elk_package_state | default('present')) == 'absent') | ternary('absent', 'present') }}"
  key_url: "https://artifacts.elastic.co/GPG-KEY-elasticsearch"

**********
DECISION===>: PASS
**********
=========================:::805:::END!!!=========================
=========================:::806:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_repositories/vars/ubuntu-14.04.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

elastic_repo_distro_packages:
  - apt-transport-https

elastic_repo_ppas:
  - "ppa:openjdk-r/ppa"

# elk apt repo
elastic_repo:
  repo: 'deb https://artifacts.elastic.co/packages/6.x/apt stable main'
  state: "{{ ((elk_package_state | default('present')) == 'absent') | ternary('absent', 'present') }}"
  key_url: "https://artifacts.elastic.co/GPG-KEY-elasticsearch"

**********
DECISION===>: PASS
**********
=========================:::806:::END!!!=========================
=========================:::807:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_repositories/tasks/elastic_apt_repos.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: add Elastic search public GPG key
  apt_key:
    url: "{{ elastic_repo.key_url }}"
    state: "present"
  register: _apt_task
  until: _apt_task is success
  retries: 3
  delay: 2
  tags:
    - package_install

- name: add elk repo to apt sources list
  apt_repository:
    repo: "{{ elastic_repo.repo }}"
    state: "{{ elastic_repo.state }}"
    filename: "{{ elastic_repo.filename | default(omit) }}"
  register: _apt_task
  until: _apt_task is success
  retries: 3
  delay: 2
  tags:
    - package_install

- name: Add PPA (legacy)
  apt_repository:
    repo: "{{ item }}"
  with_items: "{{ elastic_repo_ppas }}"

**********
DECISION===>: PASS
**********
=========================:::807:::END!!!=========================
=========================:::808:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_repositories/tasks/elastic_zypper_repos.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: add Elastic search public GPG key
  rpm_key:
    state: "{{ elastic_repo.state }}"
    key: "{{ elastic_repo.key_url }}"
  register: _zypp_task
  until: _zypp_task is success
  retries: 3
  delay: 2
  tags:
    - package_install

# Force refresh of a repository
- name: add elk repo to zypper sources list
  zypper_repository:
    name: "elastic"
    repo: "{{ elastic_repo.repo }}"
    state: "{{ elastic_repo.state }}"
    runrefresh: yes
  register: _zypp_task
  until: _zypp_task is success
  retries: 3
  delay: 2
  tags:
    - package_install

**********
DECISION===>: PASS
**********
=========================:::808:::END!!!=========================
=========================:::809:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_repositories/tasks/elastic_yum_repos.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Add Elastic search public GPG key
  rpm_key:
    state: "{{ elastic_repo.state }}"
    key: "{{ elastic_repo.key_url }}"
  register: _zypp_task
  until: _zypp_task is success
  retries: 3
  delay: 2
  tags:
    - package_install

# Force refresh of a repository
- name: Add elk repo to yum sources list
  yum_repository:
    name: "elastic"
    file: "elastic"
    description: "Elastic repositories, you know, for ELK."
    baseurl: "{{ elastic_repo.repo }}"
    state: "{{ elastic_repo.state }}"
    enabled: yes
  register: _yum_task
  until: _yum_task is success
  retries: 3
  delay: 2
  tags:
    - package_install

# Force refresh of a repository
- name: Add nginx repo to yum sources list
  yum_repository:
    name: "nginx"
    file: "nginx"
    description: "NGINX repo"
    baseurl: "{{ elastic_nginx_repo.repo }}"
    state: "{{ elastic_nginx_repo.state }}"
    enabled: yes
    gpgcheck: no
  register: _yum_task
  until: _yum_task is success
  retries: 3
  delay: 2
  tags:
    - package_install

**********
DECISION===>: PASS
**********
=========================:::809:::END!!!=========================
=========================:::810:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_repositories/tasks/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Gather variables for each operating system
  include_vars: "{{ item }}"
  with_first_found:
    - "{{ ansible_distribution | lower }}-{{ ansible_distribution_version | lower }}.yml"
    - "{{ ansible_distribution | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
    - "{{ ansible_os_family | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
    - "{{ ansible_distribution | lower }}.yml"
    - "{{ ansible_os_family | lower }}-{{ ansible_distribution_version.split('.')[0] }}.yml"
    - "{{ ansible_os_family | lower }}.yml"
  tags:
    - always

- name: Install repo disto packages
  package:
    name: "{{ elastic_repo_distro_packages }}"
    state: present
    update_cache: "{{ (ansible_pkg_mgr == 'apt') | ternary('yes', omit) }}"
  register: _apt_task
  until: _apt_task is success
  retries: 3
  delay: 2
  tags:
    - package_install

- include_tasks: "elastic_{{ ansible_pkg_mgr }}_repos.yml"

**********
DECISION===>: PASS
**********
=========================:::810:::END!!!=========================
=========================:::811:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_repositories/meta/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

galaxy_info:
  author: OpenStack
  description: Elastic v6.x repositories role
  company: Rackspace
  license: Apache2
  min_ansible_version: 2.5
  platforms:
    - name: Ubuntu
      versions:
        - trusty
        - xenial
        - bionic
  categories:
    - cloud
    - development
    - elasticsearch
    - elastic-stack
dependencies: []

**********
DECISION===>: PASS
**********
=========================:::811:::END!!!=========================
=========================:::812:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_repositories/defaults/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# List of PPA repositories used on ubuntu based systems
elastic_repo_ppas: []

# List of packages to install
elastic_repo_distro_packages: []

**********
DECISION===>: PASS
**********
=========================:::812:::END!!!=========================
=========================:::813:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_journalbeat/vars/redhat.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

journalbeat_distro_packages:
  - journalbeat

**********
DECISION===>: PASS
**********
=========================:::813:::END!!!=========================
=========================:::814:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_journalbeat/vars/suse.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

journalbeat_distro_packages:
  - journalbeat

**********
DECISION===>: PASS
**********
=========================:::814:::END!!!=========================
=========================:::815:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_journalbeat/vars/ubuntu.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

journalbeat_distro_packages:
  - journalbeat
**********
DECISION===>: PASS
**********
=========================:::815:::END!!!=========================
=========================:::816:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_journalbeat/tasks/journalbeat_setup.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Load templates
  shell: >-
    journalbeat setup
    {{ item }}
    -E 'output.logstash.enabled=false'
    -E 'output.elasticsearch.hosts={{ coordination_nodes | to_json }}'
    -E 'setup.template.enabled=true'
    -E 'setup.template.overwrite=true'
    -e -v
  with_items:
    - "--template"
    - "--pipelines"
    - "--machine-learning"
    - "--dashboards"
  register: templates
  until: templates is success
  retries: 5
  delay: 5
  run_once: true
  tags:
    - setup

**********
DECISION===>: PASS
**********
=========================:::816:::END!!!=========================
=========================:::817:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_journalbeat/tasks/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Gather variables for each operating system
  include_vars: "{{ item }}"
  with_first_found:
    - "{{ ansible_distribution | lower }}-{{ ansible_distribution_version | lower }}.yml"
    - "{{ ansible_distribution | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
    - "{{ ansible_os_family | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
    - "{{ ansible_distribution | lower }}.yml"
    - "{{ ansible_os_family | lower }}-{{ ansible_distribution_version.split('.')[0] }}.yml"
    - "{{ ansible_os_family | lower }}.yml"
  tags:
    - always

- name: Uninstall legacy journalbeat
  file:
    path: "{{ item }}"
    state: absent
  with_items:
    - /etc/systemd/system/journalbeat.service
    - /usr/local/bin/journalbeat

- name: Ensure beat is installed
  package:
    name: "{{ journalbeat_distro_packages }}"
    state: "{{ elk_package_state | default('present') }}"
    update_cache: "{{ (ansible_pkg_mgr == 'apt') | ternary('yes', omit) }}"
  register: _package_task
  until: _package_task is success
  retries: 3
  delay: 2
  notify:
    - Enable and restart journalbeat
  tags:
    - package_install

- name: Ensure beat is installed (aarch64)
  apt:
    deb: 'https://object-storage-ca-ymq-1.vexxhost.net/swift/v1/8709ca2640344a4ba85cba0a1d6eea69/aarch64/journalbeat-6.5.0-arm64.deb'
  when:
    - ansible_pkg_mgr == 'apt'
    - ansible_architecture == 'aarch64'
  notify:
    - Enable and restart heartbeat
  tags:
    - package_install

- name: Create journalbeat systemd service config dir
  file:
    path: "/etc/systemd/system/journalbeat.service.d"
    state: "directory"
    group: "root"
    owner: "root"
    mode: "0755"

- name: Apply systemd options
  template:
    src: "{{ item.src }}"
    dest: "{{ item.dest }}"
    mode: "0644"
  with_items:
    - src: "systemd.general-overrides.conf.j2"
      dest: "/etc/systemd/system/journalbeat.service.d/journalbeat-overrides.conf"
  notify:
    - Enable and restart journalbeat

- name: Drop journalbeat configs
  template:
    src: "{{ item.src }}"
    dest: "{{ item.dest }}"
    mode: "0644"
  with_items:
    - src: "journalbeat.yml.j2"
      dest: "/etc/journalbeat/journalbeat.yml"
  notify:
    - Enable and restart journalbeat

- include_tasks: journalbeat_setup.yml
  tags:
    - setup

- name: Force beat handlers
  meta: flush_handlers

- name: set journalbeat service state (upstart)
  service:
    name: "journalbeat"
    state: "{{ journalbeat_service_state }}"
    enabled: "{{ journalbeat_service_state in ['running', 'started', 'restarted'] }}"
  when:
    - ansible_service_mgr == 'upstart'
    - journalbeat_service_state in ['started', 'stopped']

- name: set journalbeat service state (systemd)
  systemd:
    name: "journalbeat"
    state: "{{ journalbeat_service_state }}"
    enabled: "{{ journalbeat_service_state in ['running', 'started', 'restarted'] }}"
  when:
    - ansible_service_mgr == 'systemd'
    - journalbeat_service_state in ['started', 'stopped']

**********
DECISION===>: PASS
**********
=========================:::817:::END!!!=========================
=========================:::818:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_journalbeat/meta/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

galaxy_info:
  author: OpenStack
  description: Elastic v6.x journalbeat role
  company: Rackspace
  license: Apache2
  min_ansible_version: 2.5
  platforms:
    - name: Ubuntu
      versions:
        - trusty
        - xenial
        - bionic
  categories:
    - cloud
    - development
    - elasticsearch
    - elastic-stack
dependencies:
  - role: elastic_data_hosts
  - role: elastic_repositories

**********
DECISION===>: PASS
**********
=========================:::818:::END!!!=========================
=========================:::819:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_journalbeat/defaults/main.yml
**********
---
# Copyright 2018, Vexxhost, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

journalbeat_service_state: restarted

**********
DECISION===>: PASS
**********
=========================:::819:::END!!!=========================
=========================:::820:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_journalbeat/handlers/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Enable and restart journalbeat
  systemd:
    name: "journalbeat"
    enabled: true
    state: "{{ journalbeat_service_state }}"
    daemon_reload: yes
  when:
    - (elk_package_state | default('present')) != 'absent'
  tags:
    - config

**********
DECISION===>: PASS
**********
=========================:::820:::END!!!=========================
=========================:::821:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/go_install_1.10/tasks/go_install.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: GET go
  get_url:
    url: "{{ go_download_url }}"
    dest: "/opt/{{ go_download_filename }}"
  register: _get_task
  until: _get_task is success
  retries: 3
  delay: 2
  tags:
    - package_install

- name: Create go directory
  file:
    path: "/opt/go{{ go_download_version }}"
    state: directory

- name: Unarchive go
  unarchive:
    src: "/opt/{{ go_download_filename }}"
    dest: "/opt/go{{ go_download_version }}"
    remote_src: yes

- name: Create go defaults file
  copy:
    content: |
      GOROOT=/opt/go{{ go_download_version }}/go
      GOPATH=/usr/local
      PATH=${PATH}:${GOROOT}/bin
    dest: "/etc/default/go{{ go_download_version }}"

**********
DECISION===>: PASS
**********
=========================:::821:::END!!!=========================
=========================:::822:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/go_install_1.10/tasks/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Check for go
  stat:
    path: "/opt/go{{ go_download_version }}/go/bin/go"
  register: go_path

- include_tasks: go_install.yml
  when:
    - not go_path.stat.exists | bool

**********
DECISION===>: PASS
**********
=========================:::822:::END!!!=========================
=========================:::823:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/go_install_1.10/meta/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

galaxy_info:
  author: OpenStack
  description: Elastic v6.x go install role
  company: Rackspace
  license: Apache2
  min_ansible_version: 2.5
  platforms:
    - name: Ubuntu
      versions:
        - trusty
        - xenial
        - bionic
  categories:
    - cloud
    - development
    - elasticsearch
    - elastic-stack
dependencies: []

**********
DECISION===>: PASS
**********
=========================:::823:::END!!!=========================
=========================:::824:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/go_install_1.10/defaults/main.yml
**********
---
# Copyright 2018, Logan Vig <logan2211@gmail.com>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Versions and SHAs published at https://golang.org/dl/
go_download_version: 1.10.1
go_download_url: "https://dl.google.com/go/{{ go_download_filename }}"
go_download_arch: "{{ go_arch_translation[ansible_architecture] | default(ansible_architecture) }}"
go_download_filename: "go{{ go_download_version }}.linux-{{ go_download_arch }}.tar.gz"
go_arch_translation:
  x86_64: amd64
  aarch64: arm64

**********
DECISION===>: PASS
**********
=========================:::824:::END!!!=========================
=========================:::825:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/go_install_1.10/handlers/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

**********
DECISION===>: PASS
**********
=========================:::825:::END!!!=========================
=========================:::826:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_metricbeat/vars/redhat.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

metricbeat_nginx_vhost_path: /etc/nginx/conf.d/
metricbeat_distro_packages:
  - metricbeat

**********
DECISION===>: PASS
**********
=========================:::826:::END!!!=========================
=========================:::827:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_metricbeat/vars/suse.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

metricbeat_nginx_vhost_path: /etc/nginx/vhosts.d
metricbeat_distro_packages:
  - metricbeat

**********
DECISION===>: PASS
**********
=========================:::827:::END!!!=========================
=========================:::828:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_metricbeat/vars/ubuntu.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

metricbeat_nginx_vhost_path: /etc/nginx/sites-enabled
metricbeat_distro_packages:
  - metricbeat

**********
DECISION===>: PASS
**********
=========================:::828:::END!!!=========================
=========================:::829:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_metricbeat/tasks/metricbeat_setup.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Load templates
  shell: >-
    metricbeat setup
    {{ item }}
    -E 'output.logstash.enabled=false'
    -E 'output.elasticsearch.hosts={{ coordination_nodes | to_json }}'
    -E 'setup.template.enabled=true'
    -E 'setup.template.overwrite=true'
    -e -v
  with_items:
    - "--template"
    - "--pipelines"
    - "--machine-learning"
    - "--dashboards"
  register: templates
  environment:
    no_proxy: "{{ hostvars[groups['kibana'][0]]['ansible_host'] }}"
  until: templates is success
  retries: 5
  delay: 5
  run_once: true
  tags:
    - setup

**********
DECISION===>: PASS
**********
=========================:::829:::END!!!=========================
=========================:::830:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_metricbeat/tasks/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Gather variables for each operating system
  include_vars: "{{ item }}"
  with_first_found:
    - "{{ ansible_distribution | lower }}-{{ ansible_distribution_version | lower }}.yml"
    - "{{ ansible_distribution | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
    - "{{ ansible_os_family | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
    - "{{ ansible_distribution | lower }}.yml"
    - "{{ ansible_os_family | lower }}-{{ ansible_distribution_version.split('.')[0] }}.yml"
    - "{{ ansible_os_family | lower }}.yml"
  tags:
    - always

- name: Refresh physical host facts
  setup: {}
  delegate_to: "{{ physical_host }}"
  delegate_facts: true
  when:
    - physical_host is defined and physical_host != inventory_hostname
  tags:
    - always

- name: Ensure beat is installed
  package:
    name: "{{ metricbeat_distro_packages }}"
    state: "{{ elk_package_state | default('present') }}"
    update_cache: "{{ (ansible_pkg_mgr == 'apt') | ternary('yes', omit) }}"
  register: _package_task
  until: _package_task is success
  retries: 3
  delay: 2
  when:
    - ansible_architecture == 'x86_64'
  notify:
    - Enable and restart metricbeat
  tags:
    - package_install

- name: Ensure beat is installed (aarch64)
  apt:
    deb: 'https://object-storage-ca-ymq-1.vexxhost.net/swift/v1/8709ca2640344a4ba85cba0a1d6eea69/aarch64/metricbeat-6.5.0-arm64.deb'
  when:
    - ansible_pkg_mgr == 'apt'
    - ansible_architecture == 'aarch64'
  notify:
    - Enable and restart metricbeat
  tags:
    - package_install

- name: Check for apache
  stat:
    path: /etc/apache2/sites-available
  register: apache2

- name: Check for ceph
  stat:
    path: /etc/ceph
  register: ceph

# gather ceph stats from localhost
# except when a list of mons is provided
- name: Set ceph stats hosts
  set_fact:
    ceph_stats_hosts: |-
      {% set ceph_stats = [] %}
      {% if (ceph_mons is defined) and (ceph_mons | length > 0) %}
      {%   for mon in ceph_mons %}
      {%     set _ = ceph_stats.insert(loop.index, (mon + ":5000")) %}
      {%   endfor %}
      {% else %}
      {%   set ceph_stats = [ ansible_hostname + ":5000" ] %}
      {% endif %}
      {{ ceph_stats }}

- name: Check for Ceph restapi metric port
  wait_for:
    port: "{{ item | regex_replace('^.+:', '') | int }}"
    delay: 2
    timeout: 5
    host: "{{ item | regex_replace(':\\d+$', '') }}"
  with_items: "{{ ceph_stats_hosts }}"
  when: ceph.stat.exists
  register: ceph_restapi_port_check
  ignore_errors: yes

- name: Set ceph_restapi_listening
  set_fact:
    ceph_restapi_listening: true
  when: not (item.failed | default(true))
  with_items: "{{ ceph_restapi_port_check.results }}"

- name: Check for Ceph prometheus metric port
  wait_for:
    port: 9283
    delay: 2
    timeout: 5
    host: "{{ item | regex_replace(':\\d+$', '') }}"
  with_items: "{{ ceph_stats_hosts }}"
  when: ceph.stat.exists
  register: ceph_prometheus_port_check
  ignore_errors: yes

- name: Set ceph_prometheus_listening
  set_fact:
    ceph_prometheus_listening: true
  when: not (item.failed | default(true))
  with_items: "{{ ceph_prometheus_port_check.results }}"

- name: Check for etcd
  stat:
    path: /etc/etcd
  register: etcd

- name: Check for docker
  stat:
    path: /var/run/docker.sock
  register: docker

- name: Check for haproxy
  stat:
    path: /etc/haproxy
  register: haproxy

- name: Check for httpd
  stat:
    path: /etc/httpd
  register: httpd

- name: Check for kvm
  stat:
    path: /var/run/libvirt/libvirt-sock
  register: kvm

- name: Check for memcached
  stat:
    path: /etc/memcached.conf
  register: memcached

- name: Check for mysql
  stat:
    path: /var/lib/mysql
  register: mysql

- name: Check for nginx
  stat:
    path: /etc/nginx/nginx.conf
  register: nginx

- name: Check for rabbitmq
  stat:
    path: /var/lib/rabbitmq
  register: rabbitmq

- name: Check for uwsgi
  stat:
    path: /etc/uwsgi
  register: uwsgi

- name: Check for uwsgi stats sockets
  find:
    paths: /tmp
    file_type: any
    patterns: '*uwsgi-stats.sock'
  register: uwsgi_find_sockets

- name: Set discovery facts
  set_fact:
    apache_enabled: "{{ (apache2.stat.exists | bool) or (httpd.stat.exists | bool) }}"

    # Only enable ceph if something is listening on the ceph-rest-api port
    # enable ceph on:  cinder volume hosts when we have a list of ceph mons
    #      otherwise:  all hosts which have /etc/ceph
    ceph_restapi_enabled: |-
      {% set ceph_detect = false %}
      {% if ceph_restapi_listening is defined %}
      {%   if (ceph_mons is defined) and (ceph_mons | length > 0) and (inventory_hostname in groups[ceph_metricbeat_group])  %}
      {%     set ceph_detect = true %}
      {%   else %}
      {%     set ceph_detect = ceph.stat.exists | bool %}
      {%   endif %}
      {% endif %}
      {{ ceph_detect }}

    ceph_prometheus_enabled: |-
      {% set ceph_detect = false %}
      {% if ceph_prometheus_listening is defined %}
      {%   if (ceph_mons is defined) and (ceph_mons | length > 0) and (inventory_hostname in groups[ceph_metricbeat_group])  %}
      {%     set ceph_detect = true %}
      {%   else %}
      {%     set ceph_detect = ceph.stat.exists | bool %}
      {%   endif %}
      {% endif %}
      {{ ceph_detect }}


    docker_enabled: "{{ docker.stat.exists | bool }}"
    etcd_enabled: "{{ etcd.stat.exists | bool }}"
    haproxy_enabled: "{{ haproxy.stat.exists | bool }}"
    kvm_enabled: "{{ kvm.stat.exists | bool }}"
    memcached_enabled: "{{ memcached.stat.exists | bool }}"
    mysql_enabled: "{{ mysql.stat.exists | bool }}"
    nginx_enabled: "{{ nginx.stat.exists | bool }}"
    rabbitmq_enabled: "{{ rabbitmq.stat.exists | bool }}"
    uwsgi_enabled: "{{ uwsgi.stat.exists | bool }}"
    uwsgi_sockets: "{{ uwsgi_find_sockets }}"

# Apache 2 stats enablement
- name: Enable apache2
  block:
    - name: Drop apache2 stats site config
      template:
        src: apache-status.conf.j2
        dest: /etc/apache2/sites-available/apache-status.conf

    - name: Enable apache2 stats site
      file:
        src: /etc/apache2/sites-available/apache-status.conf
        dest: /etc/apache2/sites-enabled/apache-status.conf
        state: link

    - name: Ensure apache2 stats mode is enabled
      apache2_module:
        name: status
        state: present
      register: apache_status_mod

    - name: Reload apache2
      service:
        name: apache2
        state: reloaded
      when:
        - apache_status_mod is changed
  rescue:
    - name: Apache2 monitoring not enabled
      debug:
        msg: >-
          The apache2 module was not enabled because of an error within the
          enablement process. Check the host to ensure apache2 is really
          available and resolve the noted errors before continuing.

    - name: Disable apache2 check
      set_fact:
        apache_enabled: false
  when:
    - apache_enabled | bool


# NGINX stats enablement
- name: Drop nginx stats site config
  template:
    src: nginx-status.conf.j2
    dest: "{{ metricbeat_nginx_vhost_path }}/nginx-status.conf"
  register: nginx_status
  when: nginx_enabled

- name: Reload nginx
  service:
    name: nginx
    state: reloaded
  when:
    - nginx_enabled
    - nginx_status is changed

- name: Create metricbeat systemd service config dir
  file:
    path: "/etc/systemd/system/metricbeat.service.d"
    state: "directory"
    group: "root"
    owner: "root"
    mode: "0755"
  when:
    - ansible_service_mgr == 'systemd'

- name: Apply systemd options
  template:
    src: "{{ item.src }}"
    dest: "{{ item.dest }}"
    mode: "0644"
  when:
    - ansible_service_mgr == 'systemd'
  with_items:
    - src: "systemd.general-overrides.conf.j2"
      dest: "/etc/systemd/system/metricbeat.service.d/metricbeat-overrides.conf"
  notify:
    - Enable and restart metricbeat

- name: Drop metricbeat conf files
  template:
    src: "{{ item.src }}"
    dest: "{{ item.dest }}"
    mode: "0644"
  with_items:
    - src: "metricbeat.yml.j2"
      dest: "/etc/metricbeat/metricbeat.yml"
  notify:
    - Enable and restart metricbeat

- include_tasks: metricbeat_setup.yml
  tags:
    - setup

- name: Force beat handlers
  meta: flush_handlers

- name: set metricbeat service state (upstart)
  service:
    name: "metricbeat"
    state: "{{ metricbeat_service_state }}"
    enabled: "{{ metricbeat_service_state in ['running', 'started', 'restarted'] }}"
  when:
    - ansible_service_mgr == 'upstart'
    - metricbeat_service_state in ['started', 'stopped']

- name: set metricbeat service state (systemd)
  systemd:
    name: "metricbeat"
    state: "{{ metricbeat_service_state }}"
    enabled: "{{ metricbeat_service_state in ['running', 'started', 'restarted'] }}"
  when:
    - ansible_service_mgr == 'systemd'
    - metricbeat_service_state in ['started', 'stopped']

**********
DECISION===>: PASS
**********
=========================:::830:::END!!!=========================
=========================:::831:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_metricbeat/meta/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

galaxy_info:
  author: OpenStack
  description: Elastic v6.x metricbeat role
  company: Rackspace
  license: Apache2
  min_ansible_version: 2.5
  platforms:
    - name: Ubuntu
      versions:
        - trusty
        - xenial
        - bionic
  categories:
    - cloud
    - development
    - elasticsearch
    - elastic-stack
dependencies:
  - role: elastic_data_hosts
  - role: elastic_repositories

**********
DECISION===>: PASS
**********
=========================:::831:::END!!!=========================
=========================:::832:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_metricbeat/defaults/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

#metricbeats monitoring endpoints
elastic_metricbeat_rabbitmq_monitoring_hosts: '"localhost:15672"'
elastic_metricbeat_haproxy_monitoring_hosts: '"unix:///var/run/haproxy.stat"'

metricbeat_service_state: restarted

# Inventory group to configure metricbeat ceph monitoring
# via either ceph-restapi or mgr prometheus module
ceph_metricbeat_group: cinder_volume

**********
DECISION===>: PASS
**********
=========================:::832:::END!!!=========================
=========================:::833:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_metricbeat/handlers/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Enable and restart metricbeat (systemd)
  systemd:
    name: "metricbeat"
    enabled: true
    state: "{{ metricbeat_service_state }}"
    daemon_reload: true
  when:
    - ansible_service_mgr == 'systemd'
  listen: Enable and restart metricbeat

- name: Enable and restart metricbeat (upstart)
  service:
    name: "metricbeat"
    state: "{{ metricbeat_service_state }}"
    enabled: yes
  when:
    - ansible_service_mgr == 'upstart'
  listen: Enable and restart metricbeat

**********
DECISION===>: PASS
**********
=========================:::833:::END!!!=========================
=========================:::834:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_kibana/vars/redhat.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

kibana_nginx_vhost_path: /etc/nginx/conf.d/
kibana_distro_packages:
  - kibana
  - nginx
  - python-passlib

**********
DECISION===>: PASS
**********
=========================:::834:::END!!!=========================
=========================:::835:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_kibana/vars/suse.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

kibana_nginx_vhost_path: /etc/nginx/vhosts.d
kibana_distro_packages:
  - apache2-utils
  - kibana
  - nginx
  - python-passlib

**********
DECISION===>: PASS
**********
=========================:::835:::END!!!=========================
=========================:::836:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_kibana/vars/ubuntu.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

kibana_nginx_vhost_path: /etc/nginx/sites-available
kibana_distro_packages:
  - apache2-utils
  - kibana
  - nginx
  - python-passlib

**********
DECISION===>: PASS
**********
=========================:::836:::END!!!=========================
=========================:::837:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_kibana/tasks/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Gather variables for each operating system
  include_vars: "{{ item }}"
  with_first_found:
    - "{{ ansible_distribution | lower }}-{{ ansible_distribution_version | lower }}.yml"
    - "{{ ansible_distribution | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
    - "{{ ansible_os_family | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
    - "{{ ansible_distribution | lower }}.yml"
    - "{{ ansible_os_family | lower }}-{{ ansible_distribution_version.split('.')[0] }}.yml"
    - "{{ ansible_os_family | lower }}.yml"
  tags:
    - always

- name: Ensure distro packages are installed
  package:
    name: "{{ kibana_distro_packages }}"
    state: "{{ elk_package_state | default('present') }}"
    update_cache: "{{ (ansible_pkg_mgr == 'apt') | ternary('yes', omit) }}"
  register: _package_task
  until: _package_task is success
  retries: 3
  delay: 2
  notify:
    - Enable and restart services
  tags:
    - package_install

- name: create kibana user to access web interface
  htpasswd:
    path: "/etc/nginx/htpasswd.users"
    name: "{{ kibana_username }}"
    password: "{{ kibana_password }}"
    owner: root
    mode: 0644
  when:
    - kibana_enable_basic_auth

- name: Drop Nginx default conf file
  template:
    src: "nginx_default.j2"
    dest: "{{ kibana_nginx_vhost_path }}/default"
  notify:
    - Enable and restart services

- name: Create kibana systemd service config dir
  file:
    path: "/etc/systemd/system/kibana.service.d"
    state: "directory"
    group: "root"
    owner: "root"
    mode: "0755"
  when:
    - ansible_service_mgr == 'systemd'

- name: Apply systemd options
  template:
    src: "{{ item.src }}"
    dest: "{{ item.dest }}"
    mode: "0644"
  when:
    - ansible_service_mgr == 'systemd'
  with_items:
    - src: "systemd.general-overrides.conf.j2"
      dest: "/etc/systemd/system/kibana.service.d/kibana-overrides.conf"
  notify:
    - Enable and restart services

- name: Drop kibana conf file
  template:
    src: "kibana.yml.j2"
    dest: "/etc/kibana/kibana.yml"
    mode: "0666"
  notify:
    - Enable and restart services

**********
DECISION===>: PASS
**********
=========================:::837:::END!!!=========================
=========================:::838:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_kibana/meta/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

galaxy_info:
  author: OpenStack
  description: Elastic v6.x kibana role
  company: Rackspace
  license: Apache2
  min_ansible_version: 2.5
  platforms:
    - name: Ubuntu
      versions:
        - trusty
        - xenial
        - bionic
  categories:
    - cloud
    - development
    - elasticsearch
    - elastic-stack
dependencies:
  - role: elastic_repositories

**********
DECISION===>: PASS
**********
=========================:::838:::END!!!=========================
=========================:::839:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_kibana/defaults/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

kibana_enable_basic_auth: false

# kibana vars
kibana_interface: 0.0.0.0
kibana_port: 5601
kibana_username: admin
kibana_password: admin
kibana_nginx_port: 81
kibana_server_name: "{{ ansible_hostname }}"
kibana_index_on_elasticsearch: "http://{{ hostvars[groups['elastic-logstash'][0]]['ansible_host'] }}:{{ elastic_port}}/.kibana"
kibana_elastic_request_timeout: 1800000

**********
DECISION===>: hardcoded secret
**********
=========================:::839:::END!!!=========================
=========================:::840:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_kibana/handlers/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Enable and restart services (systemd)
  systemd:
    name: "{{ item }}"
    enabled: true
    state: restarted
    daemon_reload: true
  when:
    - ansible_service_mgr == 'systemd'
  with_items:
    - nginx
    - kibana
  listen: Enable and restart services

- name: Enable and restart services (upstart)
  service:
    name: "{{ item }}"
    state: restarted
    enabled: yes
  when:
    - ansible_service_mgr == 'upstart'
  with_items:
    - nginx
    - kibana
  listen: Enable and restart services

**********
DECISION===>: PASS
**********
=========================:::840:::END!!!=========================
=========================:::841:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_filebeat/vars/redhat.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

filebeat_distro_packages:
  - filebeat

**********
DECISION===>: PASS
**********
=========================:::841:::END!!!=========================
=========================:::842:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_filebeat/vars/suse.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

filebeat_distro_packages:
  - filebeat

**********
DECISION===>: PASS
**********
=========================:::842:::END!!!=========================
=========================:::843:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_filebeat/vars/ubuntu.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

filebeat_distro_packages:
  - filebeat

**********
DECISION===>: PASS
**********
=========================:::843:::END!!!=========================
=========================:::844:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_filebeat/tasks/filebeat_setup.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Load templates
  shell: >-
    filebeat setup
    {{ item }}
    -E 'output.logstash.enabled=false'
    -E 'output.elasticsearch.hosts={{ coordination_nodes | to_json }}'
    -E 'setup.template.enabled=true'
    -E 'setup.template.overwrite=true'
    -e -v
  with_items:
    - "--template"
    - "--pipelines"
    - "--machine-learning"
    - "--dashboards"
  register: templates
  environment:
    no_proxy: "{{ hostvars[groups['kibana'][0]]['ansible_host'] }}"
  until: templates is success
  retries: 5
  delay: 5
  run_once: true
  tags:
    - setup

**********
DECISION===>: PASS
**********
=========================:::844:::END!!!=========================
=========================:::845:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_filebeat/tasks/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Gather variables for each operating system
  include_vars: "{{ item }}"
  with_first_found:
    - "{{ ansible_distribution | lower }}-{{ ansible_distribution_version | lower }}.yml"
    - "{{ ansible_distribution | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
    - "{{ ansible_os_family | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
    - "{{ ansible_distribution | lower }}.yml"
    - "{{ ansible_os_family | lower }}-{{ ansible_distribution_version.split('.')[0] }}.yml"
    - "{{ ansible_os_family | lower }}.yml"
  tags:
    - always

- name: Ensure beat is installed
  package:
    name: "{{ filebeat_distro_packages }}"
    state: "{{ elk_package_state | default('present') }}"
    update_cache: "{{ (ansible_pkg_mgr == 'apt') | ternary('yes', omit) }}"
  register: _package_task
  until: _package_task is success
  retries: 3
  delay: 2
  when:
    - ansible_architecture == 'x86_64'
  notify:
    - Enable and restart filebeat
  tags:
    - package_install

- name: Ensure beat is installed (aarch64)
  apt:
    deb: 'https://object-storage-ca-ymq-1.vexxhost.net/swift/v1/8709ca2640344a4ba85cba0a1d6eea69/aarch64/filebeat-6.5.0-arm64.deb'
  when:
    - ansible_pkg_mgr == 'apt'
    - ansible_architecture == 'aarch64'
  notify:
    - Enable and restart filebeat
  tags:
    - package_install

- name: Create filebeat systemd service config dir
  file:
    path: "/etc/systemd/system/filebeat.service.d"
    state: "directory"
    group: "root"
    owner: "root"
    mode: "0755"
  when:
    - ansible_service_mgr == 'systemd'

- name: Apply systemd options
  template:
    src: "{{ item.src }}"
    dest: "/etc/systemd/system/filebeat.service.d/{{ item.dest }}"
    mode: "0644"
  when:
    - ansible_service_mgr == 'systemd'
  with_items:
    - src: "systemd.general-overrides.conf.j2"
      dest: "filebeat-overrides.conf"
  notify:
    - Enable and restart filebeat

- name: Drop Filebeat conf file
  template:
    src: "filebeat.yml.j2"
    dest: "/etc/filebeat/filebeat.yml"
  notify:
    - Enable and restart filebeat

- include_tasks: filebeat_setup.yml
  tags:
    - setup

- name: Force beat handlers
  meta: flush_handlers

- name: set filebeat service state (upstart)
  service:
    name: "filebeat"
    state: "{{ filebeat_service_state }}"
    enabled: "{{ filebeat_service_state in ['running', 'started', 'restarted'] }}"
  when:
    - ansible_service_mgr == 'upstart'
    - filebeat_service_state in ['started', 'stopped']

- name: set filebeat service state (systemd)
  systemd:
    name: "filebeat"
    state: "{{ filebeat_service_state }}"
    enabled: "{{ filebeat_service_state in ['running', 'started', 'restarted'] }}"
  when:
    - ansible_service_mgr == 'systemd'
    - filebeat_service_state in ['started', 'stopped']

**********
DECISION===>: PASS
**********
=========================:::845:::END!!!=========================
=========================:::846:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_filebeat/meta/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

galaxy_info:
  author: OpenStack
  description: Elastic v6.x filebeat role
  company: Rackspace
  license: Apache2
  min_ansible_version: 2.5
  platforms:
    - name: Ubuntu
      versions:
        - trusty
        - xenial
        - bionic
  categories:
    - cloud
    - development
    - elasticsearch
    - elastic-stack
dependencies:
  - role: elastic_data_hosts
  - role: elastic_repositories

**********
DECISION===>: PASS
**********
=========================:::846:::END!!!=========================
=========================:::847:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_filebeat/defaults/main.yml
**********
---
# Copyright 2018, Vexxhost, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

filebeat_service_state: restarted
filebeat_oslo_log_multiline_config:
  pattern: '^[0-9-]{10} +[0-9:\.]+ +[0-9]+ +[A-Z]+ +[A-Za-z0-9\._]+ \[|Traceback'
  negate: true
  match: after
filebeat_prospectors:
  - type: log
    enabled: "{{ filebeat_repo_enabled | default(true) }}"
    paths:
      - /openstack/log/*repo_container*/apt-cacher-ng/apt-cacher.*
      - /openstack/log/*repo_container*/pypiserver/*.log
      - /openstack/log/*repo_container*/rsyncd.log
    tags:
      - infrastructure
      - repo-server
  - type: log
    enabled: "{{ filebeat_haproxy_enabled | default(true) }}"
    paths:
      - /var/log/haproxy/*.log
    tags:
      - infrastructure
      - haproxy
  - type: log
    enabled: "{{ filebeat_rabbitmq_enabled | default(true) }}"
    paths:
      - /openstack/log/*rabbit*/rabbitmq/*.log
      - /openstack/log/*rabbit*/rabbitmq/log/*.log
      - /var/log/rabbitmq/*.log
      - /var/log/rabbitmq/log/*.log
    multiline:
      pattern: '^='
      negate: true
      match: after
    tags:
      - infrastructure
      - rabbitmq
  - type: log
    enabled: "{{ filebeat_ceph_enabled | default(true) }}"
    paths:
      - /openstack/log/*ceph*/ceph/ceph-mon.*.log
      - /var/log/ceph/ceph-mon.*.log
    tags:
      - infrastructure
      - ceph
      - ceph-mon
  - type: log
    enabled: "{{ filebeat_ceph_enabled | default(true) }}"
    paths:
      - /openstack/log/*ceph*/ceph/ceph-mgr.*.log
      - /var/log/ceph/ceph-mgr.*.log
    tags:
      - infrastructure
      - ceph
      - ceph-mgr
  - type: log
    enabled: "{{ filebeat_ceph_enabled | default(true) }}"
    paths:
      - /openstack/log/*ceph*/ceph/ceph-osd.*.log
      - /var/log/ceph-osd.*.log
    tags:
      - infrastructure
      - ceph
      - ceph-osd
  - type: log
    enabled: "{{ filebeat_keystone_enabled | default(true) }}"
    paths:
      - /openstack/log/*keystone*/keystone/keystone.log
      - /var/log/keystone/keystone.log
    multiline: "{{ filebeat_oslo_log_multiline_config }}"
    tags:
      - openstack
      - keystone
  # NOTE(mnaser): Barbican ships to Journal
  - type: log
    enabled: "{{ filebeat_glance_enabled | default(true) }}"
    paths:
      - /openstack/log/*glance*/glance/*.log
      - /var/log/glance/*.log
    multiline: "{{ filebeat_oslo_log_multiline_config }}"
    tags:
      - openstack
      - glance
  # NOTE(mnaser): Cinder ships to journal
  - type: log
    enabled: "{{ filebeat_nova_enabled | default(true) }}"
    paths:
      - /openstack/log/*nova*/nova/*.log
      - /var/log/nova/*.log
    multiline: "{{ filebeat_oslo_log_multiline_config }}"
    tags:
      - openstack
      - nova
  - type: log
    enabled: "{{ filebeat_neutron_enabled | default(true) }}"
    paths:
      - /openstack/log/*neutron*/neutron/*.log
      - /var/log/neutron/*.log
    multiline: "{{ filebeat_oslo_log_multiline_config }}"
    tags:
      - openstack
      - neutron
  - type: log
    enabled: "{{ filebeat_heat_enabled | default(true) }}"
    paths:
      - /openstack/log/*heat*/heat/*.log
      - /var/log/heat/*.log
    multiline: "{{ filebeat_oslo_log_multiline_config }}"
    tags:
      - openstack
      - heat
  - type: log
    enabled: "{{ filebeat_designate_enabled | default(true) }}"
    paths:
      - /openstack/log/*designate*/designate/*.log
      - /var/log/designate/*.log
    multiline: "{{ filebeat_oslo_log_multiline_config }}"
    tags:
      - openstack
      - designate
  - type: log
    enabled: "{{ filebeat_swift_enabled | default(true) }}"
    paths:
      - /openstack/log/*swift*/account*.log
      - /var/log/swift/account*.log
    multiline:
      pattern: '^[A-Za-z]+[[:space:]]* +[0-9]{1,2} +[0-9:\.]+ +[A-Za-z0-9-]+ container-replicator: +[A-Za-z0-9-\ ]+'
      negate: false
      match: after
    tags:
      - openstack
      - swift
      - swift-account
  - type: log
    enabled: "{{ filebeat_swift_enabled | default(true) }}"
    paths:
      - /openstack/log/*swift*/container*.log
      - /var/log/swift/container*.log
    multiline:
      pattern: '^[A-Za-z]+[[:space:]]* +[0-9]{1,2} +[0-9:\.]+ +[A-Za-z0-9-]+ account-replicator: +[A-Za-z0-9-\ ]+'
      negate: false
      match: after
    tags:
      - openstack
      - swift
      - swift-container
  - type: log
    enabled: "{{ filebeat_swift_enabled | default(true) }}"
    paths:
      - /openstack/log/*swift*/object*.log
      - /var/log/swift/object*.log
    multiline:
      pattern: '^[A-Za-z]+[[:space:]]* +[0-9]{1,2} +[0-9:\.]+ +[A-Za-z0-9-]+ object-replicator: +[A-Za-z0-9-\ ]+'
      negate: false
      match: after
    tags:
      - openstack
      - swift
      - swift-object
  - type: log
    enabled: "{{ filebeat_swift_enabled | default(true) }}"
    paths:
      - /openstack/log/*swift*/proxy*.log
      - /var/log/swift/proxy*.log
    tags:
      - openstack
      - swift
      - swift-proxy
  - type: log
    enabled: "{{ filebeat_gnocchi_enabled | default(true) }}"
    paths:
      - /openstack/log/*gnocchi*/gnocchi/*.log
      - /var/log/gnocchi/*.log
    multiline: "{{ filebeat_oslo_log_multiline_config }}"
    tags:
      - openstack
      - gnocchi
  - type: log
    enabled: "{{ filebeat_ceilometer_enabled | default(true) }}"
    paths:
      - /openstack/log/*ceilometer*/ceilometer/*.log
      - /var/log/ceilometer/*.log
    multiline: "{{ filebeat_oslo_log_multiline_config }}"
    tags:
      - openstack
      - ceilometer
  - type: log
    enabled: "{{ filebeat_aodh_enabled | default(true) }}"
    paths:
      - /openstack/log/*aodh*/aodh/*.log
      - /var/log/aodh/*.log
    multiline: "{{ filebeat_oslo_log_multiline_config }}"
    tags:
      - openstack
      - aodh
  - type: log
    enabled: "{{ filebeat_ironic_enabled | default(true) }}"
    paths:
      - /openstack/log/*ironic*/ironic/*.log
      - /var/log/ironic/*.log
    multiline: "{{ filebeat_oslo_log_multiline_config }}"
    tags:
      - openstack
      - ironic
  - type: log
    enabled: "{{ filebeat_magnum_enabled | default(true) }}"
    paths:
      - /openstack/log/*magnum*/magnum/*.log
      - /var/log/magnum/*.log
    multiline: "{{ filebeat_oslo_log_multiline_config }}"
    tags:
      - openstack
      - magnum
  - type: log
    enabled: "{{ filebeat_trove_enabled | default(true) }}"
    paths:
      - /openstack/log/*trove*/trove/*.log
      - /var/log/trove/*.log
    multiline: "{{ filebeat_oslo_log_multiline_config }}"
    tags:
      - openstack
      - trove
  - type: log
    enabled: "{{ filebeat_sahara_enabled | default(true) }}"
    paths:
      - /openstack/log/*sahara*/sahara/*.log
      - /var/log/sahara/*.log
    multiline: "{{ filebeat_oslo_log_multiline_config }}"
    tags:
      - openstack
      - sahara
  - type: log
    enabled: "{{ filebeat_octavia_enabled | default(true) }}"
    paths:
      - /openstack/log/*octavia*/octavia/*.log
      - /var/log/octavia/*.log
    multiline: "{{ filebeat_oslo_log_multiline_config }}"
    tags:
      - openstack
      - octavia
  - type: log
    enabled: "{{ filebeat_tacker_enabled | default(true) }}"
    paths:
      - /openstack/log/*tacker*/tacker/*.log
      - /var/log/tacker/*.log
    multiline: "{{ filebeat_oslo_log_multiline_config }}"
    tags:
      - openstack
      - tacker
  - type: log
    enabled: "{{ filebeat_system_enabled | default(true) }}"
    paths:
      - /openstack/log/ansible-logging/*.log
      - /var/log/*.log
      - /var/log/libvirt/*.log
      - /var/log/libvirt/*/*.log
      - /var/log/lxc/*.log
    tags:
      - system
  - type: log
    enabled: "{{ filebeat_logging_enabled | default(true) }}"
    paths:
      - /openstack/log/*/beats/*.log
      - /openstack/log/*/curator/curator
      - /openstack/log/*/elasticsearch/*.log
      - /var/log/beats/*.log
      - /var/log/curator/curator
      - /var/log/elasticsearch/*.log
    tags:
      - beats

**********
DECISION===>: PASS
**********
=========================:::847:::END!!!=========================
=========================:::848:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_filebeat/handlers/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Enable and restart filebeat (systemd)
  systemd:
    name: "filebeat"
    enabled: true
    state: "{{ filebeat_service_state }}"
    daemon_reload: true
  when:
    - ansible_service_mgr == 'systemd'
  listen: Enable and restart filebeat

- name: Enable and restart filebeat (upstart)
  service:
    name: "filebeat"
    state: "{{ filebeat_service_state }}"
    enabled: yes
  when:
    - ansible_service_mgr == 'upstart'
  listen: Enable and restart filebeat

**********
DECISION===>: PASS
**********
=========================:::848:::END!!!=========================
=========================:::849:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_packetbeat/vars/redhat.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

packetbeat_distro_packages:
  - tcpdump
  - packetbeat

**********
DECISION===>: PASS
**********
=========================:::849:::END!!!=========================
=========================:::850:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_packetbeat/vars/suse.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

packetbeat_distro_packages:
  - tcpdump
  - packetbeat

**********
DECISION===>: PASS
**********
=========================:::850:::END!!!=========================
=========================:::851:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_packetbeat/vars/ubuntu.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

packetbeat_distro_packages:
  - tcpdump
  - packetbeat

**********
DECISION===>: PASS
**********
=========================:::851:::END!!!=========================
=========================:::852:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_packetbeat/tasks/packetbeat_setup.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Load templates
  shell: >-
    packetbeat setup
    {{ item }}
    -E 'output.logstash.enabled=false'
    -E 'output.elasticsearch.hosts={{ coordination_nodes | to_json }}'
    -E 'setup.template.enabled=true'
    -E 'setup.template.overwrite=true'
    -e -v
  with_items:
    - "--template"
    - "--pipelines"
    - "--machine-learning"
    - "--dashboards"
  register: templates
  environment:
    no_proxy: "{{ hostvars[groups['kibana'][0]]['ansible_host'] }}"
  until: templates is success
  retries: 5
  delay: 5
  run_once: true
  tags:
    - setup

**********
DECISION===>: PASS
**********
=========================:::852:::END!!!=========================
=========================:::853:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_packetbeat/tasks/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Gather variables for each operating system
  include_vars: "{{ item }}"
  with_first_found:
    - "{{ ansible_distribution | lower }}-{{ ansible_distribution_version | lower }}.yml"
    - "{{ ansible_distribution | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
    - "{{ ansible_os_family | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
    - "{{ ansible_distribution | lower }}.yml"
    - "{{ ansible_os_family | lower }}-{{ ansible_distribution_version.split('.')[0] }}.yml"
    - "{{ ansible_os_family | lower }}.yml"
  tags:
    - always

- name: Ensure beat is installed
  package:
    name: "{{ packetbeat_distro_packages }}"
    state: "{{ elk_package_state | default('present') }}"
    update_cache: "{{ (ansible_pkg_mgr == 'apt') | ternary('yes', omit) }}"
  register: _package_task
  until: _package_task is success
  retries: 3
  delay: 2
  notify:
    - Enable and restart packetbeat
  tags:
    - package_install

- name: Create packetbeat systemd service config dir
  file:
    path: "/etc/systemd/system/packetbeat.service.d"
    state: "directory"
    group: "root"
    owner: "root"
    mode: "0755"
  when:
    - ansible_service_mgr == 'systemd'

- name: Apply systemd options
  template:
    src: "{{ item.src }}"
    dest: "{{ item.dest }}"
    mode: "0644"
  when:
    - ansible_service_mgr == 'systemd'
  with_items:
    - src: "systemd.general-overrides.conf.j2"
      dest: "/etc/systemd/system/packetbeat.service.d/packetbeat-overrides.conf"
  notify:
    - Enable and restart packetbeat

- name: Drop packetbeat conf files
  template:
    src: "{{ item.src }}"
    dest: "{{ item.dest }}"
    mode: "0644"
  with_items:
    - src: "packetbeat.yml.j2"
      dest: "/etc/packetbeat/packetbeat.yml"
  notify:
    - Enable and restart packetbeat

- include_tasks: packetbeat_setup.yml
  tags:
    - setup

- name: Force beat handlers
  meta: flush_handlers

- name: set packetbeat service state (upstart)
  service:
    name: "packetbeat"
    state: "{{ packetbeat_service_state }}"
    enabled: "{{ packetbeat_service_state in ['running', 'started', 'restarted'] }}"
  when:
    - ansible_service_mgr == 'upstart'
    - packetbeat_service_state in ['started', 'stopped']

- name: set packetbeat service state (systemd)
  systemd:
    name: "packetbeat"
    state: "{{ packetbeat_service_state }}"
    enabled: "{{ packetbeat_service_state in ['running', 'started', 'restarted'] }}"
  when:
    - ansible_service_mgr == 'systemd'
    - packetbeat_service_state in ['started', 'stopped']

**********
DECISION===>: PASS
**********
=========================:::853:::END!!!=========================
=========================:::854:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_packetbeat/meta/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

galaxy_info:
  author: OpenStack
  description: Elastic v6.x packetbeat role
  company: Rackspace
  license: Apache2
  min_ansible_version: 2.5
  platforms:
    - name: Ubuntu
      versions:
        - trusty
        - xenial
        - bionic
  categories:
    - cloud
    - development
    - elasticsearch
    - elastic-stack
dependencies:
  - role: elastic_data_hosts
  - role: elastic_repositories

**********
DECISION===>: PASS
**********
=========================:::854:::END!!!=========================
=========================:::855:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_packetbeat/defaults/main.yml
**********
---
# Copyright 2018, Vexxhost, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

packetbeat_service_state: restarted

**********
DECISION===>: PASS
**********
=========================:::855:::END!!!=========================
=========================:::856:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_packetbeat/handlers/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Enable and restart packetbeat (systemd)
  systemd:
    name: "packetbeat"
    enabled: true
    state: "{{ packetbeat_service_state }}"
    daemon_reload: true
  when:
    - ansible_service_mgr == 'systemd'
  listen: Enable and restart packetbeat

- name: Enable and restart packetbeat (upstart)
  service:
    name: "elasticsearch"
    state: "{{ packetbeat_service_state }}"
    enabled: yes
  when:
    - ansible_service_mgr == 'upstart'
  listen: Enable and restart packetbeat

**********
DECISION===>: PASS
**********
=========================:::856:::END!!!=========================
=========================:::857:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_curator/vars/redhat.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

curator_distro_packages:
  - python-virtualenv

**********
DECISION===>: PASS
**********
=========================:::857:::END!!!=========================
=========================:::858:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_curator/vars/suse.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

curator_distro_packages:
  - python-virtualenv

**********
DECISION===>: PASS
**********
=========================:::858:::END!!!=========================
=========================:::859:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_curator/vars/ubuntu.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

curator_distro_packages:
  - python-virtualenv
  - virtualenv

**********
DECISION===>: PASS
**********
=========================:::859:::END!!!=========================
=========================:::860:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_curator/tasks/curator_systemd.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Run the systemd service role
  include_role:
    name: systemd_service
    private: true
  vars:
    systemd_service_enabled: "{{ ((elk_package_state | default('present')) != 'absent') | ternary(true, false) }}"
    systemd_service_restart_changed: false
    systemd_user_name: curator
    systemd_group_name: curator
    systemd_services:
      - service_name: "curator"
        execstarts:
          - /opt/elasticsearch-curator/bin/curator
            --config /var/lib/curator/curator.yml
            /var/lib/curator/actions-age.yml
        timer:
          state: "started"
          options:
            OnBootSec: 30min
            OnUnitActiveSec: 24h
            Persistent: true
      - service_name: "curator-size"
        execstarts:
          - /opt/elasticsearch-curator/bin/curator
            --config /var/lib/curator/curator.yml
            /var/lib/curator/actions-size.yml
        timer:
          state: "started"
          options:
            OnBootSec: 30min
            OnUnitActiveSec: 5h
            Persistent: true

**********
DECISION===>: PASS
**********
=========================:::860:::END!!!=========================
=========================:::861:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_curator/tasks/curator_upstart.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Create cron job for curator (age)
  cron:
    name: "Run curator"
    minute: 0
    hour: 1
    user: "curator"
    job: "/opt/elasticsearch-curator/bin/curator --config /var/lib/curator/curator.yml /var/lib/curator/actions-age.yml"
    cron_file: "elasticsearch-curator"

- name: Create cron job for curator (size)
  cron:
    name: "Run curator"
    minute: 0
    hour: */5
    user: "curator"
    job: "/opt/elasticsearch-curator/bin/curator --config /var/lib/curator/curator.yml /var/lib/curator/actions-size.yml"
    cron_file: "elasticsearch-curator"

**********
DECISION===>: PASS
**********
=========================:::861:::END!!!=========================
=========================:::862:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_curator/tasks/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Gather variables for each operating system
  include_vars: "{{ item }}"
  with_first_found:
    - "{{ ansible_distribution | lower }}-{{ ansible_distribution_version | lower }}.yml"
    - "{{ ansible_distribution | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
    - "{{ ansible_os_family | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
    - "{{ ansible_distribution | lower }}.yml"
    - "{{ ansible_os_family | lower }}-{{ ansible_distribution_version.split('.')[0] }}.yml"
    - "{{ ansible_os_family | lower }}.yml"
  tags:
    - always

- name: exit playbook after uninstall
  meta: end_play
  when:
      ansible_service_mgr != 'systemd'

- name: Ensure virtualenv is installed
  package:
    name: "{{ curator_distro_packages }}"
    state: "{{ elk_package_state | default('present') }}"
    update_cache: "{{ (ansible_pkg_mgr == 'apt') | ternary('yes', omit) }}"
  tags:
    - package_install

- name: Create the virtualenv (if it does not exist)
  command: "virtualenv --never-download --no-site-packages /opt/elasticsearch-curator"
  args:
    creates: "/opt/elasticsearch-curator/bin/activate"

- name: Ensure curator is installed
  pip:
    name: "elasticsearch-curator<6"
    state: "{{ elk_package_state | default('present') }}"
    extra_args: --isolated
    virtualenv: /opt/elasticsearch-curator
  register: _pip_task
  until: _pip_task is success
  retries: 3
  delay: 2
  tags:
    - package_install

- name: create the system group
  group:
    name: "curator"
    state: "present"
    system: "yes"

- name: Create the curator system user
  user:
    name: "curator"
    group: "curator"
    comment: "curator user"
    shell: "/bin/false"
    createhome: "yes"
    home: "/var/lib/curator"

- name: Create curator data path
  file:
    path: "{{ item }}"
    state: directory
    owner: "curator"
    group: "curator"
    mode: "0755"
    recurse: true
  with_items:
    - "/var/lib/curator"
    - "/var/log/curator"
    - "/etc/curator"

- name: Drop curator conf file(s)
  template:
    src: "{{ item.src }}"
    dest: "{{ item.dest }}"
  with_items:
    - src: "curator.yml.j2"
      dest: /var/lib/curator/curator.yml
    - src: "curator-actions-age.yml.j2"
      dest: /var/lib/curator/actions-age.yml
    - src: "curator-actions-size.yml.j2"
      dest: /var/lib/curator/actions-size.yml
  notify:
    - Enable and restart curator.timer

- include_tasks: "curator_{{ ansible_service_mgr }}.yml"

**********
DECISION===>: PASS
**********
=========================:::862:::END!!!=========================
=========================:::863:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_curator/meta/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

galaxy_info:
  author: OpenStack
  description: Elastic v6.x curator role
  company: Rackspace
  license: Apache2
  min_ansible_version: 2.5
  platforms:
    - name: Ubuntu
      versions:
        - trusty
        - xenial
        - bionic
  categories:
    - cloud
    - development
    - elasticsearch
    - elastic-stack
dependencies:
  - role: elastic_retention

**********
DECISION===>: PASS
**********
=========================:::863:::END!!!=========================
=========================:::864:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_curator/handlers/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Enable and restart curator.timer
  systemd:
    name: "curator.timer"
    enabled: true
    state: restarted
  when:
    - (elk_package_state | default('present')) != 'absent'
  tags:
    - config

**********
DECISION===>: PASS
**********
=========================:::864:::END!!!=========================
=========================:::865:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_auditbeat/vars/redhat.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

auditbeat_distro_packages:
  - audispd-plugins
  - auditbeat

**********
DECISION===>: PASS
**********
=========================:::865:::END!!!=========================
=========================:::866:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_auditbeat/vars/suse.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

auditbeat_distro_packages:
  - audit-audispd-plugins
  - auditbeat

**********
DECISION===>: PASS
**********
=========================:::866:::END!!!=========================
=========================:::867:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_auditbeat/vars/ubuntu.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

auditbeat_distro_packages:
  - audispd-plugins
  - auditbeat

**********
DECISION===>: PASS
**********
=========================:::867:::END!!!=========================
=========================:::868:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_auditbeat/tasks/auditbeat_setup.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Load templates
  shell: >-
    auditbeat setup
    {{ item }}
    -E 'output.logstash.enabled=false'
    -E 'output.elasticsearch.hosts={{ coordination_nodes | to_json }}'
    -E 'setup.template.enabled=true'
    -E 'setup.template.overwrite=true'
    -e -v
  with_items:
    - "--template"
    - "--pipelines"
    - "--machine-learning"
    - "--dashboards"
  register: templates
  environment:
    no_proxy: "{{ hostvars[groups['kibana'][0]]['ansible_host'] }}"
  until: templates is success
  retries: 5
  delay: 5
  run_once: true
  tags:
    - setup

**********
DECISION===>: PASS
**********
=========================:::868:::END!!!=========================
=========================:::869:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_auditbeat/tasks/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Gather variables for each operating system
  include_vars: "{{ item }}"
  with_first_found:
    - "{{ ansible_distribution | lower }}-{{ ansible_distribution_version | lower }}.yml"
    - "{{ ansible_distribution | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
    - "{{ ansible_os_family | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
    - "{{ ansible_distribution | lower }}.yml"
    - "{{ ansible_os_family | lower }}-{{ ansible_distribution_version.split('.')[0] }}.yml"
    - "{{ ansible_os_family | lower }}.yml"
  tags:
    - always

- name: Ensure beat is installed (x86_64)
  package:
    name: "{{ auditbeat_distro_packages }}"
    state: "{{ elk_package_state | default('present') }}"
    update_cache: "{{ (ansible_pkg_mgr == 'apt') | ternary('yes', omit) }}"
  register: _package_task
  until: _package_task is success
  retries: 3
  delay: 2
  when:
    - ansible_architecture == 'x86_64'
  notify:
    - Enable and restart auditbeat
  tags:
    - package_install

- name: Ensure beat is installed (aarch64)
  apt:
    deb: 'https://object-storage-ca-ymq-1.vexxhost.net/swift/v1/8709ca2640344a4ba85cba0a1d6eea69/aarch64/auditbeat-6.5.0-arm64.deb'
  when:
    - ansible_pkg_mgr == 'apt'
    - ansible_architecture == 'aarch64'
  notify:
    - Enable and restart auditbeat
  tags:
    - package_install

- name: Create auditbeat systemd service config dir
  file:
    path: "/etc/systemd/system/auditbeat.service.d"
    state: "directory"
    group: "root"
    owner: "root"
    mode: "0755"
  when:
    - ansible_service_mgr == 'systemd'

- name: Apply systemd options
  template:
    src: "{{ item.src }}"
    dest: "/etc/systemd/system/auditbeat.service.d/{{ item.dest }}"
    mode: "0644"
  when:
    - ansible_service_mgr == 'systemd'
  with_items:
    - src: "systemd.general-overrides.conf.j2"
      dest: "auditbeat-overrides.conf"
  notify:
    - Enable and restart auditbeat

- name: Drop auditbeat conf file
  template:
    src: templates/auditbeat.yml.j2
    dest: /etc/auditbeat/auditbeat.yml
  notify:
    - Enable and restart auditbeat

- include_tasks: auditbeat_setup.yml
  tags:
    - setup

- name: Force beat handlers
  meta: flush_handlers

- name: set auditbeat service state (upstart)
  service:
    name: "auditbeat"
    state: "{{ auditbeat_service_state }}"
    enabled: "{{ auditbeat_service_state in ['running', 'started', 'restarted'] }}"
  when:
    - ansible_service_mgr == 'upstart'
    - auditbeat_service_state in ['started', 'stopped']

- name: set auditbeat service state (systemd)
  systemd:
    name: "auditbeat"
    state: "{{ auditbeat_service_state }}"
    enabled: "{{ auditbeat_service_state in ['running', 'started', 'restarted'] }}"
  when:
    - ansible_service_mgr == 'systemd'
    - auditbeat_service_state in ['started', 'stopped']

**********
DECISION===>: PASS
**********
=========================:::869:::END!!!=========================
=========================:::870:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_auditbeat/meta/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

galaxy_info:
  author: OpenStack
  description: Elastic v6.x auditbeat role
  company: Rackspace
  license: Apache2
  min_ansible_version: 2.5
  platforms:
    - name: Ubuntu
      versions:
        - trusty
        - xenial
        - bionic
  categories:
    - cloud
    - development
    - elasticsearch
    - elastic-stack
dependencies:
  - role: elastic_data_hosts
  - role: elastic_repositories

**********
DECISION===>: PASS
**********
=========================:::870:::END!!!=========================
=========================:::871:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_auditbeat/defaults/main.yml
**********
---
# Copyright 2018, Vexxhost, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

auditbeat_service_state: restarted

**********
DECISION===>: PASS
**********
=========================:::871:::END!!!=========================
=========================:::872:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_auditbeat/handlers/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Enable and restart auditbeat (systemd)
  systemd:
    name: "auditbeat"
    enabled: true
    state: "{{ auditbeat_service_state }}"
    daemon_reload: true
  when:
    - ansible_service_mgr == 'systemd'
  listen: Enable and restart auditbeat

- name: Enable and restart auditbeat (upstart)
  service:
    name: "auditbeat"
    state: "{{ auditbeat_service_state }}"
    enabled: yes
  when:
    - ansible_service_mgr == 'upstart'
  listen: Enable and restart auditbeat

**********
DECISION===>: PASS
**********
=========================:::872:::END!!!=========================
=========================:::873:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_retention/vars/calculate_index_retention_default.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Set available storage fact. This tasks the total amount of storage found
# within the data nodes of the elasticsearch cluster and converts bytes to
# megabytes.
es_total_available_storage: "{{ ((es_storage_json['nodes'].values() | list) | map(attribute='fs.total.total_in_bytes') | list | sum) // 1024 // 1024 }}"

# Set assumed buffer storage fact. This will result in 25% of the total
# available storage.
es_assumed_buffer_storage: "{{ ((es_total_available_storage | int) * 0.25) | round | int }}"

# Set usable buffer storage fact(s). This is the toal storage minus the buffer.
es_usable_buffer_storage: "{{ (es_total_available_storage | int) - (es_assumed_buffer_storage | int) }}"

# This function will take the sum total of all hosts in the retention policy
# after weighting. Once the policy is set the sum total will be carved up into
# individual percentages of the total amount of usable storage after the buffer
# is calculated.
es_storage_per_index: |-
  {%- set es_hash = {} %}
  {%- set total_weight = (elastic_beat_retention_policy_hosts.values() | list | map(attribute='weight') | list | sum) %}
  {%- set host_count = (elastic_beat_retention_policy_hosts.values() | list | map(attribute='hosts') | list | map('flatten') | list | length) %}
  {%- set total_values = (total_weight | int) * (host_count | int) %}
  {%- for key, value in elastic_beat_retention_policy_hosts.items() %}
  {%-   set value_pct = (((value.weight | int) * (value.hosts | length)) / (total_values | int)) %}
  {%-   set value_total = ((value_pct | float) * (es_usable_buffer_storage | int)) %}
  {%-   set _ = es_hash.__setitem__(key, value_total | int) %}
  {%- endfor %}
  {{ es_hash }}

# The assumed number of days an index will be retained is based on the size of
# the given index. With the sizes all figured out in the function above this
# function will divide each retention size be a constant of 1024 and the number
# of hosts within a given collector segment.
es_days_per_index: |-
  {%- set es_hash = {} %}
  {%- for key, value in elastic_beat_retention_policy_hosts.items() %}
  {%-   if (es_storage_per_index[key] | int) > 0 %}
  {%-     set value_days = ((es_storage_per_index[key] | int) // ((value.hosts | length) * 1024)) %}
  {%-     set _ = es_hash.__setitem__(key, ((value_days | int) > 0) | ternary(value_days, 1) ) %}
  {%-   else %}
  {%-     set _ = es_hash.__setitem__(key, 1) %}
  {%-   endif %}
  {%- endfor %}
  {{ es_hash }}

**********
DECISION===>: PASS
**********
=========================:::873:::END!!!=========================
=========================:::874:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_retention/tasks/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Query es storage
  uri:
    url: "http://{{ coordination_nodes[0] }}/_nodes/{{ (data_nodes | map('extract', hostvars, 'ansible_host') | list) | join(',') }}/stats/fs"
    method: GET
  register: elk_data
  environment:
    no_proxy: "{{ coordination_nodes[0].split(':')[0] }}"
  until:
    - elk_data is success and elk_data['json'] is defined
  retries: 5
  delay: 30
  run_once: true

- name: Set retention keys fact
  set_fact:
    es_storage_json: "{{ elk_data['json'] }}"

- name: Load retention algo variables
  include_vars: "calculate_index_retention_{{ elastic_index_retention_algorithm }}.yml"
  tags:
    - always

- name: Set retention facts (mb size)
  set_fact: "elastic_{{ item.key }}_size={{ item.value }}"
  when:
    - hostvars[inventory_hostname]["elastic_" ~ item.key ~ "_size"] is undefined
  with_dict: "{{ es_storage_per_index }}"

- name: Set retention facts (days)
  set_fact: "elastic_{{ item.key }}_retention={{ item.value }}"
  when:
    - hostvars[inventory_hostname]["elastic_" ~ item.key ~ "_retention"] is undefined
  with_dict: "{{ es_days_per_index }}"

- name: Set retention keys fact
  set_fact:
    elastic_beat_retention_policy_keys: "{{ elastic_beat_retention_policy_hosts.keys() | list }}"

**********
DECISION===>: PASS
**********
=========================:::874:::END!!!=========================
=========================:::875:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_retention/meta/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

galaxy_info:
  author: OpenStack
  description: Elastic v6.x retention role
  company: Rackspace
  license: Apache2
  min_ansible_version: 2.5
  platforms:
    - name: Ubuntu
      versions:
        - trusty
        - xenial
        - bionic
  categories:
    - cloud
    - development
    - elasticsearch
    - elastic-stack
dependencies:
  - role: elastic_data_hosts

**********
DECISION===>: PASS
**********
=========================:::875:::END!!!=========================
=========================:::876:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_retention/defaults/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

elastic_index_retention_algorithm: default

### Elastic curator variables
## If any of these retention policy option are undefined a dynamic fact will be
## generated.
## These options are all in days.
#  elastic_logstash_retention: 1
#  elastic_apm_retention: 1
#  elastic_auditbeat_retention: 1
#  elastic_filebeat_retention: 1
#  elastic_heartbeat_retention: 1
#  elastic_journalbeat_retention: 1
#  elastic_metricbeat_retention: 1
#  elastic_packetbeat_retention: 1

## These options are all in megabytes.
#  elastic_logstash_size: 1024
#  elastic_apm_size: 1024
#  elastic_auditbeat_size: 1024
#  elastic_filebeat_size: 1024
#  elastic_heartbeat_size: 1024
#  elastic_journalbeat_size: 1024
#  elastic_metricbeat_size: 1024
#  elastic_packetbeat_size: 1024

## WHen a static retention policy option is not defined these options will be
## used for dynamic fact generation.
##
## Facts will be generated for the general retention using the total available
## storage from the ES data nodes, subtracting 25%. Using the weights, each
## index will be given a percentage of the total available storage. Indexes with
## higher weights are expected to use more storage. The list of hosts in a given
## index will be used to determine the number of days data can exist within an
## index before it's pruned.

## Example:
#  es cluster has 4TiB of storage
#  filebeat is deployed to 100 hosts
#  filebeat has a weight of 10
#  metricbeat is deployed to 125 hosts
#  metricbeat has a weight of 2
#
#  es storage in MiB: 4194304
#  hosts and weighting total: (100 + 125) x (10 + 2) = 2700
#  filebeat pct: (100 x 10) / 2700 = 0.37
#  filebeat storage allowed: 0.37 * 4194304 = 1551892.48 MiB
#  filebeat days allowed: 1551892.48 / (100 * 1024) = 15.1552 Days
#  filebeat result: 15 days of retention or 1.5TiB of storage, whatever comes first
#  metricbeat pct: (125 x 2) / 2700 = 0.09
#  metricbeat storage allowed: 0.09 * 4194304 = 377487.36 MiB
#  metricbeat days allowed: 377487.36 / (125 * 1024) = 2.94912 Days
#  metricbeat result: 2 days of retention or 38GiB of storage, whatever comes first

elastic_beat_retention_policy_hosts:
  logstash:
    weight: 1
    hosts: "{{ groups['elastic-logstash'] | default([]) }}"
  apm:
    weight: 1
    hosts: "{{ groups['apm-server'] | default([]) }}"
  auditbeat:
    weight: 10
    hosts: "{{ groups['hosts'] | default([]) }}"
  filebeat:
    weight: 10
    hosts: "{{ groups['hosts'] | default([]) }}"
  syslog:
    weight: 1
    hosts: "{{ groups['hosts'] | default([]) }}"
  heartbeat:
    weight: 1
    hosts: "{{ groups['kibana'][:3] | default([]) }}"
  journalbeat:
    weight: 3
    hosts: "{{ groups['all'] | default([]) }}"
  metricbeat:
    weight: 2
    hosts: "{{ groups['all'] | default([]) }}"
  packetbeat:
    weight: 1
    hosts: "{{ groups['hosts'] | default([]) }}"

**********
DECISION===>: PASS
**********
=========================:::876:::END!!!=========================
=========================:::877:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_data_hosts/vars/data-node-variables.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# storage node count is equal to the cluster size
storage_node_count: "{{ groups['elastic-logstash'] | length }}"

# the elasticserch cluster elects one master from all those which are marked as master-eligible
# 1 node cluster can only have one master
# 2 node clusters have 1 master-eligable nodes to avoid split-brain
# 3 node clusters have 3 master-eligable nodes
# >3 node clusters have (nodes // 2) eligable masters rounded up to the next odd number
elastic_master_node_count: |-
  {% set masters = 0 %}
  {% if (storage_node_count | int) < 3 %}
  {%   set masters = 1 %}
  {% elif (storage_node_count | int) == 3 %}
  {%   set masters = 3 %}
  {% else %}
  {%   set masters = (storage_node_count | int ) // 2 %}
  {%   if ((masters | int) % 2 == 0) %}
  {%     set masters = (masters | int) + 1 %}
  {%   endif %}
  {% endif %}
  {{ masters }}

# Assign node roles
# the first 'elastic_master_node_count' hosts in groups['elastic-logstash'] become master-eligible nodes
# the first 'elastic_master_node_count' and subsequent alternate hosts in groups['elastic-logstash'] becomes data nodes
## While the data node group is dynamically chosen the override
## `elasticsearch_node_data` can be used to override the node type.
## Dynamic node inclusion will still work for all other nodes in the group.
_data_nodes: "{{ (groups['elastic-logstash'][:elastic_master_node_count | int] | union(groups['elastic-logstash'][elastic_master_node_count | int::2])) }}"
data_nodes: |-
  {% set nodes = [] %}
  {% for node in groups['elastic-logstash'] %}
  {%   if (hostvars[node]['elasticsearch_node_data'] is defined) and (hostvars[node]['elasticsearch_node_data'] | bool) %}
  {%     set _ = nodes.append(node) %}
  {%   endif %}
  {% endfor %}
  {% for node in groups['elastic-logstash'] %}
  {%   if (nodes | length) <= (_data_nodes | length) %}
  {%     if (node in _data_nodes) %}
  {%       set _ = nodes.append(node) %}
  {%     endif %}
  {%   endif %}
  {% endfor %}
  {{ nodes }}

## While the logstash node group is dynamically chosen the override
## `elasticsearch_node_ingest` can be used to override the node type.
## Dynamic node inclusion will still work for all other nodes in the group.
_logstash_nodes: "{{ data_nodes }}"
logstash_nodes: |-
  {% set nodes = [] %}
  {% for node in groups['elastic-logstash'] %}
  {%   if (hostvars[node]['elasticsearch_node_ingest'] is defined) and (hostvars[node]['elasticsearch_node_ingest'] | bool) %}
  {%     set _ = nodes.append(node) %}
  {%   endif %}
  {% endfor %}
  {% for node in groups['elastic-logstash'] %}
  {%   if (nodes | length) <= (_logstash_nodes | length) %}
  {%     if (node in _logstash_nodes) %}
  {%       set _ = nodes.append(node) %}
  {%     endif %}
  {%   endif %}
  {% endfor %}
  {{ nodes }}

## While the logstash node group is dynamically chosen the override
## `elasticsearch_node_ingest` can be used to override the node type.
## Dynamic node inclusion will still work for all other nodes in the group.
_ingest_nodes: "{{ data_nodes }}"
ingest_nodes: |-
  {% set nodes = [] %}
  {% for node in groups['elastic-logstash'] %}
  {%   if (hostvars[node]['elasticsearch_node_ingest'] is defined) and (hostvars[node]['elasticsearch_node_ingest'] | bool) %}
  {%     set _ = nodes.append(node) %}
  {%   endif %}
  {% endfor %}
  {% for node in groups['elastic-logstash'] %}
  {%   if (nodes | length) <= (_ingest_nodes | length) %}
  {%     if (node in _ingest_nodes) %}
  {%       set _ = nodes.append(node) %}
  {%     endif %}
  {%   endif %}
  {% endfor %}
  {{ nodes }}

## While the master node group is dynamically chosen the override
## `elasticsearch_node_master` can be used to override the node type.
## Dynamic node inclusion will still work for all other nodes in the group.
_master_nodes: "{{ groups['elastic-logstash'][:elastic_master_node_count | int] }}"
master_nodes: |-
  {% set nodes = [] %}
  {% for node in groups['elastic-logstash'] %}
  {%   if (nodes | length) <= (elastic_master_node_count | int) %}
  {%     if (hostvars[node]['elasticsearch_node_master'] is defined) and (hostvars[node]['elasticsearch_node_master'] | bool) %}
  {%       set _ = nodes.append(node) %}
  {%     endif %}
  {%   endif %}
  {% endfor %}
  {% for node in groups['elastic-logstash'] %}
  {%   if (nodes | length) <= (elastic_master_node_count | int) %}
  {%     if (node in _master_nodes) %}
  {%       set _ = nodes.append(node) %}
  {%     endif %}
  {%   endif %}
  {% endfor %}
  {{ nodes }}
master_node_count: "{{ master_nodes | length }}"

coordination_nodes: >-
  {{
    (groups['kibana'] | map('extract', hostvars, 'ansible_host') | list)
      | map('regex_replace', '(.*)' ,'\1:' ~ elastic_port)
      | list
  }}
zen_nodes: >-
  {{
    (groups['elastic-logstash'] | union(groups['kibana'])) | map('extract', hostvars, 'ansible_host') | list | shuffle(seed=inventory_hostname)
  }}
elasticserch_interface_speed: |-
  {% set default_interface_fact = hostvars[inventory_hostname]['ansible_' + (elastic_data_interface | replace('-', '_'))] %}
  {% set speeds = [] %}
  {% if default_interface_fact['type'] == 'bridge' %}
  {%   for interface in default_interface_fact['interfaces'] %}
  {%     set interface_fact = hostvars[inventory_hostname]['ansible_' + (interface | replace('-', '_'))] %}
  {%     if 'speed' in interface_fact %}
  {%       set speed = (interface_fact['speed'] | default(1000)) | string %}
  {%       if speed == "-1" %}
  {%         set _ = speeds.append(1000) %}
  {%       else %}
  {%         set _ = speeds.append(speed | int) %}
  {%       endif %}
  {%       if 'module' in interface_fact %}
  {%         set _ = speeds.append((interface_fact['speed'] | default(1000)) | int) %}
  {%       else %}
  {%         set _ = speeds.append(1000) %}
  {%       endif %}
  {%     endif %}
  {%   endfor %}
  {% else %}
  {%   if ('module' in default_interface_fact) or (default_interface_fact['type'] == 'bond') %}
  {%     set speed = (default_interface_fact['speed'] | default(1000)) | string %}
  {%     if speed == "-1" %}
  {%       set _ = speeds.append(1000) %}
  {%     else %}
  {%       set _ = speeds.append(speed | int) %}
  {%     endif %}
  {%   else %}
  {%     set _ = speeds.append(1000) %}
  {%   endif %}
  {% endif %}
  {% set interface_speed = ((speeds | min) * 0.20) | int %}
  {{ ((interface_speed | int) > 750) | ternary(750, interface_speed) }}
elasticsearch_data_node_details: >-
  {{
    (data_nodes | map('extract', hostvars, 'ansible_host') | list) | map('regex_replace', '(.*)' ,'\1:' ~ elastic_port) | list
  }}
logstash_data_node_details: >-
  {{
    (logstash_nodes | map('extract', hostvars, 'ansible_host') | list) | map('regex_replace', '(.*)' ,'\1:' ~ logstash_beat_input_port) | list
  }}

# based on the assignment of roles to hosts, set per host booleans
master_node: "{{ (inventory_hostname in master_nodes) | ternary(true, false) }}"
data_node: "{{ (inventory_hostname in data_nodes) | ternary(true, false) }}"

elastic_processors_floor: "{{ ((ansible_processor_count | int) - 1) }}"
elastic_processors_floor_set: "{{ ((elastic_processors_floor | int) > 0) | ternary(elastic_processors_floor, 1) }}"
elastic_thread_pool_size: "{{ ((ansible_processor_count | int) >= 24) | ternary(23, elastic_processors_floor_set) }}"

# Set a data node facts. The data nodes, in the case of elasticsearch are also
# ingest nodes.
elasticsearch_number_of_replicas: "{{ ((data_nodes | length) > 2) | ternary('2', ((data_nodes | length) > 1) | ternary('1', '0')) }}"
elasticsearch_data_hosts: |-
  {% set data_hosts = elasticsearch_data_node_details | shuffle(seed=inventory_hostname) %}
  {% if inventory_hostname in data_nodes %}
  {%   set _ = data_hosts.insert(0, '127.0.0.1:' ~ elastic_port) %}
  {% endif %}
  {{ data_hosts }}
logstash_data_hosts: |-
  {% set data_hosts = logstash_data_node_details | shuffle(seed=inventory_hostname) %}
  {% if inventory_hostname in data_nodes %}
  {%   set _ = data_hosts.insert(0, '127.0.0.1:' ~ logstash_beat_input_port) %}
  {% endif %}
  {{ data_hosts }}

**********
DECISION===>: PASS
**********
=========================:::877:::END!!!=========================
=========================:::878:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_data_hosts/tasks/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Refresh minimal facts
  setup:
    gather_subset: '!all,!any,network,virtual'
  tags:
    - always

- name: Load data node variables
  include_vars: "data-node-variables.yml"
  tags:
    - always

**********
DECISION===>: PASS
**********
=========================:::878:::END!!!=========================
=========================:::879:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_data_hosts/meta/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

galaxy_info:
  author: OpenStack
  description: Elastic v6.x data hosts role
  company: Rackspace
  license: Apache2
  min_ansible_version: 2.5
  platforms:
    - name: Ubuntu
      versions:
        - trusty
        - xenial
        - bionic
  categories:
    - cloud
    - development
    - elasticsearch
    - elastic-stack
dependencies: []

**********
DECISION===>: PASS
**********
=========================:::879:::END!!!=========================
=========================:::880:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_data_hosts/defaults/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This interface is used to determine cluster recovery speed.
elastic_data_interface: "{{ ansible_default_ipv4['alias'] }}"

**********
DECISION===>: PASS
**********
=========================:::880:::END!!!=========================
=========================:::881:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_rollup/tasks/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Get rollup job
  uri:
    url: "http://{{ coordination_nodes[0] }}/_xpack/rollup/job/rollup_{{ index_name }}"
    method: GET
  register: check_rollup
  environment:
    no_proxy: "{{ coordination_nodes[0].split(':')[0] }}"
  until: check_rollup is success
  retries: 3
  delay: 5
  run_once: true

- name: Check for existing rollup job
  debug:
    msg: >-
      An existing rollup job was found for {{ index_name }}. In order to
      re-create this rollup job the old job will need to be purged. If you're
      OK with the old rollup job being purged, add the following option
      `elastic_allow_rollup_purge=yes` to the command line and rerun the
      playbook.
  when:
    - check_rollup['json']['jobs'] | length > 0
    - not elastic_allow_rollup_purge | bool

- name: Create rollup block
  block:
    - name: Set min retention days fact
      set_fact:
        min_days_until_rollup: |-
          {% set index_retention = [] %}
          {% for item in ansible_play_hosts %}
          {%   set _ = index_retention.append(hostvars[item]['elastic_' + index_name + '_retention'] | int) %}
          {% endfor %}
          {{ index_retention | min }}
      run_once: true

    - name: Set retention days fact
      set_fact:
        days_until_rollup: "{{ ((min_days_until_rollup | int) > 1) | ternary(((min_days_until_rollup | int) - 1), min_days_until_rollup) }}"
      run_once: true

    - name: Create rollup job
      uri:
        url: "{{ item.url }}"
        method: "{{ item.method }}"
        body: "{{ item.index_options | to_json }}"
        status_code: "{{ item.status_code }}"
        body_format: json
      register: elk_indexes
      environment:
        no_proxy: "{{ coordination_nodes[0].split(':')[0] }}"
      until: elk_indexes is success
      retries: 5
      delay: 5
      when:
        - (days_until_rollup | int) > 0
      with_items:
        - url: "http://{{ coordination_nodes[0] }}/_xpack/rollup/job/rollup_{{ index_name }}/_stop"
          method: POST
          status_code: 200,404
          index_options: {}
        - url: "http://{{ coordination_nodes[0] }}/_xpack/rollup/job/rollup_{{ index_name }}"
          method: DELETE
          status_code: 200,404
          index_options: {}
        - url: "http://{{ coordination_nodes[0] }}/rollup_{{ index_name }}"
          method: DELETE
          status_code: 200,404
          index_options: {}
        - url: "http://{{ coordination_nodes[0] }}/_xpack/rollup/job/rollup_{{ index_name }}"
          method: PUT
          status_code: 200,400
          index_options:
            index_pattern: "{{ index_name }}-*"
            rollup_index: "rollup_{{ index_name }}"
            cron: "*/30 * * * * ?"
            page_size: 1000
            groups:
              date_histogram:
                field: "@timestamp"
                interval: "1h"
                delay: "{{ days_until_rollup }}d"
        - url: "http://{{ coordination_nodes[0] }}/_xpack/rollup/job/rollup_{{ index_name }}/_start"
          method: POST
          status_code: 200,404
          index_options: {}
      run_once: true
  when:
    - check_rollup['json']['jobs'] | length < 1 or
      elastic_allow_rollup_purge | bool

**********
DECISION===>: PASS
**********
=========================:::881:::END!!!=========================
=========================:::882:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_rollup/meta/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

galaxy_info:
  author: OpenStack
  description: Elastic v6.x rollup role
  company: Rackspace
  license: Apache2
  min_ansible_version: 2.5
  platforms:
    - name: Ubuntu
      versions:
        - trusty
        - xenial
        - bionic
  categories:
    - cloud
    - development
    - elasticsearch
    - elastic-stack
dependencies:
  - role: elastic_retention

**********
DECISION===>: PASS
**********
=========================:::882:::END!!!=========================
=========================:::883:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_rollup/defaults/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

elastic_allow_rollup_purge: false

**********
DECISION===>: PASS
**********
=========================:::883:::END!!!=========================
=========================:::884:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_apm_server/vars/redhat.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

apm_server_distro_packages:
  - apm-server

**********
DECISION===>: PASS
**********
=========================:::884:::END!!!=========================
=========================:::885:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_apm_server/vars/suse.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

apm_server_distro_packages:
  - apm-server

**********
DECISION===>: PASS
**********
=========================:::885:::END!!!=========================
=========================:::886:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_apm_server/vars/ubuntu.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

apm_server_distro_packages:
  - apm-server

**********
DECISION===>: PASS
**********
=========================:::886:::END!!!=========================
=========================:::887:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_apm_server/tasks/apm_setup.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Load templates
  shell: >-
    apm-server setup
    {{ item }}
    -E 'apm-server.host=localhost:8200'
    -E 'output.elasticsearch.hosts={{ coordination_nodes | to_json }}'
    -E 'setup.template.enabled=true'
    -E 'setup.template.overwrite=true'
    -e -v
  with_items:
    - "--template"
    - "--pipelines"
    - "--machine-learning"
    - "--dashboards"
  register: templates
  environment:
    no_proxy: "{{ hostvars[groups['kibana'][0]]['ansible_host'] }}"
  until: templates is success
  retries: 5
  delay: 5
  run_once: true

**********
DECISION===>: PASS
**********
=========================:::887:::END!!!=========================
=========================:::888:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_apm_server/tasks/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Gather variables for each operating system
  include_vars: "{{ item }}"
  with_first_found:
    - "{{ ansible_distribution | lower }}-{{ ansible_distribution_version | lower }}.yml"
    - "{{ ansible_distribution | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
    - "{{ ansible_os_family | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
    - "{{ ansible_distribution | lower }}.yml"
    - "{{ ansible_os_family | lower }}-{{ ansible_distribution_version.split('.')[0] }}.yml"
    - "{{ ansible_os_family | lower }}.yml"
  tags:
    - always

- name: Ensure apm-server is installed
  package:
    name: "{{ apm_server_distro_packages }}"
    state: "{{ elk_package_state | default('present') }}"
    update_cache: "{{ (ansible_pkg_mgr == 'apt') | ternary('yes', omit) }}"
  register: _package_task
  until: _package_task is success
  retries: 3
  delay: 2
  notify:
    - Enable and restart apm server
  tags:
    - package_install

- name: Create apm-server systemd service config dir
  file:
    path: "/etc/systemd/system/apm-server.service.d"
    state: "directory"
    group: "root"
    owner: "root"
    mode: "0755"
  when:
    - ansible_service_mgr == 'systemd'

- name: Apply systemd options
  template:
    src: "{{ item.src }}"
    dest: "/etc/systemd/system/apm-server.service.d/{{ item.dest }}"
    mode: "0644"
  when:
    - ansible_service_mgr == 'systemd'
  with_items:
    - src: "systemd.general-overrides.conf.j2"
      dest: "apm-server-overrides.conf"
  notify:
    - Enable and restart apm server

- name: Drop apm-server conf file
  template:
    src: "apm-server.yml.j2"
    dest: "/etc/apm-server/apm-server.yml"
  notify:
    - Enable and restart apm server

- include_tasks: apm_setup.yml
  tags:
    - setup

- name: Force beat handlers
  meta: flush_handlers

**********
DECISION===>: PASS
**********
=========================:::888:::END!!!=========================
=========================:::889:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_apm_server/meta/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

galaxy_info:
  author: OpenStack
  description: Elastic v6.x apm-server role
  company: Rackspace
  license: Apache2
  min_ansible_version: 2.5
  platforms:
    - name: Ubuntu
      versions:
        - trusty
        - xenial
        - bionic
  categories:
    - cloud
    - development
    - elasticsearch
    - elastic-stack
dependencies:
  - role: elastic_data_hosts
  - role: elastic_repositories

**********
DECISION===>: PASS
**********
=========================:::889:::END!!!=========================
=========================:::890:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_apm_server/defaults/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# APM vars
apm_interface: 0.0.0.0
apm_port: 8200
apm_token: SuperSecrete

**********
DECISION===>: PASS 
**********
=========================:::890:::END!!!=========================
=========================:::891:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_apm_server/handlers/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Enable and restart apm-server (systemd)
  systemd:
    name: "apm-server"
    enabled: true
    state: restarted
    daemon_reload: true
  when:
    - ansible_service_mgr == 'systemd'
  listen: Enable and restart apm server

- name: Enable and restart apm-server (upstart)
  service:
    name: "apm-server"
    state: restarted
    enabled: yes
  when:
    - ansible_service_mgr == 'upstart'
  listen: Enable and restart apm server

**********
DECISION===>: PASS
**********
=========================:::891:::END!!!=========================
=========================:::892:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elasticsearch/vars/redhat.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

elasticsearch_distro_packages:
  - logrotate
  - elasticsearch

elasticsearch_sysconfig_path: /etc/sysconfig/elasticsearch

**********
DECISION===>: PASS
**********
=========================:::892:::END!!!=========================
=========================:::893:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elasticsearch/vars/suse.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

elasticsearch_distro_packages:
  - logrotate
  - elasticsearch

elasticsearch_sysconfig_path: /etc/sysconfig/elasticsearch

**********
DECISION===>: PASS
**********
=========================:::893:::END!!!=========================
=========================:::894:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elasticsearch/vars/ubuntu.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

elasticsearch_distro_packages:
  - logrotate
  - elasticsearch

elasticsearch_sysconfig_path: /etc/default/elasticsearch

**********
DECISION===>: PASS
**********
=========================:::894:::END!!!=========================
=========================:::895:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elasticsearch/vars/vars_kibana.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Set kibana as elasticsearch coordinators
elasticsearch_node_master: false
elasticsearch_node_data: false
elasticsearch_node_ingest: false
elastic_coordination_node: true
elastic_heap_size: "{{ (elastic_heap_size_default | int) // 3 }}"

# This variable is redefined because kibana runs elasticsearch but only in a
# load balancer capacity.
elastic_processors_half: "{{ ((ansible_processor_count | int) // 2) }}"
elastic_processors_half_set: "{{ ((elastic_processors_half | int) > 0) | ternary(elastic_processors_half, 1) }}"
elastic_thread_pool_size: "{{ ((elastic_processors_half_set | int) > 4) | ternary(4, elastic_processors_half_set) }}"

**********
DECISION===>: PASS
**********
=========================:::895:::END!!!=========================
=========================:::896:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elasticsearch/vars/vars_default.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Set elasticsearch facts
elastic_heap_size: "{{ elastic_heap_size_default }}"

**********
DECISION===>: PASS
**********
=========================:::896:::END!!!=========================
=========================:::897:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elasticsearch/tasks/elasticsearch_plugins.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Remove plugins
  command: "/usr/share/elasticsearch/bin/elasticsearch-plugin remove --verbose {{ item }}"
  failed_when: false
  changed_when:
    - remove_plugin.rc == 0
  register: remove_plugin
  with_items: "{{ elastic_plugins }}"

- name: Install plugins
  command: "/usr/share/elasticsearch/bin/elasticsearch-plugin install --batch --verbose {{ item }}"
  with_items: "{{ elastic_plugins }}"

**********
DECISION===>: PASS
**********
=========================:::897:::END!!!=========================
=========================:::898:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elasticsearch/tasks/elasticsearch_nfs_setup.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Ensure nfs client is available if necessary
  package:
    name: nfs-common
    state: present

- name: Ensure backup filesystems are mounted
  mount:
    fstype: "{{ item.fstype }}"
    src: "{{ item.src }}"
    opts: "{{ item.opts }}"
    path: "{{ item.path }}"
    state: "{{ item.state }}"
  with_items:
    - "{{ elastic_shared_fs_repos }}"

**********
DECISION===>: PASS
**********
=========================:::898:::END!!!=========================
=========================:::899:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elasticsearch/tasks/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Gather variables for each operating system
  include_vars: "{{ item }}"
  with_first_found:
    - "{{ ansible_distribution | lower }}-{{ ansible_distribution_version | lower }}.yml"
    - "{{ ansible_distribution | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
    - "{{ ansible_os_family | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
    - "{{ ansible_distribution | lower }}.yml"
    - "{{ ansible_os_family | lower }}-{{ ansible_distribution_version.split('.')[0] }}.yml"
    - "{{ ansible_os_family | lower }}.yml"
  tags:
    - always

- name: Set elasticsearch variables
  include_vars: "vars_{{ ((inventory_hostname in (groups['kibana'] | default([])) and not inventory_hostname in (groups['elastic-logstash']) | default([]))) | ternary('kibana', 'default') }}.yml"
  tags:
    - always

- name: Ensure elasticsearch is installed
  package:
    name: "{{ elasticsearch_distro_packages }}"
    state: "{{ elk_package_state | default('present') }}"
    update_cache: "{{ (ansible_pkg_mgr == 'apt') | ternary('yes', omit) }}"
  register: _package_task
  until: _package_task is success
  retries: 3
  delay: 2
  notify:
    - Enable and restart elastic
  tags:
    - package_install

- name: Create elasticsearch systemd service config dir
  file:
    path: "/etc/systemd/system/elasticsearch.service.d"
    state: "directory"
    group: "root"
    owner: "root"
    mode: "0755"
  when:
    - ansible_service_mgr == 'systemd'

- name: Apply systemd options
  template:
    src: "{{ item.src }}"
    dest: "{{ item.dest }}"
  when:
    - ansible_service_mgr == 'systemd'
  with_items:
    - src: "systemd.elasticsearch-overrides.conf.j2"
      dest: "/etc/systemd/system/elasticsearch.service.d/elasticsearch-overrides.conf"
  notify:
    - Enable and restart elastic
  tags:
    - config

- name: Set sysconfig service defaults
  lineinfile:
    path: "{{ elasticsearch_sysconfig_path }}"
    regexp: '^{{ item.key }}='
    line: '{{ item.key }}={{ item.value }}'
  with_items:
    - key: MAX_OPEN_FILES
      value: 65536
    - key: MAX_LOCKED_MEMORY
      value: unlimited
    - key: MAX_MAP_COUNT
      value: 524288

- name: Drop jvm conf file(s)
  template:
    src: "{{ item.src }}"
    dest: "{{ item.dest }}"
  with_items:
    - src: "jvm.options.j2"
      dest: "/etc/elasticsearch/jvm.options"
  notify:
    - Enable and restart elastic

- name: Drop elasticsearch conf file
  template:
    src: "{{ item.src }}"
    dest: "{{ item.dest }}"
  with_items:
    - src: "elasticsearch.yml.j2"
      dest: "/etc/elasticsearch/elasticsearch.yml"
    - src: "es-log4j2.properties.j2"
      dest: "/etc/elasticsearch/log4j2.properties"
  notify:
    - Enable and restart elastic
  tags:
    - config

- name: Ensure elasticsearch ownership
  file:
    path: "/var/lib/elasticsearch/"
    owner: elasticsearch
    group: elasticsearch
    recurse: true
  register: e_perms
  until: e_perms is success
  retries: 3
  delay: 1
  tags:
    - config

- name: Ensure elasticsearch tmp dir
  file:
    path: "/var/lib/elasticsearch/tmp"
    state: directory
    owner: "elasticsearch"
    group: "elasticsearch"
    mode: "0750"

- include_tasks: "elasticsearch_nfs_setup.yml"
  when:
    - elastic_shared_fs_repos is defined
    - (elastic_shared_fs_repos | json_query(nfs_query)) | length > 0

- include_tasks: "elasticsearch_plugins.yml"

**********
DECISION===>: PASS
**********
=========================:::899:::END!!!=========================
=========================:::900:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elasticsearch/meta/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

galaxy_info:
  author: OpenStack
  description: Elastic v6.x elasticsearch role
  company: Rackspace
  license: Apache2
  min_ansible_version: 2.5
  platforms:
    - name: Ubuntu
      versions:
        - trusty
        - xenial
        - bionic
  categories:
    - cloud
    - development
    - elasticsearch
    - elastic-stack
dependencies:
  - role: elastic_data_hosts
  - role: elastic_repositories
  - role: elastic_dependencies
    service_name: elasticsearch
    service_owner: elasticsearch
    service_group: elasticsearch

**********
DECISION===>: PASS
**********
=========================:::900:::END!!!=========================
=========================:::901:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elasticsearch/defaults/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

cluster_name: openstack_elk
elastic_log_rotate_path: "/var/log/elasticsearch"

temp_dir: /var/lib/elasticsearch/tmp
nfs_query: "[?fstype=='nfs' || fstype=='nfs4']"

# Enable or Disable memory locking.
elastic_memory_lock: true

# Elasticsearch plugin list. These plugins will be re-installed whenever the
# playbooks are executed, which ensures the plugins are always upgraded.
elastic_plugins:
  - ingest-attachment
  - ingest-geoip
  - ingest-user-agent

**********
DECISION===>: PASS
**********
=========================:::901:::END!!!=========================
=========================:::902:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elasticsearch/handlers/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Enable and restart elasticsearch (systemd)
  systemd:
    name: "elasticsearch"
    enabled: true
    state: restarted
    daemon_reload: true
  when:
    - ansible_service_mgr == 'systemd'
  listen: Enable and restart elastic

- name: Enable and restart elasticsearch (upstart)
  service:
    name: "elasticsearch"
    state: restarted
    enabled: yes
  when:
    - ansible_service_mgr == 'upstart'
  listen: Enable and restart elastic

**********
DECISION===>: PASS
**********
=========================:::902:::END!!!=========================
=========================:::903:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_logstash/vars/redhat.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

logstash_distro_packages:
  - logrotate
  - logstash

logstash_sysconfig_path: /etc/default/logstash

**********
DECISION===>: PASS
**********
=========================:::903:::END!!!=========================
=========================:::904:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_logstash/vars/suse.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

logstash_distro_packages:
  - logrotate
  - logstash

logstash_sysconfig_path: /etc/default/logstash

**********
DECISION===>: PASS
**********
=========================:::904:::END!!!=========================
=========================:::905:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_logstash/vars/ubuntu.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

logstash_distro_packages:
  - logrotate
  - logstash

logstash_sysconfig_path: /etc/default/logstash

**********
DECISION===>: PASS
**********
=========================:::905:::END!!!=========================
=========================:::906:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_logstash/tasks/logstash_kafka_ssl.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Copy kafka keystore into place
  copy:
    src: "{{ logstash_kafka_ssl_keystore_location }}"
    dest: "/var/lib/logstash/{{ logstash_kafka_ssl_keystore_location | basename }}"

- name: Copy kafka truststore into place
  copy:
    src: "{{ logstash_kafka_ssl_truststore_location }}"
    dest: "/var/lib/logstash/{{ logstash_kafka_ssl_truststore_location | basename }}"

**********
DECISION===>: PASS
**********
=========================:::906:::END!!!=========================
=========================:::907:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_logstash/tasks/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Gather variables for each operating system
  include_vars: "{{ item }}"
  with_first_found:
    - "{{ ansible_distribution | lower }}-{{ ansible_distribution_version | lower }}.yml"
    - "{{ ansible_distribution | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
    - "{{ ansible_os_family | lower }}-{{ ansible_distribution_major_version | lower }}.yml"
    - "{{ ansible_distribution | lower }}.yml"
    - "{{ ansible_os_family | lower }}-{{ ansible_distribution_version.split('.')[0] }}.yml"
    - "{{ ansible_os_family | lower }}.yml"
  tags:
    - always

- name: Ensure Logstash is installed
  package:
    name: "{{ logstash_distro_packages }}"
    state: "{{ elk_package_state | default('present') }}"
    update_cache: "{{ (ansible_pkg_mgr == 'apt') | ternary('yes', omit) }}"
  register: _package_task
  until: _package_task is success
  retries: 3
  delay: 2
  notify:
    - Enable and restart logstash
  tags:
    - package_install

- name: Create logstash systemd service config dir
  file:
    path: "/etc/systemd/system/logstash.service.d"
    state: "directory"
    group: "root"
    owner: "root"
    mode: "0755"
  when:
    - ansible_service_mgr == 'systemd'

- name: Apply systemd options
  template:
    src: "{{ item.src }}"
    dest: "{{ item.dest }}"
    mode: "0644"
  when:
    - ansible_service_mgr == 'systemd'
  with_items:
    - src: "systemd.general-overrides.conf.j2"
      dest: "/etc/systemd/system/logstash.service.d/logstash-overrides.conf"
  notify:
    - Enable and restart logstash

- name: Set sysconfig service defaults
  lineinfile:
    path: "{{ logstash_sysconfig_path }}"
    regexp: '^{{ item.key }}='
    line: '{{ item.key }}={{ item.value }}'
  with_items:
    - key: LS_OPEN_FILES
      value: 32768

- name: Drop jvm conf file(s)
  template:
    src: "{{ item.src }}"
    dest: "{{ item.dest }}"
  with_items:
    - src: "jvm.options.j2"
      dest: "/etc/logstash/jvm.options"
  notify:
    - Enable and restart logstash

- name: Check queue type
  block:
    - name: Get block device for logstash
      command: findmnt -vno SOURCE --target=/var/lib/logstash
      changed_when: false
      register: _logstash_block_device

    - name: Set device fact
      set_fact:
        _logstash_device: "{{ _logstash_block_device.stdout.split('/')[-1] | regex_replace('[0-9]$','') }}"

    - name: Set device info fact
      set_fact:
        _logstash_device_info: "{{ ansible_devices[_logstash_device] }}"

    - name: Set persisted queue fact
      set_fact:
        logstash_queue_type: "{{ ((_logstash_device_info['rotational'] | int) != 1) | ternary('persisted', 'memory') }}"
  rescue:
    - name: Set persisted queue fact (fallback)
      set_fact:
        logstash_queue_type: memory
  when:
    - logstash_queue_type is undefined

- name: Systemd memory backed queue block
  block:
    - name: Get logstash UID
      command: id -u logstash
      register: logstash_uid
      changed_when: false
      when:
        - ansible_service_mgr == 'systemd'

    - name: Get logstash GID
      command: id -g logstash
      register: logstash_gid
      changed_when: false
      when:
        - ansible_service_mgr == 'systemd'

    - name: Run the systemd mount role
      include_role:
        name: systemd_mount
        private: true
      vars:
        systemd_mounts:
          - what: "tmpfs"
            where: "/var/lib/logstash/queue"
            type: "tmpfs"
            options: "size={{ (q_mem | int) // 2 }}m,uid={{ logstash_uid.stdout }},gid={{ logstash_gid.stdout }},nodev,nodiratime,noatime"
            unit:
              Before:
                - logstash.service
            state: 'started'
            enabled: true
      when:
        - ansible_service_mgr == 'systemd'

    - name: Apply fstab options for memory queues
      mount:
        path: /var/lib/logstash/queue
        src: tmpfs
        fstype: tmpfs
        opts: size={{ (q_mem | int) // 2 }}m
        state: mounted
      when:
        - ansible_service_mgr != 'systemd'
  when:
    - logstash_queue_type == 'memory'

- name: Create patterns directory
  file:
    name: "/opt/logstash/patterns"
    owner: "logstash"
    group: "logstash"
    state: directory
  tags:
    - logstash-patterns

- name: Logstash Extra Patterns
  template:
    src: "extras"
    dest: "/opt/logstash/patterns/extras"
    owner: "logstash"
    group: "logstash"
  when:
    - logstash_deploy_filters
  notify:
    - Enable and restart logstash
  tags:
    - logstash-filters
    - config

- name: Run kafka ssl deployment
  include_tasks: logstash_kafka_ssl.yml
  when:
    - logstash_kafka_options is defined
    - logstash_kafka_ssl_keystore_location is defined

- name: Drop logstash conf file(s)
  template:
    src: "{{ item.src }}"
    dest: "{{ item.dest }}"
  with_items:
    - src: "logstash.yml.j2"
      dest: "/etc/logstash/logstash.yml"
    - src: "logstash-pipelines.yml.j2"
      dest: "/etc/logstash/pipelines.yml"
  notify:
    - Enable and restart logstash
  tags:
    - config

- name: Ensure logstash ownership
  file:
    path: "/var/lib/logstash/"
    owner: logstash
    group: logstash
    recurse: true
  register: l_perms
  until: l_perms is success
  retries: 3
  delay: 1

- name: Ensure logstash tmp dir
  file:
    path: "/var/lib/logstash/tmp"
    state: directory
    owner: "logstash"
    group: "logstash"
    mode: "0750"

- name: Deploy arcsight collector
  include_tasks: logstash_arcsight.yml
  when:
    - logstash_arcsight_smart_connectors or
      logstash_arcsight_event_brokers

**********
DECISION===>: PASS
**********
=========================:::907:::END!!!=========================
=========================:::908:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_logstash/tasks/logstash_arcsight.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Initialise arcsight local facts
  ini_file:
    dest: "/etc/ansible/facts.d/logstash.fact"
    section: arcsight
    option: "initialise"
    value: true

- name: refresh local facts
  setup:
    filter: ansible_local
    gather_subset: "!all"
  tags:
    - nova-config

- name: Setup arcsight smart connector
  shell: >-
    /usr/local/bin/logstash --modules arcsight {{ (ansible_local['arcsight'][item.host] is defined) | ternary('', '--setup') }}
      -M "arcsight.var.input.smartconnector.bootstrap_servers={{ item.host }}:{{ item.port }}"
      -M "arcsight.var.elasticsearch.hosts=localhost:{{ elastic_port }}"
      -M "arcsight.var.kibana.host={{ hostvars[groups['kibana'][0]]['ansible_host'] }}:{{ kibana_port }}"
  with_items: "{{ logstash_arcsight_smart_connectors }}"
  run_once: true
  register: smart_connector
  until: smart_connector is success
  retries: 5
  delay: 5

- name: Setup arcsight event broker
  shell: >-
    /usr/local/bin/logstash --modules arcsight {{ (ansible_local['arcsight'][item.host] is defined) | ternary('', '--setup') }}
      -M "arcsight.var.input.eventbroker.bootstrap_servers={{ item.host }}:{{ item.port }}"
      -M "arcsight.var.elasticsearch.hosts=localhost:{{ elastic_port }}"
      -M "arcsight.var.kibana.host={{ hostvars[groups['kibana'][0]]['ansible_host'] }}:{{ kibana_port }}"
  with_items: "{{ logstash_arcsight_event_brokers }}"
  run_once: true
  register: event_broker
  until: event_broker is success
  retries: 5
  delay: 5

- name: Set arcsight local facts
  ini_file:
    dest: "/etc/ansible/facts.d/logstash.fact"
    section: arcsight
    option: "{{ item.host }}"
    value: "{{ item.port }}"
  with_items: "{{ logstash_arcsight_smart_connectors | union(logstash_arcsight_event_brokers) }}"

**********
DECISION===>: PASS
**********
=========================:::908:::END!!!=========================
=========================:::909:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_logstash/meta/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

galaxy_info:
  author: OpenStack
  description: Elastic v6.x logstash role
  company: Rackspace
  license: Apache2
  min_ansible_version: 2.5
  platforms:
    - name: Ubuntu
      versions:
        - trusty
        - xenial
        - bionic
  categories:
    - cloud
    - development
    - elasticsearch
    - elastic-stack
dependencies:
  - role: elastic_data_hosts
  - role: elastic_repositories
  - role: elastic_dependencies
    service_name: logstash
    service_owner: logstash
    service_group: logstash

**********
DECISION===>: PASS
**********
=========================:::909:::END!!!=========================
=========================:::910:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_logstash/defaults/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

temp_dir: /var/lib/logstash/tmp
logstash_pipelines: "{{lookup('template', 'logstash-pipelines.yml.j2') }}"

# Set processor cores fact
q_storage: 1

# Set logstash facts
logstash_queue_size: "{{ ((((q_storage | int) >= 2) | ternary(q_storage, 2) | int) * 1024) // ((logstash_pipelines | from_yaml) | length) }}"
elastic_log_rotate_path: "/var/log/logstash"

# Enable direct syslog input into logstash. When this is enabled syslog messages
# can be sent directly to logstash via TCP or UDP.
logstash_syslog_input_enabled: false

# The typical syslog port is 514 however that is not available to logstash
# because it's a "privledged" port. For this reason 5140 is used as the default.
# Changing this port to 514 will require overrides to the service files making
# logstash run as root (not recommended).
logstash_syslog_input_port: 5140

# Protocol used when the syslog input is enabled. Modes are "tcp" or "udp".
logstash_syslog_input_mode: udp

logstash_beat_input_port: 5044
logstash_deploy_filters: true

## Logstash config showing a complete kafka setup using SSL for authentication.
# logstash_kafka_options:
#   codec: json
#   topic_id: "elk_kafka"
#   ssl_key_password: "{{ logstash_kafka_ssl_key_password }}"
#   ssl_keystore_password: "{{ logstash_kafka_ssl_keystore_password }}"
#   ssl_keystore_location: "/var/lib/logstash/{{ logstash_kafka_ssl_keystore_location | basename }}"
#   ssl_truststore_location: "/var/lib/logstash/{{ logstash_kafka_ssl_truststore_location | basename }}"
#   ssl_truststore_password: "{{ logstash_kafka_ssl_truststore_password }}"
#   bootstrap_servers:
#     - server1.local:9092
#     - server2.local:9092
#     - server3.local:9092
#   client_id: "elk_metrics_6x"
#   compression_type: "gzip"
#   security_protocol: "SSL"

## The following variables are options that correspond to the
## `logstash_kafka_options` variable.
# logstash_kafka_ssl_key_password: "secrete"
# logstash_kafka_ssl_keystore_password: "secrete"
# logstash_kafka_ssl_truststore_password: "secrete"
# logstash_kafka_ssl_keystore_location: "/root/kafka/keystore.jks"
# logstash_kafka_ssl_truststore_location: "/root/kafka/truststore.jks"

## Setup servers that read events from the Smart Connector directly. This
## supports multiple entries in list format using the "host" and "port" for the
## smart connector.
# logstash_arcsight_smart_connectors:
#   - host: 127.0.0.1
#     port: 5000
logstash_arcsight_smart_connectors: []

## Setup servers to read events from the Eevnt Broker Stream. This
## multiple entries in list format using the "host" and "port" for the
## for the event brokers.
# logstash_arcsight_event_brokers:
#   - host: 127.0.0.1
#     port: 5000
logstash_arcsight_event_brokers: []

## The logstash queue type can be set to "memory" or "persisted". If the queue
## type is set to memory a ramdisk will be created limiting the in memory queue
## to 50% of the JVM heap size. When this option is undefined the playbook will
## detect the media type where the queue will exist. If the media type is
## "rotational" in memory queues will be used.
# logstash_queue_type:

**********
DECISION===>: PASS
**********
=========================:::910:::END!!!=========================
=========================:::911:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/elk_metrics_6x/roles/elastic_logstash/handlers/main.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Enable and restart logstash (systemd)
  systemd:
    name: "logstash"
    enabled: true
    state: "{{ (inventory_hostname in logstash_nodes) | ternary('restarted', 'stopped') }}"
    daemon_reload: true
  when:
    - ansible_service_mgr == 'systemd'
  listen: Enable and restart logstash

- name: Enable and restart logstash (upstart)
  service:
    name: "logstash"
    state: "{{ (inventory_hostname in logstash_nodes) | ternary('restarted', 'stopped') }}"
    enabled: yes
  when:
    - ansible_service_mgr == 'upstart'
  listen: Enable and restart logstash

**********
DECISION===>: PASS
**********
=========================:::911:::END!!!=========================
=========================:::912:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/ansible_tools/playbooks/archive-containers.yml
**********
---
# Copyright 2017, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Archive container(s)
  hosts: "{{ container_group|default('all_containers') }}"
  gather_facts: false
  serial: '20%'
  user: root
  pre_tasks:
    - name: Create archive directory
      file:
        path: /opt/archives
        state: directory
      delegate_to: "{{ physical_host }}"
  tasks:
    - name: Get container current state
      shell: "lxc-info -sn {{ inventory_hostname }} | awk '{print $2}'"
      register: current_state
      delegate_to: "{{ physical_host }}"

    - name: Archive container
      lxc_container:
        name: "{{ inventory_hostname }}"
        state: "{{ container_state[current_state.stdout.strip()] }}"
        archive: true
        archive_path: /opt/archives
      delegate_to: "{{ physical_host }}"
  vars:
    container_state:
      RUNNING: started
      STOPPED: stopped
      FROZEN: frozen

**********
DECISION===>: PASS
**********
=========================:::912:::END!!!=========================
=========================:::913:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/ansible_tools/playbooks/remove_compute_node.yml
**********
---
# Copyright 2014, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Remove a compute node from the OSA environment
  hosts: utility[0]
  user: root
  pre_tasks:
    - name: Fail if host_to_be_removed is not defined
      fail:
        msg: "host_to_be_removed must be defined as ansible user variable"
      when: host_to_be_removed is not defined
    - name: Find ID of the nova-compute service we want to remove
      shell: |
        . {{ ansible_env.HOME }}/openrc
        openstack compute service list | grep {{ host_to_be_removed }} | awk '{print $2}'
      register: results
      changed_when: results.rc == 0 and results.stdout_lines|length > 0
      failed_when: results.rc > 0 or results.stdout_lines|length == 0
    - name: Find ID of the neutron agent service we want to remove
      shell: |
        . {{ ansible_env.HOME }}/openrc
        neutron agent-list | grep {{ host_to_be_removed }} | awk '{print $2}'
      register: neutron_agent_list_results
      changed_when: neutron_agent_list_results.rc == 0
      failed_when: neutron_agent_list_results.rc > 0
  tasks:
    - name: Remove the nova-compute service from compute node
      shell: |
        . {{ ansible_env.HOME }}/openrc
        openstack compute service delete {{ results.stdout }}
      register: compute_delete_result
      changed_when: compute_delete_result.rc
      failed_when: compute_delete_result.rc > 0
    - name: Remove neutron agent service on {{ host_to_be_removed }}
      shell: |
        . {{ ansible_env.HOME }}/openrc
        neutron agent-delete {{ item }}
      with_items: "{{ neutron_agent_list_results.stdout_lines }}"
      register: neutron_delete_results
      changed_when: neutron_delete_results.rc == 0
      failed_when: neutron_delete_results.rc > 0
    - name: Delete the host from the OSA inventory file
      shell: |
         python /opt/openstack-ansible/scripts/inventory-manage.py -r {{ host_to_be_removed }}
      register: inventory_manage_output
      delegate_to: 127.0.0.1
      connection: local
      failed_when : inventory_manage_output.rc > 0



**********
DECISION===>: PASS
**********
=========================:::913:::END!!!=========================
=========================:::914:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/ansible_tools/playbooks/swift_storage_mount_drives.yml
**********
---
# Copyright 2016, @WalmartLabs, Bangalore.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


#This role is to mount the drives in swift object node and is optional.
#This gets executed only when the flag 'mount_drives' in swift configuration
#file is set to true.

- name: Mount drives in swift object servers
  hosts: swift_hosts
  user: root
  vars:
    device_path: 'opt'
    filesystem_to_mount: 'xfs'
  tasks:
    - name: "Set swift_vars if undefined"
      set_fact:
        swift_vars: "{}"
      when: swift_vars is not defined

    - name: "Create mount point directory"
      file:
        state: "directory"
        path: "{{ swift_vars.mount_point | default(swift.mount_point) }}/{{ item.name }}"
      with_items: swift_vars.drives
      when: swift_vars.drives is defined

    - name: "Create mount point directory"
      file:
        state: "directory"
        path: "{{ swift_vars.mount_point | default(swift.mount_point) }}/{{ item.name }}"
      with_items: swift.drives
      when: swift_vars.drives is not defined

    - name: "Format to {{ filesystem_to_mount }}"
      filesystem:
        fstype: "{{ filesystem_to_mount }}"
        dev: "/{{ device_path }}/{{ item.name }}"
        force: "yes"
      with_items: swift_vars.drives
      when: swift_vars.drives is defined

    - name: "Format to {{ filesystem_to_mount }}"
      filesystem:
        fstype: "{{ filesystem_to_mount }}"
        dev: "/{{ device_path }}/{{ item.name }}"
        force: "yes"
      with_items: swift.drives
      when: swift_vars.drives is not defined

    - name: "Mount the storage"
      mount:
        name: "{{ swift_vars.mount_point | default(swift.mount_point) }}/{{ item.name }}"
        src: "/{{ device_path }}/{{ item.name }}"
        fstype: "{{ filesystem_to_mount }}"
        opts: "rw,noatime,nodiratime,nobarrier,inode64,delaylog,logbufs=8,logbsize=256k,allocsize=4M"
        dump: 0
        passno: 0
        state: "mounted"
      with_items: swift_vars.drives
      when: swift_vars.drives is defined

    - name: "Mount the storage"
      mount:
        name: "{{ swift_vars.mount_point | default(swift.mount_point) }}/{{ item.name }}"
        src: "/{{ device_path }}/{{ item.name }}"
        fstype: "{{ filesystem_to_mount }}"
        opts: "rw,noatime,nodiratime,nobarrier,inode64,delaylog,logbufs=8,logbsize=256k,allocsize=4M"
        dump: 0
        passno: 0
        state: "mounted"
      with_items: swift.drives
      when: swift_vars.drives is not defined

**********
DECISION===>: PASS
**********
=========================:::914:::END!!!=========================
=========================:::915:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/ansible_tools/playbooks/cleanup-venvs.yml
**********
---
# Copyright 2017, Osones.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Remove older venvs
  hosts: all
  tasks:
  - name: List venvs directories
    find:
      paths: /openstack/venvs
      file_type: directory
      patterns: '.*(?<!{{ venv_tag }})$'
      use_regex: yes
    register: result
  - name: Delete older directories
    file:
      path: "{{ item.path }}"
      state: absent
    with_items: "{{ result.files }}"

- name: Remove older venv tgz
  hosts: all
  tasks:
  - name: List venv tgz
    find:
      paths: /var/cache
      file_type: file
      patterns: '.*(?<!{{ venv_tag }})-{{ ansible_architecture | lower }}\.tgz$'
      use_regex: yes
    register: result
  - name: Delete older tgz
    file:
      path: "{{ item.path }}"
      state: absent
    with_items: "{{ result.files }}"

**********
DECISION===>: PASS
**********
=========================:::915:::END!!!=========================
=========================:::916:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/leap-upgrades/upgrade-utilities-kilo/playbooks/host-adjustments.yml
**********
---
# Copyright 2015, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Host adjustments
  hosts: "hosts"
  max_fail_percentage: 100
  gather_facts: false
  user: root
  tasks:
    - name: Remove old lxc cache files
      file:
        path: "{{ item }}"
        state: "absent"
      with_items:
        - "/var/cache/lxc_trusty.tgz"
        - "/var/cache/lxc/rpc-trusty-container.tgz"
    - name: Ensure services log files are fix
      shell: |
        if [ ! -h "/var/log/{{ item }}" ] && [ -d "/var/log/{{ item }}" ];then
          mv /var/log/{{ item }} /openstack/log/{{ inventory_hostname }}-{{ item }}
          ln -s /openstack/log/{{ inventory_hostname }}-{{ item }} /var/log/{{ item }}
        else
          # Exit 99 when nothing found to change
          exit 99
        fi
      failed_when: false
      changed_when: log_change.rc == 0
      register: log_change
      with_items:
        - "cinder"
        - "glance"
        - "heat"
        - "horizon"
        - "keystone"
        - "nova"
        - "neutron"
        - "swift"

**********
DECISION===>: PASS
**********
=========================:::916:::END!!!=========================
=========================:::917:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/leap-upgrades/upgrade-utilities-kilo/playbooks/swift-ring-adjustments.yml
**********
---
# Copyright 2015, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Send swift rings from localhost to the first swift node
  hosts: "swift_hosts[0]"
  max_fail_percentage: 100
  gather_facts: false
  user: root
  tasks:
    - name: Ensure the swift system user
      user:
        name: "{{ swift_system_user_name }}"
        group: "{{ swift_system_group_name }}"
        comment: "{{ swift_system_comment }}"
        shell: "{{ swift_system_shell }}"
        system: "yes"
        createhome: "yes"
        home: "{{ swift_system_home_folder }}"
    - name: Ensure "/etc/swift/ring_build_files/" exists
      file:
        path: "{{ item }}"
        owner: "{{ swift_system_user_name }}"
        group: "{{ swift_system_group_name }}"
        state: "directory"
      with_items:
        - "/etc/swift"
        - "/etc/swift/ring_build_files"
    - name: "Copy the rings from localhost to swift_host[0]"
      copy:
        src: "{{ item }}"
        dest: "/etc/swift/ring_build_files/"
        mode: "0644"
        owner: "{{ swift_system_user_name }}"
        group: "{{ swift_system_group_name }}"
      with_fileglob:
        - /etc/swift/rings/*.ring.gz
        - /etc/swift/rings/*.builder
      when: >
        inventory_hostname == groups['swift_hosts'][0]
  vars:
    swift_system_user_name: swift
    swift_system_group_name: swift
    swift_system_shell: /bin/bash
    swift_system_comment: swift system user
    swift_system_home_folder: "/var/lib/{{ swift_system_user_name }}"
**********
DECISION===>: PASS
**********
=========================:::917:::END!!!=========================
=========================:::918:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/leap-upgrades/upgrade-utilities-kilo/playbooks/container-network-adjustments.yml
**********
---
# Copyright 2015, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Container network adjustments
  hosts: "all_containers"
  max_fail_percentage: 100
  gather_facts: false
  user: root
  tasks:
    - name: Get interface files
      command: ls -1 /etc/network/interfaces.d/
      register: interface_files
      failed_when: false
    - name: Remove old interface files
      file:
        path: "/etc/network/interfaces.d/{{ item }}"
        state: "absent"
      with_items:
        - "{{ interface_files.stdout_lines }}"
      failed_when: false

**********
DECISION===>: PASS
**********
=========================:::918:::END!!!=========================
=========================:::919:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/leap-upgrades/upgrade-utilities-kilo/playbooks/swift-repo-adjustments.yml
**********
---
# Copyright 2015, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Ensure swift has access to the backports repo
  hosts: "swift_all"
  max_fail_percentage: 100
  gather_facts: false
  user: root
  tasks:
    - name: Ensure all swift nodes have access to the backports repo
      shell: |
        UBUNTU_RELEASE=$(lsb_release -sc)
        UBUNTU_REPO=$(awk "/^deb .*ubuntu\/? ${UBUNTU_RELEASE} main/ {print \$2; exit}" /etc/apt/sources.list)
        UBUNTU_BACKPORTS="deb ${UBUNTU_REPO} ${UBUNTU_RELEASE}-backports main restricted universe multiverse"
        if ! grep "^$UBUNTU_BACKPORTS" /etc/apt/sources.list; then
          echo $UBUNTU_BACKPORTS | tee -a /etc/apt/sources.list
          apt-get update
        else
          exit 1
        fi
      environment:
        PATH: "/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games"
      changed_when: repo_updates.rc == 0
      failed_when: false
      register: repo_updates

**********
DECISION===>: PASS
**********
=========================:::919:::END!!!=========================
=========================:::920:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/leap-upgrades/upgrade-utilities-kilo/playbooks/remove-juno-log-rotate.yml
**********
---
# Copyright 2015, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Remove juno log-rotate config
  hosts: "hosts"
  gather_facts: false
  user: root
  tasks:
    - name: find log rotate config in /etc/logrotate.d/
      command: "find /etc/logrotate.d -type f -name 'openstack_*'"
      register: log_rotate
    - name: Remove juno log rotate files
      file:
        path: "{{ item }}"
        state: absent
      with_items: log_rotate.stdout_lines
**********
DECISION===>: PASS
**********
=========================:::920:::END!!!=========================
=========================:::921:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/leap-upgrades/upgrade-utilities-kilo/playbooks/user-secrets-adjustments-kilo.yml
**********
---
# Copyright 2015, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: User secrets adjustments
  hosts: localhost
  connection: local
  gather_facts: false
  user: root
  tasks:
    - name: Read example user secrets file
      shell: "grep '^[a-zA-Z]' {{ osa_playbook_dir }}/etc/openstack_deploy/user_secrets.yml"
      register: secrets
    - name: Add missing secret
      shell: |
        if ! grep '^{{ item }}' /etc/openstack_deploy/user_secrets.yml; then
          echo {{ item }} | tee -a /etc/openstack_deploy/user_secrets.yml
        fi
      with_items: secrets.stdout_lines
    - name: Generate new secrets
      shell: "{{ osa_playbook_dir }}/scripts/pw-token-gen.py --file /etc/openstack_deploy/user_secrets.yml"


**********
DECISION===>: hardcoded secret
**********
=========================:::921:::END!!!=========================
=========================:::922:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/leap-upgrades/upgrade-utilities-kilo/playbooks/container-network-bounce.yml
**********
---
# Copyright 2015, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Container network restart
  hosts: "all_containers"
  max_fail_percentage: 100
  gather_facts: false
  user: root
  tasks:
    - name: Ensure network interfaces are all up
      lxc_container:
        name: "{{ inventory_hostname }}"
        container_command: |
          INTERFACES=""
          INTERFACES+="\$(awk '/auto/ {print \$2}' /etc/network/interfaces) "
          INTERFACES+="\$(ls -1 /etc/network/interfaces.d/ | awk -F'.cfg' '{print \$1}')"
          for i in \${INTERFACES}; do
            ifdown \$i || true
            ifup \$i || true
          done
      delegate_to: "{{ physical_host }}"

**********
DECISION===>: PASS
**********
=========================:::922:::END!!!=========================
=========================:::923:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/leap-upgrades/upgrade-utilities-liberty/playbooks/memcached-flush.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Memcached cache flush
  hosts: memcached_all
  gather_facts: false
  user: root
  tasks:
    - name: Flush all of the cache in memcached
      shell: |
        echo 'flush_all' | nc $(awk '/^\-l/ {print $2}' /etc/memcached.conf) $(awk '/^\-p/ {print $2}' /etc/memcached.conf)

**********
DECISION===>: PASS
**********
=========================:::923:::END!!!=========================
=========================:::924:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/leap-upgrades/upgrade-utilities-liberty/playbooks/disable-neutron-port-security.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Update neutron security bindings variables
  hosts: localhost
  connection: local
  gather_facts: false
  user: root
  tasks:
      - fail:
          msg: >
            neutron_ml2_conf_ini_overrides is defined in one of your overrides files but
            neutron_ml2_conf_ini_overrides.ml2.extension_drivers is unset. Please set
            neutron_ml2_conf_ini_overrides.ml2.extension_drivers = '' to prevent
            https://bugs.launchpad.net/neutron/+bug/1509312
        when:
          - neutron_ml2_conf_ini_overrides is defined
          - "'extension_drivers' not in (neutron_ml2_conf_ini_overrides.ml2 | default({}))"
      - name: Disable the port security driver
        # The below is not ideal, but it preserves whatever was in the
        # user_variables file without clobbering comments or having an
        # additional script.
        lineinfile:
            dest: /etc/openstack_deploy/user_variables.yml
            line: "neutron_ml2_conf_ini_overrides:\n  ml2:\n    extension_drivers: ''"
        when:
          - neutron_ml2_conf_ini_overrides is not defined

**********
DECISION===>: PASS
**********
=========================:::924:::END!!!=========================
=========================:::925:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/leap-upgrades/upgrade-utilities-liberty/playbooks/mariadb-apt-cleanup.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: MariaDB apt sources cleanup
  hosts: "hosts"
  max_fail_percentage: 100
  gather_facts: false
  user: root
  tasks:
    - name: Remove MariaDB repositories left over from Juno
      shell: |
        sed -i '/http:.*maria.*/d' /etc/apt/sources.list.d/*
      ignore_errors: true
    - name: Remove MariaDB repositories left over from Mitaka
      apt_repository:
        repo: "deb https://mirror.rackspace.com/mariadb/repo/10.0/ubuntu trusty main"
        state: "absent"

**********
DECISION===>: PASS
**********
=========================:::925:::END!!!=========================
=========================:::926:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/leap-upgrades/upgrade-utilities-liberty/playbooks/user-secrets-adjustment-liberty.yml
**********
---
# Copyright 2015, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: User secrets adjustments
  hosts: localhost
  connection: local
  gather_facts: false
  user: root
  tasks:
    - name: Read example user secrets file
      shell: "grep '^[a-zA-Z]' {{ osa_playbook_dir }}/etc/openstack_deploy/user_secrets.yml"
      register: secrets
    - name: Add missing secret
      shell: |
        if ! grep '^{{ item }}' /etc/openstack_deploy/user_secrets.yml; then
          echo {{ item }} | tee -a /etc/openstack_deploy/user_secrets.yml
        fi
      with_items: secrets.stdout_lines
    - name: Generate new secrets
      shell: "{{ osa_playbook_dir }}/scripts/pw-token-gen.py --file /etc/openstack_deploy/user_secrets.yml"


**********
DECISION===>: hardcoded secret
**********
=========================:::926:::END!!!=========================
=========================:::927:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/leap-upgrades/upgrade-utilities-liberty/playbooks/ansible_fact_cleanup-liberty.yml
**********
---
# Copyright 2015, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Ansible fact cleanup
  hosts: localhost
  connection: local
  gather_facts: false
  user: root
  tasks:
    - name: Remove any of the stored facts ansible may already have
      command: >
        find /etc/openstack_deploy/ansible_facts/ -type f -exec rm {} \;

**********
DECISION===>: PASS
**********
=========================:::927:::END!!!=========================
=========================:::928:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/leap-upgrades/upgrade-utilities-liberty/playbooks/deploy-config-changes-liberty.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Upgrade environment/inventory configuration
  hosts: localhost
  connection: local
  gather_facts: false
  user: root
  tasks:
      - name: Create an old copy of openstack_deploy
        copy:
          src: "/etc/openstack_deploy/"
          dest: "/etc/openstack_deploy.KILO/"
          force: no

      - name: Copy new env.d files into place
        copy:
            src: "{{ repo_root_dir }}/etc/openstack_deploy/env.d/{{ item }}.yml"
            dest: "/etc/openstack_deploy/env.d/{{ item }}.yml"
            force: no
        with_items:
            - aodh
            - haproxy

      - name: Add new neutron environment memberships
        command: "{{ playbook_dir }}/../scripts/add_new_neutron_env.py {{ repo_root_dir }}"
        args:
            creates: /etc/openstack_deploy.KILO/NEUTRON_MIGRATED

      - name: Remove old ceilometer environment memberships
        command: "{{ playbook_dir }}/../scripts/fix_ceilometer_env.py"
        args:
            creates: /etc/openstack_deploy.KILO/CEILOMETER_MIGRATED

      - name: Update OpenStack variable names
        command: "{{ playbook_dir }}/../scripts/migrate_openstack_vars.py {{ item }} {{ (item | basename)[:-4] }}"
        args:
            creates: "/etc/openstack_deploy.KILO/VARS_MIGRATED_{{ (item | basename)[:-4] }}"
        with_fileglob:
          - "/etc/openstack_deploy/user_*.yml"
  vars:
      repo_root_dir: "{{ osa_playbook_dir }}/"

**********
DECISION===>: PASS
**********
=========================:::928:::END!!!=========================
=========================:::929:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/leap-upgrades/upgrade-utilities-newton/playbooks/deploy-config-changes-newton.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Upgrade environment/inventory configuration
  hosts: localhost
  connection: local
  gather_facts: false
  user: root
  tasks:
      - name: Create an old copy of openstack_deploy
        copy:
          src: "/etc/openstack_deploy/"
          dest: "/etc/openstack_deploy.NEWTON/"
          force: no

      - name: Retrieve differences
        shell: rsync -avun "{{ repo_root_dir }}/playbooks/inventory/env.d/" "/etc/openstack_deploy/env.d/" | grep "yml$"
        failed_when: false
        register: diff_result

      - name: Copy new env.d files into place
        copy:
            src: "{{ repo_root_dir }}/playbooks/inventory/env.d/{{ item }}"
            dest: "/etc/openstack_deploy/env.d/{{ item }}"
            force: no
        with_items:
            - "{{ diff_result.stdout_lines }}"
        when: diff_result.stdout != ""

      - name: Check result for emptiness
        debug: msg="All new env.d files are placed in the stock repo. No new changes"
        when: diff_result.stdout == ""

      - name: Update OpenStack variable names
        command: "{{ playbook_dir }}/../scripts/migrate_openstack_vars.py {{ item }} {{ (item | basename)[:-4] }}"
        args:
            creates: "/etc/openstack_deploy.NEWTON/VARS_MIGRATED_{{ (item | basename)[:-4] }}"
        with_fileglob:
          - "/etc/openstack_deploy/user_*.yml"

  vars:
      repo_root_dir: "{{ osa_playbook_dir }}/"

**********
DECISION===>: PASS
**********
=========================:::929:::END!!!=========================
=========================:::930:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/leap-upgrades/upgrade-utilities-newton/playbooks/lbaas-version-check.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Fail fast if LBaaS v1 is configured
  hosts: localhost
  connection: local
  tasks:
    - name: Checking if neutron_lbaas variable exists
      fail:
        msg: |
          LBaaS v1 has been removed from OpenStack in Newton and there is no migration path for it.
          Please implement LBaaS v2.
          https://docs.openstack.org/openstack-ansible-os_neutron/latest/configure-network-services.html#special-notes-about-lbaas
      when:
        - neutron_lbaas is defined and neutron_lbaas | bool

**********
DECISION===>: PASS
**********
=========================:::930:::END!!!=========================
=========================:::931:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/leap-upgrades/upgrade-utilities-newton/playbooks/ansible_fact_cleanup-newton.yml
**********
---
# Copyright 2015, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Ansible fact cleanup
  hosts: localhost
  connection: local
  gather_facts: false
  user: root
  tasks:
    - name: Remove any of the stored facts ansible may already have
      command: >
        find /etc/openstack_deploy/ansible_facts/ -type f -exec rm {} \;

**********
DECISION===>: PASS
**********
=========================:::931:::END!!!=========================
=========================:::932:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/leap-upgrades/upgrade-utilities-newton/playbooks/memcached-flush.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Memcached cache flush
  hosts: memcached_all
  gather_facts: false
  user: root
  tasks:
    - name: Flush all of the cache in memcached
      shell: |
        echo 'flush_all' | nc $(awk '/^\-l/ {print $2}' /etc/memcached.conf | awk -F, '{ print $1 }') $(awk '/^\-p/ {print $2}' /etc/memcached.conf)

**********
DECISION===>: PASS
**********
=========================:::932:::END!!!=========================
=========================:::933:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/leap-upgrades/upgrade-utilities-newton/playbooks/user-secrets-adjustment-newton.yml
**********
---
# Copyright 2018, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: User secrets adjustments
  hosts: localhost
  connection: local
  gather_facts: false
  user: root
  tasks:
    - name: Read example user secrets file
      shell: "grep '^[a-zA-Z]' {{ osa_playbook_dir }}/etc/openstack_deploy/user_secrets.yml"
      register: secrets
    - name: Rename changed secrets
      lineinfile:
        dest: "/etc/openstack_deploy/{{ _osa_secrets_file_name }}"
        regexp: "^{{ item.old_name }}: (.*)$"
        line: "{{ item.new_name }}: \\1"
        backrefs: yes
      with_items:
        - { old_name: "ironic_galera_password", new_name: "ironic_container_mysql_password" }
    - name: Read user secrets file
      shell: "grep '^[a-zA-Z]' /etc/openstack_deploy/{{ _osa_secrets_file_name }}"
      register: user_secrets
    - name: Add missing secrets
      lineinfile:
        dest: "/etc/openstack_deploy/{{ _osa_secrets_file_name }}"
        line: "{{ item }}"
      with_items: "{{ secrets.stdout_lines }}"
      when: user_secrets.stdout.find("{{ item }}") == -1
    - name: Generate new secrets
      shell: "{{ osa_playbook_dir }}/scripts/pw-token-gen.py --file /etc/openstack_deploy/{{ _osa_secrets_file_name }}"
  vars:
    _osa_secrets_file_name: "{{ osa_secrets_file_name | default('user_secrets.yml') }}"

**********
DECISION===>: PASS
**********
=========================:::933:::END!!!=========================
=========================:::934:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/leap-upgrades/upgrade-utilities-newton/playbooks/old-hostname-compatibility-newton.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Set hostname alias for local lookup compatibility
  hosts: "hosts"
  gather_facts: true
  tasks:
    - name: Update Alias hostnames
      lineinfile:
        dest: /etc/hosts
        insertafter: "^127.0.0.1"
        regexp: "^127.0.1.1"
        line: "127.0.1.1 {{ rfc_1034_1035_name }}.{{ domain_name }} {{ rfc_1034_1035_name }} {{ inventory_hostname }} {{ ansible_hostname }}"
        state: present
      register: result1
      when:
        - rfc_1034_1035_name != inventory_hostname
        - rfc_1034_1035_name != ansible_hostname
    - name: Update Alias hostnames
      lineinfile:
        dest: /etc/hosts
        insertafter: "^127.0.0.1"
        regexp: "^127.0.1.1"
        line: "127.0.1.1 {{ rfc_1034_1035_name }}.{{ domain_name }} {{ rfc_1034_1035_name }} {{ ansible_hostname }}"
        state: present
      register: result2
      when:
        - rfc_1034_1035_name == inventory_hostname
        - rfc_1034_1035_name != ansible_hostname
    - name: Update Alias hostnames
      lineinfile:
        dest: /etc/hosts
        insertafter: "^127.0.0.1"
        regexp: "^127.0.1.1"
        line: "127.0.1.1 {{ rfc_1034_1035_name }}.{{ domain_name }} {{ rfc_1034_1035_name }} {{ inventory_hostname }}"
        state: present
      when:
        - result1 | skipped
        - result2 | skipped
  vars:
    rfc_1034_1035_name: "{{ inventory_hostname | replace('_', '-') }}"
    domain_name: "{{ openstack_domain|default('.openstack.local') }}"

**********
DECISION===>: PASS
**********
=========================:::934:::END!!!=========================
=========================:::935:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/leap-upgrades/upgrade-utilities-newton/playbooks/ceilometer-api-init-delete.yml
**********
---
# Copyright 2016, Logan Vig <logan2211@gmail.com>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Delete ceilometer-api init file
  hosts: ceilometer_api
  gather_facts: false
  user: root
  pre_tasks:
    - name: Check init system
      command: cat /proc/1/comm
      register: _pid1_name
    - name: Set the name of pid1
      set_fact:
        pid1_name: "{{ _pid1_name.stdout }}"
  tasks:
    - name: Stop the ceilometer-api service
      service:
        name: ceilometer-api
        state: stopped
        enabled: no
    - name: Remove the ceilometer-api upstart init file
      file:
        path: '/etc/init/ceilometer-api.conf'
        state: absent
      when: pid1_name == "init"
    - name: Reload upstart init scripts
      command: initctl reload-configuration
      when: pid1_name == "init"
    - name: Remove the ceilometer-api systemd init file
      file:
        path: '/etc/systemd/system/ceilometer-api.service'
      when: pid1_name == "systemd"
    - name: Reload systemd
      command: systemctl daemon-reload
      when: pid1_name == "systemd"

**********
DECISION===>: PASS
**********
=========================:::935:::END!!!=========================
=========================:::936:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/leap-upgrades/upgrade-utilities-newton/playbooks/aodh-api-init-delete.yml
**********
---
# Copyright 2016, Logan Vig <logan2211@gmail.com>
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Delete aodh-api init file
  hosts: aodh_all
  gather_facts: false
  user: root
  pre_tasks:
    - name: Check init system
      command: cat /proc/1/comm
      register: _pid1_name
    - name: Set the name of pid1
      set_fact:
        pid1_name: "{{ _pid1_name.stdout }}"
  tasks:
    - name: Stop the aodh-api service
      service:
        name: aodh-api
        state: stopped
        enabled: no
    - name: Remove the aodh-api upstart init file
      file:
        path: '/etc/init/aodh-api.conf'
        state: absent
      when: pid1_name == "init"
    - name: Reload upstart init scripts
      command: initctl reload-configuration
      when: pid1_name == "init"
    - name: Remove the aodh-api systemd init file
      file:
        path: '/etc/systemd/system/aodh-api.service'
      when: pid1_name == "systemd"
    - name: Reload systemd
      command: systemctl daemon-reload
      when: pid1_name == "systemd"

**********
DECISION===>: PASS
**********
=========================:::936:::END!!!=========================
=========================:::937:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/leap-upgrades/upgrade-utilities-newton/playbooks/galera-cluster-rolling-restart.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Gracefully restart mariadb/galera cluster
  hosts: galera_all
  serial: 1
  max_fail_percentage: 0
  gather_facts: false
  user: root
  tasks:
    - name: Stop mariadb
      service:
        name: mysql
        state: stopped
      retries: 5
      delay: 10

    - name: Stop container
      lxc_container:
        name: "{{ inventory_hostname }}"
        state: "stopped"
      delegate_to: "{{ physical_host }}"

    - name: Start container
      lxc_container:
        name: "{{ inventory_hostname }}"
        state: "started"
      delegate_to: "{{ physical_host }}"

  post_tasks:
    - name: Wait for mariadb port 3306 to be available
      local_action:
        module: wait_for
        port: "3306"
        host: "{{ ansible_ssh_host | default(inventory_hostname) }}"
      retries: 10
      delay: 10

    - name: Check that WSREP is ready and Synced
      shell: "/usr/bin/mysqladmin --defaults-file=/etc/mysql/debian.cnf extended-status | egrep '(wsrep_local_state_comment)'"
      register: mysql_ready
      until:
        - mysql_ready.rc == 0
        - (mysql_ready.stdout).find("Synced") != -1
      retries: 60
      delay: 1

**********
DECISION===>: PASS
**********
=========================:::937:::END!!!=========================
=========================:::938:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/leap-upgrades/upgrade-utilities-mitaka/playbooks/user-secrets-adjustment-mitaka.yml
**********
---
# Copyright 2015, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: User secrets adjustments
  hosts: localhost
  connection: local
  gather_facts: false
  user: root
  tasks:
    - name: Read example user secrets file
      shell: "grep '^[a-zA-Z]' {{ osa_playbook_dir }}/etc/openstack_deploy/user_secrets.yml"
      register: secrets
    - name: Add missing secret
      shell: |
        if ! grep '^{{ item }}' /etc/openstack_deploy/user_secrets.yml; then
          echo {{ item }} | tee -a /etc/openstack_deploy/user_secrets.yml
        fi
      with_items: secrets.stdout_lines
    - name: Generate new secrets
      shell: "{{ osa_playbook_dir }}/scripts/pw-token-gen.py --file /etc/openstack_deploy/user_secrets.yml"

**********
DECISION===>: hardcoded secret
**********
=========================:::938:::END!!!=========================
=========================:::939:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/leap-upgrades/upgrade-utilities-mitaka/playbooks/old-hostname-compatibility-mitaka.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Set hostname alias for local lookup compatibility
  hosts: hosts
  gather_facts: true
  tasks:
    - name: Update Alias hostnames
      lineinfile:
        dest: /etc/hosts
        insertafter: "^127.0.0.1"
        regexp: "^127.0.1.1"
        line: "127.0.1.1 {{ rfc_1034_1035_name }}.{{ domain_name }} {{ rfc_1034_1035_name }} {{ inventory_hostname }} {{ ansible_hostname }}"
        state: present
      register: result1
      when:
        - rfc_1034_1035_name != inventory_hostname
        - rfc_1034_1035_name != ansible_hostname
    - name: Update Alias hostnames
      lineinfile:
        dest: /etc/hosts
        insertafter: "^127.0.0.1"
        regexp: "^127.0.1.1"
        line: "127.0.1.1 {{ rfc_1034_1035_name }}.{{ domain_name }} {{ rfc_1034_1035_name }} {{ ansible_hostname }}"
        state: present
      register: result2
      when:
        - rfc_1034_1035_name == inventory_hostname
        - rfc_1034_1035_name != ansible_hostname
    - name: Update Alias hostnames
      lineinfile:
        dest: /etc/hosts
        insertafter: "^127.0.0.1"
        regexp: "^127.0.1.1"
        line: "127.0.1.1 {{ rfc_1034_1035_name }}.{{ domain_name }} {{ rfc_1034_1035_name }} {{ inventory_hostname }}"
        state: present
      when:
        - result1 | skipped
        - result2 | skipped
  vars:
    rfc_1034_1035_name: "{{ inventory_hostname | replace('_', '-') }}"
    domain_name: "{{ openstack_domain|default('.openstack.local') }}"

- name: Cleanup heat services through the database
  hosts: galera_all[0]
  user: root
  tasks:
    - name: Run database clean up for rfc1034/5
      command: >
        mysql --verbose --unbuffered -e "delete from service where host like '%\_%';" heat
      failed_when: false

**********
DECISION===>: PASS
**********
=========================:::939:::END!!!=========================
=========================:::940:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/leap-upgrades/upgrade-utilities-mitaka/playbooks/deploy-config-changes-mitaka.yml
**********
---
# Copyright 2016, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Upgrade environment/inventory configuration
  hosts: localhost
  connection: local
  gather_facts: false
  user: root
  tasks:
      - name: Create an old copy of openstack_deploy
        copy:
          src: "/etc/openstack_deploy/"
          dest: "/etc/openstack_deploy.LIBERTY/"
          force: no

      - name: Copy new env.d files into place
        copy:
            src: "{{ repo_root_dir }}/etc/openstack_deploy/env.d/{{ item }}.yml"
            dest: "/etc/openstack_deploy/env.d/{{ item }}.yml"
            force: no
        with_items:
            - ironic

      - name: Update OpenStack variable names
        command: "{{ playbook_dir }}/../scripts/migrate_openstack_vars.py {{ item }} {{ (item | basename)[:-4] }}"
        args:
            creates: "/etc/openstack_deploy.LIBERTY/VARS_MIGRATED_{{ (item | basename)[:-4] }}"
        with_fileglob:
          - "/etc/openstack_deploy/user_*.yml"
  vars:
      repo_root_dir: "{{ osa_playbook_dir }}/"

**********
DECISION===>: PASS
**********
=========================:::940:::END!!!=========================
=========================:::941:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/leap-upgrades/upgrade-utilities-mitaka/playbooks/pip-conf-removal.yml
**********
---
# Copyright 2015, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Remove pip.conf if found
  hosts: "hosts"
  gather_facts: true
  user: root
  tasks:
    - name: Remove pip.conf
      file:
        path: "{{ ansible_env.HOME }}/.pip/pip.conf"
        state: "absent"

**********
DECISION===>: PASS
**********
=========================:::941:::END!!!=========================
=========================:::942:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/leap-upgrades/upgrade-utilities-mitaka/playbooks/ansible_fact_cleanup-mitaka-1.yml
**********
---
# Copyright 2015, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Ansible fact cleanup
  hosts: localhost
  connection: local
  gather_facts: false
  user: root
  tasks:
    - name: Remove any of the stored facts ansible may already have
      command: >
        find /etc/openstack_deploy/ansible_facts/ -type f -exec rm {} \;

**********
DECISION===>: PASS
**********
=========================:::942:::END!!!=========================
=========================:::943:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/openstack-ansible-ops/leap-upgrades/upgrade-utilities-mitaka/playbooks/ansible_fact_cleanup-mitaka-2.yml
**********
---
# Copyright 2015, Rackspace US, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- name: Ansible fact cleanup
  hosts: localhost
  connection: local
  gather_facts: false
  user: root
  tasks:
    - name: Remove any of the stored facts ansible may already have
      command: >
        find /etc/openstack_deploy/ansible_facts/ -type f -exec rm {} \;

**********
DECISION===>: PASS
**********
=========================:::943:::END!!!=========================
=========================:::944:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/puppet-openstack-integration/playbooks/run-unit-tests.yaml
**********
- hosts: all
  tasks:
    - shell:
        cmd: |
          if [ "{{ puppet_gem_version }}" != "latest" ]; then
            if [ "{{ puppet_gem_version }}" == "5.5" ]; then
              # Pin to 5.5.6. See PUP-9270 and PUP-9271
              export PUPPET_GEM_VERSION='{{ puppet_gem_version }}.6'
            else
              export PUPPET_GEM_VERSION='~> {{ puppet_gem_version }}.0'
            fi
          fi
          mkdir .bundled_gems
          export GEM_HOME=`pwd`/.bundled_gems
          gem install bundler --no-rdoc --no-ri --verbose
          $GEM_HOME/bin/bundle install --retry 3
          $GEM_HOME/bin/bundle exec rake spec SPEC_OPTS='--format documentation'
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

**********
DECISION===>: PASS
**********
=========================:::944:::END!!!=========================
=========================:::945:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/puppet-openstack-integration/playbooks/prepare-node-common.yaml
**********
- hosts: all
  tasks:
    - name: Ensure legacy workspace directory
      file:
        path: "{{ ansible_user_dir }}/workspace"
        state: directory

    - name: Install python2-dnf(Fedora)
      command: "dnf -y install python2-dnf python3-dnf yum"
      become: true
      when:
        - ansible_os_family == 'RedHat'
        - ansible_distribution == "Fedora"

    - name: Remove excludes from /etc/dnf/dnf.conf (Fedora)
      lineinfile:
        path: /etc/dnf/dnf.conf
        state: absent
        regexp: '^exclude='
      become: true
      when:
        - ansible_os_family == 'RedHat'
        - ansible_distribution == "Fedora"

    - name: Reinstall python3-setuptools (Fedora)
      command: "dnf -y reinstall python3-setuptools"
      become: true
      when:
        - ansible_os_family == 'RedHat'
        - ansible_distribution == "Fedora"

    - name: Clean-up system state (non Fedora)
      yum:
        name: "{{ item }}"
        state: absent
      become: true
      when:
        - ansible_os_family == 'RedHat'
        - ansible_distribution != "Fedora"
      with_items:
        - rdo-release
        - centos-release-openstack-*
        - centos-release-ceph-*

    - name: Clean-up system state (Fedora)
      dnf:
        name: "{{ item }}"
        state: absent
      become: true
      when:
        - ansible_os_family == 'RedHat'
        - ansible_distribution == "Fedora"
      with_items:
        - rdo-release
        - centos-release-openstack-*
        - centos-release-ceph-*

    - name: Install Ruby dependencies (Fedora)
      dnf:
        name: "{{ item }}"
      become: true
      when:
        - ansible_os_family == 'RedHat'
        - ansible_distribution == "Fedora"
      with_items:
        - "@Development tools"
        - libxml2-devel
        - libxslt-devel
        - ruby-devel
        - zlib-devel

    - name: Install Ruby dependencies (non Fedora)
      yum:
        name: "{{ item }}"
      become: true
      when:
        - ansible_os_family == 'RedHat'
        - ansible_distribution != "Fedora"
      with_items:
        - "@Development tools"
        - libxml2-devel
        - libxslt-devel
        - ruby-devel
        - zlib-devel

    - name: Install Ruby dependencies (Ubuntu)
      apt:
        name: "{{ item }}"
      become: true
      when:
        - ansible_os_family == 'Debian'
        - ansible_distribution == "Ubuntu"
      with_items:
        - libxml2-dev
        - libxslt-dev
        - ruby-dev
        - zlib1g-dev

    - name: Install Ruby dependencies (Debian)
      apt:
        name: "{{ item }}"
      become: true
      when:
        - ansible_os_family == 'Debian'
        - ansible_distribution == "Debian"
      with_items:
        - libicu-dev
        - libxml2-dev
        - libxslt1-dev
        - ruby-dev
        - zlib1g-dev

    - name: Install puppetlabs puppet-agent
      shell:
        cmd: |
          set -e
          set -x
          if type "dnf" 2>/dev/null;then
              export YUM=dnf
          else
              export YUM=yum
          fi
          if [[ -f /usr/bin/yum || -f /usr/bin/dnf ]]; then
              $YUM install -y https://yum.puppetlabs.com/puppet5/puppet5-release-el-7.noarch.rpm
              $YUM install -y puppet-agent
          elif [ -f /usr/bin/apt-get ]; then
              wget https://apt.puppetlabs.com/puppet5-release-{{ ansible_distribution_release }}.deb -O /tmp/puppet.deb
              dpkg -i /tmp/puppet.deb
              apt-get update
              apt-get install puppet-agent
              rm -rf /tmp/puppet.deb
          fi
        executable: /bin/bash
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'
      become: true
      when:
        - use_puppetlabs is defined
        - use_puppetlabs|bool

**********
DECISION===>: PASS
**********
=========================:::945:::END!!!=========================
=========================:::946:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/puppet-openstack-integration/playbooks/run-lint-tests.yaml
**********
- hosts: all
  tasks:
    - shell:
        cmd: |
          if [ -f Modulefile -o -f metadata.json ]; then
            if [ -f Modulefile ]; then
              MODULE=$(awk '/^name/ {print $NF}' Modulefile |tr -d \"\')
            elif [ -f metadata.json ]; then
              MODULE=$(python -c 'import json;print json.load(open("metadata.json"))["name"]')
            fi
            if [ -z "$MODULE" ]; then
              echo "Module name not defined in Modulefile or metadata.json"
            else
              mkdir -p "$MODULE"
              rsync -a --exclude="$MODULE" --exclude ".*" . "$MODULE"
              cd "$MODULE"
            fi
          fi
          mkdir .bundled_gems
          export GEM_HOME=`pwd`/.bundled_gems
          if [ -f Gemfile ]; then
            gem install bundler --no-rdoc --no-ri --verbose
            $GEM_HOME/bin/bundle install --without system_tests --retry 3
            $GEM_HOME/bin/bundle exec rake lint 2>&1
            if [ -f metadata.json ]; then
              $GEM_HOME/bin/bundle exec rake metadata_lint 2>&1
            fi
          else
            gem install rake -n ./.bundled_gems/
            gem install puppet-lint
            gem install metadata-json-lint -n ./.bundled_gems/ --no-ri --no-rdoc
            gem install puppetlabs_spec_helper
            ./.bundled_gems/rake lint 2>&1
            if [ -f metadata.json ]; then
              ./.bundled_gems/metadata-json-lint
            fi
          fi
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

**********
DECISION===>: PASS
**********
=========================:::946:::END!!!=========================
=========================:::947:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/puppet-openstack-integration/playbooks/run-libraries-syntax-tests.yaml
**********
- hosts: all
  tasks:
    - shell:
        cmd: |
          set -e
          set -x
          export PUPPET_VERSION="{{ puppet }}"
          ./run_syntax_tests.sh
        executable: /bin/bash
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

**********
DECISION===>: PASS
**********
=========================:::947:::END!!!=========================
=========================:::948:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/puppet-openstack-integration/playbooks/run-libraries-beaker-tests.yaml
**********
- hosts: all
  tasks:
    - shell:
        cmd: |
          echo "" | sudo tee -a /etc/ssh/sshd_config
          echo "Match address 127.0.0.1" | sudo tee -a /etc/ssh/sshd_config
          echo "    PermitRootLogin without-password" | sudo tee -a /etc/ssh/sshd_config
          echo "" | sudo tee -a /etc/ssh/sshd_config
          echo "Match address ::1" | sudo tee -a /etc/ssh/sshd_config
          echo "    PermitRootLogin without-password" | sudo tee -a /etc/ssh/sshd_config
          mkdir -p .ssh
          ssh-keygen -f ~/.ssh/id_rsa -b 2048 -P ""
          sudo mkdir -p /root/.ssh
          cat ~/.ssh/id_rsa.pub | sudo tee -a /root/.ssh/authorized_keys
          if [[ -f /usr/bin/yum || -f /usr/bin/dnf ]]; then
              sudo systemctl reload sshd
          elif [ -f /usr/bin/apt-get ]; then
              sudo service ssh restart
          fi
        executable: /bin/bash
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'
    - shell:
        cmd: |
          set -e
          set -x
          trap "{{ ansible_user_dir }}/workspace/openstack/puppet-openstack-integration/copy_logs.sh" EXIT
          export BEAKER_PUPPET_COLLECTION=puppet5
          export BEAKER_set=nodepool-{{ nodepool_type }}
          ./run_beaker_tests.sh
        executable: /bin/bash
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

**********
DECISION===>: hardcoded secret
**********
=========================:::948:::END!!!=========================
=========================:::949:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/puppet-openstack-integration/playbooks/upload-logs.yaml
**********
- hosts: all
  tasks:
    - name: Upload log files
      synchronize:
        src: '{{ ansible_user_dir }}/workspace/'
        dest: '{{ zuul.executor.log_root }}'
        mode: pull
        copy_links: true
        verify_host: true
        rsync_opts:
          - --include=/logs/**
          - --include=*/
          - --exclude=*
          - --prune-empty-dirs

**********
DECISION===>: PASS
**********
=========================:::949:::END!!!=========================
=========================:::950:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/puppet-openstack-integration/playbooks/run-integration-tests.yaml
**********
- hosts: all
  tasks:
    - shell:
        cmd: |
          set -ex
          trap "./copy_logs.sh" EXIT
          export CEPH_VERSION={{ ceph }}
          export PUPPET_MAJ_VERSION={{ puppet }}
          export SCENARIO={{ scenario }}
          export GEM_HOME=`pwd`/.bundled_gems
          ./run_tests.sh
        executable: /bin/bash
        chdir: '{{ ansible_user_dir }}/workspace/puppet-openstack-integration'
      environment: '{{ zuul | zuul_legacy_vars }}'

**********
DECISION===>: PASS
**********
=========================:::950:::END!!!=========================
=========================:::951:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/puppet-openstack-integration/playbooks/run-libraries-lint-tests.yaml
**********
- hosts: all
  tasks:
    - shell:
        cmd: |
          set -e
          set -x
          ./run_lint_tests.sh
        executable: /bin/bash
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

**********
DECISION===>: PASS
**********
=========================:::951:::END!!!=========================
=========================:::952:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/puppet-openstack-integration/playbooks/prepare-node-beaker.yaml
**********
- hosts: all
  tasks:
    - shell:
        cmd: |
          set -e
          set -x
          CLONEMAP=`mktemp`
          function cleanup {
              # In cases where zuul-cloner is aborted during a git
              # clone operation, git will remove the git work tree in
              # its cleanup. The work tree in these jobs is the
              # workspace directory, which means that subsequent
              # jenkins post-build actions can not run because the
              # workspace has been removed.
              # To reduce the likelihood of this having an impact,
              # recreate the workspace directory if needed
              mkdir -p $WORKSPACE
              rm -f $CLONEMAP
          }
          trap cleanup EXIT
          cat > $CLONEMAP << EOF
          clonemap:
            - name: $ZUUL_PROJECT
              dest: .
            - name: openstack/puppet-openstack-integration
              dest: openstack/puppet-openstack-integration
          EOF
          /usr/zuul-env/bin/zuul-cloner -m $CLONEMAP --cache-dir /opt/git \
              git://git.openstack.org $ZUUL_PROJECT openstack/puppet-openstack-integration
        executable: /bin/bash
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

    - include_role:
        name: bindep

**********
DECISION===>: PASS
**********
=========================:::952:::END!!!=========================
=========================:::953:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/puppet-openstack-integration/playbooks/prepare-node-integration.yaml
**********
- hosts: all
  tasks:
    - shell:
        cmd: |
          set -e
          set -x
          ZUUL_BRANCH_REAL=${ZUUL_BRANCH:-master}
          # Workaround for puppet-ceph, where we need to checkout
          # puppet-openstack-integration from stable/pike when working on
          # stable/jewel.
          # Ceph Jewel works with Newton to Pike
          if [[ "$ZUUL_BRANCH" == "stable/jewel" ]]; then
              ZUUL_BRANCH_REAL='stable/pike'
          fi
          CLONEMAP=`mktemp`
          function cleanup {
              rm -f $CLONEMAP
          }
          trap cleanup EXIT
          cat > $CLONEMAP << EOF
          clonemap:
            - name: openstack/puppet-openstack-integration
              dest: puppet-openstack-integration
          EOF
          /usr/zuul-env/bin/zuul-cloner -m $CLONEMAP \
              --cache-dir /opt/git \
              --zuul-branch $ZUUL_BRANCH_REAL \
              git://git.openstack.org openstack/puppet-openstack-integration
        executable: /bin/bash
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

    - include_role:
        name: bindep
      vars:
        bindep_dir: "src/git.openstack.org/openstack/puppet-openstack-integration"

    - name: Create folder for gems
      file:
        path: "{{ ansible_user_dir }}/workspace/puppet-openstack-integration/.bundled_gems"
        state: directory

    - name: Install bundler
      gem:
        name: bundler
        user_install: false
      environment:
        GEM_HOME: "{{ ansible_user_dir }}/workspace/puppet-openstack-integration/.bundled_gems"
**********
DECISION===>: PASS
**********
=========================:::953:::END!!!=========================
=========================:::954:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/puppet-openstack-integration/playbooks/run-syntax-tests.yaml
**********
- hosts: all
  tasks:
    - shell:
        cmd: |
          export PUPPET_GEM_VERSION='~> {{ puppet }}'
          mkdir .bundled_gems
          export GEM_HOME=`pwd`/.bundled_gems
          gem install bundler --no-rdoc --no-ri --verbose
          $GEM_HOME/bin/bundle install --retry 3
          $GEM_HOME/bin/bundle exec rake syntax
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

**********
DECISION===>: PASS
**********
=========================:::954:::END!!!=========================
=========================:::955:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/puppet-openstack-integration/playbooks/run-beaker-tests.yaml
**********
- hosts: all
  tasks:
    - name: Prepare ssh config on the host to run beaker
      shell:
        cmd: |
          echo "" | sudo tee -a /etc/ssh/sshd_config
          echo "Match address 127.0.0.1" | sudo tee -a /etc/ssh/sshd_config
          echo "    PermitRootLogin without-password" | sudo tee -a /etc/ssh/sshd_config
          echo "" | sudo tee -a /etc/ssh/sshd_config
          echo "Match address ::1" | sudo tee -a /etc/ssh/sshd_config
          echo "    PermitRootLogin without-password" | sudo tee -a /etc/ssh/sshd_config
          mkdir -p .ssh
          ssh-keygen -f ~/.ssh/id_rsa -b 2048 -P ""
          sudo mkdir -p /root/.ssh
          cat ~/.ssh/id_rsa.pub | sudo tee -a /root/.ssh/authorized_keys
          if [[ -f /usr/bin/yum || -f /usr/bin/dnf ]]; then
              sudo systemctl reload sshd
          elif [ -f /usr/bin/apt-get ]; then
              sudo service ssh restart
          fi
        executable: /bin/bash
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'
    - name: Run beaker
      shell:
        cmd: |
          trap "{{ ansible_user_dir }}/workspace/openstack/puppet-openstack-integration/copy_logs.sh" EXIT
          export BEAKER_PUPPET_COLLECTION=puppet5
          export BEAKER_set=nodepool-{{ nodepool_type }}
          export BEAKER_debug=yes
          export BEAKER_color=no
          if [ -f Modulefile -o -f metadata.json ]; then
            if [ -f Modulefile ]; then
              MODULE=$(awk '/^name/ {print $NF}' Modulefile |tr -d \"\')
            elif [ -f metadata.json ]; then
              MODULE=$(python -c 'import json;print json.load(open("metadata.json"))["name"]')
            fi
            if [ -z "$MODULE" ]; then
              echo "Module name not defined in Modulefile or metadata.json"
            else
              mkdir -p "$MODULE"
              rsync -a --exclude="$MODULE" --exclude ".*" . "$MODULE"
              cd "$MODULE"
            fi
          fi
          mkdir .bundled_gems
          export GEM_HOME=`pwd`/.bundled_gems
          if [ -f Gemfile ]; then
            gem install bundler --no-rdoc --no-ri --verbose
            $GEM_HOME/bin/bundle install --without system_tests --retry 3
            $GEM_HOME/bin/bundle exec rspec spec/acceptance
          else
            gem install rake -n ./.bundled_gems/
            gem install beaker-rspec
            gem install puppetlabs_spec_helper
            ./.bundled_gems/rake acceptance 2>&1
          fi
        chdir: '{{ ansible_user_dir }}/workspace'
        executable: /bin/bash
      environment: '{{ zuul | zuul_legacy_vars }}'

**********
DECISION===>: hardcoded secret
**********
=========================:::955:::END!!!=========================
=========================:::956:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/puppet-openstack-integration/playbooks/run-libraries-unit-tests.yaml
**********
- hosts: all
  tasks:
    - shell:
        cmd: |
          set -e
          set -x
          if [ "{{ puppet_gem_version }}" != "latest" ]; then
            if [ "{{ puppet_gem_version }}" == "5.5" ]; then
              # Pin to 5.5.6. See PUP-9270 and PUP-9271
              export PUPPET_GEM_VERSION='{{ puppet_gem_version }}.6'
            else
              export PUPPET_GEM_VERSION='~> {{ puppet_gem_version }}.0'
            fi
          fi
          ./run_unit_tests.sh
        executable: /bin/bash
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

**********
DECISION===>: PASS
**********
=========================:::956:::END!!!=========================
=========================:::957:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/puppet-openstack-integration/playbooks/prepare-node-unit.yaml
**********
- hosts: all
  tasks:
    - shell:
        cmd: |
          set -e
          set -x
          CLONEMAP=`mktemp`
          function cleanup {
              # In cases where zuul-cloner is aborted during a git
              # clone operation, git will remove the git work tree in
              # its cleanup. The work tree in these jobs is the
              # workspace directory, which means that subsequent
              # jenkins post-build actions can not run because the
              # workspace has been removed.
              # To reduce the likelihood of this having an impact,
              # recreate the workspace directory if needed
              mkdir -p $WORKSPACE
              rm -f $CLONEMAP
          }
          trap cleanup EXIT
          cat > $CLONEMAP << EOF
          clonemap:
            - name: $ZUUL_PROJECT
              dest: .
          EOF
          /usr/zuul-env/bin/zuul-cloner -m $CLONEMAP --cache-dir /opt/git \
              git://git.openstack.org $ZUUL_PROJECT
        executable: /bin/bash
        chdir: '{{ ansible_user_dir }}/workspace'
      environment: '{{ zuul | zuul_legacy_vars }}'

    - include_role:
        name: bindep

**********
DECISION===>: PASS
**********
=========================:::957:::END!!!=========================
=========================:::958:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/ansible-role-requirements.yml
**********
- name: image-build
  src: https://github.com/redhat-openstack/ansible-role-tripleo-image-build
  scm: git
  version: master


**********
DECISION===>: PASS
**********
=========================:::958:::END!!!=========================
=========================:::959:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/provision/support_check/tasks/main.yml
**********
---
# Check the virthost distribution for either RHEL or CentOS
- name: Check the linux distro
  debug: msg="Unfortunately your linux distribution is not supported at the moment. We welcome community support,
              please see https://github.com/openstack/tripleo-quickstart .

              To run quickstart with out this check set 'quickstart.sh -e supported_distro_check=false'"
  failed_when: supported_distro_check == true
  when: not (ansible_distribution == 'CentOS' or ansible_distribution == 'RedHat')


**********
DECISION===>: PASS
**********
=========================:::959:::END!!!=========================
=========================:::960:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/provision/support_check/meta/main.yml
**********
dependencies:
  - provision


**********
DECISION===>: PASS
**********
=========================:::960:::END!!!=========================
=========================:::961:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/provision/teardown/tasks/main.yml
**********
# Check that the non-root user exists.
- name: Get UID of non-root user
  command: >
    id -u {{ non_root_user }}
  register: non_root_uid
  ignore_errors: true
  changed_when: false

# If the non-root user exists, perform a variety of cleanup tasks.
- when: non_root_uid is success
  block:
    # Look for and kill any processes owned by the non-root user.
    # This will let us remove the user later on.
    - name: Check for processes owned by non-root user
      command: >
        pgrep -u {{ non_root_user }}
      register: proc_exist
      ignore_errors: true
      become: true

    - name: Kill (SIGTERM) all processes owned by non-root user
      command: >
        pkill -u {{ non_root_user }}
      ignore_errors: true
      become: true
      when: proc_exist is success

    - name: Wait for processes to exit
      command: >
        pgrep -c -u {{ non_root_user }}
      register: proc_kill
      retries: 5
      delay: 3
      until: proc_kill.stdout == '0'
      ignore_errors: true
      when: proc_exist is success
      become: true

    - name: Kill (SIGKILL) all processes owned by non-root user
      command: >
        pkill -9 -u {{ non_root_user }}
      when: proc_exist is success
      ignore_errors: true
      become: true

    # Now that we have taken care of any processes owned by this user
    # account we can delete it.
    - name: Remove non-root user account
      user:
        name: "{{ non_root_user }}"
        state: absent
        remove: true
      become: true

    # The `XDG_RUNTIME_DIR` (`/run/user/<uid>`) doesn't always get cleaned
    # up when we remove the user, which can lead to libvirt problems
    # later on.  We can't remove the directory itself -- it's a tmpfs
    # mountpoint -- but we can remove the content.
    - name: Remove non-root user ephemeral files
      file:
        path: "{{ item }}"
        state: absent
      with_fileglob:
        - /run/user/{{ non_root_uid.stdout }}/*
      become: true


**********
DECISION===>: PASS
**********
=========================:::961:::END!!!=========================
=========================:::962:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/provision/teardown/meta/main.yml
**********
dependencies:
  - provision


**********
DECISION===>: PASS
**********
=========================:::962:::END!!!=========================
=========================:::963:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/provision/meta/main.yml
**********
dependencies:
  - common


**********
DECISION===>: PASS
**********
=========================:::963:::END!!!=========================
=========================:::964:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/provision/user/tasks/main.yml
**********
# Create a non-root user on the target host.  This is the user that
# will own the virtual infrastructure on which we deploy openstack.
- name: Create non-root group
  group:
    name: "{{ non_root_group }}"
    state: present
  become: true
  when: not chrooted|bool

- name: Create non-root user
  user:
    name: "{{ non_root_user }}"
    group: "{{ non_root_group }}"
    state: present
    shell: /bin/bash
    create_home: true
  become: true
  when: not chrooted|bool


**********
DECISION===>: PASS
**********
=========================:::964:::END!!!=========================
=========================:::965:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/provision/user/meta/main.yml
**********
dependencies:
  - provision


**********
DECISION===>: PASS
**********
=========================:::965:::END!!!=========================
=========================:::966:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/provision/local/tasks/main.yml
**********
# Error out early if the `virthost` variable is not set.
- name: Check that virthost is set
  fail:
    msg: "You need to set virthost before running these playbooks."
  when: virthost|default("") == ""

- name: Get current user group for localhost
  command: "id -gn"
  register: local_user_group
  changed_when: false

- name: Register fact for current user group
  set_fact:
    current_group_local: "{{ local_user_group.stdout }}"
    cacheable: true
  tags:
    - provision

- block:
  - name: Ensure local working dir exists
    file:
      path: "{{ local_working_dir }}"
      state: directory
      owner: "{{ ansible_env.USER }}"
      group: "{{ current_group_local }}"
  rescue:
  # if it fails we try again as with become, become must be fallback because
  # otherwise first attempt will fail on local machines without sudo, a
  # use case that we want to support.
  - name: Ensure local working dir exists
    file:
      path: "{{ local_working_dir }}"
      state: directory
      owner: "{{ ansible_env.USER }}"
      group: "{{ current_group_local }}"
    become: true

# This file needs to exist because it will later be referenced in some
# ssh command lines.
- name: Create empty ssh config file
  file:
    path: "{{ local_working_dir }}/ssh.config.ansible"
    state: touch

# Add the virthost to the in-memory inventory.  The inventory is not
# written out to disk unless you call the `tripleo-inventory` role.
- name: Add the virthost to the inventory
  add_host:
    name: "{{virthost}}"
    groups: "virthost"
    ansible_fqdn: "{{ virthost }}"
    ansible_user: "root"
    ansible_host: "{{ virthost }}"


**********
DECISION===>: PASS
**********
=========================:::966:::END!!!=========================
=========================:::967:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/provision/local/meta/main.yml
**********
dependencies:
  - provision


**********
DECISION===>: PASS
**********
=========================:::967:::END!!!=========================
=========================:::968:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/provision/defaults/main.yml
**********
# The path to an ssh key (that we will generate) that can be used to
# log in to the virt host.
virt_host_key: "{{ local_working_dir }}/id_rsa_virt_host"

# Exit the playbook when a non suported linux distro is found on the virthost
supported_distro_check: yes


**********
DECISION===>: PASS
**********
=========================:::968:::END!!!=========================
=========================:::969:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/provision/remote/tasks/main.yml
**********
# Create `virt_host_key`, which we will use to log in to the target
# host.  Note that this tasks runs on the ansible control host
# (because of the `delegate_to: localhost`), and we will later copy
# the public key to the appropriate location.
- name: Create virthost access key
  delegate_to: localhost
  command: >
    ssh-keygen -f {{ virt_host_key }} -N ''
    -C 'ansible_generated_virt_host'
    -t rsa -b 4096
  args:
    creates: "{{ virt_host_key }}"

- when: not chrooted|bool
  block:
    - name: Ensure tuned is installed
      package:
        name: "tuned"
        state: "present"
      become: true

    - name: Ensure tuned is enabled and started
      service:
        name: "tuned"
        enabled: "yes"
        state: "started"
      become: true

    - name: Retrieve current tuned profile
      command: tuned-adm active
      register: tuned
      changed_when: False

    - name: Set tuned profile if not already set
      command: tuned-adm profile "{{ tuned_profile }}"
      become: true
      when: tuned.stdout.find(tuned_profile) != 1

    # Create a non-root user on the target host.  This is the user that
    # will own the virtual infrastructure on which we deploy openstack.
    - name: Create non-root user
      user:
        name: "{{ non_root_user }}"
        state: present
        shell: /bin/bash
        create_home: yes
      become: true

- name: Get the non-root user UID
  command: "id {{ non_root_user }} -u"
  register: non_root_user_uid_output
  changed_when: false
  retries: 3
  delay: 5
  until: non_root_user_uid_output is not failed

- name: Get the non-root user homedir
  shell: "getent passwd {{ non_root_user }} | cut -d: -f6"
  register: non_root_user_homedir_output
  changed_when: false

- name: Save the non-root user UID
  set_fact:
    non_root_user_uid: "{{ non_root_user_uid_output.stdout }}"
    cacheable: true

- name: Save the non-root user homedir
  set_fact:
    non_root_user_homedir: "{{ non_root_user_homedir_output.stdout }}"
    cacheable: true

# Install the public component of `virt_host_key` in the
# `.ssh/authorized_keys` file for the non-root user.
- name: Configure non-root user authorized_keys
  authorized_key:
    user: "{{ ssh_user }}"
    key: "{{ lookup('file', virt_host_key|quote + '.pub')|default('') }}"
  become: true

- name: Ensure polkit packages are installed
  package:
    name: "polkit"
    state: "present"
  become: true

# This lets the non-root user access the `qemu://system` endpoint.  We
# don't need this with the default configuration (which uses
# `qemu://session`), but this permits things to work if someone
# explicitly passes in `libvirt_uri`.
- name: Grant libvirt privileges to non-root user
  template:
    src: libvirt.pkla.j2
    dest: "/etc/polkit-1/localauthority/50-local.d/50-{{ non_root_user }}-libvirt.pkla"
  become: true

- name: Ensure XDG_RUNTIME_DIR is set
  blockinfile:
    path: "{{ non_root_user_homedir }}/.bashrc"
    create: true
    block: |
      # Setting up XDG_RUNTIME_DIR for creating non-essential runtime files and other file objects in accordance with
      # https://standards.freedesktop.org/basedir-spec/basedir-spec-latest.html
      if [[ -z "${XDG_RUNTIME_DIR}" && -d "/run/user/${UID}" ]] ; then
          export XDG_RUNTIME_DIR="/run/user/${UID}"
      fi
  become: true
  become_user: "{{ non_root_user }}"

# I'm not always root, but when I am it's because of `sudo`.
- name: Grant sudo privileges to non-root user
  copy:
    content: |
      {{ non_root_user }} ALL=(ALL) NOPASSWD:ALL
    dest: /etc/sudoers.d/{{ non_root_user }}
    owner: root
    group: root
    mode: 0440
  become: true

# This replaces the inventory entry for the virthost.  The original
# entry had `ansible_user: root`, but from now on we will connect as
# the non-root user.
- name: Re-add the virthost to the inventory
  add_host:
    name: "{{ virthost }}"
    groups: "virthost"
    ansible_fqdn: "{{ virthost }}"
    ansible_user: "{{ ssh_user }}"
    ansible_host: "{{ virthost }}"
    ansible_private_key_file: "{{ virt_host_key }}"

# Create the volume pool directory if it doesn't already exist.  This
# will be the target of the libvirt volume pool we create in the next
# task.
- name: Ensure volume pool directory exists
  file:
    path: "{{ libvirt_volume_path }}"
    state: directory
    owner: "{{ non_root_user }}"
    group: "{{ non_root_group }}"
  become: true


**********
DECISION===>: PASS
**********
=========================:::969:::END!!!=========================
=========================:::970:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/provision/remote/meta/main.yml
**********
dependencies:
  - provision


**********
DECISION===>: PASS
**********
=========================:::970:::END!!!=========================
=========================:::971:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/convert-image/tasks/main.yml
**********
- name: generate convert script
  template:
    src: "{{ convert_image_template }}"
    dest: "{{ convert_image_working_dir}}/convert_image.sh"

- name: check if we have an overcloud-full.qcow2 to start from
  stat:
    path: "{{ convert_image_working_dir}}/overcloud-full.qcow2"
  register: overcloud_full_qcow2

# This tasks is not be used in CI or on any public systems
# Only use this option when debugging locally on a secure system
- name: set root password for image
  command: >
    virt-customize --smp 2 -m {{ convert_image_host_memory }}
    -a {{ convert_image_working_dir}}/overcloud-full.qcow2
    --root-password password:{{ overcloud_full_root_pwd }}
  when:
    - overcloud_full_root_pwd is defined
    - overcloud_full_qcow2.stat.exists

- name: copy overcloud-full.qcow2 to undercloud.qcow2
  command: >
    cp {{ convert_image_working_dir}}/overcloud-full.qcow2
       {{ convert_image_working_dir}}/undercloud.qcow2
  changed_when: true
  when: overcloud_full_qcow2.stat.exists and overcloud_as_undercloud|bool

# Resize the undercloud image using qemu-img resize
- name: Resize the undercloud image using qemu-image resize
  command: >
    qemu-img resize {{ convert_image_working_dir }}/undercloud.qcow2
                    {{ flavors[undercloud_node.name].disk }}G
  changed_when: true

- name: convert image
  command: >
    virt-customize -v --smp 2 -m {{ convert_image_host_memory }}
    -a {{ convert_image_working_dir }}/undercloud.qcow2
    --run convert_image.sh
  changed_when: true
  args:
    chdir: "{{ convert_image_working_dir }}"
  environment:
    LIBGUESTFS_BACKEND: direct
    LIBVIRT_DEFAULT_URI: "{{ libvirt_uri }}"

- name: collect diagnostic log from undercloud image
  shell: >
    virt-cat -a undercloud.qcow2 /tmp/builder.log > builder-undercloud.log 2>&1;
  changed_when: true
  args:
    chdir: "{{ convert_image_working_dir }}"
  environment:
    LIBGUESTFS_BACKEND: direct
    LIBVIRT_DEFAULT_URI: "{{ libvirt_uri }}"


**********
DECISION===>: PASS
**********
=========================:::971:::END!!!=========================
=========================:::972:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/convert-image/meta/main.yml
**********
# Include the `common` role as a dependency.
dependencies:
  - common


**********
DECISION===>: PASS
**********
=========================:::972:::END!!!=========================
=========================:::973:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/convert-image/defaults/main.yml
**********
# By default do image conversion in the global working_dir
convert_image_working_dir: "{{ working_dir }}"
convert_image_template: convert_image.sh.j2

# Do a yum update when converting overcloud to undercloud
convert_image_update: true

# List of packages that should be removed from the overcloud image
convert_image_remove_pkgs:
  - cloud-init
  - python-django-horizon
  - openstack-dashboard

# List of packages that should be installed to convert overcloud to undercloud
convert_image_install_pkgs:
  - python-tripleoclient

convert_image_tempest_plugins: []
convert_image_host_memory: 2048
guest_partition: /dev/sda

**********
DECISION===>: PASS
**********
=========================:::973:::END!!!=========================
=========================:::974:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/tripleo-inventory/tasks/openstack.yml
**********
---
- name: Cloud access credentials and URL
  assert:
    that:
      - os_username is defined
      - os_password is defined
      - os_tenant_name is defined or os_project_name is defined
      - os_auth_url is defined
      - cloud_name is defined

- name: copy clouds.yaml file
  template:
    src: clouds.yaml.j2
    dest: "{{ local_working_dir }}/clouds.yaml"
    mode: 0400

- name: fetch all nodes from openstack shade dynamic inventory
  command: shade-inventory --list
  args:
    chdir: '{{ local_working_dir }}'
  register: registered_nodes_output
  no_log: true

- name: set_fact for filtered openstack inventory nodes by types
  set_fact:
    registered_overcloud_nodes: "{{ (registered_nodes_output.stdout | from_json) | json_query(jq_overcloud) }}"
    registered_undercloud_nodes: "{{ (registered_nodes_output.stdout | from_json) | json_query(jq_undercloud) }}"
    cacheable: true
  vars:
    jq_overcloud: "[] | [?contains(name, 'overcloud')]"
    jq_undercloud: "[] | [?contains(name, 'undercloud')]"

- name: set_fact for all filtered openstack inventory nodes by cluster id
  when: clusterid is defined
  set_fact:
    registered_nodes: "{{ (registered_nodes_output.stdout | from_json) | json_query(jq_cluster) }}"
    cacheable: true
  vars:
    jq_cluster: "[?metadata.clusterid] | [?metadata.clusterid=='{{ clusterid }}']"

- name: set_fact for all filtered openstack inventory nodes
  when: not clusterid is defined
  set_fact:
    registered_nodes: "{{ registered_overcloud_nodes|union(registered_undercloud_nodes) }}"
    cacheable: true

- name: Add overcloud nodes to inventory, accessed via undercloud/bastion
  with_items: "{{ registered_overcloud_nodes|intersect(registered_nodes) }}"
  add_host:
    name: '{{ item.name }}'
    groups: >-
      {{ item.metadata.group|default('overcloud') }},
      {{ item.name|regex_replace('overcloud-(?:nova)?([a-zA-Z0-9_]+)-[0-9]+$', '\\1') }}
    ansible_host: '{{ item.name }}'
    ansible_fqdn: '{{ item.name }}'
    ansible_user: "{{ overcloud_user | default('heat-admin') }}"
    ansible_private_key_file: "{{ overcloud_key }}"
    ansible_ssh_extra_args: "-F {{ local_working_dir }}/ssh.config.ansible"
    private_v4: >-
      {% set node = registered_nodes | json_query("[?name=='" + item.name + "']") -%}
      {{ node[0].addresses[openstack_private_network_name|quote][0].addr }}

- name: Add undercloud node to inventory, accessed via floating IP
  with_items: "{{ registered_undercloud_nodes|intersect(registered_nodes) }}"
  add_host:
    name: undercloud
    groups: "bastion,{{ item.metadata.group|default('undercloud') }}"
    ansible_host: '{{ item.public_v4 }}'
    ansible_fqdn: undercloud
    ansible_user: '{{ undercloud_user }}'
    ansible_private_key_file: '{{ undercloud_key }}'
    undercloud_ip: >-
      {% set node = registered_nodes | json_query("[?name=='" + item.name + "']") -%}
      {{ node[0].addresses[openstack_private_network_name|quote][0].addr }}

- name: Bastion accessing requirements
  assert:
    that:
      - hostvars['undercloud'] is defined
      - hostvars['undercloud'].ansible_host is defined

- name: set ssh proxy command prefix for accessing nodes via bastion
  set_fact:
    ssh_proxy_command: "ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no
      -o ConnectTimeout=60 -i {{ hostvars['undercloud'].ansible_private_key_file }}
      {{ ssh_user }}@{{ hostvars['undercloud'].ansible_host }}"
    cacheable: true

- name: create inventory from template
  delegate_to: localhost
  template:
    src: 'inventory.j2'
    dest: '{{ local_working_dir }}/hosts'
  run_once: true

- name: regenerate ssh config
  delegate_to: localhost
  template:
    src: 'openstack_ssh_config.j2'
    dest: '{{ local_working_dir }}/ssh.config.ansible'
    mode: 0644
  run_once: true

**********
DECISION===>: PASS
**********
=========================:::974:::END!!!=========================
=========================:::975:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/tripleo-inventory/tasks/main.yml
**********
---

- name: Ensure gather_facts has been run against localhost
  setup:
    filter: "*"
  delegate_to: localhost
  delegate_facts: True
  when: hostvars['localhost'].ansible_user_dir is not defined

- include_tasks: inventory.yml
  when: inventory in ['multinode', 'all', 'undercloud']

- include_tasks: openstack.yml
  when: inventory == 'openstack'

**********
DECISION===>: PASS
**********
=========================:::975:::END!!!=========================
=========================:::976:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/tripleo-inventory/tasks/inventory.yml
**********
---

- when: inventory == 'all'
  block:
    - name: list the overcloud nodes
      debug: var=registered_overcloud_nodes.stdout

    - name: fetch the undercloud ssh key
      fetch:
        src: '{{ working_dir }}/.ssh/id_rsa'
        dest: '{{ overcloud_key }}'
        flat: yes
        mode: 0400

    # add host to the ansible group formed from its type
    # novacompute nodes are added as compute for backwards compatibility
    - name: add overcloud node to ansible
      with_dict: '{{ registered_overcloud_nodes.stdout | default({}) }}'
      add_host:
        name: '{{ item.key }}'
        groups: "overcloud,{{ item.key | regex_replace('overcloud-(?:nova)?([a-zA-Z0-9_]+)-[0-9]+$', '\\1') }}"
        ansible_host: '{{ item.key }}'
        inventory_ip: '{{ item.value }}'
        ansible_user: "{{ overcloud_user | default('heat-admin') }}"
        ansible_private_key_file: "{{ overcloud_key }}"
        ansible_ssh_extra_args: '-F "{{ local_working_dir }}/ssh.config.ansible"'

- when: inventory == 'multinode'
  block:
    - name: Get subnodes
      command: cat /etc/nodepool/sub_nodes_private
      register: nodes

    - name: Add subnode to ansible inventory
      with_indexed_items: '{{ nodes.stdout_lines | default([]) }}'
      add_host:
        name: 'subnode-{{ item.0 + 2 }}'
        groups: "overcloud"
        ansible_host: '{{ item.1 }}'
        inventory_ip: '{{ item.1 }}'
        ansible_user: "{{ lookup('env','USER') }}"
        ansible_private_key_file: "/etc/nodepool/id_rsa"

#required for regeneration of ssh.config.ansible
- name: set_fact for undercloud ip
  set_fact:
    undercloud_ip: "{{ hostvars['undercloud'].undercloud_ip }}"
    cacheable: true
  when: hostvars['undercloud'] is defined and hostvars['undercloud'].undercloud_ip is defined

- name: set_fact for virthost
  set_fact:
    virthost_with_private_key: "{{ 'virthost' in groups and groups['virthost']|length>0 and hostvars[groups['virthost'][0]].ansible_private_key_file is defined }}"

# Add the supplemental to the in-memory inventory.
- name: Add supplemental node vm to inventory
  add_host:
    name: supplemental
    groups: supplemental
    ansible_host: supplemental
    ansible_fqdn: supplemental
    ansible_user: '{{ supplemental_user }}'
    ansible_private_key_file: '{{ local_working_dir }}/id_rsa_supplemental'
    ansible_ssh_extra_args: '-F "{{local_working_dir}}/ssh.config.ansible"'
    supplemental_node_ip: "{{ supplemental_node_ip }}"
  when: supplemental_node_ip is defined

- name: set_fact for supplemental ip
  set_fact:
    supplemental_node_ip: "{{ hostvars['supplemental'].supplemental_node_ip }}"
    cacheable: true
  when: hostvars['supplemental'] is defined and hostvars['supplemental'].supplemental_node_ip is defined

#readd the undercloud to reset the ansible_ssh parameters set in quickstart
- name: Add undercloud vm to inventory
  add_host:
    name: undercloud
    ansible_host: '{{ undercloud_ip }}'
    ansible_fqdn: undercloud
    ansible_user: '{{ undercloud_user }}'
    ansible_private_key_file: '{{ undercloud_key }}'
    ansible_ssh_extra_args: '-F "{{ local_working_dir }}/ssh.config.local.ansible"'
    undercloud_ip: "{{ undercloud_ip }}"
  when: not virthost_with_private_key and undercloud_ip is defined

#required for regeneration of ssh.config.ansible
- name: set undercloud ssh proxy command
  set_fact:
    undercloud_ssh_proxy_command: "ssh -q -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no
      -o ConnectTimeout=60 -i {{ hostvars[groups['virthost'][0]].ansible_private_key_file }}
      {{ ssh_user }}@{{ hostvars[groups['virthost'][0]].ansible_host }}
      -W {{ undercloud_ip }}:22"
    cacheable: true
  when: virthost_with_private_key and undercloud_ip is defined

#required for regeneration of ssh.config.ansible
- name: set undercloud ssh proxy command
  set_fact:
    undercloud_ssh_proxy_command: "ssh -q -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no
      -o ConnectTimeout=60 -i {{ local_working_dir }}/id_rsa_virt_power
      {{ ssh_user }}@{{ hostvars['localhost'].ansible_default_ipv4.address }}
      -W {{ undercloud_ip }}:22"
    cacheable: true
  when: not virthost_with_private_key and undercloud_ip is defined

- name: set supplemental ssh proxy command
  set_fact:
    supplemental_ssh_proxy_command: "ssh -q -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no
      -o ConnectTimeout=60 -i {{ local_working_dir }}/id_rsa_virt_power
      {{ ssh_user }}@{{ hostvars[groups['virthost'][0]].ansible_host }}
      -W {{ supplemental_node_ip }}:22"
    cacheable: true
  when: supplemental_node_ip is defined

- name: create inventory from template
  delegate_to: localhost
  template:
    src: 'inventory.j2'
    dest: '{{ local_working_dir }}/hosts'

- name: regenerate ssh config
  delegate_to: localhost
  template:
    src: 'ssh_config.j2'
    dest: '{{ local_working_dir }}/ssh.config.ansible'
    mode: 0644
  when: undercloud_ip is defined

- name: regenerate ssh config for ssh connections from the virthost
  delegate_to: localhost
  template:
    src: 'ssh_config_localhost.j2'
    dest: '{{ local_working_dir }}/ssh.config.local.ansible'
    mode: 0644
  when: undercloud_ip is defined

# just setup the ssh.config.ansible and hosts file for the virthost
- name: check for existence of identity key
  delegate_to: localhost
  stat: path="{{ local_working_dir }}/id_rsa_virt_power"
  when: undercloud_ip is not defined
  register: result_stat_id_rsa_virt_power

- name: set fact used in ssh_config_no_undercloud.j2 to determine if IdentityFile should be included
  set_fact:
    id_rsa_virt_power_exists: true
    cacheable: true
  when: undercloud_ip is not defined and result_stat_id_rsa_virt_power.stat.exists == True

- name: regenerate ssh config, if no undercloud has been launched.
  delegate_to: localhost
  template:
    src: 'ssh_config_no_undercloud.j2'
    dest: '{{ local_working_dir }}/ssh.config.ansible'
    mode: 0644
  when: undercloud_ip is not defined

**********
DECISION===>: PASS
**********
=========================:::976:::END!!!=========================
=========================:::977:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/tripleo-inventory/tests/test.yml
**********
---
- hosts: localhost
  remote_user: root
  roles:
    - tripleo-inventory


**********
DECISION===>: PASS
**********
=========================:::977:::END!!!=========================
=========================:::978:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/tripleo-inventory/tests/playbooks/quickstart-usb.yml
**********
# This is the playbook used by the `quickstart.sh` script.

# The [provision.yml](provision.yml.html) playbook is responsible for
# creating an inventory entry for our `virthost` and for creating an
# unprivileged user on that host for use by our virtual environment.
- include_tasks: provision.yml
  tags:
    - provision

# The `environment/setup` role performs any tasks that require `root`
# access on the target host.
- name: Install libvirt packages and configure networks
  hosts: virthost
  tags:
    - environment
  roles:
    - environment/setup

# The `libvirt/setup` role creates the undercloud and overcloud
# virtual machines.
- name:  Setup undercloud and overcloud vms
  hosts: virthost
  gather_facts: yes
  roles:
    - libvirt/teardown
    - libvirt/setup

# Add the undercloud node to the generated
# inventory.
- name:  Inventory the undercloud
  hosts: undercloud
  gather_facts: no
  vars:
      inventory: undercloud
  roles:
    - tripleo-inventory

# DEPLOY ALL THE THINGS!  Depending on the currently selected set of
# tags, this will deploy the undercloud, deploy the overcloud, and
# perform some validation tests on the overcloud.
- name:  Install undercloud and deploy overcloud
  hosts: undercloud
  gather_facts: no
  roles:
    - tripleo/undercloud
    - tripleo/overcloud


**********
DECISION===>: PASS
**********
=========================:::978:::END!!!=========================
=========================:::979:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/tripleo-inventory/meta/main.yml
**********
# Include the `common` role as a dependency.
dependencies:
  - { role: common }


**********
DECISION===>: PASS
**********
=========================:::979:::END!!!=========================
=========================:::980:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/tripleo-inventory/defaults/main.yml
**********
---

# SSH key used to access the undercloud/overcloud machines.
undercloud_key: "{{ local_working_dir }}/id_rsa_undercloud"
overcloud_key: "{{ local_working_dir }}/id_rsa_overcloud"
# Default to 'undercloud' if the overcloud has not been deployed yet, or 'all'
# in case we want to inventory all the hosts. For OpenStack provider case,
# use the 'openstack' value.
inventory: undercloud
# Type of undercloud.
undercloud_type: virtual
# Admin/control network name for the openstack inventory provider
openstack_private_network_name: private

**********
DECISION===>: PASS
**********
=========================:::980:::END!!!=========================
=========================:::981:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/fetch-images/tasks/fetch.yml
**********
- name: image name
  debug:
    msg: "checking for image {{ image.name }}"

# Set some convenience variables here to avoid boilerplate code
# elsewhere in this file.  These are all set unconditionally to avoid
# any cruft leftover from a previous call to this file.
- name: set local variables
  set_fact:
    _force_cached_image: >-
      {{ force_cached_images|default(false)|bool
      or image.force_cached|default(false)|bool }}
    _latest: >-
      {{ image_cache_dir }}/latest-{{ image.name }}.{{ image.type }}
    cacheable: true

# This looks for the latest image symlink that may have been created
# by a previous run of this tasklist.
- name: Check if we have a latest image
  command: >
    test -f {{ _latest }}
  args:
    chdir: "{{ image_cache_dir }}"
  ignore_errors: true
  register: latest_exists
  changed_when: false

# If we want to use the most recent image in the local cache
# (`_force_cached_image` is `true`) *and* such an image exists, point
# `image_cache_path` at `latest-{{image.name}}.qcow2`.
- name: Set path to cached image [local]
  set_fact:
    image_cache_path: "{{ _latest }}"
    cacheable: true
  when: latest_exists is success and _force_cached_image

# The md5sum for base OS images are not hosted, they are defined in a configuration file.
# Handle base os images slightly differently
- when: image.md5sum is defined
  block:

    # Get the expected checksum from settings vs. pulling the md5sum.
    - name: Get image expected checksum for base OS images
      set_fact:
        md5_expected: "{{ image.md5sum.split()[0] }}"
        cacheable: true

    - name: Set path to cached image
      set_fact:
        image_cache_path: "{{ image_cache_dir }}/{{ md5_expected }}.{{ image.type }}"
        cacheable: true

    # See if a matching image exists locally.
    - name: Check for base OS image in cache
      command: >
        test -f {{ image_cache_path }}
      args:
        chdir: "{{ image_cache_dir }}"
      ignore_errors: true
      register: base_image_exists
      changed_when: false

# Otherwise, check if there's a new image available.
- when:
    - image.md5sum is not defined
    - not _force_cached_image or latest_exists is failed
  block:

    # Get the expected checksum for the remote image.
    - name: Get image expected checksum
      command: >
        curl -skfL {{ image.url }}.md5
      register: md5_expected
      until: md5_expected.rc not in [18, 56, 22]
      retries: 5
      delay: 5

    - name: sanitize the md5sum
      set_fact:
        md5_expected: "{{ md5_expected.stdout.split()[0] }}"
        cacheable: true

    - name: Set path to cached image [upstream]
      set_fact:
        image_cache_path: "{{ image_cache_dir }}/{{ md5_expected }}.{{ image.type }}"
        cacheable: true

    # See if a matching image exists locally.
    - name: Check for image in cache
      command: >
        test -f {{ image_cache_path }}
      args:
        chdir: "{{ image_cache_dir }}"
      ignore_errors: true
      register: image_exists
      changed_when: false

# Looks like we're going to have to download the image after all.

# Note.. image_exists and base_image_exists are required variables because
# even unused variables will overwrite each other.
- when: image_exists is defined and (image_exists is failed or base_image_exists is failed)
  block:

    # This task will download the image.  We're using `curl` here
    # rather than `wget` because while `wget` has built-in retry
    # capabilities, it is unable to handle `file://` URLs.  We instead
    # use an ansible `until` loop, combined with curl's `-C-` option
    # to continue interrupted downloads.
    - name: Get image
      command: >
        curl -skfL -C- -o _{{ image.name }}.{{ image.type}} {{ image.url }}
      args:
        chdir: "{{ image_cache_dir }}"
      register: curl_result
      until: curl_result.rc not in [18, 56]
      retries: 20
      delay: 5

    # Compute the md5 checksum of the image we just downloaded
    - name: Get actual md5 checksum of image
      command: >
        md5sum -b _{{ image.name }}.{{ image.type}}
      args:
        chdir: "{{ image_cache_dir }}"
      register: md5_actual

    - name: sanitize the md5sum for the downloaded image
      set_fact:
        md5_actual: "{{ md5_actual.stdout.split()[0] }}"
        cacheable: true

    # Verify that what we have is what we wanted.
    - name: Verify image checksum
      fail:
        msg: image checksum does not match
      when: >
        image_exists is failed and
        (md5_expected != md5_actual)

    - name: Cache image by checksum
      command: >
        mv _{{ image.name }}.{{ image.type}} {{ image_cache_path }}
      args:
        chdir: "{{ image_cache_dir }}"

    - name: Update "latest" symlink
      file:
        path: "{{ _latest }}"
        state: link
        src: "{{ image_cache_path }}"

  # This is a workaround for ansible issue [15625][].
  #
  # [15625]: https://github.com/ansible/ansible/issues/15625
  rescue:

    - name: Note that there was a failure.
      set_fact:
        image_fetch_failed: true
        cacheable: true

  # Ensure that even if there are failures we still clean up our
  # temporary image file.
  always:

    - name: Clean up temporary image file
      file:
        path: "{{ image_cache_dir }}/_{{ image.name }}.{{ image.type }}"
        state: absent

    - name: Propagate failure
      fail:
      when: image_fetch_failed|default(false)

# Use `image_cache_path`, which was set by one of the above tasks, and
# copy it to `undercloud.qcow2 in our `{{ image_fetch_dir }}`.
- name: Get qcow2 image from cache
  command: >
    cp {{ image_cache_path }} {{ image_fetch_dir }}/{{ image.name }}.{{ image.type }}
  when: image.type  == "qcow2" and image.md5sum is not defined

# Same as the above just copy the base os image to the fetch_dir as undercloud
- name: Get base OS qcow2 image from cache
  command: >
    cp {{ image_cache_path }} {{ image_fetch_dir }}/undercloud.{{ image.type }}
  when: image.type  == "qcow2" and image.md5sum is defined

- name: Get tar images from cache
  unarchive:
    src: "{{ image_cache_path }}"
    copy: no
    dest: "{{ image_fetch_dir }}"
    list_files: yes
  when: image.type == "tar"

- name: Clean image cache directory
  shell: >-
    find {{ image_cache_dir }} -type f
    {% if not image_cache_dir_cleanup|bool %}
    -mtime +{{ image_cache_expire_days|int - 1 }} {% endif %}|
    xargs --no-run-if-empty -t rm -rf

**********
DECISION===>: PASS
**********
=========================:::981:::END!!!=========================
=========================:::982:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/fetch-images/tasks/main.yml
**********
# Fetching the undercloud images can take a long time.  This
# role caches images in `{{ image_cache_dir }}` if an image is
# (a) downloaded successfully and (b) successfully verifies against
# the checksum.  Images are cached using the checksum as the filename,
# and subsequent playbook runs will use the cached copy rather than
# trying to fetch the remote copy.

# This checks that the image_cache_dir directory exists.  When running
# the full quickstart, this is created by the provision/remote role.
# If you are running this role by itself, you will need to ensure that
# either the directory exists ahead of time or that ansible has the
# permissions to create the directory.
- name: Ensure image cache directory exists
  file:
    path: "{{ image_cache_dir }}"
    state: directory
    owner: "{{ non_root_user }}"
    group: "{{ non_root_group }}"
    mode: "ug+rwx"
  become: true

- name: Get dlrn hash when fetch-images is run before repo-setup
  include_role:
    name: repo-setup
    tasks_from: get-dlrn-hash
  when: dlrn_hash_tag is defined and dlrn_task_run is not defined

- name: Get dlrn hash newest when fetch-images is run before repo-setup
  include_role:
    name: repo-setup
    tasks_from: get-dlrn-hash-newest
  when: dlrn_hash_tag_newest is defined and dlrn_task_run_newest is not defined

- include: fetch.yml
  vars:
    image: "{{ item }}"
  with_items: "{{ images }}"


**********
DECISION===>: PASS
**********
=========================:::982:::END!!!=========================
=========================:::983:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/fetch-images/meta/main.yml
**********
dependencies:
  - common


**********
DECISION===>: PASS
**********
=========================:::983:::END!!!=========================
=========================:::984:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/fetch-images/defaults/main.yml
**********
# After fetching images remove cache directory
image_cache_dir_cleanup: false
# After fetching images remove files older than image_cache_expire_days
image_cache_expire_days: 14

**********
DECISION===>: PASS
**********
=========================:::984:::END!!!=========================
=========================:::985:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/libvirt/teardown/nodes/tasks/main.yml
**********
# NB: We use `virsh` here instead of the `virt` module because
# these tasks may be called before the dependencies of the `virt`
# module are satisfied.

- name: Include vars for libvirt-nodepool
  include_vars:
    file:  ../roles/libvirt/setup/overcloud/tasks/vars/libvirt_nodepool_vars.yml
  when: libvirt_nodepool|default(false)

- name: Check if libvirt is available
  command: >
    virsh uri
  ignore_errors: true
  changed_when: false
  register: libvirt_check
  environment:
    LIBVIRT_DEFAULT_URI: "{{ libvirt_uri }}"

# If libvirt isn't available we can skip everything else.
- when: libvirt_check is success
  environment:
    LIBVIRT_DEFAULT_URI: "{{ libvirt_uri }}"
  block:

    - when: overcloud_nodes
      block:

      # Check if the overcloud nodes exist.
      - name: Check overcloud vms
        command: >
          virsh domid "{{ item.name }}"
        with_items: "{{ overcloud_nodes }}"
        ignore_errors: true
        register: overcloud_check

      # Destroy and undefine the overcloud nodes.
      - name: Destroy overcloud vms
        command:
          virsh destroy "{{ item.item.name }}"
        when: item is success
        with_items: "{{ overcloud_check.results }}"
        ignore_errors: true

      - name: Undefine overcloud vms
        command:
          virsh undefine "{{ item.item.name }}"
        when: item is success
        with_items: "{{ overcloud_check.results }}"

      # The `virsh vol-dumpxml ... > /dev/null` is here (and elsewhere) due to
      # [1293804].
      #
      # [1293804]: https://bugzilla.redhat.com/show_bug.cgi?id=1293804
      - name: Delete baremetal vm storage
        shell: |
          virsh vol-dumpxml --pool '{{ libvirt_volume_pool }}' \
            '{{ item.name }}'.qcow2 2>&1 > /dev/null
          virsh vol-delete --pool '{{ libvirt_volume_pool }}' \
            '{{ item.name }}'.qcow2
        with_items: "{{ overcloud_nodes }}"
        ignore_errors: true

    # Do the same thing to the supplemental node.
    - environment:
        LIBVIRT_DEFAULT_URI: "{{ libvirt_uri }}"
      block:
      - name: Check undercloud vm
        command: >
          virsh domid "{{ supplemental_node.name|default('') }}"
        ignore_errors: true
        register: supplemental_check

      - name: Destroy supplemental vm
        command: >
          virsh destroy "{{ supplemental_node.name|default('') }}"
        when: supplemental_check is success
        ignore_errors: true

      - name: Undefine supplemental vm
        command: >
          virsh undefine "{{ supplemental_node.name|default('') }}" --remove-all-storage
        when: supplemental_check is success
        ignore_errors: true

    # Do the same thing to the undercloud node.
    - name: Check undercloud vm
      command: >
        virsh domid "{{ undercloud_node.name }}"
      ignore_errors: true
      register: undercloud_check

    - name: Destroy undercloud vm
      command: >
        virsh destroy "{{ undercloud_node.name }}"
      when: undercloud_check is success
      ignore_errors: true

    - name: Undefine undercloud vm
      command: >
        virsh undefine "{{ undercloud_node.name }}"
      when: undercloud_check is success

    - name: Delete undercloud vm storage
      shell: |
        virsh vol-dumpxml --pool '{{ libvirt_volume_pool }}' \
          '{{ undercloud_node.name }}'.qcow2 2>&1 > /dev/null
        virsh vol-delete --pool '{{ libvirt_volume_pool }}' \
          '{{ undercloud_node.name }}'.qcow2
      ignore_errors: true

    - name: Destroy intermediate disk image
      file:
        path: "{{ working_dir }}/undercloud-resized.qcow2"
        state: absent

    - name: Check volume pool
      command: >
        virsh pool-uuid "{{ libvirt_volume_pool }}"
      register: pool_check
      ignore_errors: true

    # See https://www.redhat.com/archives/libvirt-users/2016-March/msg00123.html
    # TL;DR: ensure that the pool really exists if the previous
    # task says it does.
    - name: Work around libvirt bug
      shell: |
        virsh pool-dumpxml "{{ libvirt_volume_pool }}" |
        virsh pool-define /dev/stdin
      when: pool_check is success

    - name: Destroy volume pool
      command: >
        virsh pool-destroy "{{ libvirt_volume_pool }}"
      when: pool_check is success
      ignore_errors: true

    - name: Undefine volume pool
      command: >
        virsh pool-undefine "{{ libvirt_volume_pool }}"
      when: pool_check is success

    - name: Get UID of pool user
      command: id -u "{{ ansible_user_id }}"
      register: pool_uid
      changed_when: false
      when: pool_check is success

    - name: Destroy pool definition file
      file:
        path: "/run/user/{{ pool_uid.stdout }}/libvirt/storage/run/{{ libvirt_volume_pool }}.xml"
        state: absent
      when: pool_check is success


**********
DECISION===>: PASS
**********
=========================:::985:::END!!!=========================
=========================:::986:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/libvirt/teardown/meta/main.yml
**********
# Include settings from the libvirt role, and include all the
# `teardown/*` roles.  This means that when your playbook has:
#
#     roles:
#       - libvirt/teardown
#
# You also get:
#
# - `libvirt/teardown/nodes`
# - `libvirt/teardown/user`
dependencies:
  - role: libvirt
  - role: teardown/nodes
  - role: teardown/user


**********
DECISION===>: PASS
**********
=========================:::986:::END!!!=========================
=========================:::987:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/libvirt/teardown/user/tasks/main.yml
**********
# This removes the `virt_power_key` from the remote `authorized_keys`
# file.
- name: Remove virt_power_key from remote authorized_keys
  authorized_key:
    user: "{{ ansible_user_id }}"
    state: absent
    key: "{{ item }}"
    manage_dir: true
  with_file:
    - "{{ virt_power_key }}.pub"
  ignore_errors: true


**********
DECISION===>: PASS
**********
=========================:::987:::END!!!=========================
=========================:::988:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/libvirt/setup/undercloud/tasks/inject_repos.yml
**********
---
- name: get all qcow2 images
  find:
    path: "{{ working_dir }}"
    patterns: "*.qcow2"
  register: qcow_images

- name: upload repos on the images
  include_role:
    name: repo-setup
  vars:
    repo_inject_image_path: "{{ item.path }}"
    repo_run_live: false
    repo_setup_dir: "{{ working_dir }}"
  with_items: "{{ qcow_images.files | default([]) }}"
  changed_when: true


**********
DECISION===>: PASS
**********
=========================:::988:::END!!!=========================
=========================:::989:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/libvirt/setup/undercloud/tasks/update_image.yml
**********
---
- name: get all qcow2 images
  find:
    path: "{{ working_dir }}"
    patterns: "*.qcow2"
  register: qcow_images

- name: generate image specific update script
  template:
    src: update_image.sh.j2
    dest: "{{ working_dir}}/update_image-{{ item.inode }}.sh"
  with_items: "{{ qcow_images.files | default([]) }}"

- name: run update
  command: >
    virt-customize -v --smp 2 -m 4096 -a {{ item.path }}
    --run update_image-{{ item.inode }}.sh
  args:
    chdir: "{{ working_dir }}"
  environment:
    LIBGUESTFS_BACKEND: direct
    LIBVIRT_DEFAULT_URI: "{{ libvirt_uri }}"
  with_items: "{{ qcow_images.files | default([]) }}"
  changed_when: true


**********
DECISION===>: PASS
**********
=========================:::989:::END!!!=========================
=========================:::990:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/libvirt/setup/undercloud/tasks/convert_image.yml
**********

- name: indirect role include (workaround to https://github.com/ansible/ansible/issues/19472)
  include_role:
    name: convert-image


**********
DECISION===>: PASS
**********
=========================:::990:::END!!!=========================
=========================:::991:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/libvirt/setup/undercloud/tasks/inject_gating_repo.yml
**********
---
- name: Create the injection script
  template:
    src: inject_gating_repo.sh.j2
    dest: "{{ working_dir }}/inject_gating_repo.sh"

- environment:
    LIBGUESTFS_BACKEND: direct
    LIBVIRT_DEFAULT_URI: "{{ libvirt_uri }}"
  block:
  # We need to extract the overcloud image, if it's not already extracted.
  # so we can inject the gating repo into it.
  - name: check if overcloud image is already extracted
    stat:
      path: '{{ working_dir }}/overcloud-full.qcow2'
    register: overcloud_image_stat

  - name: Extract overcloud-full image
    command: >
      virt-copy-out -a {{ working_dir }}/undercloud.qcow2
      /home/{{ undercloud_user }}/overcloud-full.qcow2 {{ working_dir }}
    register: overcloud_image_extracted
    when: not overcloud_image_stat.stat.exists

  - name: Inject the gating repo (overcloud-full)
    command: >
      virt-customize -a {{ working_dir }}/overcloud-full.qcow2
      --upload {{ compressed_gating_repo }}:/tmp/gating_repo.tar.gz
      --run '{{ working_dir }}/inject_gating_repo.sh'

  - name: Copy updated overcloud-full image back to undercloud
    command: >
      virt-copy-in -a {{ working_dir }}/undercloud.qcow2
      {{ working_dir }}/overcloud-full.qcow2 /home/{{ undercloud_user }}/
    when: overcloud_image_extracted is defined and overcloud_image_extracted|changed

  - name: Inject the gating repo (undercloud)
    command: >
      virt-customize -a {{ working_dir }}/undercloud.qcow2
      --upload {{ compressed_gating_repo }}:/tmp/gating_repo.tar.gz
      --run '{{ working_dir }}/inject_gating_repo.sh'
    when: not overcloud_as_undercloud|bool


**********
DECISION===>: PASS
**********
=========================:::991:::END!!!=========================
=========================:::992:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/libvirt/setup/undercloud/tasks/customize_overcloud.yml
**********
- name: Create overcloud customize script
  template:
    src: "{{ overcloud_customize_script }}"
    dest: "{{ working_dir }}/overcloud-customize.sh"
    mode: 0755

- environment:
    LIBGUESTFS_BACKEND: direct
    LIBVIRT_DEFAULT_URI: "{{ libvirt_uri }}"
  block:
  # We need to extract the overcloud image, if it's not already extracted.
  # so we can inject the gating repo into it.
  - name: check if overcloud image is already extracted
    stat:
      path: '{{ working_dir }}/overcloud-full.qcow2'
    register: overcloud_image_stat_for_customize

  - name: Extract overcloud-full image
    command: >
      virt-copy-out -a {{ working_dir }}/undercloud.qcow2
      /home/{{ undercloud_user }}/overcloud-full.qcow2 {{ working_dir }}
    when: not overcloud_image_stat_for_customize.stat.exists

  # only customize overcloud-full image if that is not going to be
  # used as undercloud
  - name: Perform extra overcloud customizations
    command: >
      virt-customize -a {{ working_dir}}/overcloud-full.qcow2
      --run '{{ working_dir}}/overcloud-customize.sh'

  - name: Copy updated overcloud-full image back to undercloud
    command: >
      virt-copy-in -a {{ working_dir }}/undercloud.qcow2
      {{ working_dir }}/overcloud-full.qcow2 /home/{{ undercloud_user }}/


**********
DECISION===>: PASS
**********
=========================:::992:::END!!!=========================
=========================:::993:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/libvirt/setup/undercloud/tasks/main.yml
**********
# We're going to try putting files in `local_working_dir`, so make
# sure it exists first.
- name: Ensure local working dir exists
  delegate_to: localhost
  file:
    path: "{{ local_working_dir }}"
    state: directory

# Generate MAC addresses for the undercloud node.
- name: get MACs for the undercloud
  generate_macs:
    nodes:
      - "{{ undercloud_node }}"
    networks: "{{ networks }}"
  register: undercloud_mac_map

# Check if the undercloud volume exists.  If not, we call out to
# [fetch_image.yml](fetch_image.yml.html) to download the image.
- name: Check if undercloud volume exists
  command: >
    virsh vol-info --pool '{{ libvirt_volume_pool }}'
    '{{ undercloud_node.name }}.qcow2'
  ignore_errors: true
  changed_when: false
  register: undercloud_vol_check
  environment:
    LIBVIRT_DEFAULT_URI: "{{ libvirt_uri }}"

- when: undercloud_vol_check is failed
  environment:
    LIBGUESTFS_BACKEND: direct
    LIBVIRT_DEFAULT_URI: "{{ libvirt_uri }}"
  block:
  # Conditionally include a playbook for all the images specified
  # in options that downloads, cache and extract if tar archived
  # only if the images aren't already in volume pool
  - name: Fetch the images
    include_role:
      name: fetch-images

  # Conditionally include a playbook for all the images specified
  # in options that updates images with the repos provided via the
  # release config.
  - include_tasks: inject_repos.yml
    when: update_images|bool or devmode|bool

  # inject the gating repo generated by ansible-role-tripleo-gate
  - include_tasks: inject_gating_repo.yml
    when: compressed_gating_repo is defined and compressed_gating_repo

  # Converts an overcloud-full.qcow2 into a undercloud.qcow2
  - include_tasks: convert_image.yml
    when: overcloud_as_undercloud|bool or baseos_as_undercloud|bool

  # Update images after we have converted the overcloud-full to an
  # undercloud image when using devmode. This also clones tripleo-ci
  # on the undercloud image.
  - include_tasks: update_image.yml
    when: devmode|bool

  # Inject updated overcloud and ipa images into our converted undercloud
  # image
  - name: Inject additional images
    command: >
      virt-customize -a {{ working_dir }}/undercloud.qcow2
      --upload {{ working_dir }}/{{ item }}:/home/{{ undercloud_user }}/{{ item }}
      --run-command 'chown {{ undercloud_user }}:{{ undercloud_user }} /home/{{ undercloud_user }}/{{ item }}'
    changed_when: true
    with_items: "{{ inject_images | default('') }}"
    when:
      - overcloud_as_undercloud|bool or use_external_images|bool
      - inject_images|length > 0

  # This copies the `instackenv.json` configuration file that we
  # generated in the overcloud setup role to the undercloud host.
  - name: Copy instackenv.json to appliance
    command: >
      virt-customize -a {{ working_dir }}/undercloud.qcow2
      --upload {{ working_dir }}/instackenv.json:/home/{{ undercloud_user }}/instackenv.json
      --run-command 'chown {{ undercloud_user }}:{{ undercloud_user }} /home/{{ undercloud_user }}/instackenv.json'
    when: inject_instackenv|bool

  # Copy the undercloud public key to the virthost, because we're going
  # to inject it into the undercloud image in the next task.
  - name: Copy undercloud ssh public key to working dir
    copy:
      src: "{{ undercloud_key }}.pub"
      dest: "{{ working_dir }}/id_rsa_undercloud.pub"

  # Copy the virt host private key to `$HOME/.ssh/id_rsa_virt_power` for
  # VirtualBMC be able to access the hypervisor where the VMs are located
  - name: Copy virt host ssh private key to working dir
    when: release not in ['mitaka', 'newton']
    copy:
      src: "{{ virt_power_key }}"
      dest: "{{ working_dir }}/id_rsa_virt_power"

  # When using qemu:///system, the vbmc will need to ssh back to the virthost
  # as the root user to perform power operations
  - name: Add virt power key to root authorized keys if using qemu:///system
    authorized_key:
      user: root
      key: "{{ lookup('file', virt_power_key|quote + '.pub')|default('') }}"
    when: libvirt_uri == "qemu:///system"
    become: true

  # Copy the public key to `$HOME/.ssh/authorized_keys` for the `root`
  # and `undercloud_user` user on the undercloud.
  - name: Inject undercloud ssh public key to appliance
    command: >
      virt-customize -a {{ working_dir }}/undercloud.qcow2
      --mkdir {{item.homedir}}/.ssh/
      --upload '{{ working_dir }}/id_rsa_undercloud.pub:{{item.homedir}}/.ssh/authorized_keys'
      --run-command 'chown -R {{item.owner}}:{{item.group}} {{item.homedir}}/.ssh'
      --run-command 'chmod 0700 {{item.homedir}}/.ssh'
      --run-command 'chmod 0600 {{item.homedir}}/.ssh/authorized_keys'
    with_items:
      - homedir: /root
        owner: root
        group: root
      - homedir: '/home/{{ undercloud_user }}'
        owner: '{{ undercloud_user }}'
        group: '{{ undercloud_user }}'

  # This copies the `id_rsa_virt_power` private key that we generated
  # in the overcloud setup role to the undercloud host to be used by
  # VirtualBMC+libvirt to access the virthost.
  - name: Copy id_rsa_virt_power to appliance
    when: release not in ['mitaka', 'newton']
    command: >
      virt-customize -a {{ working_dir }}/undercloud.qcow2
      --upload '{{ working_dir }}/id_rsa_virt_power:/root/.ssh/id_rsa_virt_power'
      --run-command 'chown root:root /root/.ssh/id_rsa_virt_power'
      --run-command 'chmod 0600 /root/.ssh/id_rsa_virt_power'

  - name: Create undercloud customize script
    template:
      src: "{{ undercloud_customize_script }}"
      dest: "{{ working_dir}}/undercloud-customize.sh"
      mode: 0755
    when: undercloud_customize_script is defined

  # This allows to run a customization script on the
  # undercloud image, to cover any extra needs.
  - name: Perform extra undercloud customizations
    command: >
      virt-customize -a {{ working_dir }}/undercloud.qcow2
      --run '{{ working_dir }}/undercloud-customize.sh'
    when: undercloud_customize_script is defined

  # This allows to run a customization script on the
  # overcloud image, to cover any extra needs.
  - name: Perform extra overcloud customizations
    include_tasks: customize_overcloud.yml
    when: overcloud_customize_script is defined

  # Perform an SELinux relabel on the undercloud image to avoid problems
  # caused by bad labelling, since by default the undercloud runs in
  # enforcing mode.
  - name: Perform selinux relabel on undercloud image
    command: >
      virt-customize -a {{ working_dir }}/undercloud.qcow2
      --selinux-relabel

# NOTE(trown) Nested blocks do not seem to work as expected so instead using
# conditionals with AND to simulate the same thing.
# Resize the undercloud image if it was not converted from an overcloud
# image
- when:
    - undercloud_vol_check is failed
    - not overcloud_as_undercloud|bool
  block:
  - name: >
      Determine if the undercloud image is a whole disk image
      so we can resize it appropriately
    command: >
      virt-filesystems -a {{ working_dir }}/undercloud.qcow2
    environment:
      LIBGUESTFS_BACKEND: direct
    register: undercloud_partitions

- when:
    - undercloud_vol_check is failed
    - not overcloud_as_undercloud|bool
    - undercloud_partitions.stdout=='/dev/sda1'
  block:
  # Handle the resize for the whole disk image case
  - name: Resize undercloud image (create target image)
    command: >
      qemu-img create -f qcow2 -o preallocation=off
      '{{ working_dir }}/undercloud-resized.qcow2'
      '{{ flavors[undercloud_node.flavor].disk }}G'

  - name: Resize undercloud image (call virt-resize)
    command: >
      virt-resize --expand /dev/sda1
      '{{ working_dir }}/undercloud.qcow2'
      '{{ working_dir }}/undercloud-resized.qcow2'
    environment:
      LIBGUESTFS_BACKEND: direct
      LIBGUESTFS_DEBUG: 1
      LIBGUESTFS_TRACE: 1

  - name: Rename resized image to original name
    command: >
      mv -f '{{ working_dir }}/undercloud-resized.qcow2'
            '{{ working_dir }}/undercloud.qcow2'

- when:
    - undercloud_vol_check is failed
    - not overcloud_as_undercloud|bool
    - undercloud_partitions.stdout=='/dev/sda'
  block:
  # Handle the resize for the partition image case
  - name: Resize undercloud image (expand the image)
    command: >
      qemu-img resize
      '{{ working_dir }}/undercloud.qcow2'
      '{{ flavors[undercloud_node.flavor].disk }}G'

  - name: Resize undercloud image (expand the FS)
    command: >
      virt-customize -a '{{ working_dir }}/undercloud.qcow2'
      --run-command 'FS_TYPE=`findmnt -o FSTYPE -fn /`;
      if [ "$FS_TYPE" = "xfs" ]; then xfs_growfs /;
      elif [ "$FS_TYPE" = "ext4" ]; then resize2fs /dev/sda;
      else echo "ERROR: Unknown filesystem $FSTYPE, cannot resize.";
      exit 1; fi'
    environment:
      LIBGUESTFS_BACKEND: direct
      LIBGUESTFS_DEBUG: 1
      LIBGUESTFS_TRACE: 1

  - name: Set libvirt environment when using root to run tasks
    set_fact:
      libvirt_environment:
        LIBVIRT_DEFAULT_URI: "{{ libvirt_uri }}"
        LIBGUESTFS_BACKEND: "direct"
      cacheable: true
    when: ssh_user == "root"

  - name: Set libvirt environment when not using root to run tasks
    set_fact:
      libvirt_environment:
        LIBVIRT_DEFAULT_URI: "{{ libvirt_uri }}"
      cacheable: true
    when: ssh_user != "root"

  # NOTE(trown) We use the overcloud-full initramfs and kernel as DIB
  # seems a bit smarter about extracting them than virt-get-kernel and
  # the partition image is simply a converted overcloud-full
  - name: Extract the kernel and initramfs from the undercloud image
    command: >
      virt-copy-out -a '{{ working_dir }}/undercloud.qcow2'
      '/home/{{ undercloud_user }}/overcloud-full.vmlinuz'
      '/home/{{ undercloud_user }}/overcloud-full.initrd'
      '{{ working_dir }}'
    environment: "{{ libvirt_environment }}"
    when:  not undercloud_use_custom_boot_images|bool

- when:
    - not undercloud_use_custom_boot_images|bool
    - not overcloud_as_undercloud|bool
  block:
  # NOTE(ykarel) This is required to get the undercloud specific
  # kernel when not using overcloud_as_undercloud.
  - name: Extract the kernel and initramfs from the undercloud image
    command: >
      virt-get-kernel -a '{{ working_dir }}/undercloud.qcow2' --unversioned-names
      --output '{{ working_dir }}'
    environment:
      LIBVIRT_DEFAULT_URI: "{{ libvirt_uri }}"

  # NOTE(trown) The undercloudvm template expects this to be
  # named overcloud-full.vmlinuz. We can update the devmode case
  # to not require this step
  - name: rename undercloud kernel
    command: >
      mv '{{ working_dir }}/vmlinuz'
      '{{ working_dir }}/overcloud-full.vmlinuz'

  # NOTE(trown) The undercloudvm template expects this to be
  # named overcloud-full.initrd. We can update the devmode case
  # to not require this step
  - name: rename undercloud initramfs
    command: >
      mv '{{ working_dir }}/initramfs'
      '{{ working_dir }}/overcloud-full.initrd'

  # NOTE(trown): This is a bit of a hack to get the undercloud vm
  # template to use the external kernel and initrd. We should
  # instead use a different var for this and set it in the devmode
  # case as well.
  - name: Set overcloud_as_undercloud to true
    set_fact:
        overcloud_as_undercloud: true
        cacheable: true

- when: undercloud_vol_check is failed
  environment:
    LIBVIRT_DEFAULT_URI: "{{ libvirt_uri }}"
  block:
  # Create a libvirt volume and upload the undercloud image to
  # libvirt.
  - name: Create undercloud volume
    command: >
      virsh vol-create-as {{ libvirt_volume_pool}}
      {{ undercloud_node.name }}.qcow2
      {{ flavors[undercloud_node.flavor].disk }}G --format qcow2

  - name: Upload undercloud volume to storage pool
    command: >
      virsh -k 0 vol-upload --pool '{{ libvirt_volume_pool }}'
      '{{ undercloud_node.name }}.qcow2'
      '{{ working_dir }}/undercloud.qcow2'
    async: 600
    poll: 10

# Define (but do no start) the undercloud virtual machine.
- name: Define undercloud vm
  virt:
    name: "{{ undercloud_node.name }}"
    command: define
    xml: "{{ lookup('template', 'undercloudvm.xml.j2') }}"
    uri: "{{ libvirt_uri }}"

# Make sure we can read the image file after the copy
- name: Ensure file permissions if root used as task runner
  file:
    path: "{{ working_dir }}"
    owner: "{{ non_root_user }}"
    group: "{{ non_root_user }}"
    mode: "a+x"
    recurse: yes
    state: 'directory'
  when: non_root_chown|bool

# This block only run when ansible version < 2.3.
- block:
    # Start the undercloud virtual machine.
    - name: Start undercloud vm
      virt:
        name: "{{ undercloud_node.name }}"
        command: start
        state: running
        uri: "{{ libvirt_uri }}"

    # Configure the undercloud virtual machine to be
    # automatically started at boot.
    - name: Configure undercloud vm to start at virthost boot
      virt:
        name: "{{ undercloud_node.name }}"
        command: autostart
        uri: "{{ libvirt_uri }}"
  when: ansible_version.full|version_compare('2.3','<')

# Start the undercloud virtual machine and make it
# automatically start for ansible-version >= 2.3
- name: Start undercloud vm
  virt:
    name: "{{ undercloud_node.name }}"
    command: start
    autostart: true
    state: running
    uri: "{{ libvirt_uri }}"
  when: ansible_version.full|version_compare('2.3','>=')

# Get the ip address of the undercloud.  This will retry several times
# (`undercloud_ip_retries`) until the undercloud is ready.  The script
# works by getting the MAC address of the first undercloud interface,
# and then looking that up in the kernel ARP table.
- name: Get undercloud vm ip address
  script: "get-undercloud-ip.sh {{ undercloud_node.name }}"
  register: undercloud_vm_ip_result
  until: undercloud_vm_ip_result is success
  retries: "{{ undercloud_ip_retries }}"
  delay: 10
  environment:
    LIBVIRT_DEFAULT_URI: "{{ libvirt_uri }}"

- name: Set_fact for undercloud ip
  set_fact:
    undercloud_ip: "{{ undercloud_vm_ip_result.stdout_lines[0] }}"
    cacheable: true

- name: Wait until ssh is available on undercloud node
  wait_for:
    host: "{{ undercloud_ip }}"
    state: started
    port: 22
    timeout: 600

# Add the undercloud to the in-memory inventory.
- name: Add undercloud vm to inventory
  add_host:
    name: undercloud
    groups: undercloud
    ansible_host: undercloud
    ansible_fqdn: undercloud
    ansible_user: '{{ undercloud_user }}'
    ansible_private_key_file: "{{ undercloud_key }}"
    ansible_ssh_extra_args: '-F "{{local_working_dir}}/ssh.config.ansible"'
    undercloud_ip: "{{ undercloud_ip }}"

- name: Generate ssh configuration
  delegate_to: localhost
  template:
    src: ssh.config.j2
    dest: "{{ local_working_dir }}/ssh.config.ansible"

- when: enable_port_forward_for_tripleo_ui|bool
  block:

# TO-DO weshayutin
# In the upcoming release of ansible 2.4 this should be moved to
# iptables_raw
#  - name: ensure the required tcp ports are open on the virthost
  - iptables:
      table: filter
      chain: INPUT
      action: insert
      protocol: tcp
      match: tcp
      ctstate: NEW
      jump: ACCEPT
      destination_port: "{{ item }}"
    become: true
    with_items:
      - 6385
      - 5000
      - 5050
      - 8004
      - 8080
      - 9000
      - 8989
      - 8774
      - 3000
      - 8181
      - 8443
      - 443

  - name: Create ssh tunnel systemd service
    template:
      src: "{{ ssh_tunnel_service_file }}"
      dest: "/etc/systemd/system/ssh-tunnel.service"
      mode: 0644
    become: true

  - name: reload the systemctl daemon after file update
    shell: systemctl daemon-reload
    become: true

  - name: Enable ssh tunnel service
    service:
      name: ssh-tunnel
      enabled: true
      state: restarted
    become: true

**********
DECISION===>: PASS
**********
=========================:::993:::END!!!=========================
=========================:::994:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/libvirt/setup/undercloud/meta/main.yml
**********
dependencies:
  - common
  - libvirt/setup/common

**********
DECISION===>: PASS
**********
=========================:::994:::END!!!=========================
=========================:::995:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/libvirt/setup/undercloud/defaults/main.yml
**********
# variable only used during gating (when compressed_gating_repo is defined)
gating_repo_enabled: true

undercloud_use_custom_boot_images: false
undercloud_custom_vmlinuz: "{{ working_dir }}/overcloud-full.vmlinuz"
undercloud_custom_initrd: "{{ working_dir }}/overcloud-full.initrd"

ssh_tunnel_service_file: ssh-tunnel.service.j2

**********
DECISION===>: PASS
**********
=========================:::995:::END!!!=========================
=========================:::996:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/libvirt/setup/meta/main.yml
**********
# Include settings from the libvirt role, and include all the
# `setup/*` roles.  This means that when your playbook has:
#
#     roles:
#       - libvirt/setup
#
# You also get:
#
# - `libvirt/setup/user`
# - `libvirt/setup/overcloud`
# - `libvirt/setup/undercloud`
# - `libvirt/setup/supplemental`
dependencies:
  - { role: libvirt }
  - { role: setup/user }
  - { role: setup/overcloud }
  - { role: setup/undercloud }
  - { role: setup/supplemental, when: deploy_supplemental_node|bool }

**********
DECISION===>: PASS
**********
=========================:::996:::END!!!=========================
=========================:::997:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/libvirt/setup/user/tasks/main.yml
**********
# Also make sure `local_working_dir` exists.  This is a directory on
# the ansible control host.
- name: Ensure local working dir exists
  delegate_to: localhost
  file:
    path: "{{ local_working_dir }}"
    state: directory

# Create ssh keypairs.  `virt_power_key` is used by ironic on the
# undercloud to control libvirt on the physical host, and
# `undercloud_key` is used to log in to the undercloud.
- name: Generate ssh keys
  delegate_to: localhost
  command: >
    ssh-keygen -f '{{ item.path }}' -N ''
    -C '{{ item.comment }}'
    -t rsa -b 4096
  args:
    creates: "{{ item.path }}"
  with_items:
    - path: "{{ virt_power_key }}"
      comment: "ansible_generated_virt_power"
    - path: "{{ undercloud_key }}"
      comment: "ansible_generated_undercloud"

# Copy the undercloud key to the virthost in the ssh_user directory
- name: copy ssh keys to virthost
  copy:
    src: "{{ undercloud_key }}"
    dest: "{{ working_dir }}"
    owner: "{{ ssh_user }}"
    group: "{{ ssh_user }}"
    mode: 0600

- name: Read virt_power private key
  no_log: True
  set_fact:
    virt_power_key_pvt: "{{ lookup('file', virt_power_key)|default('') }}"
    cacheable: true

- name: add virt_power_key to remote authorized_keys
  authorized_key:
    user: "{{ ansible_user_id }}"
    key: "{{ lookup('file', virt_power_key|quote + '.pub')|default('') }}"
    manage_dir: true


**********
DECISION===>: PASS
**********
=========================:::997:::END!!!=========================
=========================:::998:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/libvirt/setup/user/meta/main.yml
**********
dependencies:
  - libvirt


**********
DECISION===>: PASS
**********
=========================:::998:::END!!!=========================
=========================:::999:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/libvirt/setup/supplemental/tasks/provision.yml
**********
---

# We're going to try putting files in `local_working_dir`, so make
# sure it exists first.
- name: Ensure local working dir exists
  delegate_to: localhost
  file:
    path: '{{ local_working_dir }}'
    state: directory

- name: Generate ssh keys
  delegate_to: localhost
  command: >
    ssh-keygen -f '{{ supplemental_node_key }}' -N ''
    -C ansible_generated_supplemental
    -t rsa -b 4096
  args:
    creates: '{{ supplemental_node_key }}'

- name: Ensure working dir exists on virthost
  file:
    path: '{{ working_dir }}'
    state: directory

- name: Copy ssh pub key to the virthost
  copy:
    src: '{{ supplemental_node_key }}.pub'
    dest: '{{ working_dir }}'
    owner: '{{ undercloud_user }}'
    group: '{{ undercloud_user }}'
    mode: 0600
  become: true

# Check if the supplemental volume exists. If not, we call out to
# [fetch_image.yml](fetch_image.yml.html) to download the image.
- name: Check if the supplemental node volume already exists
  command: >
    virsh vol-info --pool '{{ libvirt_volume_pool }}'
    '{{ supplemental_node.name }}.qcow2'
  ignore_errors: true
  changed_when: false
  register: supplemental_vol_check
  environment:
    LIBVIRT_DEFAULT_URI: '{{ libvirt_uri }}'

- when: supplemental_vol_check is failed
  block:
  # TODO(hrybacki): Update fetch-images role to handle supplemental images
  - name: Fetch centos image for ipa
    get_url:
      url: '{{ supplemental_base_image_url }}'
      dest: '{{ image_cache_dir }}/supplemental_base.qcow2'

  - name: Ensure virt-manager in installed on virthost
    package:
      name: 'virt-install'
      state: 'present'
    become: true

  - name: Prepare TLS everywhere provisoner script
    template:
      src: tls_everywhere_provisioner.sh.j2
      dest: '~/tls_everywhere_provisioner.sh'
      mode: 0700
    when: enable_tls_everywhere|bool

  - name: Execute tls everywhere provisioner script
    shell: 'bash ~/tls_everywhere_provisioner.sh &> ~/tls_everywhere_provisioner.log'
    when: enable_tls_everywhere|bool

- when: supplemental_provisioning_script is defined and not enable_tls_everywhere|bool
  block:
  - name: Move scripts to virthost
    copy:
      src: '{{ supplemental_provisioning_script }}'
      dest: '~/supplemental_node_provisioner.sh'
      mode: 0744
  - name: Provision script execution
    shell: >
      'bash ~/supplemental_node_provisioner.sh'

# Start the supplemental node virtual machine.
- name: Start supplemental node vm
  virt:
    name: '{{ supplemental_node.name }}'
    command: start
    state: running
    autostart: True
    uri: '{{ libvirt_uri }}'

- name: Wait for VM to come online
  wait_for: timeout=30

# Add the supplemental to the in-memory inventory.
- name: Add supplemental node vm to inventory
  add_host:
    name: supplemental
    groups: supplemental
    ansible_host: supplemental
    ansible_fqdn: supplemental
    ansible_user: '{{ supplemental_user }}'
    ansible_private_key_file: '{{ supplemental_node_key }}'
    ansible_ssh_extra_args: '-F "{{ local_working_dir }}/ssh.config.ansible"'
    supplemental_node_ip: '{{ supplemental_node_ip }}'

**********
DECISION===>: PASS
**********
=========================:::999:::END!!!=========================
=========================:::1000:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/libvirt/setup/supplemental/tasks/main.yml
**********
---

- include: provision.yml

**********
DECISION===>: PASS
**********
=========================:::1000:::END!!!=========================
=========================:::1001:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/libvirt/setup/supplemental/meta/main.yml
**********
dependencies:
  - common

**********
DECISION===>: PASS
**********
=========================:::1001:::END!!!=========================
=========================:::1002:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/libvirt/setup/supplemental/defaults/main.yml
**********
---

supplemental_node_key: "{{ local_working_dir }}/id_rsa_supplemental"
supplemental_base_image_url: https://cloud.centos.org/centos/7/images/CentOS-7-x86_64-GenericCloud.qcow2
supplemental_user: stack
supplemental_tls_everywhere_dns_server: 192.168.23.1

**********
DECISION===>: PASS
**********
=========================:::1002:::END!!!=========================
=========================:::1003:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/libvirt/setup/overcloud/tasks/libvirt_nodepool.yml
**********
---

- name: Fetch a CentOS image to use for libvirt nodepool nodes
  include_role:
    name: fetch-images

- name: Resize undercloud image (create target image)
  command: >
    qemu-img create -f qcow2 -o preallocation=off
    '{{ working_dir }}/undercloud-resized.qcow2'
    '80G'
- name: Resize undercloud image (call virt-resize)
  command: >
    virt-resize --expand /dev/sda1
    '{{ working_dir }}/undercloud.qcow2'
    '{{ working_dir }}/undercloud-resized.qcow2'
  environment:
    LIBGUESTFS_BACKEND: direct
    LIBGUESTFS_DEBUG: 1
    LIBGUESTFS_TRACE: 1

- name: Rename resized image to original name
  command: >
    mv -f '{{ working_dir }}/undercloud-resized.qcow2'
          '{{ working_dir }}/undercloud.qcow2'

- name: Calculate password hash
  no_log: true
  shell: >
    import crypt;
    print crypt.crypt("{{ vm_pass }}", "$1$SecretSalt$")
  args:
    executable: /usr/bin/python
  register: hash

- name: Copy generated password to file
  local_action: copy content={{ hash.stdout }} dest="{{ working_dir }}/pwtemp" mode=0600

- name: Inject password into the image
  command: >
    virt-customize -a {{ working_dir }}/undercloud.qcow2
    --root-password file:"{{ working_dir }}/pwtemp"
  environment:
    LIBGUESTFS_BACKEND: direct
    LIBVIRT_DEFAULT_URI: "{{ libvirt_uri }}"
  register: root_password

- name: Remove root password file
  file:
    path: "{{ working_dir }}/pwtemp"
    state: absent

- name: Resize the filesystem
  command: >
    virt-customize -a {{ working_dir }}/undercloud.qcow2
    --run-command 'xfs_growfs /'
  environment:
    LIBGUESTFS_BACKEND: direct
    LIBVIRT_DEFAULT_URI: "{{ libvirt_uri }}"
  when: resize_qcow_filesystem|default(true)|bool

- name: Disable cloud-init
  command: >
    virt-customize -a {{ working_dir }}/undercloud.qcow2
    --run-command "grubby --update-kernel=ALL --args=\"cloud-init=disabled\""
  environment:
    LIBGUESTFS_BACKEND: direct
    LIBVIRT_DEFAULT_URI: "{{ libvirt_uri }}"

- name: Inject ssh public key into the image
  command: >
    virt-customize -a {{ working_dir }}/undercloud.qcow2
    --mkdir /root/.ssh/
    --upload '{{ pub_key }}:/root/.ssh/authorized_keys'
    --run-command 'chown -R root:root /root/.ssh'
    --run-command 'chmod 0700 /root/.ssh'
    --run-command 'chmod 0600 /root/.ssh/authorized_keys'
    --selinux-relabel
  environment:
    LIBGUESTFS_BACKEND: direct
    LIBVIRT_DEFAULT_URI: "{{ libvirt_uri }}"

# note upstream images may be in use and have the zuul user created
- name: Add zuul user to the image
  command: >
    virt-customize -a {{ working_dir }}/undercloud.qcow2
    --run-command 'id -u zuul &>/dev/null || useradd zuul'
    --mkdir /home/zuul/.ssh
    --run-command 'cp /root/.ssh/authorized_keys /home/zuul/.ssh/'
    --run-command 'chown -R zuul:zuul /home/zuul/.ssh'
    --run-command 'chmod 0700 /home/zuul/.ssh'
    --run-command 'chmod 0600 /home/zuul/.ssh/authorized_keys'
    --run-command 'echo "zuul ALL=(root) NOPASSWD:ALL" > /etc/sudoers.d/zuul'
    --run-command 'chmod 0440 /etc/sudoers.d/zuul'
    --selinux-relabel
  # we should NOT create symlinks between python->python3
  # see https://www.python.org/dev/peps/pep-0394/
  # --run-command 'ln -s /usr/bin/python3 /usr/bin/python'
  environment:
    LIBGUESTFS_BACKEND: direct
    LIBVIRT_DEFAULT_URI: "{{ libvirt_uri }}"

- debug:
    msg: "Add basic packages we need to the image"

- environment:
    LIBVIRT_DEFAULT_URI: "{{ libvirt_uri }}"
  block:
  # Create libvirt volumes and upload them to libvirt.
  - name: Create libvirt nodepool volumes
    command: >
      virsh vol-create-as {{ libvirt_volume_pool}}
      {{ item.name }}.qcow2
      {{ flavors[item.flavor].disk }}G --format qcow2
    with_items: "{{ overcloud_nodes }}"

  - name: Upload the volume to storage pool
    command: >
      virsh -k 0 vol-upload --pool '{{ libvirt_volume_pool }}'
      '{{ item.name }}.qcow2'
      '{{ local_working_dir }}/undercloud.qcow2'
    async: 600
    poll: 10
    with_items: "{{ overcloud_nodes }}"

- name: Start libvirt nodepool nodes
  virt:
    name: "{{ item.name }}"
    command: start
    autostart: true
    state: running
    uri: "{{ libvirt_uri }}"
  with_items: "{{ overcloud_nodes }}"

## need to find a way to make these next tasks generic

- name: Get libvirt nodepool IP addresses
  script: "get-domain-ip.sh subnode-0"
  register: "subnode_0_ip_result"
  until: "subnode_0_ip_result is success"
  retries: 20
  delay: 10

- name: Set_fact for undercloud ip
  set_fact:
    subnode_0_ip: "{{ subnode_0_ip_result.stdout_lines[0] }}"
    cacheable: true

- name: Wait until ssh is available
  wait_for:
    host: "{{ subnode_0_ip }}"
    state: started
    port: 22
    timeout: 600

- name: Add subnode-0 to inventory
  add_host:
    name: subnode-0
    groups: subnodes
    ansible_host: "{{ subnode_0_ip }}"
    ansible_fqdn: "{{ subnode_0_ip }}"
    ansible_user: zuul
    ansible_private_key_file: "~/.ssh/id_rsa"
    subnode_private_ip: "{{ subnode_0_ip }}"
    subnode_public_ip: "{{ subnode_0_ip }}"
    ansible_python_interpreter: "{{ python_interpreter|default('/usr/bin/python') }}"

- name: Set hostname correctly for subnode-0
  delegate_to: subnode-0
  shell: >
    echo "127.0.0.1  subnode-0 localhost" > /etc/hosts;
    echo "HOSTNAME=subnode-0" >> /etc/sysconfig/network;
    echo "subnode-0" > /etc/hostname;
    hostnamectl set-hostname subnode-0;
    echo "nameserver {{ custom_nameserver|default('8.8.8.8') }} " >> /etc/resolv.conf;
    echo "append domain-name-servers {{ custom_nameserver|default('8.8.8.8') }};" >> /etc/dhcp/dhclient.conf
  become: true

- name: Get libvirt nodepool IP addresses
  script: "get-domain-ip.sh subnode-1"
  register: "subnode_1_ip_result"
  until: "subnode_1_ip_result is success"
  retries: 20
  delay: 10

- name: Set_fact for undercloud ip
  set_fact:
    subnode_1_ip: "{{ subnode_1_ip_result.stdout_lines[0] }}"
    cacheable: true

- name: Wait until ssh is available
  wait_for:
    host: "{{ subnode_1_ip }}"
    state: started
    port: 22
    timeout: 600

- name: Add subnode-1 to inventory
  add_host:
    name: subnode-1
    groups: subnodes
    ansible_host: "{{ subnode_1_ip }}"
    ansible_fqdn: "{{ subnode_1_ip }}"
    ansible_user: zuul
    ansible_private_key_file: "~/.ssh/id_rsa"
    subnode_private_ip: "{{ subnode_1_ip }}"
    subnode_public_ip: "{{ subnode_1_ip }}"
    ansible_python_interpreter: "{{ python_interpreter|default('/usr/bin/python') }}"

- name: Set hostname correctly for subnode-1
  delegate_to: subnode-1
  shell: >
    echo "127.0.0.1  subnode-1 localhost" > /etc/hosts;
    echo "HOSTNAME=subnode-1" >> /etc/sysconfig/network;
    echo "subnode-1" > /etc/hostname;
    hostnamectl set-hostname subnode-1;
    echo "nameserver {{ custom_nameserver|default('8.8.8.8') }} " >> /etc/resolv.conf;
    echo "append domain-name-servers {{ custom_nameserver|default('8.8.8.8') }};" >> /etc/dhcp/dhclient.conf
  become: true

- name: Create inventory suitable for zuul-jobs/multinode
  template:
    src: "{{ zuul_hosts_template }}"
    dest: "{{ local_working_dir }}/zuul-hosts.yaml"
    mode: 0755

**********
DECISION===>: PASS
**********
=========================:::1003:::END!!!=========================
=========================:::1004:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/libvirt/setup/overcloud/tasks/main.yml
**********
- name: Include vars for libvirt-libvirt-nodepool
  include_vars:
    file: libvirt_nodepool_vars.yml
  when: libvirt_nodepool|default(false)

- when: overcloud_nodes
  environment:
    LIBVIRT_DEFAULT_URI: "{{ libvirt_uri }}"
  block:

    #ensure python-netaddr is installed for next task
    - name: ensure python-netaddr
      become: true
      package:
        name: python-netaddr
        state: present

    # Generate MAC addresses that we'll use for the overcloud nodes.
    # By generating these in advance we can populate the
    # `instackenv.json` file with MAC addresses without running
    # introspection.
    - name: get a list of MACs to use
      generate_macs:
        nodes: "{{ overcloud_nodes }}"
        networks: "{{ networks }}"
      register: node_mac_map

    # Create libvirt volumes for the overcloud hosts.
    - name: Check if overcloud volumes exist
      command: >
        virsh vol-info --pool '{{libvirt_volume_pool}}' '{{item.name}}.qcow2'
      register: overcloud_vol_check
      ignore_errors: true
      with_items: "{{ overcloud_nodes }}"

    - name: Create overcloud vm storage
      command: >
        virsh vol-create-as '{{ libvirt_volume_pool }}'
        '{{ item.item.name }}'.qcow2 '{{ flavors[item.item.flavor].disk }}'G
        --format qcow2
      when:
        - item is failed
        - not libvirt_nodepool_vms|default("false")|bool
      with_items: "{{ overcloud_vol_check.results }}"

    # Define (but do not start) the overcloud nodes.  These will be
    # booted later by ironic during the provisioning process.
    - name: Define overcloud vms
      virt:
        name: "{{ item.name }}"
        command: define
        xml: "{{ lookup('template', 'baremetalvm.xml.j2') }}"
        uri: "{{ libvirt_uri }}"
      with_items: "{{ overcloud_nodes }}"
      when: not libvirt_nodepool_vms|default("false")|bool

    - name: Define overcloud vms
      virt:
        name: "{{ item.name }}"
        command: define
        xml: "{{ lookup('template', 'libvirtnodepoolvm.xml.j2') }}"
        uri: "{{ libvirt_uri }}"
      with_items: "{{ overcloud_nodes }}"
      when: libvirt_nodepool_vms|default("false")|bool

    - include: libvirt_nodepool.yml
      when: libvirt_nodepool_vms|default("false")|bool

    # Create additional blockdevices for each objectstorage flavor node
    # These are sparse files, not using space if unused
    - name: Create additional blockdevice for objectstorage nodes
      command: >
        dd if=/dev/zero of={{ libvirt_volume_path }}/{{ item[0].name }}_{{ item[1] }}.img bs=1 count=0 seek={{ extradisks_size }}
      when: flavors[item[0].flavor].extradisks|default(false)
      with_nested:
        - "{{ overcloud_nodes }}"
        - "{{ extradisks_list }}"

    - name: Check if additional blockdevices are attached
      command: >
        virsh domblkinfo {{ item[0].name }} {{ libvirt_volume_path }}/{{ item[0].name }}_{{ item[1] }}.img
      when: flavors[item[0].flavor].extradisks|default(false)
      changed_when: false
      ignore_errors: true
      register: overcloud_extradisks_check
      with_nested:
        - "{{ overcloud_nodes }}"
        - "{{ extradisks_list }}"

    - name: Attach additional blockdevices to overcloud objectstorage VMs
      command: >
        virsh attach-disk --config {{ item.item[0].name }} {{ libvirt_volume_path }}/{{ item.item[0].name }}_{{ item.item[1] }}.img {{ item.item[1] }}
      when: item is failed
      with_items: "{{ overcloud_extradisks_check.results }}"

# Generate the `instackenv.json` configuration file.  Note that this
# task *must* occur after the above overcloud tasks, because if
# `overcloud_nodes` is defined the template depends on the
# `node_mac_map` variable.
- name: Write instackenv script
  template:
    src: "{{ undercloud_instackenv_template }}"
    dest: "{{ working_dir }}/instackenv.json"
  when: create_instackenv_json|default("true")|bool

**********
DECISION===>: PASS
**********
=========================:::1004:::END!!!=========================
=========================:::1005:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/libvirt/setup/overcloud/tasks/vars/libvirt_nodepool_vars.yml
**********
# vars required to run playbooks/libvirt-nodepool.yml

libvirt_volume_pool: oooq_pool
libvirt_volume_path: /opt/vm_images
libvirt_uri: qemu:///system
overcloud_nodes:
  - name: subnode-0
    flavor: control

  - name: subnode-1
    flavor: control
pub_key: "{{ lookup('env', 'HOME') }}/.ssh/id_rsa.pub"
image_fetch_dir: "{{ local_working_dir }}"
libvirt_nodepool_vms: true
create_instackenv_json: false
vm_pass: random
control_vcpu: 6
control_memory: 16384
images:
  - name: centos
    url: https://cloud.centos.org/centos/7/images/CentOS-7-x86_64-GenericCloud-1802.qcow2
    type: qcow2
    md5sum: "b3ff9077d80b5f17bcbb7356f7982fd4 *CentOS-7-x86_64-GenericCloud-1802.qcow2"

**********
DECISION===>: PASS
**********
=========================:::1005:::END!!!=========================
=========================:::1006:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/libvirt/setup/overcloud/meta/main.yml
**********
dependencies:
  - libvirt
  - common
  - libvirt/setup/common

**********
DECISION===>: PASS
**********
=========================:::1006:::END!!!=========================
=========================:::1007:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/libvirt/setup/common/tasks/main.yml
**********
# Create a libvirt volume pool.  This is where we'll be creating
# images for the undercloud and overcloud.
# Note: the virt_pool module is not working properly on rhel-7.2
# https://bugs.launchpad.net/tripleo-quickstart/+bug/1597905
- name: ensure libvirt volume path exists
  file:
    path: "{{ libvirt_volume_path }}"
    state: directory

- name: Check volume pool
  command: >
    virsh pool-uuid "{{ libvirt_volume_pool }}"
  register: pool_check
  ignore_errors: true
  changed_when: false
  environment:
    LIBVIRT_DEFAULT_URI: "{{ libvirt_uri }}"

- name: create the volume pool xml file
  template:
    src: volume_pool.xml.j2
    dest: "{{ working_dir }}/volume_pool.xml"
  when: pool_check is failed

- name: Define volume pool
  command: "virsh pool-define {{ working_dir }}/volume_pool.xml"
  when: pool_check is failed
  environment:
    LIBVIRT_DEFAULT_URI: "{{ libvirt_uri }}"

- name: Start volume pool
  virt_pool:
    command: start
    state: active
    name: "{{ libvirt_volume_pool }}"
    uri: "{{ libvirt_uri }}"

# In some cases the pool_check can pass and the pool xml config is absent
# In this case it is required to dump the xml and redefine the pool.
- name: ensure tripleo-quickstart volume pool is defined
  shell: >
    virsh pool-dumpxml {{ libvirt_volume_pool }} |
    virsh pool-define /dev/stdin
  changed_when: true
  environment:
    LIBVIRT_DEFAULT_URI: "{{ libvirt_uri }}"

- name: Mark volume pool for autostart
  virt_pool:
    name: "{{ libvirt_volume_pool }}"
    autostart: "yes"
    uri: "{{ libvirt_uri }}"

**********
DECISION===>: PASS
**********
=========================:::1007:::END!!!=========================
=========================:::1008:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/libvirt/meta/main.yml
**********
# Include the `common` role as a dependency. This makes sure the
# variables defined in that role are available here.
dependencies:
  - common


**********
DECISION===>: PASS
**********
=========================:::1008:::END!!!=========================
=========================:::1009:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/libvirt/defaults/main.yml
**********
# Which image should we download?
release: queens
undercloud_image_url: http://artifacts.ci.centos.org/rdo/images/{{ release }}/delorean/consistent/stable/undercloud.qcow2
overcloud_image_url: http://artifacts.ci.centos.org/rdo/images/{{ release }}/delorean/consisten/stable/overcloud-full.tar
ipa_image_url: http://artifacts.ci.centos.org/rdo/images/{{ release }}/delorean/consistent/stable/ironic-python-agent.tar

# If `force_cached_image` is `true`, always use the most recent image
# available locally rather than checking for updated images.
force_cached_images: false

# You can also control the caching behavior per-image by setting the
# `force_cached` key.
images:
    - name: undercloud
      url: "{{ undercloud_image_url }}"
      type: qcow2

# These are keys that we generate; `virt_power_key` is used *by the
# undercloud* to start/stop virtual machines on the virthost.
# `undercloud_key` is used to log in to the undercloud.
virt_power_key: "{{ local_working_dir }}/id_rsa_virt_power"
undercloud_key: "{{ local_working_dir }}/id_rsa_undercloud"

# Which libvirt session should we use?  Using `qemu://session` does
# not require privileged access (but does require the setup performed by the
# `environment/setup` role).
libvirt_volume_pool: oooq_pool
libvirt_domain_type: kvm
libvirt_diskdev: vda
libvirt_diskbus: virtio
libvirt_arch: x86_64
libvirt_cpu_mode: host-model

# how many times to try getting the undercloud ip
# address before giving up.
undercloud_ip_retries: 20

# controls either to inject instackenv.json or omit it, which may be the case
# for virtual undercloud deployments w/o overcloud nodes (neither virtual,
# nor BM, nor OVB hosted).
undercloud_instackenv_template: instackenv.json.j2
inject_instackenv: true

# set to true if you want to inject additional overcloud
# and ipa images. You will need to define the images and
# mapping, and inject_images list as well
use_external_images: false

# how many disks should be created when using extradisks
extradisks_list:
  - vdb
  - vdc
  - vdd

# size of the disks to create when using extradisks
extradisks_size: 8G

# template for zuul-hosts file
zuul_hosts_template: zuul-hosts.yaml.j2

**********
DECISION===>: use of http without tls
**********
=========================:::1009:::END!!!=========================
=========================:::1010:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/common/defaults/main.yml
**********
# This directory is used to store a variety of files generated
# during the deploy process (ansible inventory, ssh configuration, ssh
# key files, etc)
local_working_dir: "{{ lookup('env', 'HOME') }}/.quickstart"

# this will define the user that ansible will connect with
ssh_user: stack

# This defines the users that deploys the overcloud from the undercloud
# and accesses overcloud as the orchestration admin user
undercloud_user: stack
overcloud_user: heat-admin

# This is where we store generated artifacts (like ssh config files,
# keys, deployment scripts, etc) on the undercloud.
working_dir: "/home/{{ undercloud_user }}"

# This is a directory no the virthost in which we store the downloaded
# undercloud image.
image_cache_dir: "/var/cache/tripleo-quickstart/images/{{ release }}"

image_fetch_dir: "{{ working_dir}}"

# This determines whether to download a pre-built undercloud.qcow2 or
# whether to instead use an overcloud-full.qcow2 and convert it on
# the fly. The default is to use a pre-built undercloud.qcow2.
overcloud_as_undercloud: false

# This determines whether or not to treat the undercloud.qcow2 as a
# stock CentOS or RHEL image.  The default is a pre-built undercloud.qcow2
baseos_as_undercloud: false

# optionally setup the yum repos on the virthost
virthost_repo_setup: false

# When a base os image is used in lieu of a quickstart prepared image
# additional setup steps are required for the undercloud install.
undercloud_setup: false

# Set selinux, by default RDO builds are always set to selinux permissive
selinux_enforcing: false

# These defaults are used if there are no flavor-specific
# overrides configured.
default_disk: 50
default_memory: 8192

# Setting controller and compute nodes to 2 vcpus, so we have more processing
# power to run the tests
default_vcpu: 2

# The undercloud needs more than the default amount of memory
# and disk.
undercloud_memory: 12288
undercloud_disk: 50
# Setting undercloud to 6 cpus, so we continue to have around 10 vcpus
# by default
undercloud_vcpu: 6

# The default deployment has flavors for compute, controllers, ceph
# nodes, and undercloud nodes.  All flavors defined in the `flavors`
# key will be created with an `oooq_` prefix to avoid conflicts with
# the pre-defined flavors created by `openstack install undercloud`.
flavors:
  compute:
    memory: '{{compute_memory|default(default_memory)}}'
    disk: '{{compute_disk|default(default_disk)}}'
    vcpu: '{{compute_vcpu|default(default_vcpu)}}'

  control:
    memory: '{{control_memory|default(default_memory)}}'
    disk: '{{control_disk|default(default_disk)}}'
    vcpu: '{{control_vcpu|default(default_vcpu)}}'

  ceph:
    memory: '{{ceph_memory|default(default_memory)}}'
    disk: '{{ceph_disk|default(default_disk)}}'
    vcpu: '{{ceph_vcpu|default(default_vcpu)}}'
    extradisks: true

  blockstorage:
    memory: '{{block_memory|default(default_memory)}}'
    disk: '{{block_disk|default(default_disk)}}'
    vcpu: '{{block_vcpu|default(default_vcpu)}}'

  objectstorage:
    memory: '{{objectstorage_memory|default(default_memory)}}'
    disk: '{{objectstorage_disk|default(default_disk)}}'
    vcpu: '{{objectstorage_vcpu|default(default_vcpu)}}'
    extradisks: true

  undercloud:
    memory: '{{undercloud_memory|default(undercloud_memory)}}'
    disk: '{{undercloud_disk|default(undercloud_disk)}}'
    vcpu: '{{undercloud_vcpu|default(undercloud_vcpu)}}'

# We create a single undercloud node.
undercloud_node:
  name: undercloud
  flavor: undercloud

# Do not deploy supplemental nodes by default.
deploy_supplemental_node: false

# Do not deploy FreeIPA server by default.
enable_tls_everywhere: false

# allow the nic model to be overridden by environment variable
overcloud_libvirt_nic_model: virtio

# The overcloud will have three controllers, one compute node,
# and a ceph storage node.
overcloud_nodes:
  - name: control_0
    flavor: control
  - name: control_1
    flavor: control
  - name: control_2
    flavor: control

  - name: compute_0
    flavor: compute

  - name: ceph_0
    flavor: ceph

# Describe our virtual networks.  These networks will be attached to
# the undercloud node and to the overcloud nodes in the order in which
# they are defined with the following caveats:
#   *  If no networks are using forward_mode: 'nat', then the default libvirt
#   network will be attached to the undercloud. This is required to ssh from the
#   virt host to the undercloud
#   *  The first bridge network defined will be used for pxe booting
#
external_network_cidr: 192.168.23.0/24
networks:
  - name: overcloud
    bridge: brovc

  - name: external
    bridge: brext
    forward_mode: nat
    address: "{{ external_network_cidr|nthhost(1) }}"
    netmask: "{{ external_network_cidr|ipaddr('netmask') }}"
    dhcp_range:
      - "{{ external_network_cidr|nthhost(10) }}"
      - "{{ external_network_cidr|nthhost(50) }}"
    nat_port_range:
      - 1024
      - 65535

#Enable network isolation with single-nic-vlans for virtualized deployments
undercloud_network_cidr: 192.168.24.0/24
undercloud_external_network_cidr: >-
  {%- if overcloud_ipv6|bool %}2001:db8:fd00:1000::/64{% else %}10.0.0.1/24{% endif -%}
undercloud_networks:
  external:
    address: "{{ undercloud_external_network_cidr|nthhost(1) }}"
    netmask: "{{ undercloud_external_network_cidr|ipaddr('netmask') }}"
    address6: "{{ undercloud_external_network_cidr6|nthhost(1) }}"
    device_type: ovs
    type: OVSIntPort
    ovs_bridge: br-ctlplane
    ovs_options: '"tag=10"'
    tag: 10

network_isolation: true
network_isolation_type: 'single-nic-vlans'
enable_pacemaker: false
ipv6: false

# This enables the deployment of the overcloud with SSL.
ssl_overcloud: false
# If ssl_overcloud is True, then the overcloud public vip must be explicitly
# specified as part of the deployment configuration. Note that the VIP used has
# to be set accordingly with the `undercloud_external_network_cidr`.
overcloud_public_vip: 10.0.0.5
overcloud_public_vip6: 2001:db8:fd00:1000::14

# Enable the virt_bmc ( virtual baremetal controllers )
enable_vbmc: true

# Set this to `false` if you don't want your undercloud and overcloud vms
# to have a VNC console available.
enable_vnc_console: true

# We have some version specific behaviors, so we need a release variable
#
# TODO(trown): It would be better to write a release into the image itself
# and set this variable from there.
release: queens

# This option controls whether or not to use the repo setup for TripleO
# development. Since this requires some other options to be functional,
# it is best to specify release master-tripleo-ci rather than
# just flipping this to true.
devmode: false

# Tuned profile set while provisioning remote hosts to optimize for deployment
tuned_profile: 'virtual-host'

# This is the name of the user the `provision` role will create on the
# remote host.
non_root_user: stack
non_root_group: "{{ non_root_user }}"

# Path for volume storage
libvirt_volume_path: "{{ working_dir }}/pool"

libvirt_uri: qemu:///session

# Whether to give permissive access to files owned by the non_root_user.
# This is required if the non_root_user is not used to run libvirt tasks.
# The most common case for this is when openvswitch is used for networks
# on the virthost. This requires running libvirt tasks as the root user so
# that they have sufficient privileges to connect to ovs bridges.
non_root_chown: false

# Enable port forwarding for tripleo-ui access
# It is safe to mark this as default true as it only runs on a virthost
# This variable is set to true in config/environments/default_libvirt.yml
enable_port_forward_for_tripleo_ui: false

# This enables the run of several tripleo-validations tests through Mistral
run_tripleo_validations: False
# This enables the run of tripleo-validations negative tests through shell
# scripts
run_tripleo_validations_negative_tests: False
# Exit tripleo-quickstart on validations failures
exit_on_validations_failure: False

# Update undercloud and overcloud images with the repos provided via the
# release config.
update_images: false

# If running in chroot-like environments (containers)
chrooted: false

# moved from tqe
undercloud_generate_service_certificate: true

**********
DECISION===>: PASS
**********
=========================:::1010:::END!!!=========================
=========================:::1011:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/tripleo/undercloud/tasks/main.yml
**********
- name: deprecation message
  vars:
    deprecation_warning_msg: |
         WARNING: This role is deprecated for removal since Ocata.
         Reason: The tripleo/undercloud role is now deprecated, has moved
         into the tripleo-quickstart-extras repository, and been renamed
         to undercloud-deploy. The tripleo/undercloud role will be removed in
         the Queens release. Please revise your playbooks to use the new role
         location and name.

  debug:
    msg: "{{ deprecation_warning_msg.split('\n') }}"

- name: include the tripleo-quickstart-extras undercloud-deploy
  include_role:
    name: undercloud-deploy


**********
DECISION===>: PASS
**********
=========================:::1011:::END!!!=========================
=========================:::1012:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/parts/ovs/tasks/main.yml
**********
- name: Install Openvswitch package
  package:
    name: "{{ ovs_package }}"
    state: present
  become: true

- name: Start Openvswitch
  service:
    name: "{{ ovs_service }}"
    state: started
    enabled: true
  become: true

**********
DECISION===>: PASS
**********
=========================:::1012:::END!!!=========================
=========================:::1013:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/parts/ovs/defaults/main.yml
**********
# The package name for openvswitch
ovs_package: openvswitch

# The name of the openvswitch service.
ovs_service: openvswitch

**********
DECISION===>: PASS
**********
=========================:::1013:::END!!!=========================
=========================:::1014:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/parts/libvirt/tasks/main.yml
**********
# We have identified this specific ipxe-roms-qemu-20130517 as having issues w/ timeouts. It is possible
# that a virthost has a later valid version of ipxe-roms-qemu that will work.  At this time, let's only
# remove the known bad version of ipxe-roms if it's found
- name: Check for older iPXE rpm
  shell: >
    if rpm -q ipxe-roms-qemu-20130517; then
       rpm -e --nodeps ipxe-roms-qemu-20130517 && echo "rpm removed";
    fi;
  become: true
  register: old_ipxe
  changed_when: '"rpm removed" in old_ipxe.stdout'

# Install the packages required for our desired libvirt environment.
# We store the list of packages in `libvirt_packages` so that in
# theory we can support multiple distributions simply by passing in a
# different list of packages.
- name: Install packages for libvirt
  package:
    name: "{{ item }}"
    state: present
  with_items: "{{ libvirt_packages }}"
  become: true

- name: Start libvirtd
  service:
    name: "{{ libvirtd_service }}"
    state: started
    enabled: true
  become: true
  when: not chrooted|bool

**********
DECISION===>: PASS
**********
=========================:::1014:::END!!!=========================
=========================:::1015:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/parts/libvirt/defaults/main.yml
**********
# The packages required to set up our desired libvirt environment.
libvirt_packages:
  - qemu-kvm
  - libvirt
  - libvirt-python
  - libguestfs-tools
  - python-lxml
  - polkit-pkla-compat

# The name of the libvirt service.
libvirtd_service: libvirtd

# If running in chroot-like environments (containers)
chrooted: false

**********
DECISION===>: PASS
**********
=========================:::1015:::END!!!=========================
=========================:::1016:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/parts/kvm/tasks/main.yml
**********
- name: Set CPU vendor
  set_fact:
    cpu_vendor: "{{ 'intel' if 'Intel' in ansible_processor|join('') else
                    'amd' if 'AMD' in ansible_processor|join('') else 'unknown' }}"
    cacheable: true

- name: Get CPU flags
  command: "awk -F: '/^flags/ {print $2; exit}' /proc/cpuinfo"
  register: cpu_flags_cmd
  changed_when: false

- name: Check for nested support
  set_fact:
    cpu_nested_support: "{{ true if cpu_vendor == 'intel' and 'vmx' in cpu_flags_cmd.stdout.split() else
                            true if cpu_vendor == 'amd' and 'svm' in cpu_flags_cmd.stdout.split() else false }}"
    cacheable: true

- name: Disable nested if not supported
  set_fact:
    nested: "{{ false if not cpu_nested_support|bool else nested }}"
    cacheable: true

- name: Remove previous KVM modprobe configs
  shell: find /etc/modprobe.d/ -type f -print0| xargs -r -0 sed -i '/^options kvm_intel/d;/^options kvm_amd/d'
  become: true
  changed_when: true

- name: Configure KVM module
  copy:
    dest: "/etc/modprobe.d/kvm.conf"
    content: |
      options kvm_{{ cpu_vendor }} nested={{ nested|bool|ternary('1', '0') }}
  become: true

- name: Fetch current runtime nested setting
  command: cat /sys/module/kvm_{{ cpu_vendor }}/parameters/nested
  register: kvm_nested_info
  changed_when: false
  when: nested|bool

- name: Set fact for nested to false if virtualization is not enabled
  set_fact:
    cpu_nested_enabled: false
    cacheable: true
  when: not nested|bool

- name: Check if nested is enabled currently
  set_fact:
    cpu_nested_enabled: "{{ true if 'Y' in kvm_nested_info.stdout else
                            true if '1' in kvm_nested_info.stdout else false }}"
    cacheable: true
  when: nested|bool

- when: nested|bool != cpu_nested_enabled|bool
  block:
    - name: Unload KVM module
      modprobe:
        name: "kvm_{{ cpu_vendor }}"
        state: "absent"
      become: true

    - name: Reload KVM module
      modprobe:
        name: "kvm_{{ cpu_vendor }}"
        state: "present"
      become: true

    - name: Fetch current runtime nested setting
      command: cat /sys/module/kvm_{{ cpu_vendor }}/parameters/nested
      register: kvm_nested_info
      changed_when: false

    - name: Check again if nested is enabled currently
      set_fact:
        cpu_nested_enabled: "{{ true if 'Y' in kvm_nested_info.stdout else
                                true if '1' in kvm_nested_info.stdout else false }}"
        cacheable: true
    - name: Fail when the desired and actual state do not match
      fail:
        msg: "Cannot change the state of nested virtualization. Please shut down any running VMs."
      when: nested|bool != cpu_nested_enabled|bool


**********
DECISION===>: PASS
**********
=========================:::1016:::END!!!=========================
=========================:::1017:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/parts/kvm/defaults/main.yml
**********
nested: true


**********
DECISION===>: PASS
**********
=========================:::1017:::END!!!=========================
=========================:::1018:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/environment/vars/redhat.yml
**********
qemu_bridge_conf: /etc/qemu-kvm/bridge.conf


**********
DECISION===>: PASS
**********
=========================:::1018:::END!!!=========================
=========================:::1019:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/environment/vars/fedora.yml
**********
qemu_bridge_conf: /etc/qemu/bridge.conf


**********
DECISION===>: PASS
**********
=========================:::1019:::END!!!=========================
=========================:::1020:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/environment/vars/centos-7.yml
**********
qemu_bridge_conf: /etc/qemu-kvm/bridge.conf


**********
DECISION===>: PASS
**********
=========================:::1020:::END!!!=========================
=========================:::1021:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/environment/vars/main.yml
**********
qemu_bridge_conf: /etc/qemu/bridge.conf


**********
DECISION===>: PASS
**********
=========================:::1021:::END!!!=========================
=========================:::1022:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/environment/tasks/main.yml
**********
- name: Include os_family specific vars
  include_vars: "{{ ansible_os_family|lower }}.yml"
  ignore_errors: true
- name: Include distribution specific vars
  include_vars: "{{ ansible_distribution|lower }}.yml"
  ignore_errors: true
- name: Include version specific vars
  include_vars: "{{ ansible_distribution|lower }}-{{ ansible_distribution_major_version|lower }}.yml"
  ignore_errors: true


**********
DECISION===>: PASS
**********
=========================:::1022:::END!!!=========================
=========================:::1023:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/environment/teardown/tasks/main.yml
**********
# Tear down the virtual environment that was created by the
# `environment/setup` role.
#
# NB: We use `virsh` here instead of the `virt_net` module because
# these tasks may be called before the dependencies of the `virt_net`
# module are satisfied.

- name: Check if libvirt is available
  command: >
    virsh uri
  ignore_errors: true
  register: libvirt_check
  changed_when: false

# If libvirt is not available, we can skip the rest of the tasks.
- when: libvirt_check is success
  block:

  # Check to see if the networks exist.
    - name: Check libvirt networks
      command: >
        virsh net-uuid "{{ item.name }}"
      with_items: "{{ networks }}"
      register: network_check
      ignore_errors: true
      become: true

    # If the networks exist, stop them, undefine them, and remove the
    # bridges devices from the qemu whitelist.
    - name: Stop libvirt networks
      command: >
        virsh net-destroy "{{ item.item.name }}"
      when: libvirt_check is success and item is success
      with_items: "{{ network_check.results }}"
      ignore_errors: true
      become: true

    - name: Undefine libvirt networks
      command: >
        virsh net-undefine "{{ item.item.name }}"
      when: libvirt_check is success and item is success
      with_items: "{{ network_check.results }}"
      ignore_errors: true
      become: true

    - name: Remove bridge whitelisting from qemu bridge helper
      lineinfile:
        dest: "{{ qemu_bridge_conf }}"
        line: "allow {{item.bridge}}"
        state: absent
      with_items: "{{ networks }}"
      become: true

- name: Delete any existing dstat log file
  file: dest=/var/log/extra/dstat-csv.log state=absent
  become: true

- name: Delete OVS Bridges
  openvswitch_bridge:
    bridge: "{{ item.bridge }}"
    state: absent
  when: item.virtualport_type is defined and item.virtualport_type == "openvswitch"
  with_items: "{{ networks }}"
  become: true

**********
DECISION===>: PASS
**********
=========================:::1023:::END!!!=========================
=========================:::1024:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/environment/teardown/meta/main.yml
**********
---
dependencies:
  - environment


**********
DECISION===>: PASS
**********
=========================:::1024:::END!!!=========================
=========================:::1025:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/environment/setup/tasks/main.yml
**********
# If virtualport_type is defined for any networks, include OVS dependencies
- when: networks|selectattr('virtualport_type', 'defined')|map(attribute='name')|list|length > 0
  block:

  # Install OVS dependencies
  - name: Install OVS dependencies
    include_role:
      name: 'parts/ovs'

  # Create any OVS Bridges that have been defined
  - name: Create OVS Bridges
    openvswitch_bridge:
      bridge: "{{ item.bridge }}"
      state: present
    when: item.virtualport_type is defined and item.virtualport_type == "openvswitch"
    with_items: "{{ networks }}"
    become: true

# Create the global, root-managed libvirt networks to which we will
# attach the undercoud and overcloud virtual machines.
- name: Create libvirt networks
  virt_net:
    command: define
    state: present
    name: "{{ item.name }}"
    xml: '{{ lookup("template", "network.xml.j2") }}'
  with_items: "{{ networks }}"
  become: true

- name: Start libvirt networks
  virt_net:
    command: start
    name: "{{ item.name }}"
    state: active
  with_items: "{{ networks }}"
  become: true

- name: Mark  libvirt networks as autostarted
  virt_net:
    name: "{{ item.name }}"
    autostart: "yes"
  with_items: "{{ networks }}"
  become: true
  register: net_autostart
  ignore_errors: true

# https://bugs.launchpad.net/tripleo-quickstart/+bug/1581676
# There is a bug w/ virt_net and RHEL where the network xml
# file is not written to /etc/libvirt/qemu/networks/ This causes
# network to be considered transient.
- when: net_autostart.changed != true
  block:

    - name: Check if "virsh net-autostart" was successful
      debug: msg="Some libvirt networks were not set to autostart. Please see
             https://bugs.launchpad.net/tripleo-quickstart/+bug/1581676"

    # get the network xml from the running network
    - name: Get libvirt networks xml
      virt_net:
        command: get_xml
        name: "{{ item.name }}"
      with_items: "{{ networks }}"
      register: net_xml
      become: true

    # copy the xml to a file
    - name: copy network-xml to file
      copy: content={{ item.get_xml }} dest=/tmp/network-{{item.item.name}}.xml
      with_items: "{{ net_xml.results }}"
      become: true

    # redefine the network w/ virsh, this will write the xml file to
    # /etc/libvirt/qemu/networks/ and it will no longer be transient
    - name: redefine the libvirt networks so the config is written to /etc/libvirt
      command: virsh net-define /tmp/network-{{item.name}}.xml
      with_items: "{{ networks }}"
      become: true

    # Now we're ready to mark the network autostart
    - name: Mark libvirt networks as autostarted
      virt_net:
        name: "{{ item.name }}"
        autostart: "yes"
      with_items: "{{ networks }}"
      become: true

# Whitelist the bridges associated with these networks for
# access using qemu [helper networking][helper].  Later on we
# create virtual machines use an unprivileged `qemu://session`
# connection, and we connect to the networks using the bridge names.
#
# [helper]: http://wiki.qemu.org/Features-Done/HelperNetworking
- name: Whitelist bridges for unprivileged access
  lineinfile:
    dest: "{{ qemu_bridge_conf }}"
    line: "allow {{item.bridge}}"
  with_items: "{{ networks }}"
  become: true

# We're going to want to store things in `working_dir` so ensure it
# exists first.  `working_dir` is a directory on the target host.
- name: Ensure remote working dir exists
  file:
    path: "{{ working_dir }}"
    state: directory
  become: true

**********
DECISION===>: PASS
**********
=========================:::1025:::END!!!=========================
=========================:::1026:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/environment/setup/meta/main.yml
**********
# Include the roles for installing KVM and libvirt (as well as
# anything required by our parent `environment` module).
dependencies:
  - parts/kvm
  - parts/libvirt
  - environment


**********
DECISION===>: PASS
**********
=========================:::1026:::END!!!=========================
=========================:::1027:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/environment/meta/main.yml
**********
dependencies:
  - common


**********
DECISION===>: PASS
**********
=========================:::1027:::END!!!=========================
=========================:::1028:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/virtbmc/tasks/configure-vbmc.yml
**********
---

- name: Create VirtualBMC directories
  when: release not in ['liberty', 'mitaka', 'newton']
  file:
    path: "{{ item }}"
    state: directory
    mode: 0750
    owner: root
    group: root
  with_items:
    - "/etc/virtualbmc"
    - "/var/log/virtualbmc"
  become: true

- name: Create VirtualBMC configuration file
  when: release not in ['liberty', 'mitaka', 'newton']
  copy:
    mode: 0750
    dest: "/etc/virtualbmc/virtualbmc.conf"
    content: |
      [default]
      config_dir=/root/.vbmc
      [log]
      logfile=/var/log/virtualbmc/virtualbmc.log
      debug=True
      [ipmi]
      session_timout=20
  become: true

- name: get virthost non_root_user userid
  command: id -u {{ non_root_user }}
  register: non_root_user_uid
  delegate_to: virthost

- name: set fact on non_root_user_uid
  set_fact:
    non_root_user_uid: "{{ non_root_user_uid.stdout }}"

# The first network defined with an address will be used for vbmc access.
- name: set vbmc address if there is a (nat) network defined with an address
  set_fact:
    vbmc_address: "{{ networks|selectattr('address', 'defined')|map(attribute='address')|list|first }}"
  when: networks|selectattr('address', 'defined')|map(attribute='name')|list|length > 0

# If there is no nat network with an address, the undercloud will be
# connected to the default libvirt network to fill this role.
- name: set vbmc address fact for default libvirt network
  set_fact:
    vbmc_address: "{{ libvirt_default_network_address }}"
  when: vbmc_address is not defined

# The connection uri is slightly different when using qemu:///system
# and requires the root user.
- name: set qemu uri for qemu:///system usage
  set_fact:
    vbmc_libvirt_uri: "qemu+ssh://root@{{ vbmc_address }}/system?&keyfile=/root/.ssh/id_rsa_virt_power&no_verify=1&no_tty=1"
  when: libvirt_uri == "qemu:///system"

- name: set qemu uri for qemu:///session usage
  set_fact:
    vbmc_libvirt_uri: "qemu+ssh://{{ non_root_user }}@{{ vbmc_address }}/session?socket=/run/user/{{ non_root_user_uid }}/libvirt/libvirt-sock&keyfile=/root/.ssh/id_rsa_virt_power&no_verify=1&no_tty=1"
  when: vbmc_libvirt_uri is not defined

- name: Install VirtualBMC package
  when: release not in ['liberty', 'mitaka', 'newton']
  package:
    name: "python2-virtualbmc"
    state: present
    use: yum
  become: true

- name: Start the Virtual BMCs (virtualbmc >= 1.4.0+)
  when: release not in ['liberty', 'mitaka', 'newton', 'ocata', 'pike', 'queens']
  service:
    name: "virtualbmc"
    state: started
    enabled: true
  become: true

- name: Create the Virtual BMCs
  when: release not in ['liberty', 'mitaka', 'newton']
  command: "vbmc add {{ item.name }} --port {{ item.virtualbmc_port }} --libvirt-uri {{ vbmc_libvirt_uri }}"
  args:
    creates: /root/.vbmc/{{ item.name }}/config
  with_items: "{{ overcloud_nodes }}"
  become: true

- name: Start the Virtual BMCs (virtualbmc >= 1.4.0+)
  when: release not in ['liberty', 'mitaka', 'newton', 'ocata', 'pike', 'queens']
  command: "vbmc start {{ item.name }}"
  with_items: "{{ overcloud_nodes }}"
  become: true

- name: Create the VirtualBMC systemd service (virtualbmc < 1.4.0)
  when: release in ['ocata', 'pike', 'queens']
  copy:
    mode: 0664
    dest: "/usr/lib/systemd/system/virtualbmc@.service"
    content: |
      [Unit]
      Description=VirtualBMC %i service
      After=network.target

      [Service]
      Type=forking
      PIDFile=/root/.vbmc/%i/pid
      ExecStart=/bin/vbmc start %i
      ExecStop=/bin/vbmc stop %i
      Restart=always

      [Install]
      WantedBy=multi-user.target
  become: true

- name: Start the Virtual BMCs (virtualbmc < 1.4.0)
  when: release in ['ocata', 'pike', 'queens']
  service:
    name: "virtualbmc@{{ item.name }}"
    state: started
    enabled: true
  with_items: "{{ overcloud_nodes }}"
  become: true

**********
DECISION===>: PASS
**********
=========================:::1028:::END!!!=========================
=========================:::1029:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/virtbmc/tasks/main.yml
**********
---

- name: Include VBMC setup if enabled
  include: configure-vbmc.yml
  when: enable_vbmc|bool
**********
DECISION===>: PASS
**********
=========================:::1029:::END!!!=========================
=========================:::1030:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/virtbmc/meta/main.yml
**********
dependencies:
  - common

**********
DECISION===>: PASS
**********
=========================:::1030:::END!!!=========================
=========================:::1031:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/virtbmc/defaults/main.yml
**********
# Use the vbmc
# moved to common
# enable_vbmc: true
**********
DECISION===>: PASS
**********
=========================:::1031:::END!!!=========================
=========================:::1032:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/repo-setup/tasks/get-dlrn-hash-newest.yml
**********
---
- name: Check DLRN hash newest format
  fail:
    msg: "The newest DLRN hash or tag is not recognized. The hash or tag should not contain path slashes."
  when:
    - not dlrn_hash_tag_newest | match("[a-zA-Z0-9]{40}_[a-zA-Z0-9]{8}")
    - dlrn_hash_tag_newest not in known_hash_tags

- name: Check DLRN hash newest - passed ready hash
  set_fact:
    dlrn_hash_newest: "{{ dlrn_hash_tag_newest }}"
    cacheable: true
  when: dlrn_hash_tag_newest | match("[a-zA-Z0-9]{40}_[a-zA-Z0-9]{8}")

- when: dlrn_hash_tag_newest in known_hash_tags
  block:

    - name: Get DLRN hash newest - passed tag
      shell: >
        curl -s {{ dlrn_baseurl }}/{{ dlrn_hash_tag_newest }}/delorean.repo \
        | grep baseurl | grep -Eo '[a-zA-Z0-9]{40}_[a-zA-Z0-9]{8}'
      register: full_hash_newest_result
      retries: 3

    - name: Set fact for dlrn_hash_newest
      set_fact:
        dlrn_hash_newest: "{{ full_hash_newest_result.stdout }}"
        cacheable: true

- name: Set fact for dlrn_hash_path_newest
  set_fact:
    dlrn_hash_path_newest: "{{ dlrn_hash_newest[:2] }}/{{ dlrn_hash_newest[2:4] }}/{{ dlrn_hash_newest }}"
    cacheable: true

- name: Set fact for task already run
  set_fact:
    dlrn_task_run_newest: true
    cacheable: true

**********
DECISION===>: PASS
**********
=========================:::1032:::END!!!=========================
=========================:::1033:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/repo-setup/tasks/inject_repos_into_image.yml
**********
- name: Inject the repositories into the image
  include_role:
    name: modify-image
  vars:
    image_to_modify: "{{ repo_inject_image_path }}"
    modify_script: "{{ repo_setup_dir }}/{{ repo_setup_script }}"

**********
DECISION===>: PASS
**********
=========================:::1033:::END!!!=========================
=========================:::1034:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/repo-setup/tasks/setup_repos.yml
**********
- name: Setup repos on live host
  shell: >
    set -o pipefail &&
    {{ repo_setup_dir }}/{{ repo_setup_script }} 2>&1 {{ timestamper_cmd }}
    | tee -a {{ repo_setup_dir }}/{{ repo_setup_log }}
  become: true
  register: result
  no_log: result.rc == 0
**********
DECISION===>: PASS
**********
=========================:::1034:::END!!!=========================
=========================:::1035:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/repo-setup/tasks/get-dlrn-hash.yml
**********
---
- name: Check DLRN hash format
  fail:
    msg: "The DLRN hash or tag is not recognized. The hash or tag should not contain path slashes."
  when:
    - not dlrn_hash_tag | match("[a-zA-Z0-9]{40}_[a-zA-Z0-9]{8}")
    - dlrn_hash_tag not in known_hash_tags

- name: Check DLRN hash - passed ready hash
  set_fact:
    dlrn_hash: "{{ dlrn_hash_tag }}"
    cacheable: true
  when: dlrn_hash_tag | match("[a-zA-Z0-9]{40}_[a-zA-Z0-9]{8}")

- when: dlrn_hash_tag in known_hash_tags
  block:

    - name: Get DLRN hash - passed tag
      shell: >
        curl -s {{ dlrn_baseurl }}/{{ dlrn_hash_tag }}/delorean.repo \
        | grep baseurl | grep -Eo '[a-zA-Z0-9]{40}_[a-zA-Z0-9]{8}'
      register: full_hash_result
      retries: 3

    - name: Set fact for dlrn_hash
      set_fact:
        dlrn_hash: "{{ full_hash_result.stdout }}"
        cacheable: true

# TODO: Fix for fedora
- when: overcloud_release is defined and overcloud_release != ""
  block:

    - name: Get DLRN overcloud hash
      shell: >
        curl -s https://trunk.rdoproject.org/centos7-{{ overcloud_release }}/{{ dlrn_hash_tag }}/delorean.repo \
        | grep baseurl | grep -Eo '[a-zA-Z0-9]{40}_[a-zA-Z0-9]{8}'
      register: full_overcloud_hash_result
      retries: 3

    - name: Set fact for overcloud dlrn_hash
      set_fact:
        overcloud_dlrn_hash: "{{ full_overcloud_hash_result.stdout }}"
        cacheable: true

    - name: Set fact for overcloud dlrn_hash path
      set_fact:
        overcloud_dlrn_hash_path: "{{ overcloud_dlrn_hash[:2] }}/{{ overcloud_dlrn_hash[2:4] }}/{{ overcloud_dlrn_hash }}"
        cacheable: true

    - name: Set fact for the overcloud Docker image tag
      set_fact:
        overcloud_docker_image_tag: "{{ overcloud_dlrn_hash }}"
        cacheable: true

- name: Set fact for dlrn_hash path
  set_fact:
    dlrn_hash_path: "{{ dlrn_hash[:2] }}/{{ dlrn_hash[2:4] }}/{{ dlrn_hash }}"
    cacheable: true

- name: Set fact for the Docker image tag
  set_fact:
    docker_image_tag: "{{ dlrn_hash }}"
    cacheable: true

- name: Set fact for task already run
  set_fact:
    dlrn_task_run: true
    cacheable: true

**********
DECISION===>: PASS
**********
=========================:::1035:::END!!!=========================
=========================:::1036:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/repo-setup/tasks/main.yml
**********
---
- include: get-dlrn-hash.yml
  when: dlrn_hash_tag is defined and dlrn_task_run is not defined

- include: get-dlrn-hash-newest.yml
  when: dlrn_hash_tag_newest is defined and dlrn_task_run_newest is not defined

- include: create-repo-script.yml

- include_tasks: setup_repos.yml
  when: repo_run_live|bool

- include_tasks: inject_repos_into_image.yml
  when: repo_inject_image_path is defined

**********
DECISION===>: PASS
**********
=========================:::1036:::END!!!=========================
=========================:::1037:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/repo-setup/tasks/create-repo-script.yml
**********
---
- name: Create repo setup script
  template:
    src: "{{ repo_setup_script_source }}"
    dest: "{{ repo_setup_dir }}/{{ repo_setup_script }}"
    mode: 0755

**********
DECISION===>: PASS
**********
=========================:::1037:::END!!!=========================
=========================:::1038:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/repo-setup/meta/main.yml
**********
dependencies:
  - extras-common

**********
DECISION===>: PASS
**********
=========================:::1038:::END!!!=========================
=========================:::1039:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/roles/repo-setup/defaults/main.yml
**********
---
repo_setup_dir: "{{ working_dir }}"
repo_setup_script_source: repo_setup.sh.j2
repo_setup_log: repo_setup.log
repo_setup_script: repo_setup.sh
repo_run_live: true
# Releases shortcuts
stable:
  - pike
  - ocata
  - queens
  - rocky
repo_cmd_before: |
  {% if ansible_pkg_mgr == "yum" %}
  sudo {{ ansible_pkg_mgr }} install -y yum-plugin-priorities;
  {% endif %}
  sudo {{ ansible_pkg_mgr }} clean all;
  sudo rm -rf /etc/yum.repos.d/delorean*;
  sudo rm -rf /etc/yum.repos.d/*.rpmsave;
repo_cmd_after: |
  sudo {{ ansible_pkg_mgr }} repolist;
  sudo {{ ansible_pkg_mgr }} update -y

# Repositories definitions
dlrn_baseurl: https://trunk.rdoproject.org/centos7-{{ release }}
repos:
  - type: file
    filename: delorean.repo
    down_url: "{{ dlrn_baseurl }}/current/delorean.repo"

  - type: file
    filename: delorean-deps.repo
    down_url: "{{ dlrn_baseurl }}/delorean-deps.repo"

repo_setup_run_update: true

# For adding custom repositories in featureset files
add_repos: []
# rhsm variables
use_rhsm: false
use_use_rhsm_baseos_channel: true
use_rhsm_openstack_channel: true
use_rhsm_ceph_channel: true

rhsm_username: none
rhsm_password: none
pool_id: none
rhel_version_number: 7
osp_release_version_number: 8
rhceph_version_number: "1.3"
use_specific_hash: false
delorean_hash_label: latest
known_hash_tags:
  - current
  - consistent
  - tripleo-ci-testing
  - current-tripleo
  - current-tripleo-rdo
  - current-tripleo-rdo-internal
  - current-passed-ci


**********
DECISION===>: PASS
**********
=========================:::1039:::END!!!=========================
=========================:::1040:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/playbooks/repo-setup-virthost.yml
**********
# This will optionally setup yum repos on the virthost
- name: setup yum repos on virthost
  hosts: virthost
  gather_facts: yes
  roles:
    - repo-setup
  tags:
    - provision

**********
DECISION===>: PASS
**********
=========================:::1040:::END!!!=========================
=========================:::1041:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/playbooks/provision.yml
**********
# This playbooks is responsible for preparing a target host.
#
# Create an inventory entry for the target host
- name: Add virthost to inventory
  hosts: localhost
  roles:
    - provision/local
  tags:
    - provision

# Create non root user on the virthost
- name: Create non root user on the virthost
  hosts: virthost
  roles:
    - provision/user
  tags:
    - provision

- name: Create target user on virt host
  hosts: virthost
  roles:
    - provision/remote
  tags:
    - provision

- name: Add the virthost node to the generated inventory
  hosts: localhost
  gather_facts: yes
  roles:
    - tripleo-inventory
  tags:
    - provision

# Allow the user to optionally perform a yum repo setup
# the virthost_repo_setup variable by default is set to false
- include: repo-setup-virthost.yml
  when: virthost_repo_setup|bool

- name: Check if the target virthost distro is supported (RHEL or CentOS)
  hosts: virthost
  roles:
    - provision/support_check
  tags:
    - provision

# We need to force-refresh fact gathering because we are now connecting
# as a different user ('stack' instead of 'root'), which affects
# things like ansible_user_id and other facts.
- name: Run setup again on virthost
  hosts: virthost
  tasks:
    - name: Force-refresh facts
      setup:


**********
DECISION===>: PASS
**********
=========================:::1041:::END!!!=========================
=========================:::1042:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/playbooks/teardown-environment.yml
**********
# This teardown role will destroy libvirt networks
- name: Tear down environment
  hosts: virthost
  roles:
    - environment/teardown
  tags:
    - teardown-environment
    - teardown-all


**********
DECISION===>: PASS
**********
=========================:::1042:::END!!!=========================
=========================:::1043:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/playbooks/noop.yml
**********
# Do a quickstart run without any further actions, useful for
# basic syntax check and environment setup.

- name: noop playbook
  hosts: localhost
  tasks:
    - debug: msg="noop"


**********
DECISION===>: PASS
**********
=========================:::1043:::END!!!=========================
=========================:::1044:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/playbooks/teardown-provision.yml
**********
# Finally, we conditionally remove basic setup (users,
# groups, directories)to start from scratch
- name: Tear down non-root user on virt host
  hosts: virthost
  roles:
    - provision/teardown
  tags:
    - teardown-provision
    - teardown-all


**********
DECISION===>: PASS
**********
=========================:::1044:::END!!!=========================
=========================:::1045:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/playbooks/libvirt-setup.yml
**********
---
- name:  Setup undercloud and baremetal vms and networks in libvirt
  hosts: virthost
  gather_facts: yes
  roles:
    - libvirt/setup

- name: Add nodes to the generated inventory
  hosts: localhost
  gather_facts: yes
  roles:
    - tripleo-inventory


**********
DECISION===>: PASS
**********
=========================:::1045:::END!!!=========================
=========================:::1046:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/playbooks/build-images.yml
**********
---
- name: Add virthost to inventory
  hosts: localhost
  roles:
    - provision/local

- name: Add the virthost node to the generated inventory
  hosts: localhost
  gather_facts: yes
  roles:
    - tripleo-inventory

- name:  Setup the virthost to build images then build them
  hosts: virthost
  gather_facts: yes
  roles:
    - parts/kvm
    - parts/libvirt
    # TODO(trown): It is not ideal that we need to set this
    # variable directly on the role. However, we have the
    # same variable used in the tripleo-quickstart roles
    # with a different meaning. We should namespace the
    # variables better so that they can both be set separately
    # in a config file or extra-vars passed to ansible.
    - { role: "image-build", working_dir: "/var/lib/oooq-images" }


**********
DECISION===>: PASS
**********
=========================:::1046:::END!!!=========================
=========================:::1047:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/playbooks/quickstart.yml
**********
# This is the playbook used by the `quickstart.sh` script.

# Add the virthost to the in-memory inventory. The inventory is not
# written out to disk unless you call the `tripleo-inventory` role.
- name: Add the virthost to the inventory
  hosts: localhost
  tasks:
    - name: Add virthost
      add_host:
        name: "{{virthost}}"
        groups: "virthost"
        ansible_fqdn: "{{ virthost }}"
        ansible_user: "root"
        ansible_host: "{{ virthost }}"
  tags:
    - provision
    - teardown-all
    - teardown-nodes
    - teardown-provision
    - teardown-environment

- include: teardown-provision.yml

# The `provision.yml` playbook is responsible for
# creating an inventory entry for our `virthost` and for creating an
# unprivileged user on that host for use by our virtual environment.
- include: provision.yml

# These teardown tasks only make sense after running provision.yml,
# because they assume they are connecting as the `stack` user rather
# than `root`.
- include: teardown-nodes.yml
- include: teardown-environment.yml

# The `environment/setup` role performs any tasks that require `root`
# access on the target host.
- name: Install libvirt packages and configure networks
  hosts: virthost
  gather_facts: yes
  tags:
    - environment
  roles:
    - environment/setup

# The `libvirt/setup` role creates the undercloud and overcloud
# virtual machines.
- name:  Setup undercloud, overcloud, and supplemental vms
  hosts: virthost
  gather_facts: yes
  tags:
    - libvirt
  roles:
    - libvirt/setup


- name: Add the undercloud node to the generated inventory
  hosts: localhost
  gather_facts: yes
  tags:
    - undercloud-inventory
  roles:
    - tripleo-inventory

# Setup the virtual bmc
# This must be done after inventory is run for the first time
- name: Create the virtual BMC
  hosts: undercloud
  gather_facts: yes
  tags:
    - libvirt
  roles:
    - virtbmc

**********
DECISION===>: PASS
**********
=========================:::1047:::END!!!=========================
=========================:::1048:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/playbooks/libvirt-teardown.yml
**********
---
- name:  Teardown previous libvirt setup
  hosts: virthost
  gather_facts: no
  roles:
    - libvirt/teardown


**********
DECISION===>: PASS
**********
=========================:::1048:::END!!!=========================
=========================:::1049:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/playbooks/teardown.yml
**********
# This teardown role will destroy all vms defined in the overcloud_nodes
# key, and the undercloud
- name:  Teardown undercloud and overcloud vms
  hosts: virthost
  gather_facts: yes
  roles:
    - libvirt/teardown
  tags:
    - teardown-all
    - teardown-nodes

# This teardown role will destroy libvirt networks
- name: Tear down environment
  hosts: virthost
  roles:
    - environment/teardown
  tags:
    - teardown-all
    - teardown-environment

# Finally, we conditionally remove basic setup (users,
# groups, directories)to start from scratch
- name: Teardown user setup on virt host
  hosts: virthost
  roles:
    - provision/teardown
  tags:
    - teardown-provision
    - teardown-all


**********
DECISION===>: PASS
**********
=========================:::1049:::END!!!=========================
=========================:::1050:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/playbooks/build-images-and-quickstart.yml
**********
---
- include: build-images.yml
- include: quickstart-extras.yml


**********
DECISION===>: PASS
**********
=========================:::1050:::END!!!=========================
=========================:::1051:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/playbooks/teardown-nodes.yml
**********
# This teardown role will destroy all vms defined in the overcloud_nodes
# key, and the undercloud
- name:  Tear down undercloud and overcloud vms
  hosts: virthost
  gather_facts: yes
  roles:
    - libvirt/teardown
  tags:
    - teardown-nodes
    - teardown-all


**********
DECISION===>: PASS
**********
=========================:::1051:::END!!!=========================
=========================:::1052:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/playbooks/libvirt-nodepool.yml
**********
# create 2 libvirt domains (VM's) to mimic upstream CI's nodepool instances
# This is used for tripleo CI reproducer capability

---
- name: Destroy previous setup
  hosts: virthost
  gather_facts: yes
  vars:
    - libvirt_nodepool: true
  roles:
    - libvirt/teardown/nodes
  become: true

- name:  Setup undercloud and baremetal vms and networks in libvirt
  hosts: virthost
  gather_facts: yes
  vars:
    - libvirt_nodepool: true
  roles:
    - role: libvirt/setup/overcloud
      environment:
        SUPERMIN_KERNEL_VERSION: "{{ lookup('env', 'SUPERMIN_KERNEL_VERSION') }}"
        SUPERMIN_KERNEL: "{{ lookup('env', 'SUPERMIN_KERNEL') }}"
        SUPERMIN_MODULES:  "{{ lookup('env', 'SUPERMIN_MODULES') }}"
        LIBGUESTFS_BACKEND: "{{ lookup('env', 'LIBGUESTFS_BACKEND') }}"
        LIBGUESTFS_BACKEND_SETTINGS: "{{ lookup('env', 'LIBGUESTFS_BACKEND_SETTINGS') }}"
  become: true

- name: Add nodes to the generated inventory
  hosts: localhost
  gather_facts: yes
  roles:
    - tripleo-inventory


**********
DECISION===>: PASS
**********
=========================:::1052:::END!!!=========================
=========================:::1053:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/releasenotes/notes/openstack-shade-static-inventory-88e9985286162ccb.yaml
**********
---
features:
  - |
    An experimental provider of an openstack static inventory and SSH config.
    Is a feature for advanced dev/QE setups, like pre-provisioned VMs on
    OpenStack clouds (deployed-servers) or a split-stack. It has yet been
    tested by TripleO CI jobs. Eventually, we'll add a CI job and switch some
    of the OVB jobs in order to start testing this mode as well.

    In order to enable the feature for the 'tripleo-inventory' role, define
    `inventory: openstack`.

**********
DECISION===>: PASS
**********
=========================:::1053:::END!!!=========================
=========================:::1054:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/tripleo-quickstart/releasenotes/notes/Add-supplemental-node-role-0b6ad8afe82e327d.yaml
**********
---
features:
  - |
    Add ability to deploy supplmental node alongside the undercloud.
    Add ability to deploy FreeIPA on supplemental node and enable TLS
    Everywhere.

**********
DECISION===>: PASS
**********
=========================:::1054:::END!!!=========================
=========================:::1055:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/windmill/tests/playbooks/run.yaml
**********
- hosts: all
  tasks:
    - name: Bootstrap bastion node using ansible
      args:
        chdir: "{{ windmill_src_dir }}"
      shell: tox -evenv -- ansible-playbook -i inventory/testing/hosts playbooks/bastion.yaml

    - name: Run ansible-playbook for site.yaml
      args:
        chdir: "{{ windmill_src_dir }}"
      shell: "tox -evenv -- ansible-playbook -i inventory/testing/hosts playbooks/site.yaml -e @{{ windmill_extra_vars_file }}"

    - name: Run ansible-playbook for prove.yaml
      args:
        chdir: "{{ windmill_src_dir }}"
      shell: tox -evenv -- ansible-playbook -i inventory/testing/hosts playbooks/prove.yaml

**********
DECISION===>: PASS
**********
=========================:::1055:::END!!!=========================
=========================:::1056:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/windmill/tests/playbooks/post.yaml
**********
- hosts: all
  tasks:
    - name: Collect tox logs
      synchronize:
        dest: "{{ zuul.executor.log_root }}/tox"
        mode: pull
        src: "{{ windmill_src_dir }}/.tox/venv/log/"
        verify_host: true

    - name: Collect logs from hosts
      block:
        - name: Run ansible-playbook for collect-logs.yaml
          args:
            chdir: "{{ windmill_src_dir }}"
          shell: "tox -evenv -- ansible-playbook -i inventory/testing/hosts -ezuul_output_dir={{ zuul_output_dir }} tests/collect-logs.yaml"

      always:
        - name: Ensure ara-report directory exists
          file:
            path: "{{ zuul_output_dir }}/logs/logs/ara-report"
            state: directory

        - name: Copy ARA database to ara-report directory
          shell: "cp ~/.ara/ansible.sqlite {{ zuul_output_dir }}/logs/logs/ara-report"

        # TODO: Migrate to fetch-zuul-logs when
        # https://review.openstack.org/#/c/583346/ is merged.
        - name: Collect log output
          synchronize:
            dest: "{{ zuul.executor.log_root }}/"
            mode: pull
            src: "{{ zuul_output_dir }}/logs/"
            verify_host: true

**********
DECISION===>: PASS
**********
=========================:::1056:::END!!!=========================
=========================:::1057:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/windmill/tests/playbooks/pre.yaml
**********
- hosts: all
  tasks:
    # TODO(pabelanger): Remove once this lands in our base job in
    # project-config.
    - name: Execute ensure-output-dirs role
      include_role:
        name: ensure-output-dirs

    - name: Disable extra wheels mirror
      become: yes
      lineinfile:
        dest: /etc/pip.conf
        regexp: ^extra-index-url
        state: absent

    - name: Bootstrap bindep environment
      args:
        chdir: "{{ windmill_src_dir }}"
      command: tox -ebindep

    - name: Bootstrap tox environment
      args:
        chdir: "{{ windmill_src_dir }}"
      command: tox -evenv --notest

    - name: Install ansible roles via galaxy
      args:
        chdir: "{{ windmill_src_dir }}"
        executable: /bin/bash
      shell: source .tox/venv/bin/activate; ./tools/install_roles.sh

**********
DECISION===>: PASS
**********
=========================:::1057:::END!!!=========================
=========================:::1058:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/windmill/tests/playbooks/group_vars/all.yaml
**********
---
windmill_src_dir: "{{ zuul.projects['git.openstack.org/openstack/windmill'].src_dir }}"

**********
DECISION===>: PASS
**********
=========================:::1058:::END!!!=========================
=========================:::1059:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/windmill/tests/playbooks/windmill-tox-with-sudo/run.yaml
**********
- hosts: all
  roles:
    - tox

**********
DECISION===>: PASS
**********
=========================:::1059:::END!!!=========================
=========================:::1060:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/windmill/tests/playbooks/molecule/post.yaml
**********
- hosts: all
  tasks:
    - name: Ensure ara-report directory exists
      file:
        path: "{{ zuul_output_dir }}/logs/logs/ara-report"
        state: directory

    - name: Copy ARA database to ara-report directory
      shell: "cp ~/.ara/ansible.sqlite {{ zuul_output_dir }}/logs/logs/ara-report"

    # TODO: Migrate to fetch-zuul-logs when
    # https://review.openstack.org/#/c/583346/ is merged.
    - name: Collect log output
      synchronize:
        dest: "{{ zuul.executor.log_root }}/"
        mode: pull
        src: "{{ zuul_output_dir }}/logs/"
        verify_host: true

**********
DECISION===>: PASS
**********
=========================:::1060:::END!!!=========================
=========================:::1061:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/windmill/tests/playbooks/molecule/pre.yaml
**********
- hosts: all
  tasks:
    # TODO(pabelanger): Remove once this lands in our base job in
    # project-config.
    - name: Execute ensure-output-dirs role
      include_role:
        name: ensure-output-dirs

    - name: Reset SSH connection for new group
      meta: reset_connection

**********
DECISION===>: PASS
**********
=========================:::1061:::END!!!=========================
=========================:::1062:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/windmill/playbooks/zuul-executor.yaml
**********
# Copyright 2016 Red Hat, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
---
- name: Install zuul-executor
  hosts: zuul-executor

  tasks:
    - name: Setup openstack.zuul role
      include_role:
        name: openstack.zuul

    # TODO(pabelanger): If we want to support xenial, we'll need to use this ppa
    # since bubblewrap doesn't exist.
    - name: Add openstack-infra PPA for bubblewrap
      become: yes
      apt_repository:
        repo: ppa:openstack-ci-core/bubblewrap
      when:
        - ansible_distribution_release | lower == "xenial"

    # TODO(pabelanger): I'm thinking we should likely create
    # ansible-role-bubblewrap to allow user to better manage this dependency.
    - name: Ensure bubblewrap is installed
      become: yes
      package:
        name: bubblewrap
        state: installed

    - name: Setup openstack.ssh role
      include_role:
        name: openstack.ssh

    - name: Setup openstack.logrotate role
      include_role:
        name: openstack.logrotate

  post_tasks:
    - name: Run zuul-executor validation
      include_role:
        name: test.zuul-executor

**********
DECISION===>: PASS
**********
=========================:::1062:::END!!!=========================
=========================:::1063:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/windmill/playbooks/zuul-fingergw.yaml
**********
# Copyright 2016 Red Hat, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
---
- name: Install zuul-fingergw.
  hosts: zuul-fingergw

  tasks:
    - name: Setup openstack.zuul role.
      include_role:
        name: openstack.zuul

    - name: Setup openstack.logrotate role.
      include_role:
        name: openstack.logrotate

  post_tasks:
    - name: Run zuul-fingergw validation.
      include_role:
        name: test.zuul-fingergw

**********
DECISION===>: PASS
**********
=========================:::1063:::END!!!=========================
=========================:::1064:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/windmill/playbooks/gear.yaml
**********
# Copyright 2017 Red Hat, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
---
- name: Install gear.
  hosts: gear

  tasks:
    - name: Setup openstack.gearman role
      include_role:
        name: openstack.gearman

    - name: Setup openstack.logrotate role.
      include_role:
        name: openstack.logrotate

  post_tasks:
    - name: Run gear validation.
      include_role:
        name: test.gear

**********
DECISION===>: PASS
**********
=========================:::1064:::END!!!=========================
=========================:::1065:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/windmill/playbooks/zookeeper.yaml
**********
# Copyright 2016 Red Hat, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
---
- name: Install zookeeper
  hosts: zookeeper

  tasks:
    - name: Setup openstack.zookeeper role
      include_role:
        name: openstack.zookeeper

  post_tasks:
    - name: Run zookeeper validation
      include_role:
        name: test.zookeeper

**********
DECISION===>: PASS
**********
=========================:::1065:::END!!!=========================
=========================:::1066:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/windmill/playbooks/statsd.yaml
**********
# Copyright 2017 Red Hat, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
---
- name: Install statsd.
  hosts: statsd

  tasks:
    - name: Setup openstack.statsd role.
      include_role:
        name: openstack.statsd

    - name: Setup openstack.logrotate role.
      include_role:
        name: openstack.logrotate

  post_tasks:
    - name: Run statsd validation.
      include_role:
        name: test.statsd

**********
DECISION===>: PASS
**********
=========================:::1066:::END!!!=========================
=========================:::1067:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/windmill/playbooks/site.yaml
**********
# Copyright 2016 Red Hat, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
---
- import_playbook: bootstrap.yaml
- import_playbook: statsd.yaml
- import_playbook: gear.yaml
- import_playbook: zookeeper.yaml
- import_playbook: nodepool.yaml
- import_playbook: zuul.yaml

**********
DECISION===>: PASS
**********
=========================:::1067:::END!!!=========================
=========================:::1068:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/windmill/playbooks/prove.yaml
**********
# Copyright 2016 Red Hat, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
---
- name: Prove our CI tools are working
  hosts: bastion

  tasks:
    - name: Setup test.prove role
      include_role:
        name: test.prove

**********
DECISION===>: PASS
**********
=========================:::1068:::END!!!=========================
=========================:::1069:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/windmill/playbooks/zuul-scheduler.yaml
**********
# Copyright 2016 Red Hat, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
---
- name: Install zuul-scheduler.
  hosts: zuul-scheduler

  tasks:
    - name: Setup openstack.ssh role.
      include_role:
        name: openstack.ssh

    - name: Setup openstack.zuul role.
      include_role:
        name: openstack.zuul

    - name: Setup openstack.logrotate role.
      include_role:
        name: openstack.logrotate

  post_tasks:
    - name: Run zuul-scheduler validation.
      include_role:
        name: test.zuul-scheduler

**********
DECISION===>: PASS
**********
=========================:::1069:::END!!!=========================
=========================:::1070:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/windmill/playbooks/nodepool.yaml
**********
# Copyright 2018 Red Hat, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
---
- name: Install nodepool
  hosts: nodepool
  # TODO(pabelanger): We really don't want to use serial here, but this allows
  # us to still support a single node install.  What we should do here is expose
  # some sort of variable to only toggle this when we are doing a single node
  # install. Otherwise, we just slow down multinode deployments.
  serial: 1

  tasks:
    # NOTE(pabelanger): Because of ordering issues create the required home
    # directory first.
    - name: Create nodepool user directories.
      include_role:
        name: openstack.nodepool
      vars:
        nodepool_task_manager:
          - pre

    # TODO(pabelanger): This should be moved into ansible-role-os-client-config.
    - name: Create os-client-config directories.
      become: yes
      file:
        group: nodepool
        owner: nodepool
        path: /var/lib/nodepool/.config/openstack
        state: directory

    - name: Copy clouds.yaml into place.
      become: yes
      copy:
        dest: /var/lib/nodepool/.config/openstack/clouds.yaml
        group: nodepool
        mode: 0400
        owner: nodepool
        src: "{{ windmill_config_git_dest }}/nodepool/clouds.yaml"

- import_playbook: nodepool-builder.yaml
- import_playbook: nodepool-launcher.yaml

**********
DECISION===>: PASS
**********
=========================:::1070:::END!!!=========================
=========================:::1071:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/windmill/playbooks/bastion.yaml
**********
# Copyright 2016 Red Hat, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
---
- name: Bootstrap bastion node.
  hosts: bastion

  pre_tasks:
    - name: Create SSH keys (if missing).
      command: ssh-keygen -t rsa -f ~/.ssh/id_rsa -N ""
      args:
        creates: ~/.ssh/id_rsa

    - name: Ensure SSH public key is authorized.
      authorized_key:
        user: "{{ lookup('env', 'USER') }}"
        key: "{{ lookup('file', lookup('env','HOME') + '/.ssh/id_rsa.pub') }}"

    - name: Ensure remote SSH host keys are known.
      known_hosts:
        name: "{{ hostvars[item].ansible_host }}"
        key: "{{ lookup('pipe', 'ssh-keyscan -t rsa {{ hostvars[item].ansible_host }}') }}"
      with_inventory_hostnames: all:!bastion

**********
DECISION===>: PASS
**********
=========================:::1071:::END!!!=========================
=========================:::1072:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/windmill/playbooks/zuul-merger.yaml
**********
# Copyright 2016 Red Hat, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
---
- name: Install zuul-merger.
  hosts: zuul-merger

  tasks:
    - name: Setup openstack.zuul role.
      include_role:
        name: openstack.zuul

    - name: Setup openstack.logrotate role.
      include_role:
        name: openstack.logrotate

  post_tasks:
    - name: Run zuul-merger validation.
      include_role:
        name: test.zuul-merger

**********
DECISION===>: PASS
**********
=========================:::1072:::END!!!=========================
=========================:::1073:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/windmill/playbooks/nodepool-builder.yaml
**********
# Copyright 2016 Red Hat, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
---
- name: Install nodepool-builder
  hosts: nodepool-builder

  tasks:
    - name: Setup openstack.ssh role
      include_role:
        name: openstack.ssh

    - name: Setup openstack.diskimage-builder role
      include_role:
        name: openstack.diskimage-builder

    - name: Setup openstack.openstacksdk role
      include_role:
        name: openstack.openstacksdk

    - name: Setup openstack.nodepool role
      include_role:
        name: openstack.nodepool

    - name: Install nodepool elements directory
      become: yes
      synchronize:
        delete: yes
        dest: /etc/nodepool/
        perms: yes
        rsync_opts:
          - '--chown=nodepool:nodepool'
        src: "{{ windmill_config_git_dest }}/nodepool/elements"

    - name: Setup openstack.logrotate role
      include_role:
        name: openstack.logrotate

  post_tasks:
    - name: Run nodepool-server validation
      include_role:
        name: test.nodepool-builder

**********
DECISION===>: PASS
**********
=========================:::1073:::END!!!=========================
=========================:::1074:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/windmill/playbooks/zuul.yaml
**********
# Copyright 2018 Red Hat, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
---
- name: Install zuul
  hosts: zuul
  # TODO(pabelanger): We really don't want to use serial here, but this allows
  # us to still support a single node install.  What we should do here is expose
  # some sort of variable to only toggle this when we are doing a single node
  # install. Otherwise, we just slow down multinode deployments.
  serial: 1

  tasks:
    # NOTE(pabelanger): Because of ordering issues create the required home
    # directory first.
    - name: Create zuul user directories.
      include_role:
        name: openstack.zuul
      vars:
        zuul_task_manager:
          - pre

- import_playbook: zuul-scheduler.yaml
- import_playbook: zuul-executor.yaml
- import_playbook: zuul-fingergw.yaml
- import_playbook: zuul-merger.yaml
- import_playbook: zuul-web.yaml

**********
DECISION===>: PASS
**********
=========================:::1074:::END!!!=========================
=========================:::1075:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/windmill/playbooks/bootstrap.yaml
**********
# Copyright 2016 Red Hat, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
---
- name: Bootstrap nodes
  hosts: all,!bastion
  # NOTE(pabelanger): Because we are currently using a single host, we need this
  # operation to be serial. When we switch to multi-host, this can be removed.
  serial: 1

  pre_tasks:
    - name: Update apt cache
      become: yes
      apt:
        update_cache: yes
        upgrade: dist
      when: ansible_os_family == 'Debian'

  tasks:
    - name: Setup openstack.sudoers role
      include_role:
        name: openstack.sudoers

    - name: Setup openstack.virtualenv role
      include_role:
        name: openstack.virtualenv

**********
DECISION===>: PASS
**********
=========================:::1075:::END!!!=========================
=========================:::1076:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/windmill/playbooks/nodepool-launcher.yaml
**********
# Copyright 2016 Red Hat, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
---
- name: Install nodepool-launcher.
  hosts: nodepool-launcher

  tasks:
    - name: Setup openstack.openstacksdk role
      include_role:
        name: openstack.openstacksdk

    - name: Setup openstack.nodepool role
      include_role:
        name: openstack.nodepool

    - name: Setup openstack.logrotate role
      include_role:
        name: openstack.logrotate

  post_tasks:
    - name: Run nodepool-launcher validation.
      include_role:
        name: test.nodepool-launcher

**********
DECISION===>: PASS
**********
=========================:::1076:::END!!!=========================
=========================:::1077:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/windmill/playbooks/zuul-web.yaml
**********
# Copyright 2016 Red Hat, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
---
- name: Install zuul-web.
  hosts: zuul-web

  tasks:
    - name: Setup openstack.zuul role.
      include_role:
        name: openstack.zuul

    - name: Setup openstack.logrotate role.
      include_role:
        name: openstack.logrotate

  post_tasks:
    - name: Run zuul-web validation.
      include_role:
        name: test.zuul-web

**********
DECISION===>: PASS
**********
=========================:::1077:::END!!!=========================
=========================:::1078:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/windmill/playbooks/roles/test.zuul-scheduler/tasks/main.yaml
**********
# Copyright 2016 Red Hat, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
---
- name: Register /opt/venv/zuul
  stat:
    path: /opt/venv/zuul
  register: test_zuul_pip_virtualenv_stat

- name: Assert /opt/venv/zuul tests
  assert:
    that:
      - test_zuul_pip_virtualenv_stat.stat.exists
      - test_zuul_pip_virtualenv_stat.stat.isdir

- name: Ensure zuul-scheduler is running
  become: yes
  shell: /usr/sbin/service zuul-scheduler status
  changed_when: false
  tags:
    - skip_ansible_lint

**********
DECISION===>: PASS
**********
=========================:::1078:::END!!!=========================
=========================:::1079:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/windmill/playbooks/roles/test.zuul-web/tasks/main.yaml
**********
# Copyright 2016 Red Hat, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
---
- name: Register /opt/venv/zuul
  stat:
    path: /opt/venv/zuul
  register: test_zuul_pip_virtualenv_stat

- name: Assert /opt/venv/zuul tests
  assert:
    that:
      - test_zuul_pip_virtualenv_stat.stat.exists
      - test_zuul_pip_virtualenv_stat.stat.isdir

- name: Ensure zuul-web is running
  become: yes
  shell: /usr/sbin/service zuul-web status
  changed_when: false
  tags:
    - skip_ansible_lint

**********
DECISION===>: PASS
**********
=========================:::1079:::END!!!=========================
=========================:::1080:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/windmill/playbooks/roles/test.nodepool-launcher/tasks/main.yaml
**********
# Copyright 2016 Red Hat, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
---
- name: Register /opt/venv/nodepool
  stat:
    path: /opt/venv/nodepool
  register: test_nodepool_pip_virtualenv_stat

- name: Assert /opt/venv/nodepool tests
  assert:
    that:
      - test_nodepool_pip_virtualenv_stat.stat.exists
      - test_nodepool_pip_virtualenv_stat.stat.isdir

- name: Validate /etc/nodepool/nodepool.yaml
  become: yes
  become_user: nodepool
  command: /opt/venv/nodepool/bin/nodepool -c /etc/nodepool/nodepool.yaml config-validate
  changed_when: false

- name: Ensure nodepool-launcher is running
  become: yes
  shell: /usr/sbin/service nodepool-launcher status
  changed_when: false
  tags:
    - skip_ansible_lint

**********
DECISION===>: PASS
**********
=========================:::1080:::END!!!=========================
=========================:::1081:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/windmill/playbooks/roles/test.zuul-merger/tasks/main.yaml
**********
# Copyright 2016 Red Hat, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
---
- name: Register /opt/venv/zuul
  stat:
    path: /opt/venv/zuul
  register: test_zuul_pip_virtualenv_stat

- name: Assert /opt/venv/zuul tests
  assert:
    that:
      - test_zuul_pip_virtualenv_stat.stat.exists
      - test_zuul_pip_virtualenv_stat.stat.isdir

- name: Ensure zuul-merger is running
  become: yes
  shell: /usr/sbin/service zuul-merger status
  changed_when: false
  tags:
    - skip_ansible_lint

**********
DECISION===>: PASS
**********
=========================:::1081:::END!!!=========================
=========================:::1082:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/windmill/playbooks/roles/test.nodepool-builder/tasks/main.yaml
**********
# Copyright 2016 Red Hat, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
---
- name: Register /opt/venv/nodepool
  stat:
    path: /opt/venv/nodepool
  register: test_nodepool_pip_virtualenv_stat

- name: Assert /opt/venv/nodepool tests
  assert:
    that:
      - test_nodepool_pip_virtualenv_stat.stat.exists
      - test_nodepool_pip_virtualenv_stat.stat.isdir

- name: Validate /etc/nodepool/nodepool.yaml
  become: yes
  become_user: nodepool
  command: /opt/venv/nodepool/bin/nodepool -c /etc/nodepool/nodepool.yaml config-validate
  changed_when: false

- name: Ensure nodepool-builder is running
  become: yes
  shell: /usr/sbin/service nodepool-builder status
  changed_when: false
  tags:
    - skip_ansible_lint

**********
DECISION===>: PASS
**********
=========================:::1082:::END!!!=========================
=========================:::1083:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/windmill/playbooks/roles/test.zookeeper/tasks/main.yaml
**********
# Copyright 2016 Red Hat, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
---
- name: Ensure zookeeper is running
  become: yes
  shell: /usr/sbin/service zookeeper status
  changed_when: false
  tags:
    - skip_ansible_lint

**********
DECISION===>: PASS
**********
=========================:::1083:::END!!!=========================
=========================:::1084:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/windmill/playbooks/roles/test.zuul-executor/tasks/main.yaml
**********
# Copyright 2016 Red Hat, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
---
- name: Register /opt/venv/zuul
  stat:
    path: /opt/venv/zuul
  register: test_zuul_pip_virtualenv_stat

- name: Assert /opt/venv/zuul tests
  assert:
    that:
      - test_zuul_pip_virtualenv_stat.stat.exists
      - test_zuul_pip_virtualenv_stat.stat.isdir

- name: Ensure zuul-executor is running
  become: yes
  shell: /usr/sbin/service zuul-executor status
  changed_when: false
  tags:
    - skip_ansible_lint

**********
DECISION===>: PASS
**********
=========================:::1084:::END!!!=========================
=========================:::1085:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/windmill/playbooks/roles/test.gear/tasks/main.yaml
**********
# Copyright 2017 Red Hat, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
---
- name: Register /opt/venv/gear
  stat:
    path: /opt/venv/gear
  register: test_nodepool_pip_virtualenv_stat

- name: Assert /opt/venv/gear tests
  assert:
    that:
      - test_nodepool_pip_virtualenv_stat.stat.exists
      - test_nodepool_pip_virtualenv_stat.stat.isdir

- name: Ensure gear is running
  become: yes
  shell: /usr/sbin/service gear status
  changed_when: false
  tags:
    - skip_ansible_lint

**********
DECISION===>: PASS
**********
=========================:::1085:::END!!!=========================
=========================:::1086:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/windmill/playbooks/roles/test.statsd/tasks/main.yaml
**********
# Copyright 2017 Red Hat, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
---
- name: Ensure statsd is running
  become: yes
  shell: /usr/sbin/service statsd status
  changed_when: false
  tags:
    - skip_ansible_lint

**********
DECISION===>: PASS
**********
=========================:::1086:::END!!!=========================
=========================:::1087:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/windmill/playbooks/roles/test.zuul-fingergw/tasks/main.yaml
**********
# Copyright 2016 Red Hat, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
---
- name: Register /opt/venv/zuul
  stat:
    path: /opt/venv/zuul
  register: test_zuul_pip_virtualenv_stat

- name: Assert /opt/venv/zuul tests
  assert:
    that:
      - test_zuul_pip_virtualenv_stat.stat.exists
      - test_zuul_pip_virtualenv_stat.stat.isdir

- name: Ensure zuul-fingergw is running
  become: yes
  shell: /usr/sbin/service zuul-fingergw status
  changed_when: false
  tags:
    - skip_ansible_lint

**********
DECISION===>: PASS
**********
=========================:::1087:::END!!!=========================
=========================:::1088:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/windmill/playbooks/roles/test.prove/tasks/main.yaml
**********
# Copyright 2016 Red Hat, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
---
- name: Create required directories.
  become: yes
  file:
    group: root
    owner: root
    path: /opt/windmill/test.prove
    state: directory

- name: Install dib-image-list.sh wrapper.
  become: yes
  copy:
    dest: /opt/windmill/test.prove
    group: root
    mode: 0755
    owner: root
    src: test_dib_image_list.sh

- name: Ensure ubuntu-bionic DIB image is built.
  become: yes
  become_user: nodepool
  delay: 10
  register: task_result
  retries: 360
  shell: /opt/windmill/test.prove/test_dib_image_list.sh ubuntu-bionic ready
  tags: skip_ansible_lint
  until: task_result.rc == 0
  delegate_to: "{{ item }}"
  with_items: "{{ groups['nodepool-builder'] }}"

**********
DECISION===>: PASS
**********
=========================:::1088:::END!!!=========================
=========================:::1089:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/windmill/inventory/testing/group_vars/zuul-executor.yaml
**********
# Copyright 2016 Red Hat, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
---
# windmill.zuul
zuul_file_zuul_executor_service_config_src: zuul/etc/systemd/system/zuul-executor.service.d/override.conf.j2

zuul_file_zuul_fingergw_service_config_manage: false
zuul_file_zuul_fingergw_service_manage: false

zuul_file_zuul_merger_service_config_manage: false
zuul_file_zuul_merger_service_manage: false

zuul_file_zuul_scheduler_service_config_manage: false
zuul_file_zuul_scheduler_service_manage: false

zuul_file_zuul_web_service_config_manage: false
zuul_file_zuul_web_service_manage: false

zuul_service_zuul_fingergw_enabled: no
zuul_service_zuul_fingergw_manage: false
zuul_service_zuul_fingergw_state: stopped

zuul_service_zuul_merger_enabled: no
zuul_service_zuul_merger_manage: false
zuul_service_zuul_merger_state: stopped

zuul_service_zuul_scheduler_enabled: no
zuul_service_zuul_scheduler_manage: false
zuul_service_zuul_scheduler_state: stopped

zuul_service_zuul_web_enabled: no
zuul_service_zuul_web_manage: false
zuul_service_zuul_web_state: stopped

# openstack.logrotate
logrotate_configs:
  - name: zuul-executor
    log: /var/log/zuul/executor-debug.log /var/log/zuul/executor.log
    options:
      - compress
      - missingok
      - rotate 7
      - daily
      - notifempty

# windmill.ssh
ssh_user_name: "{{ zuul_user_name|default('zuul') }}"
ssh_user_home: "{{ zuul_user_home|default('/var/lib/zuul') }}"

ssh_key_private_content: |
  -----BEGIN RSA PRIVATE KEY-----
  MIIJKgIBAAKCAgEAzxWLE0tmkxaYCRwAhGY7ZK+JLe63/Xx42r5eToQqu68AM34k
  H6tuWEmgmUUT8sI1IOrLZuSZgQi70AGtS7oabK1ExOtU7xgSMXkcBOgdDnnD1vEq
  FzW4YL33a4FW+DiLx+dbZ3T5l2DzKVTdN4lsqEnzefGBO+2dFYqQ7hvvnQI0iYPm
  5gZZplRNy9eNfRNiZuejp0QwA1hA5b2HIhCF2hVjfaSGF0y/kNUHWCpFhj37rzLu
  pOcUoELTXlzuCFi0isqpKo/z0UHmO11QTbLUYRs8vtdH1dCeC62HEwLP/NKyNqoL
  60aIg7l7oTzF8sg9DsaFa5SDuP3+wQ9sZNZW6uia1ELYbDXi5/TuSlV/R+84ZxTN
  RFEkWc/pJ2rA0X7/I6364VLTNUKRf9yyEyn7a426/cIaTq8RkikkUbZ2JUuTq2Na
  PaqhH2D23pUHZ8+KGvmk5dEewKS30aYOuLWxdbjclV8Cb5uxGGNibtbdHWOr8RVp
  QvJS7oxOGav1Vmo3+RYc7CIekg9DVXc/FCtVv7GWCnM3o6NFB4ELo37iXid8EVgA
  f4ncz9gevf7hSZ+4Ketffet+497/95d/MUT4v5G4fMytC48L0fDyjpU8fKTCczRW
  i80ajk1Sc4ZeGJpWF7YjacX/+/3T0VLvJCZW/sr1T6PNdb+d+xJ5rbF4p/cCAwEA
  AQKCAgBLeAJzSatcN4O47ieSGN/UVdSclL8g9lflADPGUYxxUdm06men0wYnzs1k
  jjQy6GwMTwVJvk3jJJetuq65Rl2S9aJ2UX1mlVMsDIMVlrHgMKgakVFRnBZRy2l8
  GGrlk1X9yGcbURoU/RQhH/hu4Ppkam79JfJ/MJ1q2FDxNeUhR0h2RUfE1NOfNmIT
  w76gsovODOUrdEI7NdKQ5310AKmHTPwxMeBcZW/7DGfczasAvV4X/2vRVRXDQhdd
  8GgfSpShcDIufL/Spz2MrPkzF9UmfpKoyjQ3zAuNHfR4DTJXZUHlghtN5yqhNtvD
  ay6IyEjYNakyB7HpnUdWfJR4O1T5J23Kqjea9Bg+mKw5YWOVqWUDcoEFZwyfJttM
  jpKkUm9Lb211J9wTZhhryZxMbK0j2ciMdVu4ppv8tbktWj5tcY7F+rcmhNudHfeb
  q3oe4raCc9PvQRjubMRMSWZLQY30WF4eJTuAMReMX6QtGkSH6QywOUIBEs4MsgVl
  /b5SgAq2+B64BlMNCHnAWkPiDCK80Qv6G/NcoGw/F7+rYqTEyYuYfh+frmCNBECW
  yR9vZY6IzQZg9+vYf7sxTfoy0aeIqutAb5MIQBNGKY1eVH5Ytlygd4mNyZvCFlyU
  pKk4xrMHOrpgQ4Op/3ysF/59TRg0O/HKdrfSsunLJplBktH6YQKCAQEA6VApZ7eY
  nu0OkPEMAy1jw2FxI9I7YliHIN2HFjXnn2QWqU/opbSCz7PKtv2F3DNxzMYrYOJY
  RNZIfWqt22sKMnmhUbFBy7V5NWknHvkq321EJwbGe+eq1O3fLkNadmaJ5s+/UQfW
  RIEEzXE2eilfJUhf1KQSmSTE33bpqqH1aUvvJLg3Tq003MHjSRjjh9Uv4MmSoKVn
  DwWv6KZMkrdJVcFdh6LeQckYgAIn5F/H2MrhcVx/AWRonymY1fnh+90GKdLhlMAo
  TaRoFsUWURJOUkLwVhVCh/Jgqt2LwbmLPxIvsf7ROZU/Cy3aRL2DzXCMy3jVuDy3
  cMN4ydKNSyealQKCAQEA4zh3aD6necWWU3Pafm1BSGhsPE4VJq6aLnu0df4roWZW
  u23/m5JACbLFSfnFgEUTcl09EosH1vPz8pNSGfEVsjO5ywjhKQbPWuDq1XlE0Vts
  K5koqxbvVel9tEMFq+EWinebqtY6Bot3ymn86adqPJ/rkUN4aSOJEZ1Zuw1SA+kB
  YXKYj5VXlfxxPKNV5Vkbiz+t4yXNaM6L0NTHLzitrshxbT10iuo4g711oTEc4lhx
  TBpBQjNYAvWzKX7IyrDbjM/rRs7rthGkR8+puQggS37Lfqre0sC6ERXoT+uJMtZX
  xQPv0cmlCIc6nhgESm9/t07KLLWOj1+cN+KBSzmhWwKCAQEApUNo8NS1wO0+AiEc
  VyvRnNXq5GrIMbNvlDIWu/7W4Kpu+uNlcerZNfKuxsvyA7ZVB63fkDMEP05h7qSg
  HepGQNazFECw0HDtOI4RbfklCzpEqjg8ZAwHj+gmzIhdDb04NUw2wlkAx2l0U2m8
  IvAnOyt25hKKMfw/j+KVRY6PXVSyQppSYuKBrVWRf3enw9GYpmth93Tx+UwX/H2/
  g7VctufPLoKJWKPvPM1KIJRP5RpgcoIIXJ4ZFZTLc9Ya4uL+uKVtsIYkhkrMiER2
  uFp1LAPKZc+NXuqq2p0vn7ukDLr/Gd/bqCQ1kd+a2lI7iEwPDxm6mVQ4xCFR7/O6
  rd+RuQKCAQEAqZvExjO+n8813yVju2uih4IrCPjgIPfEb1433rvTpa7WnyIE4wPQ
  eWzQh9/B5XWqhnvC0sylFXcUacY+Ss8C+vpRfZUrPYyvy46IvMDA9eXgYMr66Hs+
  PEsGYkCFQz/Jq6KMuIEg3zHMQXPMLj2ht49IMC7E+vZjoppqGI5g4jpTpYH9D3DS
  6Ep/3FuwCnrxbIgkLKJTKiDDjSbHaCBOxWEqCfkNvYQIm44Y+DHI9cw/Biey/s+E
  qvDsw9S33VUXDY1GepyKpmWU02XXsx61vKTxEaRKn9btDUPlHYMb7q7A5XeC1H5I
  io0m3EvhKA8CrrpJgAYmXC9qVOzmxlhGcQKCAQEA5aq8q7pJNO45l9lyZbdShDvo
  HT5RqmSajpCVed4RKR0eE/lCOiwExN9wJLJBls89TWcuVojHxOMq+Fx9KG1sYJSV
  b980ejbSX0G4FeTmYacgn8DW+MwEVtA3tMEsFnTXirWrAV25dZ/nrKMDsT7VuoKP
  hIZhDP6ArEjB4OFwKPNeoKA81R82Ubg58jFP7QRFUZHmfP7UGkaztRd7cLLcAah7
  xD/bPqLKBBxJiFV7AjLXVkyNhFvtjB1fdqfAmlyBGFwrOGufKuBjS710ocS6bi9m
  kqNxJjwpr7RIhj0f/zerJ4VS3ZeT2XeXBOTJ8jx4IkKWywgVa4nPVrSS8A706g==
  -----END RSA PRIVATE KEY-----

ssh_key_private_dest: "{{ ssh_user_home }}/.ssh/nodepool_id_rsa"

**********
DECISION===>: hardcoded secret
**********
=========================:::1089:::END!!!=========================
=========================:::1090:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/windmill/inventory/testing/group_vars/zuul-fingergw.yaml
**********
# Copyright 2016 Red Hat, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
---
# windmill.zuul
zuul_file_zuul_executor_service_config_manage: false
zuul_file_zuul_executor_service_manage: false

zuul_file_zuul_merger_service_config_manage: false
zuul_file_zuul_merger_service_manage: false

zuul_file_zuul_scheduler_service_config_manage: false
zuul_file_zuul_scheduler_service_manage: false

zuul_file_zuul_web_service_config_manage: false
zuul_file_zuul_web_service_manage: false

zuul_service_zuul_executor_enabled: no
zuul_service_zuul_executor_manage: false
zuul_service_zuul_executor_state: stopped

zuul_service_zuul_merger_enabled: no
zuul_service_zuul_merger_manage: false
zuul_service_zuul_merger_state: stopped

zuul_service_zuul_scheduler_enabled: no
zuul_service_zuul_scheduler_manage: false
zuul_service_zuul_scheduler_state: stopped

zuul_service_zuul_web_enabled: no
zuul_service_zuul_web_manage: false
zuul_service_zuul_web_state: stopped

# openstack.logrotate
logrotate_configs:
  - name: zuul-fingergw
    log: /var/log/zuul/fingergw-debug.log /var/log/zuul/fingergw.log
    options:
      - compress
      - missingok
      - rotate 7
      - daily
      - notifempty

**********
DECISION===>: PASS
**********
=========================:::1090:::END!!!=========================
=========================:::1091:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/windmill/inventory/testing/group_vars/gear.yaml
**********
# Copyright 2016 Red Hat, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
---
# openstack.gearman
gear_file_gear_service_config_src: gear/etc/systemd/system/gear.service.d/override.conf.j2

# TODO(pabelanger): Remove once https://review.openstack.org/558938 is merged
gear_pip_extra_args: statsd
gear_pip_virtualenv_python: python3
gear_pip_virtualenv: /opt/venv/gear

gear_file_ssl_ca_content: |
  -----BEGIN CERTIFICATE-----
  MIIDmjCCAoKgAwIBAgIJAN8sAUG3GR9wMA0GCSqGSIb3DQEBCwUAMGIxCzAJBgNV
  BAYTAlVTMQ4wDAYDVQQIDAVUZXhhczEPMA0GA1UEBwwGQXVzdGluMR0wGwYDVQQK
  DBRPcGVuU3RhY2sgRm91bmRhdGlvbjETMBEGA1UEAwwKZ2Vhcm1hbi1jYTAeFw0x
  ODAzMjgwMjMzMTZaFw0yODAzMjUwMjMzMTZaMGIxCzAJBgNVBAYTAlVTMQ4wDAYD
  VQQIDAVUZXhhczEPMA0GA1UEBwwGQXVzdGluMR0wGwYDVQQKDBRPcGVuU3RhY2sg
  Rm91bmRhdGlvbjETMBEGA1UEAwwKZ2Vhcm1hbi1jYTCCASIwDQYJKoZIhvcNAQEB
  BQADggEPADCCAQoCggEBAMLqIrwY9mDh9kKc/mXDvEUifXgdHtz4GwP3hoYz6N82
  8Zl7NzUqvYFSj9tlpdJxFHWFBjB9TiGv+2UPjDfGLk7xTKPkErnEcmH6zf4F+0YH
  hEI00c7DN5sSPq0qcMk1pVCzZ96Fhdi+fIQkVq3Ovx0GGmknHy0K2If2vX9FgZNZ
  323BZw7vZUSYRIvN8ClAXg+ONvHvodVGBWts2SO5CYvnsA+kQRa6RJswoe9CkTxb
  qF8yq5CPLEdQeoTiF4RiLIsfB50ZFTcOrARw93blcMkSw4kh3EJhrRMezoJZZKPE
  JfOOaMmHiKbrF5TWjREJODgdHIz87nePDuZAWrvlyDECAwEAAaNTMFEwHQYDVR0O
  BBYEFEqtl/rooCIF+gMIfS2IKzYJC4LRMB8GA1UdIwQYMBaAFEqtl/rooCIF+gMI
  fS2IKzYJC4LRMA8GA1UdEwEB/wQFMAMBAf8wDQYJKoZIhvcNAQELBQADggEBAEck
  6wCHSOwtzWBBwM18uVlHAUywe95SNvgPJ6tt3jaM9Th6aGEaeF7Eh1wPBoQBUBUC
  YsXhXenROoEf6r0CHaJkamaJSZqEIJ5/2sdZ8RgHXG8Savp5y1r9Rw1duNREuqaD
  QsHNZ/hM1VEr9PhyVQ3HWe18EWRY8vMc22MlBAMt9QT+Okj3Ao679uPGnZD3HQ8p
  ZiJRxV6UJoFlWdmEXyljUKUryotX7bN1bfSvBaiV/RncUARMfxulIbDxHgp6/D8G
  dcdLTVD6WkbRS77Nt4rB1Gu+b/qME8zxwhjvM3J7r2p+EjVqwW7dgQQRP1I0jyGU
  9rZdDhon2y067Zr8Kuc=
  -----END CERTIFICATE-----

gear_file_ssl_cert_content: |
  -----BEGIN CERTIFICATE-----
  MIIDQTCCAikCCQDWIKrPJpjpMTANBgkqhkiG9w0BAQsFADBiMQswCQYDVQQGEwJV
  UzEOMAwGA1UECAwFVGV4YXMxDzANBgNVBAcMBkF1c3RpbjEdMBsGA1UECgwUT3Bl
  blN0YWNrIEZvdW5kYXRpb24xEzARBgNVBAMMCmdlYXJtYW4tY2EwHhcNMTgwMzI4
  MDIzMzQ5WhcNMjgwMzI1MDIzMzQ5WjBjMQswCQYDVQQGEwJVUzEOMAwGA1UECAwF
  VGV4YXMxDzANBgNVBAcMBkF1c3RpbjEdMBsGA1UECgwUT3BlblN0YWNrIEZvdW5k
  YXRpb24xFDASBgNVBAMMC2dlYXItc2VydmVyMIIBIjANBgkqhkiG9w0BAQEFAAOC
  AQ8AMIIBCgKCAQEA5CTko8DQeIxRCUizbSY4JgJfYAz7HBkZK6VIPCVmJGmuFyDS
  I3YlzhKIQdLA9SEDNpP9F9T5EJKDGcJEptvtqViQXWFv/gBth4agA89CPZu0kBz7
  X1OVxxr0LQociwbXWHpj4vDZJ0XRM0xgleZMeUFIT2A6wGDlg7eH7v4XASr/wwA0
  4XCx042UDI79SPkxvR9hkexWbKZG3OEcv5jKEbb3mvpGqND8YTHvwOc/VlCO/mOw
  /LEep2xlFO9T5WQZ1/qPLHAizOAYIqBMIUm8TP7beEVaAmZVy3Zm9V5lOw9KFE3R
  c79CMYgTssWI32MzQJ81MRJEofMVAP50bFblhQIDAQABMA0GCSqGSIb3DQEBCwUA
  A4IBAQDBhaVBFtU3ZKrJ7vMObLGcr+lUyYDi05/ccsHe3bXCdnCwdefULSgqJ4AX
  kdJ5KFsUrsA+lxLVDbc1HLrRPy8lCjRiZFZHORTGBgReB2GfeQVLWeT0VyOTl1/t
  7JKPEGhJJhEOhn9EzcMxTUdNMTTg9DrzV8yVooWgKiZCMvDlMBZNnxStEphBP6GH
  hE5mT6CITkCsDzzNDLYLCfEV4hCmzOBIt/KNp/1TQM1H5JK6R+VjGXMkRLtFqx29
  UDBz7a0g9iLvnpFq0jb7TpNgzzl256N3nIOaOPGT5OB7yYeIOEaLdBxTIIrmhuRd
  HIedlOp7IZPO/bMz334m0eL0odIl
  -----END CERTIFICATE-----

gear_file_ssl_key_content: |
  -----BEGIN PRIVATE KEY-----
  MIIEvQIBADANBgkqhkiG9w0BAQEFAASCBKcwggSjAgEAAoIBAQDkJOSjwNB4jFEJ
  SLNtJjgmAl9gDPscGRkrpUg8JWYkaa4XINIjdiXOEohB0sD1IQM2k/0X1PkQkoMZ
  wkSm2+2pWJBdYW/+AG2HhqADz0I9m7SQHPtfU5XHGvQtChyLBtdYemPi8NknRdEz
  TGCV5kx5QUhPYDrAYOWDt4fu/hcBKv/DADThcLHTjZQMjv1I+TG9H2GR7FZspkbc
  4Ry/mMoRtvea+kao0PxhMe/A5z9WUI7+Y7D8sR6nbGUU71PlZBnX+o8scCLM4Bgi
  oEwhSbxM/tt4RVoCZlXLdmb1XmU7D0oUTdFzv0IxiBOyxYjfYzNAnzUxEkSh8xUA
  /nRsVuWFAgMBAAECggEAW8GSy2Fi9vjIJsm8kCuM7YyKu2C9JcHaY7ln4fjQqdhv
  EhI7MdP0xHqjnoWa4XvThQHkCs+3FDk4zQVbAxj07uUVutjTZ/7YDmfQt3eGFq0m
  48ckOmStmpR2nB6y+B9aQNWIkt93Ftp3lwAi4GbtXt8oq/Px7SmLZXxNCYvbyLW2
  DiIkmbSNabTivDQhoC2mkhIO37+j9fNp0Z2sk0YbiesaLiJNRL5DepOS2PnZa9Vn
  e2n+/51pFQp4qcCN8u9meggZ34nCDw08DWqBaN/2HNLrQFMRtKRXsSkrVVV1EE0s
  il+pQzh3Hcia4p4H2tmtOctDEfF06vWLAByvrjtiQQKBgQD37guAytdpF5Y3o/hQ
  Gpdzr+jYQG0GAhKVYZBnvMc6VwSr7YrpbJMDW5yCuu240UDeDdok675eWTfC4jXY
  dz4/ruQ1sZ5mr9/QYDRHYZcpDsEumPhypb9YeDc65K/ZeAh5t3PecgRmK0WtsXxp
  tlKbuByCCDxDwA563WhIKRKcqQKBgQDrkfoiovOUUFSOnHbDXIDfhfieyOCdsTst
  MEM5cLy18AzfaSvjWoykJYIGqyMrIQPtJg7MLAXC527fRIZ5tNdXumsZ3e2r8abW
  bblmK6DKtn13OmtSoPMXxGhUHULtr07fNSoZhIUgiJBc/9vVPYYSmEJlLS6Xf6M8
  5zKkW46PfQKBgCBzden7ospMngrWWXASqvQneDCl7h81Mj1/MamCWglWznO6ec4n
  ue5clVW/JdJlATqPUZg3iwlKYDQP68BTi0BGofQtNXB3YLIjhXQ6X9Ct77crqolH
  DI6F3aTFvgaW4XUc//uDrPO6gjpD2ubzSEi9hm22qjyr7LlENZwMVDVRAoGARDR0
  xtiFS9jiUpQssq2yxoUEkfy5RA8PgirqG9RvXwIMyBasVVxfQht2BTZBrXgWqfAN
  8sGAPYlCibROdyiL/OOFpOyjptgFpSoJtvJE0Mx7kSzB7B+borMEPe5m9Wh/npLH
  CLJc1SmVGsgdvyTcD8Az4RVu2wBio/yQphO4OAUCgYEAv4SPmu6xQAbwHMyUf8lv
  32b23e18jfh906cCcD3EH+lS8Ddbhl3LD2n3qJi55B5ibzTBcrrVpbPhePxtoGZr
  7NSS/HJJGlt/SqWSbASpt9gfw1k6a0wffIq6h0+I6bNeajfwMz8bGAMIdHqGRhze
  TPw69kX4BM39nK3lP2/aiTQ=
  -----END PRIVATE KEY-----

# openstack.logrotate
logrotate_configs:
  - name: gear
    log: /var/log/gear/debug.log /var/log/gear/gear.log
    options:
      - compress
      - missingok
      - rotate 7
      - daily
      - notifempty

**********
DECISION===>: hardcoded secret
**********
=========================:::1091:::END!!!=========================
=========================:::1092:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/windmill/inventory/testing/group_vars/zookeeper.yaml
**********
# Copyright 2016 Red Hat, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
---

**********
DECISION===>: PASS
**********
=========================:::1092:::END!!!=========================
=========================:::1093:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/windmill/inventory/testing/group_vars/statsd.yaml
**********
# Copyright 2016 Red Hat, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
---
# windmill.statsd
statsd_file_config_js_src: statsd/etc/statsd/config.js.j2

# openstack.logrotate
logrotate_configs:
  - name: statsd
    log: /var/log/statsd/statsd.log
    options:
      - compress
      - missingok
      - rotate 7
      - daily
      - notifempty

**********
DECISION===>: PASS
**********
=========================:::1093:::END!!!=========================
=========================:::1094:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/windmill/inventory/testing/group_vars/zuul-scheduler.yaml
**********
# Copyright 2016 Red Hat, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
---
# windmill.zuul
zuul_file_zuul_scheduler_service_config_src: zuul/etc/systemd/system/zuul-scheduler.service.d/override.conf.j2

zuul_file_zuul_executor_service_config_manage: false
zuul_file_zuul_executor_service_manage: false

zuul_file_zuul_fingergw_service_config_manage: false
zuul_file_zuul_fingergw_service_manage: false

zuul_file_zuul_merger_service_config_manage: false
zuul_file_zuul_merger_service_manage: false

zuul_file_zuul_web_service_config_manage: false
zuul_file_zuul_web_service_manage: false

zuul_service_zuul_executor_enabled: no
zuul_service_zuul_executor_manage: false
zuul_service_zuul_executor_state: stopped

zuul_service_zuul_fingergw_enabled: no
zuul_service_zuul_fingergw_manage: false
zuul_service_zuul_fingergw_state: stopped

zuul_service_zuul_merger_enabled: no
zuul_service_zuul_merger_manage: false
zuul_service_zuul_merger_state: stopped

zuul_service_zuul_web_enabled: no
zuul_service_zuul_web_manage: false
zuul_service_zuul_web_state: stopped

# openstack.logrotate
logrotate_configs:
  - name: zuul-scheduler
    log: /var/log/zuul/scheduler-debug.log /var/log/zuul/scheduler.log
    options:
      - compress
      - missingok
      - rotate 7
      - daily
      - notifempty

# windmill.ssh
ssh_user_name: "{{ zuul_user_name|default('zuul') }}"
ssh_user_home: "{{ zuul_user_home|default('/var/lib/zuul') }}"

ssh_key_private_content: |
  -----BEGIN RSA PRIVATE KEY-----
  MIIJKAIBAAKCAgEA4sxcS8zPIPc3Hviv6cGVmUmvsMqMRX8lU3EBM22+yDNKfL/8
  uAj0B8y9QzWKeFPncmwvtxI3Z0igFyD+5C0coQSg7SMgSoWdFPdlkctPQAZ5jafp
  FmhAMp6UpYqSAD9IlaYIzbEaR7yx+WH5vhBLCyKmQSyhC97oewfhZMg1qDoeKQZn
  HcskUsIS4Bq8KMRGsAtEjiNWzR2EPNhJWsx74H+0t+0QDLW/kbi9PhXibETw5a8r
  0G7Jm0ZEXwaSu84lC62Afj4EYmDbYXX8qoR0+CdE7e5jXpn8HoZ+5Y2lqHfz4HHW
  RwBQ8F9a6VRDi7ypH9qFMNg/spZenwM0pMxhr3l0buty0MMhGohTbXgDXEqyJm05
  3ASjCDYHWw8XVANv+NctLDsGgp+0PgVZVJkGu82VU3LSpURtDrSymewIYt89ELvX
  8oH1ZgkVRT5f7+FRGnT0TV4ueSWX3pnI9RyRJ4tJtDPCnudJEKTwg3t2cM889ubY
  cQrbwQMdzGNdRBewdRWGA2Y08h7eBOly2L0Csn5ZvEdJWunaYZWOKrqvX00tjKLX
  iFF/YA9IcyK1+QiDmm53BWBhTUqSMDMGwMtNyHl3K9p0Vv2bKMA7bbOWLTAihx0X
  ILe8eFx2XmCev6RLnEkOx835TuYBhYmlGKbOCvy19A/SGgiBVINgXLaoQY8CAwEA
  AQKCAgAB6emJdjP1OkDL0Rti5JBHl9iUrFDcsUL2Xki9T1rBw7UIMnKGdwTgH/kk
  3QnLFCIq1ADfEZdIFtPK/itIb50DOs/E0HwQROpbZ+8CeO21Q5i4+ka8Oqr4AmCM
  uQucVuxc3ubKHYl0O4Jg8VOzJ94KPQOcHy1ItVvO1fUv7YSOY9cnT3eFR9aJoDua
  in819NoH2EB+1ot/9ZTNEqIj0v/kmA9FUgnFoa75Is7t/C9J7Jb/ySecfaLT3Zbs
  GlkYnpevbopcBlfxIJIZU26LXczC30n0nANYpAH9m/LsKvLP5hs3tJ4zQSxtqtBQ
  kbZ0MmZW73gaPmjjL+Oigdtq3JKibVnoZUSEeNZOYOwPzu+rzjk8TOX7S11+QH+h
  G8ZANnu+lmVjg/VsqUWPk/ERq76I7MUzOfd4LnIC7tUQuA3fzDSduAbX4PLFubSp
  wySzjoonAacmyLEAQSqNBQtxVRFYr/TvKm5a4zvnrCsivssueB0Oa5vSPhyKmPmZ
  ukKKfOSj1/0ohr2nGNh41EHnXrqHdeS+h9iolE9q9Y/uq6kietCmNB3Clrh/o5V+
  P4NkdfPmw9GQf95oUxjFe/Rh/yPHhqUfQC/G5kMlv7lS66dDpKlUiKoKxGLBaF7b
  pGkINC0O6s2xQGh2pSqBSQjNXbVeadPOta1fygeROGeXFnTYOQKCAQEA8k1zk2ln
  3dXFnqIRs0dkQdISJvya66jcqHmxh606QAXQYbycXHX0OESDoeKDRLla1cvWCJmr
  OE3xg084SiyJCZMwLzbI2uUfcB9G3ezpCRkGmFgmCBi3sIZx0/yL2oPyFIWEkdzN
  gJIwVgVs3XKp7WICnRqPom+cF3i9RofDuEDs+CgtJOOFiYljZ3os+LXU3zCN80uz
  9XnY6861FPLRD0AuINExz2J1JTsRd1RoH5LhIG8EiLhilVLVqABJBXdXiSZltb8M
  mlUmPoEUGsvSflu/MmCEsj8b6s4JNDbA4/Mpv7L4XogLsEJnAsY6BbrZ0IwvE2yF
  h9cd777WGAhCiwKCAQEA756I60ngoVioIm3lQm3adLgGUxIc1BldFxkvl3NdeV2g
  Stx3LF1Y2EnWZQQwx3n5IWSSoeo1zf/sMdoZXCUP9eCJrxbKYrYn0qWwsbXTz47b
  AvXCfYiWU9PE6p5oGIljJ1FSpVwuLWg4sZxuJMLYVkUuTy9d95FQMmGb6GYNXYZW
  SkUQKwO6H/ItcApvSw81YfWZdE7uQp0NiHeZBLotDMwHlfKRime+5dMhUb089bwU
  oatFJ8oogdFe1hTXW3eyA+vnVNcLaUUUKFlMpTQ6UuNkY7v3BT9slpGkrFNXiZk2
  4fV6NbVJ3MtozwwNJg74JDDtf9R3nTOWaoSYpv0xjQKCAQAhHZ7HLefJNNdOh/39
  T6uPJ2PdujZ+MNT/nao6zd0hNOo3AW0pYeGf8xU+gdPJB8A3aiV1hXMWPejdNm2O
  DaopCdnTChzHdfsm+s9Xs3JiEO6K0blY7+/jC2zxORnwIopqbZkhyli30sMSbqlj
  VrGMxRFwYVnyLGjb+F9+DT4dp5n7jJom6YWtt35DfTo6P7e5TUyJTPZqfV29VMIA
  +/LAr9feGllBa8Zw8TLA6WNVtWBZa3LmMLUgjXKwBGH2gkoPb5UFEvho+2w/rKqP
  wv2g0W8/NlvMdL2fCMvPPBB+1xQEpDQ3z0Yxr9GeWnNBpzjvvMkOUY2qdCceRinC
  nRZjAoIBAQDiiYg6ogq7n3y9qBYR+peIt55LFRmqMByBRO9oiMn7fteXTt1gVRQ0
  z4Hg2NhhDmDJADNc3ndlvSmJa/+DzQpM0653mN1X+4ykqr7lE9kfJpjKMJxiYCp3
  MAPAKGiToffa6Rhweziw9xJ6YEEFgixTS25fsJFvB7PBHeTvDuRd4i5cYvTJJenm
  X+gzP7o+RS+b4Dzm5+R7l81+kktZW8ZRjecyDTUpm7GvyC58/6LNU7ZRrgFgf9BS
  AyZc0TFVKVFkQbffzrrcGFHZX6uFmF33lUGIxODh1jeMFj+QJ+7fiLmJYLHcavtc
  wfXhoSwhKg/Q72zp6G35chcntxo27bLVAoIBAEZlZfr/ifq9gmgTxjHQ//GJ80SV
  7y0K75e0bt/BkMU8EiqqsX5CywxSTH54tACzDIduMq0EFp+sK3bEzD7vPQ1QqJ3N
  L2XkOO05o506RC4DbuwmQtYOCok+4IPuCF6FduCa0cYo/S8+UBxbjusauZET46J9
  r7KG1PGaIGfwQCcf4mzlAutR977M/FyN967J/gtP5QTBof1HEqPsTvaxe595KeUe
  csgN17HFJXSaBudMf84xmCOc7rULAItXqmLIeNHTztjbjB4IAwpDon0qe+EfVt7z
  eqZTcm7faWJiFVZNdnGD4uc0P+syWLmp1uX2hJfV/0WI+yPeDoRk6q+97W4=
  -----END RSA PRIVATE KEY-----

ssh_key_private_dest: "{{ ssh_user_home }}/.ssh/gerrit_id_rsa"

ssh_key_public_content: |
  ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQDizFxLzM8g9zce+K/pwZWZSa+wyoxFfyVTcQEzbb7IM0p8v/y4CPQHzL1DNYp4U+dybC+3EjdnSKAXIP7kLRyhBKDtIyBKhZ0U92WRy09ABnmNp+kWaEAynpSlipIAP0iVpgjNsRpHvLH5Yfm+EEsLIqZBLKEL3uh7B+FkyDWoOh4pBmcdyyRSwhLgGrwoxEawC0SOI1bNHYQ82ElazHvgf7S37RAMtb+RuL0+FeJsRPDlryvQbsmbRkRfBpK7ziULrYB+PgRiYNthdfyqhHT4J0Tt7mNemfwehn7ljaWod/PgcdZHAFDwX1rpVEOLvKkf2oUw2D+yll6fAzSkzGGveXRu63LQwyEaiFNteANcSrImbTncBKMINgdbDxdUA2/41y0sOwaCn7Q+BVlUmQa7zZVTctKlRG0OtLKZ7Ahi3z0Qu9fygfVmCRVFPl/v4VEadPRNXi55JZfemcj1HJEni0m0M8Ke50kQpPCDe3Zwzzz25thxCtvBAx3MY11EF7B1FYYDZjTyHt4E6XLYvQKyflm8R0la6dphlY4quq9fTS2MoteIUX9gD0hzIrX5CIOabncFYGFNSpIwMwbAy03IeXcr2nRW/ZsowDtts5YtMCKHHRcgt7x4XHZeYJ6/pEucSQ7HzflO5gGFiaUYps4K/LX0D9IaCIFUg2BctqhBjw== gerrit@example.org
ssh_key_public_dest: "{{ ssh_user_home }}/.ssh/gerrit_id_rsa.pub"

**********
DECISION===>: hardcoded secret
**********
=========================:::1094:::END!!!=========================
=========================:::1095:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/windmill/inventory/testing/group_vars/nodepool.yaml
**********
# Copyright 2016 Red Hat, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
---
# windmill.nodepool
nodepool_file_nodepool_yaml_src: "{{ windmill_config_git_dest }}/nodepool/nodepool.yaml.j2"

nodepool_pip_virtualenv_python: python3
nodepool_pip_virtualenv: /opt/venv/nodepool

# windmill.openstacksdk
openstacksdk_pip_virtualenv_python: python3
openstacksdk_pip_virtualenv: /opt/venv/nodepool

**********
DECISION===>: PASS
**********
=========================:::1095:::END!!!=========================
=========================:::1096:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/windmill/inventory/testing/group_vars/zuul-merger.yaml
**********
# Copyright 2016 Red Hat, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
---
# windmill.zuul
zuul_file_zuul_merger_service_config_src: zuul/etc/systemd/system/zuul-merger.service.d/override.conf.j2

zuul_file_zuul_executor_service_config_manage: false
zuul_file_zuul_executor_service_manage: false

zuul_file_zuul_fingergw_service_config_manage: false
zuul_file_zuul_fingergw_service_manage: false

zuul_file_zuul_scheduler_service_config_manage: false
zuul_file_zuul_scheduler_service_manage: false

zuul_file_zuul_web_service_config_manage: false
zuul_file_zuul_web_service_manage: false

zuul_service_zuul_executor_enabled: no
zuul_service_zuul_executor_manage: false
zuul_service_zuul_executor_state: stopped

zuul_service_zuul_fingergw_enabled: no
zuul_service_zuul_fingergw_manage: false
zuul_service_zuul_fingergw_state: stopped

zuul_service_zuul_scheduler_enabled: no
zuul_service_zuul_scheduler_manage: false
zuul_service_zuul_scheduler_state: stopped

zuul_service_zuul_web_enabled: no
zuul_service_zuul_web_manage: false
zuul_service_zuul_web_state: stopped

# openstack.logrotate
logrotate_configs:
  - name: zuul-merger
    log: /var/log/zuul/merger-debug.log /var/log/zuul/merger.log
    options:
      - compress
      - missingok
      - rotate 7
      - daily
      - notifempty

**********
DECISION===>: PASS
**********
=========================:::1096:::END!!!=========================
=========================:::1097:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/windmill/inventory/testing/group_vars/nodepool-builder.yaml
**********
# Copyright 2016 Red Hat, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
---
# windmill.diskimage-builder
diskimage_builder_pip_virtualenv_python: python3
diskimage_builder_pip_virtualenv: /opt/venv/nodepool

# windmill.nodepool
nodepool_file_nodepool_builder_service_config_src: nodepool-builder/etc/systemd/system/nodepool-builder.service.d/override.conf.j2

nodepool_file_nodepool_launcher_service_config_manage: false
nodepool_file_nodepool_launcher_service_manage: false
nodepool_service_nodepool_launcher_manage: false

# openstack.logrotate
logrotate_configs:
  - name: nodepool-builder
    log: /var/log/nodepool/builder-debug.log /var/log/nodepool/nodepool-builder.log
    options:
      - compress
      - missingok
      - rotate 7
      - daily
      - notifempty

# openstack.sudoers
sudoers_task_manager:
  - config
sudoers_file_includes_dest: /etc/sudoers.d/nodepool
sudoers_file_includes_src: nodepool-builder/etc/sudoers.d/nodepool.j2

# windmill.ssh
ssh_user_name: "{{ nodepool_user_name|default('nodepool') }}"
ssh_user_home: "{{ nodepool_user_home|default('/var/lib/nodepool') }}"

ssh_key_public_content: |
  ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAACAQDPFYsTS2aTFpgJHACEZjtkr4kt7rf9fHjavl5OhCq7rwAzfiQfq25YSaCZRRPywjUg6stm5JmBCLvQAa1LuhpsrUTE61TvGBIxeRwE6B0OecPW8SoXNbhgvfdrgVb4OIvH51tndPmXYPMpVN03iWyoSfN58YE77Z0VipDuG++dAjSJg+bmBlmmVE3L1419E2Jm56OnRDADWEDlvYciEIXaFWN9pIYXTL+Q1QdYKkWGPfuvMu6k5xSgQtNeXO4IWLSKyqkqj/PRQeY7XVBNstRhGzy+10fV0J4LrYcTAs/80rI2qgvrRoiDuXuhPMXyyD0OxoVrlIO4/f7BD2xk1lbq6JrUQthsNeLn9O5KVX9H7zhnFM1EUSRZz+knasDRfv8jrfrhUtM1QpF/3LITKftrjbr9whpOrxGSKSRRtnYlS5OrY1o9qqEfYPbelQdnz4oa+aTl0R7ApLfRpg64tbF1uNyVXwJvm7EYY2Ju1t0dY6vxFWlC8lLujE4Zq/VWajf5FhzsIh6SD0NVdz8UK1W/sZYKczejo0UHgQujfuJeJ3wRWAB/idzP2B69/uFJn7gp6199637j3v/3l38xRPi/kbh8zK0LjwvR8PKOlTx8pMJzNFaLzRqOTVJzhl4YmlYXtiNpxf/7/dPRUu8kJlb+yvVPo811v537EnmtsXin9w== zuul@example.org

**********
DECISION===>: PASS
**********
=========================:::1097:::END!!!=========================
=========================:::1098:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/windmill/inventory/testing/group_vars/zuul.yaml
**********
# Copyright 2016 Red Hat, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
---
# windmill.zuul
zuul_file_main_yaml_src: "{{ windmill_config_git_dest }}/zuul/main.yaml"
zuul_file_zuul_conf_src: "{{ windmill_config_git_dest }}/zuul/zuul.conf.j2"

zuul_pip_virtualenv_python: python3
zuul_pip_virtualenv: /opt/venv/zuul

zuul_file_gearman_ssl_ca_content: |
  -----BEGIN CERTIFICATE-----
  MIIDmjCCAoKgAwIBAgIJAN8sAUG3GR9wMA0GCSqGSIb3DQEBCwUAMGIxCzAJBgNV
  BAYTAlVTMQ4wDAYDVQQIDAVUZXhhczEPMA0GA1UEBwwGQXVzdGluMR0wGwYDVQQK
  DBRPcGVuU3RhY2sgRm91bmRhdGlvbjETMBEGA1UEAwwKZ2Vhcm1hbi1jYTAeFw0x
  ODAzMjgwMjMzMTZaFw0yODAzMjUwMjMzMTZaMGIxCzAJBgNVBAYTAlVTMQ4wDAYD
  VQQIDAVUZXhhczEPMA0GA1UEBwwGQXVzdGluMR0wGwYDVQQKDBRPcGVuU3RhY2sg
  Rm91bmRhdGlvbjETMBEGA1UEAwwKZ2Vhcm1hbi1jYTCCASIwDQYJKoZIhvcNAQEB
  BQADggEPADCCAQoCggEBAMLqIrwY9mDh9kKc/mXDvEUifXgdHtz4GwP3hoYz6N82
  8Zl7NzUqvYFSj9tlpdJxFHWFBjB9TiGv+2UPjDfGLk7xTKPkErnEcmH6zf4F+0YH
  hEI00c7DN5sSPq0qcMk1pVCzZ96Fhdi+fIQkVq3Ovx0GGmknHy0K2If2vX9FgZNZ
  323BZw7vZUSYRIvN8ClAXg+ONvHvodVGBWts2SO5CYvnsA+kQRa6RJswoe9CkTxb
  qF8yq5CPLEdQeoTiF4RiLIsfB50ZFTcOrARw93blcMkSw4kh3EJhrRMezoJZZKPE
  JfOOaMmHiKbrF5TWjREJODgdHIz87nePDuZAWrvlyDECAwEAAaNTMFEwHQYDVR0O
  BBYEFEqtl/rooCIF+gMIfS2IKzYJC4LRMB8GA1UdIwQYMBaAFEqtl/rooCIF+gMI
  fS2IKzYJC4LRMA8GA1UdEwEB/wQFMAMBAf8wDQYJKoZIhvcNAQELBQADggEBAEck
  6wCHSOwtzWBBwM18uVlHAUywe95SNvgPJ6tt3jaM9Th6aGEaeF7Eh1wPBoQBUBUC
  YsXhXenROoEf6r0CHaJkamaJSZqEIJ5/2sdZ8RgHXG8Savp5y1r9Rw1duNREuqaD
  QsHNZ/hM1VEr9PhyVQ3HWe18EWRY8vMc22MlBAMt9QT+Okj3Ao679uPGnZD3HQ8p
  ZiJRxV6UJoFlWdmEXyljUKUryotX7bN1bfSvBaiV/RncUARMfxulIbDxHgp6/D8G
  dcdLTVD6WkbRS77Nt4rB1Gu+b/qME8zxwhjvM3J7r2p+EjVqwW7dgQQRP1I0jyGU
  9rZdDhon2y067Zr8Kuc=
  -----END CERTIFICATE-----

zuul_file_gearman_ssl_cert_content: |
  -----BEGIN CERTIFICATE-----
  MIIDQTCCAikCCQDWIKrPJpjpMjANBgkqhkiG9w0BAQsFADBiMQswCQYDVQQGEwJV
  UzEOMAwGA1UECAwFVGV4YXMxDzANBgNVBAcMBkF1c3RpbjEdMBsGA1UECgwUT3Bl
  blN0YWNrIEZvdW5kYXRpb24xEzARBgNVBAMMCmdlYXJtYW4tY2EwHhcNMTgwMzI4
  MDIzNTAzWhcNMjgwMzI1MDIzNTAzWjBjMQswCQYDVQQGEwJVUzEOMAwGA1UECAwF
  VGV4YXMxDzANBgNVBAcMBkF1c3RpbjEdMBsGA1UECgwUT3BlblN0YWNrIEZvdW5k
  YXRpb24xFDASBgNVBAMMC3p1dWwtY2xpZW50MIIBIjANBgkqhkiG9w0BAQEFAAOC
  AQ8AMIIBCgKCAQEA0lHkUiVv+xKNgpXeWh/mEjxVBLvY9X0Jv+cIRnT2jgTIXzDT
  An6g0pgfVOtXJ+Zg4wpcQgreJXI1dqHzYfGp5SfOCJz8UAzarp8ISR0Dmv5iD9yo
  0++XJcfYSMI8if95jORCg07VrwcaA3G+EqVCrEV43rzbt+lwNuqaXUsAZsawV1GX
  pNKBGUkMGaKbgOn+tBMTsplsYEgZDL9CjdWyZrmjdXe+/G86KbmBvxTVHOpsjVLZ
  v6JHuPd8i21d4cBdpvZq1OjHMP+wyVOCited0U0ACq2tDy/JG7IZxTe93nIXnzbB
  bTQ8bJmDt5xS9wR4sobih+HFuSwL05rfrRVNQwIDAQABMA0GCSqGSIb3DQEBCwUA
  A4IBAQBfB1Cf1rbeym5VGubIlYr3u+mrn1stHDhBANxzazNkmmHXER4z4fJPgkq0
  8Nkq0YUptfQeJ1yoEpVHqLOGCyvgff8MWxuBEQXJXahvlbS2fV73gqWXFq/RFGoc
  PDSH2WLPqcYHDx7+083q6YrjuJTGNNcJYCYf3R3+V90JGrfoKhi3OL31gkGzuZUl
  QPkgA7AlYi8tLPThCPF/0RFTlp+6mRCeT30GkrjZ9521tV3H0vfFIhKO0vGuNhLh
  zLSZhFOb11cvw3HHpeWuSiqbNjLHbNXi3vqQIuOb+eYncapTkFQafaBj3Ho4dhxP
  EcoJZhxBAsiPa3u08rhLyXnCNKrf
  -----END CERTIFICATE-----

zuul_file_gearman_ssl_key_content: |
  -----BEGIN PRIVATE KEY-----
  MIIEvQIBADANBgkqhkiG9w0BAQEFAASCBKcwggSjAgEAAoIBAQDSUeRSJW/7Eo2C
  ld5aH+YSPFUEu9j1fQm/5whGdPaOBMhfMNMCfqDSmB9U61cn5mDjClxCCt4lcjV2
  ofNh8anlJ84InPxQDNqunwhJHQOa/mIP3KjT75clx9hIwjyJ/3mM5EKDTtWvBxoD
  cb4SpUKsRXjevNu36XA26ppdSwBmxrBXUZek0oEZSQwZopuA6f60ExOymWxgSBkM
  v0KN1bJmuaN1d778bzopuYG/FNUc6myNUtm/oke493yLbV3hwF2m9mrU6Mcw/7DJ
  U4KK153RTQAKra0PL8kbshnFN73echefNsFtNDxsmYO3nFL3BHiyhuKH4cW5LAvT
  mt+tFU1DAgMBAAECggEAJ+24JQhKfCYHi5UcQ4vux+OAWIe5JtH4OeCIp6eo70ll
  KP1B8iVMLu8Gc77CKycHmdLrtPYPOpi2IbGZXSzeDk1CRkxXcnMeSSyUDB1gA9rr
  jwtbWfEQhvGr1BRcHe7Mir0DC5653qLAg4rihPOu9rmxusesBvxge2yKpc+JYfla
  Kue6tii1D9w8QVG69pBltVd5QmY+r8rTl3CxaagIkzi5OX8KfTb6X1ALfs/XWsTx
  v2OypDJpK5oliCszLpQd437wXIQ9JDWRlglBOK0PXdYQ8SRj00veZYgoQBUlmmeX
  HxE4voAl34oq5AUhJQxaUFmQb+OFPAvVbz2vDIJdYQKBgQD9X/YRfOdCRVI9ro6O
  Qs+fsISJqO4nDK2IHKUAfIc/HIQ6cqxquUf53vLm/+N5rPy03E3lvNzvNJH82VPX
  nNZZNKPLPcA+irMP1WfmvQLSFLAuRDL8iXsiSYp5WZwji5wahGjy49Etw+K+Swdp
  +VmSvu4P71ynaxYV0P09vw13uwKBgQDUf7vdxMHSjFWysRONVuOX+N/XUmSXoLCD
  JZfKw4rldTnN3gp/A0xLpM4zZjJsdg3N/QlbDhDUYZjKa1ifSyRxLOJTTs15SoSj
  rUm8cCp4onPGo8L4yi/nr+fjaL1aYl3L6nHMEsWGFeL1XHM5hQX6eK5+NNpxO6tZ
  fbdjFp4UGQKBgBTlfijREU2Q5Ah8RfuLnQ4Bg9zKluGXlRQ9sIoKuyjEVE9xt7CR
  mVMNRSEyB3O4hZrw9Ge3HM2Jm2SsE9Mbdz4iLkQL0rgVvlDW+9u2yO3EkQcvzriv
  Kf2Y7Re3AT6ZPAWf1/v4N/87QY8KJxFhZDbLEl00E4MnPMoN02TtRdITAoGAaJxF
  WQSOwl8RpTllPbRjsKH1WCQYn0ic/MMZ+djP3Owbu8wucJ6oBakpVcZe1mQ7oYeK
  /odrI5K0TBoSc8DjPM/yzz5BCw/zQjyBy0GQtviKdGSUDDRE5xMC3kHmzcMVF9jf
  kq4/DSZjJ5UOqGdjLQ4SINFWJF5SmWi5Sg+NXKkCgYEAzD22Q8ttCKORyg7/Zi+9
  84bn2tirCKSWPYkx2Zs/XB8qgZCZJcA0XxvnHUepP0F7T9nrvgRLe2wjOKDi0OJh
  QqE7FEp7UZbDEVLb1xBaijmjkuq300f4olW+UNKzC23kSiX/VL3ngpxt0saNTWN+
  GGE1XO4oxVDrkeDSIUmxN60=
  -----END PRIVATE KEY-----

**********
DECISION===>: hardcoded secret
**********
=========================:::1098:::END!!!=========================
=========================:::1099:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/windmill/inventory/testing/group_vars/all.yaml
**********
# Copyright 2016 Red Hat, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
---
# windmill.virtualenv
virtualenv_install_method: pip

# windmill-config
# TODO(pabelanger): Create windmill-config project on git.o.o.
windmill_config_git_dest: "{{ lookup('pipe', 'pwd') | dirname }}/config"

**********
DECISION===>: PASS
**********
=========================:::1099:::END!!!=========================
=========================:::1100:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/windmill/inventory/testing/group_vars/nodepool-launcher.yaml
**********
# Copyright 2016 Red Hat, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
---
# windmill.nodepool
nodepool_file_nodepool_launcher_service_config_src: nodepool-launcher/etc/systemd/system/nodepool-launcher.service.d/override.conf.j2

nodepool_file_nodepool_builder_service_config_manage: false
nodepool_file_nodepool_builder_service_manage: false
nodepool_service_nodepool_builder_manage: false

# openstack.logrotate
logrotate_configs:
  - name: nodepool-launcher
    log: /var/log/nodepool/launcher-debug.log /var/log/nodepool/nodepool-launcher.log
    options:
      - compress
      - missingok
      - rotate 7
      - daily
      - notifempty

**********
DECISION===>: PASS
**********
=========================:::1100:::END!!!=========================
=========================:::1101:::START!=========================
/Users/akond/SECU_REPOS/ostk-ansi/windmill/inventory/testing/group_vars/zuul-web.yaml
**********
# Copyright 2016 Red Hat, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
# WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
# License for the specific language governing permissions and limitations
# under the License.
---
# windmill.zuul
zuul_file_zuul_web_service_config_src: zuul/etc/systemd/system/zuul-web.service.d/override.conf.j2

zuul_file_zuul_executor_service_config_manage: false
zuul_file_zuul_executor_service_manage: false

zuul_file_zuul_fingergw_service_config_manage: false
zuul_file_zuul_fingergw_service_manage: false

zuul_file_zuul_merger_service_config_manage: false
zuul_file_zuul_merger_service_manage: false

zuul_file_zuul_scheduler_service_config_manage: false
zuul_file_zuul_scheduler_service_manage: false

zuul_service_zuul_executor_enabled: no
zuul_service_zuul_executor_manage: false
zuul_service_zuul_executor_state: stopped

zuul_service_zuul_fingergw_enabled: no
zuul_service_zuul_fingergw_manage: false
zuul_service_zuul_fingergw_state: stopped

zuul_service_zuul_merger_enabled: no
zuul_service_zuul_merger_manage: false
zuul_service_zuul_merger_state: stopped

zuul_service_zuul_scheduler_enabled: no
zuul_service_zuul_scheduler_manage: false
zuul_service_zuul_scheduler_state: stopped

# openstack.logrotate
logrotate_configs:
  - name: zuul-web
    log: /var/log/zuul/web-debug.log /var/log/zuul/web.log
    options:
      - compress
      - missingok
      - rotate 7
      - daily
      - notifempty

**********
DECISION===>: PASS
**********
=========================:::1101:::END!!!=========================
----------------------------------------------------------------------------------------------------
